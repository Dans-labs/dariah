{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Importing InKind from FileMaker\n",
    "\n",
    "We use an XML export of the various tables in the FileMaker Inkind database.\n",
    "\n",
    "The XML will be read, field definitions will be extracted from it, the data will be read.\n",
    "We do the following:\n",
    "* adapt the table and field organization;\n",
    "* adjust the field types and the values, especially for datetime and currency;\n",
    "* generate value tables and cross tables;\n",
    "* add extra information for countries, so that they can be visualized on a map\n",
    "* link values to existing tables;\n",
    "* write SQL create statements and insert statements\n",
    "* import a moderately denormalized version of the data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections,json, xlsxwriter\n",
    "from os.path import splitext, basename\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "from lxml import etree\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR = os.path.expanduser('~').replace('\\\\', '/')\n",
    "BASE_DIR = '{}/Documents/DANS/projects/has/dacs'.format(HOME_DIR)\n",
    "FM_DIR = '{}/fm'.format(BASE_DIR)\n",
    "FMNS = '{http://www.filemaker.com/fmpxmlresult}'\n",
    "CONFIG_DIR = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Config\n",
    "All configuration in a big yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('{}/config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data description\n",
    "\n",
    "## Main source tables and fields to skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "CONFIG = yaml.load('''\n",
    "mainTables:\n",
    "- contrib\n",
    "- country\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainTables = ('contrib', 'country')\n",
    "\n",
    "SKIP_FIELDS = dict(\n",
    "    contrib=set('''\n",
    "dateandtime_ciozero\n",
    "ikid\n",
    "ikid_base\n",
    "find_country_id\n",
    "find_type\n",
    "gnewpassword\n",
    "gnewpassword2\n",
    "goldpassword\n",
    "help_description\n",
    "help_text\n",
    "message\n",
    "message_allert\n",
    "teller\n",
    "total_costs_total\n",
    "whois\n",
    "'''.strip().split()),\n",
    "    country=set('''\n",
    "'''.strip().split()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fields to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MERGE_FIELDS = dict(\n",
    "    contrib=dict(\n",
    "        academic_entity_url=['academic_entity_url_2'],\n",
    "        contribution_url=['contribution_url_2'],\n",
    "        contact_person_mail=['contact_person_mail_2'],\n",
    "        type_of_inkind=['other_type_of_inkind'],\n",
    "        vcc11_name=[\n",
    "            'vcc12_name',\n",
    "            'vcc21_name',\n",
    "            'vcc22_name',\n",
    "            'vcc31_name',\n",
    "            'vcc32_name',\n",
    "            'vcc41_name',\n",
    "            'vcc42_name',\n",
    "        ],\n",
    "        vcc_head_decision_vcc11=[\n",
    "            'vcc_head_decision_vcc12',\n",
    "            'vcc_head_decision_vcc21',\n",
    "            'vcc_head_decision_vcc22',\n",
    "            'vcc_head_decision_vcc31',\n",
    "            'vcc_head_decision_vcc32',\n",
    "            'vcc_head_decision_vcc41',\n",
    "            'vcc_head_decision_vcc42',\n",
    "        ],\n",
    "    ),\n",
    "    country=dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fields to rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAP_FIELDS = dict(\n",
    "    contrib=dict(\n",
    "        approved='approved',\n",
    "        academic_entity_url='urlAcademic',\n",
    "        contribution_url='urlContribution',\n",
    "        contact_person_mail='contactPersonEmail',\n",
    "        contact_person_name='contactPersonName',\n",
    "        costs_description='costDescription',\n",
    "        costs_total='costTotal',\n",
    "        country='country',\n",
    "        creation_date_time='dateCreated',\n",
    "        creator='creator',\n",
    "        dateandtime_approval='dateApproved',\n",
    "        dateandtime_cioapproval='dateApprovedCIO',\n",
    "        description_of_contribution='description',\n",
    "        disciplines_associated='discipline',\n",
    "        last_modifier='modifiedBy',\n",
    "        modification_date_time='dateModified',\n",
    "        other_keywords='keyword',\n",
    "        submit='submitted',\n",
    "        tadirah_research_activities='tadirahActivity',\n",
    "        tadirah_research_objects='tadirahObject',\n",
    "        tadirah_research_techniques='tadirahTechnique',\n",
    "        title='title',\n",
    "        total_costs_total='costTotalTotal',\n",
    "        type_of_inkind='typeContribution',\n",
    "        vcc='vcc',\n",
    "        vcc11_name='reviewerName',\n",
    "        vcc_head_decision='vccDecision',\n",
    "        vcc_head_decision_vcc11='reviewerDecision',\n",
    "        vcchead_approval='vccApproval',\n",
    "        vcchead_disapproval='vccDisApproval',\n",
    "        year='year',\n",
    "    ),\n",
    "    country=dict(\n",
    "        countrycode='iso',\n",
    "        countryname='name',\n",
    "        member_dariah='isMember',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fields to split into multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generic = re.compile('[ \\t]*[\\n+][ \\t\\n]*')          # split on newlines (with surrounding white space)\n",
    "genericComma = re.compile('[ \\t]*[\\n+,;][ \\t\\n]*')    # split on newlines or commas (with surrounding white space)\n",
    "\n",
    "SPLIT_FIELDS=dict(\n",
    "    contrib=dict(\n",
    "        discipline=generic,\n",
    "        keyword=genericComma,\n",
    "        typeContribution=generic,\n",
    "        tadirahActivity=generic,\n",
    "        tadirahObject=generic,\n",
    "        tadirahTechnique=generic,\n",
    "        vcc=generic,\n",
    "    ),\n",
    "    country=dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fields to hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STRIP_NUM = re.compile('^[0-9]\\s*\\.?\\s+')\n",
    "\n",
    "def stripNum(v): return STRIP_NUM.sub('', v)\n",
    "    \n",
    "HACK_FIELDS=dict(\n",
    "    contrib=dict(\n",
    "        tadirahActivity=stripNum,\n",
    "    ),\n",
    "    country=dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fields to decompose into several fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DECOMPOSE_FIELDS=dict(\n",
    "    contrib=dict(\n",
    "        typeContribution='typeContributionOther',\n",
    "    ),\n",
    "    country=dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Custom field types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FIELD_TYPE = dict(\n",
    "    contrib=dict(\n",
    "        costTotal='valuta',\n",
    "        dateCreated='datetime',\n",
    "        dateModified='datetime',\n",
    "        dateApproved='datetime',\n",
    "        dateApprovedCIO='datetime',\n",
    "        contactPersonEmail='email',\n",
    "        submitted='bool',\n",
    "        approved='bool',\n",
    "        reviewerDecision='bool',\n",
    "        vccApproval='bool',\n",
    "        vccDecision='bool',\n",
    "        vccDisApproval='bool',\n",
    "    ),\n",
    "    country=dict(\n",
    "        isMember='bool',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_VALUES=dict(\n",
    "    contrib=dict(\n",
    "        dateCreated=datetime(2000,1,1,0,0,0),\n",
    "        creator=\"admin\",\n",
    "        type_of_inkind=\"General\",\n",
    "    ),\n",
    "    country=dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fields to move to other tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MOVE_FIELDS=dict(\n",
    "    contrib=dict(\n",
    "        assessment=set('''\n",
    "approved\n",
    "dateApproved\n",
    "dateApprovedCIO\n",
    "submitted\n",
    "reviewerName\n",
    "reviewerDecision\n",
    "vccDecision\n",
    "vccApproval\n",
    "vccDisApproval\n",
    "        '''.strip().split()),\n",
    "    ),\n",
    "    country=dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fields to value lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAKE_VALUE_LISTS = dict(\n",
    "    contrib=set('''\n",
    "keyword\n",
    "year\n",
    "'''.strip().split()),\n",
    ")\n",
    "VALUE_LISTS = dict(\n",
    "    contrib=set('''\n",
    "discipline\n",
    "keyword\n",
    "tadirahActivity\n",
    "tadirahObject\n",
    "tadirahTechnique\n",
    "typeContribution\n",
    "typeContributionOther:typeContribution\n",
    "vcc\n",
    "year\n",
    "'''.strip().split()),\n",
    ")\n",
    "\n",
    "MOVE_MISSING = dict(\n",
    "    contrib='description',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Field values\n",
    "## Patterns for value types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Source field types, including types assigned by type overriding (see FIELD_TYPE_OVERRIDE above).\n",
    "# These will be translated into appropriate SQL field types\n",
    "\n",
    "TYPES = {'bool', 'number', 'decimal', 'text', 'valuta', 'email', 'date', 'datetime'}\n",
    "\n",
    "# dates are already in ISO (date2_pattern).\n",
    "# If we encounter other dates, we could use date_pattern instead)\n",
    "# datetimes are not in iso, they will be transformed to iso.\n",
    "\n",
    "DECIMAL_PATTERN = re.compile(\n",
    "    r'^-?[0-9]+\\.?[0-9]*'\n",
    ")\n",
    "DATE_PATTERN = re.compile(\n",
    "    r'^\\s*([0-9]{2})/([0-9]{2})/([0-9]{4})$'\n",
    ")\n",
    "DATE2_PATTERN = re.compile(\n",
    "    r'^\\s*([0-9]{4})-([0-9]{2})-([0-9]{2})$'\n",
    ")\n",
    "DATETIME_PATTERN = re.compile(\n",
    "    r'^\\s*([0-9]{2})/([0-9]{2})/([0-9]{4})\\s+([0-9]{2}):([0-9]{2})(?::([0-9]{2}))?$'\n",
    ")\n",
    "\n",
    "# meaningless values will be translated into None\n",
    "NULL_VALUES = {\n",
    "    'http://',\n",
    "    'https://',\n",
    "    '@',\n",
    "}\n",
    "\n",
    "BOOL_VALUES = {\n",
    "    True: {'Yes', 'YES', 'yes', 1, '1', True},\n",
    "    False: {'No', 'NO', 'no', 0, '0', 'NULL', False},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Date and Time values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def date_repl(match):\n",
    "    [d,m,y] = list(match.groups())\n",
    "    return '{}-{}-{}'.format(y,m,d)\n",
    "    \n",
    "def date2_repl(match):\n",
    "    [y,m,d] = list(match.groups())\n",
    "    return '{}-{}-{}'.format(y,m,d)\n",
    "    \n",
    "def datetime_repl(match):\n",
    "    [d,m,y,hr,mn,sc] = list(match.groups())\n",
    "    return '{}-{}-{}T{}:{}:{}'.format(y,m,d,hr,mn,sc or '00')\n",
    "\n",
    "def dt(v_raw, i, t, fname):\n",
    "    if not DATE2_PATTERN.match(v_raw):\n",
    "        warning(\n",
    "            'table `{}` field `{}` record {}: not a valid date: \"{}\"'.format(\n",
    "                t, fname, i, v_raw\n",
    "        ))\n",
    "        return v_raw\n",
    "    return datetime(*map(int, re.split('[:T-]', DATE2_PATTERN.sub(date2_repl, v_raw))))\n",
    "\n",
    "def dtm(v_raw, i, t, fname):\n",
    "    if not DATETIME_PATTERN.match(v_raw):\n",
    "        warning(\n",
    "            'table `{}` field `{}` record {}: not a valid date time: \"{}\"'.format(\n",
    "                t, fname, i, v_raw\n",
    "        ))\n",
    "        return v_raw\n",
    "    return datetime(*map(int, re.split('[:T-]', DATETIME_PATTERN.sub(datetime_repl, v_raw))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Boolean, numeric and string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bools(v_raw, i, t, fname):\n",
    "    if v_raw in BOOL_VALUES[True]: return True\n",
    "    if v_raw in BOOL_VALUES[False]: return False\n",
    "    warning(\n",
    "        'table `{}` field `{}` record {}: not a boolean value: \"{}\"'.format(\n",
    "            t, fname, i, v_raw\n",
    "    ))\n",
    "    return v_raw\n",
    "\n",
    "def num(v_raw, i, t, fname):\n",
    "    if type(v_raw) is int: return v_raw\n",
    "    if v_raw.isdigit(): return int(v_raw)\n",
    "    warning(\n",
    "        'table `{}` field `{}` record {}: not an integer: \"{}\"'.format(\n",
    "            t, fname, i, v_raw\n",
    "    ))\n",
    "    return v_raw\n",
    "\n",
    "def decimal(v_raw, i, t, fname):\n",
    "    if type(v_raw) is float: return v_raw\n",
    "    if v_raw.isdigit(): return float(v_raw)\n",
    "    if DECIMAL_PATTERN.match(v_raw): return float(v_raw)\n",
    "    warning(\n",
    "        'table `{}` field `{}` record {}: not an integer: \"{}\"'.format(\n",
    "            t, fname, i, v_raw\n",
    "    ))\n",
    "    return v_raw\n",
    "\n",
    "def email(v_raw, i, t, fname):\n",
    "    return v_raw.replace('mailto:', '', 1) if v_raw.startswith('mailto:') else v_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Money values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def money(v_raw, i, t, fname):\n",
    "    note = ',' in v_raw or '.' in v_raw\n",
    "    v = v_raw.strip().lower().replace(' ','').replace('€', '').replace('euro', '').replace('\\u00a0', '')\n",
    "    for p in range(2,4): # interpret . or , as decimal point if less than 3 digits follow it\n",
    "        if len(v) >= p and v[-p] in '.,': \n",
    "            v_i = v[::-1]\n",
    "            if v_i[p-1] == ',': v_i = v_i.replace(',', 'D', 1)\n",
    "            elif v_i[p-1] == '.': v_i = v_i.replace('.', 'D', 1)\n",
    "            v = v_i[::-1]\n",
    "    v = v.replace('.','').replace(',','')\n",
    "    v = v.replace('D', '.')\n",
    "    if not v.replace('.','').isdigit():\n",
    "        if len(set(v) & set('0123456789')):\n",
    "            warning(\n",
    "                'table `{}` field `{}` record {}: not a decimal number: \"{}\" <= \"{}\"'.format(\n",
    "                    t, fname, i, v, v_raw,\n",
    "            ))\n",
    "            money_warnings.setdefault('{}:{}'.format(t, fname), {}).setdefault(v, set()).add(v_raw)\n",
    "            v = None\n",
    "        else:\n",
    "            v = None\n",
    "            money_notes.setdefault('{}:{}'.format(t, fname), {}).setdefault('NULL', set()).add(v_raw)\n",
    "    elif note:\n",
    "        money_notes.setdefault('{}:{}'.format(t, fname), {}).setdefault(v, set()).add(v_raw)\n",
    "    return None if v == None else float(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Clean up field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sanitize(t, i, fname, value):\n",
    "    if fname == '_id': return value\n",
    "    (ftype, fmult) = allFields[t][fname]\n",
    "    newValue = []\n",
    "    for v_raw in value:\n",
    "        if v_raw == None or v_raw in NULL_VALUES: continue\n",
    "        elif ftype == 'text': v = v_raw\n",
    "        elif ftype == 'bool': v = bools(v_raw, i, t, fname)\n",
    "        elif ftype == 'number': v = num(v_raw, i, t, fname)\n",
    "        elif ftype == 'decimal': v = decimal(v_raw, i, t, fname)\n",
    "        elif ftype == 'email': v = email(v_raw, i, t, fname)\n",
    "        elif ftype == 'valuta': v = money(v_raw, i, t, fname)\n",
    "        elif ftype == 'date': v = dt(v_raw, i, t, fname)\n",
    "        elif ftype == 'datetime': v = dtm(v_raw, i, t, fname)\n",
    "        else: v = v_raw\n",
    "        if v != None and (fmult <= 1 or v != ''): newValue.append(v)\n",
    "    if len(newValue) == 0:\n",
    "        defValue = DEFAULT_VALUES.get(t, {}).get(fname, None)\n",
    "        if defValue != None:\n",
    "            newValue = [defValue]\n",
    "    return newValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Show information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def info(x): sys.stdout.write('{}\\n'.format(x))\n",
    "def warning(x): sys.stderr.write('{}\\n'.format(x))\n",
    "\n",
    "def showFields():\n",
    "    for (mt, defs) in sorted(allFields.items()):\n",
    "        info(mt)\n",
    "        for (fname, fdef) in sorted(defs.items()):\n",
    "            info('{:>25}: {:<10} ({})'.format(fname, *fdef))\n",
    "\n",
    "def showdata(rows):\n",
    "    for row in rows:\n",
    "        for f in sorted(row.items()):\n",
    "            info('{:>20} = {}'.format(*f))\n",
    "        info('o-o-o-o-o-o-o-o-o-o-o-o')\n",
    "\n",
    "def showData():\n",
    "    for (mt, rows) in sorted(allData.items()):\n",
    "        info('o-o-o-o-o-o-o TABLE {} with {} rows o-o-o-o-o-o-o-o '.format(mt, len(rows)))\n",
    "        showdata(rows[0:2])\n",
    "\n",
    "def showMoney():\n",
    "    for tf in sorted(money_notes):\n",
    "        for v in sorted(money_notes[tf]):\n",
    "            info('{} \"{}\" <= {}'.format(\n",
    "                tf, v,\n",
    "                ' | '.join(money_notes[tf][v]),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read FM fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readFmFields():\n",
    "    for mt in mainTables:\n",
    "        infile = '{}/{}.xml'.format(FM_DIR, mt)\n",
    "        root = etree.parse(infile, parser).getroot()\n",
    "        fieldroots = [x for x in root.iter(FMNS+'METADATA')]\n",
    "        fieldroot = fieldroots[0]\n",
    "        fields = []\n",
    "        fieldDefs = {}\n",
    "        for x in fieldroot.iter(FMNS+'FIELD'):\n",
    "            fname = x.get('NAME').lower().replace(' ','_').replace(':', '_')\n",
    "            ftype = x.get('TYPE').lower()\n",
    "            fmult = int(x.get('MAXREPEAT'))\n",
    "            fields.append(fname)\n",
    "            fieldDefs[fname] = [ftype, fmult]\n",
    "        rawFields[mt] = fields\n",
    "        allFields[mt] = fieldDefs\n",
    "\n",
    "        for f in SKIP_FIELDS[mt]:\n",
    "            del allFields[mt][f]\n",
    "\n",
    "        for (f, mfs) in MERGE_FIELDS[mt].items():\n",
    "            allFields[mt][f][1] += 1\n",
    "            for mf in mfs:\n",
    "                del allFields[mt][mf]\n",
    "        allFields[mt] = dict((MAP_FIELDS[mt][f], v) for (f,v) in allFields[mt].items())\n",
    "        for f in SPLIT_FIELDS[mt]:\n",
    "            allFields[mt][f][1] += 1\n",
    "        for (f, fo) in DECOMPOSE_FIELDS[mt].items():\n",
    "            allFields[mt][fo] = allFields[mt][f]\n",
    "            allFields[mt][f] = [allFields[mt][f][0], 1]\n",
    "        for (f, t) in FIELD_TYPE[mt].items():\n",
    "            allFields[mt][f][0] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read FM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readFmData():\n",
    "    for mt in mainTables:\n",
    "        infile = '{}/{}.xml'.format(FM_DIR, mt)\n",
    "        root = etree.parse(infile, parser).getroot()\n",
    "        dataroots = [x for x in root.iter(FMNS+'RESULTSET')]\n",
    "        dataroot = dataroots[0]\n",
    "        rows = []\n",
    "        rowsRaw = []\n",
    "        fields = rawFields[mt]\n",
    "        for (i, r) in enumerate(dataroot.iter(FMNS+'ROW')):\n",
    "            rowRaw = []\n",
    "            for c in r.iter(FMNS+'COL'):\n",
    "                data = [x.text.strip() for x in c.iter(FMNS+'DATA') if x.text != None]\n",
    "                rowRaw.append(data)\n",
    "            if len(rowRaw) != len(fields):\n",
    "                warning('row {}: fields encountered = {}, should be {}'.format(len(row), len(fields)))\n",
    "            rowsRaw.append(dict((f,v) for (f, v) in zip(fields, rowRaw)))\n",
    "            row = dict((f,v) for (f, v) in zip(fields, rowRaw) if f not in SKIP_FIELDS[mt])\n",
    "            for (f, mfs) in MERGE_FIELDS[mt].items():\n",
    "                for mf in mfs:\n",
    "                    row[f].extend(row[mf])\n",
    "                    del row[mf]\n",
    "            row = dict((MAP_FIELDS[mt][f], v) for (f,v) in row.items())\n",
    "            for (f, spl) in SPLIT_FIELDS[mt].items():\n",
    "                row[f] = reduce(lambda x,y: x+y, [spl.split(v) for v in row[f]], [])\n",
    "            for (f, hack) in HACK_FIELDS[mt].items():\n",
    "                row[f] = [hack(v) for v in row[f]]\n",
    "            for (f, fo) in DECOMPOSE_FIELDS[mt].items():\n",
    "                row[fo] = row[f][1:]\n",
    "                row[f] = [row[f][0]] if len(row[f]) else []\n",
    "            row['_id'] = ObjectId()\n",
    "            #info('\\n'.join('{}={}'.format(*x) for x in sorted(row.items())))\n",
    "            for (f, v) in row.items(): row[f] = sanitize(mt, i, f, v)\n",
    "            rows.append(row)\n",
    "        allData[mt] = rows\n",
    "        rawData[mt] = rowsRaw\n",
    "\n",
    "    if money_warnings:\n",
    "        for tf in sorted(money_warnings):\n",
    "            for v in sorted(money_warnings[tf]):\n",
    "                warning('{} \"{}\" <= {}'.format(\n",
    "                    tf, v,\n",
    "                    ' | '.join(money_warnings[tf][v]),\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Split tables into several tables by column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def moveFields():\n",
    "    for mt in mainTables:\n",
    "        for (omt, mfs) in MOVE_FIELDS[mt].items():\n",
    "            for mf in mfs:\n",
    "                allFields.setdefault(omt, dict())[mf] = allFields[mt][mf]\n",
    "                del allFields[mt][mf]\n",
    "            allFields.setdefault(omt, dict)['{}_id'.format(mt)] = ('id', 1)\n",
    "\n",
    "        for row in allData[mt]:\n",
    "            for (omt, mfs) in MOVE_FIELDS[mt].items():\n",
    "                orow = dict((mf, row[mf]) for mf in mfs)\n",
    "                orow['_id'] = ObjectId()\n",
    "                orow['{}_id'.format(mt)] = row['_id']\n",
    "                allData.setdefault(omt, []).append(orow)\n",
    "                for mf in mfs: del row[mf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Value Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readLists():\n",
    "    valueLists = dict()\n",
    "    for path in glob('{}/*.txt'.format(FM_DIR)):\n",
    "        tname = basename(splitext(path)[0])\n",
    "        data = []\n",
    "        with open(path) as fh:\n",
    "            for line in fh:\n",
    "                data.append(line.rstrip().split('\\t'))\n",
    "        valueLists[tname] = data\n",
    "\n",
    "    for (vList, data) in valueLists.items():\n",
    "        if vList == 'countryExtra':\n",
    "            mapping = dict((x[0], x[1:]) for x in data)\n",
    "        else:\n",
    "            mapping = dict((i+1, x[0]) for (i, x) in enumerate(data))\n",
    "        valueDict[vList] = mapping\n",
    "        allFields[vList] = dict(\n",
    "            _id=('id', 1),\n",
    "            value=('string', 1),\n",
    "        )\n",
    "    \n",
    "    for mt in allData:\n",
    "        fs = MAKE_VALUE_LISTS.get(mt, set())\n",
    "        for f in fs:\n",
    "            valSet = set()\n",
    "            for row in allData[mt]:\n",
    "                values = row.get(f, [])\n",
    "                if type(values) is not list:\n",
    "                    values = [values]\n",
    "                valSet |= set(values)\n",
    "            valueDict[f] = dict((i+1, x) for (i, x) in enumerate(sorted(valSet)))\n",
    "            allFields[f] = dict(\n",
    "                _id=('id', 1),\n",
    "                value=('string', 1),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Country table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def countryTable():\n",
    "    extraInfo = valueDict['countryExtra']\n",
    "    idMapping = dict()\n",
    "\n",
    "    for row in allData['country']:\n",
    "        for f in row:\n",
    "            if type(row[f]) is list: row[f] = row[f][0]\n",
    "        iso = row['iso']\n",
    "        row['_id'] = ObjectId()\n",
    "        idMapping[iso] = row['_id']\n",
    "        (name, lat, long) = extraInfo[iso]\n",
    "        row['latitude'] = lat\n",
    "        row['longitude'] = long\n",
    "\n",
    "    for row in allData['contrib']:\n",
    "        newValue = []\n",
    "        for iso in row['country']:\n",
    "            newValue.append(dict(_id=idMapping[iso], iso=iso, value=extraInfo[iso][0]))\n",
    "        row['country'] = newValue\n",
    "    \n",
    "    allFields['country']['_id'] = ('id', 1)\n",
    "    allFields['country']['iso'] = ('string', 1)\n",
    "    allFields['country']['latitude'] = ('float', 1)\n",
    "    allFields['country']['longitude'] = ('float', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# User table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def userTable():\n",
    "    idMapping = dict()\n",
    "    existingUsers = []\n",
    "    testUsers = [\n",
    "        dict(eppn='suzan', email='suzan1@test.eu', mayLogin=True, authority='local', \n",
    "             firstName='Suzan', lastName='Karelse'),\n",
    "        dict(eppn='marie', email='suzan2@test.eu', mayLogin=True, authority='local',\n",
    "            firstName='Marie', lastName='Pieterse'),\n",
    "        dict(eppn='gertjan', email='gertjan@test.eu', mayLogin=False, authority='local',\n",
    "            firstName='Gert Jan', lastName='Klein-Holgerink'),\n",
    "        dict(eppn='lisa', email='lisa@test.eu', mayLogin=True, authority='local',\n",
    "            firstName='Lisa', lastName='de Leeuw'),\n",
    "        dict(eppn='dirk', email='dirk@test.eu', mayLogin=True, authority='local',\n",
    "            firstName='Dirk', lastName='Roorda'),\n",
    "    ]    \n",
    "\n",
    "    users = collections.defaultdict(set)\n",
    "    eppnSet = set()\n",
    "    for c in allData['contrib']:\n",
    "        crs = c.get('creator', []) + c.get('modifiedBy', [])\n",
    "        for cr in crs:\n",
    "            eppnSet.add(cr)\n",
    "    idMapping = dict((eppn, ObjectId()) for eppn in sorted(eppnSet))\n",
    "    for c in allData['contrib']:\n",
    "        c['creator'] = [dict(_id=idMapping[cr]) for cr in c['creator']]\n",
    "\n",
    "        if 'modifiedBy' not in c:\n",
    "            c['modifiedBy'] = []\n",
    "        else:\n",
    "            c['modifiedBy'] = [dict(_id=idMapping[cr]) for cr in c['modifiedBy']]\n",
    "\n",
    "    users = dict((i, eppn) for (eppn, i) in idMapping.items())\n",
    "    for (i, eppn) in sorted(users.items()):\n",
    "        existingUsers.append(dict(_id=i, eppn=eppn, mayLogin=False, authority='legacy'))\n",
    "\n",
    "    for u in testUsers:\n",
    "        u['_id'] = ObjectId()\n",
    "        idMapping[u['eppn']] = u['_id']\n",
    "        existingUsers.append(u)\n",
    "    inGroups = [\n",
    "        dict(eppn='DirkRoorda@dariah.eu', authority='DARIAH', group='system'),\n",
    "        dict(eppn='LisaDeLeeuw@dariah.eu', authority='DARIAH', group='office'),\n",
    "        dict(eppn='suzan', authority='local', group='auth'),\n",
    "        dict(eppn='marie', authority='local', group='auth'),\n",
    "        dict(eppn='gertjan', authority='local', group='auth'),\n",
    "        dict(eppn='lisa', authority='local', group='office'),\n",
    "        dict(eppn='dirk', authority='local', group='system'),\n",
    "    ]\n",
    "    inGroups = [dict(tuple(ig.items())+(('_id', ObjectId()),)) for ig in inGroups]\n",
    "    allData['user'] = existingUsers\n",
    "    allData['group'] = inGroups\n",
    "    \n",
    "    allFields['user'] = dict(\n",
    "        _id=('id', 1),\n",
    "        eppn=('string', 1),\n",
    "        email=('email', 1),\n",
    "        mayLogin=('bool', 1),\n",
    "        authority=('string', 1),\n",
    "        firstName=('string', 1),\n",
    "        lastName=('string', 1),\n",
    "    )\n",
    "    allFields['group'] = dict(\n",
    "        _id=('id', 1),\n",
    "        eppn=('string', 1),\n",
    "        authority=('string', 1),\n",
    "        group=('string', 1),\n",
    "    )\n",
    "    uidMapping.update(idMapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Related tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relTables():\n",
    "    def norm(x): return x.strip().lower()\n",
    "    \n",
    "    relIndex = dict()\n",
    "    for mt in sorted(VALUE_LISTS):\n",
    "        rows = allData[mt]\n",
    "        for f in sorted(VALUE_LISTS[mt]):\n",
    "            comps = f.split(':')\n",
    "            if len(comps) == 2:\n",
    "                (f, fAs) = comps\n",
    "            else:\n",
    "                fAs = f\n",
    "            relInfo = valueDict[fAs]\n",
    "            if not fAs in relIndex:\n",
    "                idMapping = dict((i, ObjectId()) for i in relInfo)\n",
    "                allData[fAs] = [dict(_id=idMapping[i], value=v) for (i, v) in relInfo.items()]\n",
    "                relIndex[fAs] = dict((norm(v), (idMapping[i], v)) for (i, v) in relInfo.items())\n",
    "            for row in rows:\n",
    "                newValue = []\n",
    "                for v in row[f]:\n",
    "                    rnv = norm(v)\n",
    "                    (i, nv) = relIndex[fAs].get(rnv, (\"-1\", None))\n",
    "                    if nv == None:\n",
    "                        target = MOVE_MISSING[mt]\n",
    "                        if target not in row: row[target] = ['']\n",
    "                        row[target][0] += '\\nMOVED FROM {}: {}'.format(f, v)\n",
    "                    else: newValue.append(dict(_id=i, value=nv))\n",
    "                row[f] = newValue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test tweaks\n",
    "\n",
    "Tweaks for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def testTweaks():\n",
    "    mt = 'contrib'\n",
    "    myContribs = {'3DHOP', 'AAI'}\n",
    "    my = uidMapping['dirk']\n",
    "    for row in allData[mt]:\n",
    "        title = row.get('title', [None])\n",
    "        if len(title) == 0: title = [None]\n",
    "        if title[0] in myContribs:\n",
    "            row['creator'] = [dict(_id=my)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Insert into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def importMongo():\n",
    "    client = MongoClient()\n",
    "    client.drop_database('dariah')\n",
    "    db = client.dariah\n",
    "    for (mt, rows) in allData.items():\n",
    "        info(mt)\n",
    "        db[mt].insert_many(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrib\n",
      "country\n",
      "assessment\n",
      "user\n",
      "group\n",
      "discipline\n",
      "keyword\n",
      "tadirahActivity\n",
      "tadirahObject\n",
      "tadirahTechnique\n",
      "typeContribution\n",
      "vcc\n",
      "year\n"
     ]
    }
   ],
   "source": [
    "money_warnings = {}\n",
    "money_notes = {}\n",
    "valueDict = dict()\n",
    "rawFields = dict()\n",
    "allFields = dict()\n",
    "rawData = dict()\n",
    "allData = dict()\n",
    "uidMapping = dict()\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True, ns_clean=True)\n",
    "readFmFields()\n",
    "readFmData()\n",
    "readLists()\n",
    "moveFields()\n",
    "countryTable()\n",
    "userTable()\n",
    "relTables()\n",
    "testTweaks()\n",
    "importMongo()\n",
    "#showData()\n",
    "#showMoney()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To import the bson dump in another mongodb installation, use the commandline to dump the dariah database here\n",
    "\n",
    "    mongodump -d dariah -o dariah\n",
    "\n",
    "and to import it elsewhere.\n",
    "\n",
    "    mongorestore --drop -d dariah dariah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['countryExtra', 'disciplines', 'tadirahActivities', 'tadirahObjects', 'tadirahTechniques', 'typeContribution', 'vcc', 'keywords', 'year'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '(socio-)linguistic analyses',\n",
       " 2: '1795-2015',\n",
       " 3: '3D modeling',\n",
       " 4: '3D scanning',\n",
       " 5: 'Analyse quantitative',\n",
       " 6: 'Analysis-Stylistic Analysis',\n",
       " 7: 'Architecture',\n",
       " 8: 'Archives',\n",
       " 9: 'Arts',\n",
       " 10: 'Arts and Humanities',\n",
       " 11: 'Augmented reality',\n",
       " 12: 'Belgian justice',\n",
       " 13: 'Belgium',\n",
       " 14: 'Browsing',\n",
       " 15: 'Brussels',\n",
       " 16: 'Cairo',\n",
       " 17: 'Certification',\n",
       " 18: 'Commenting',\n",
       " 19: 'Community Involvement',\n",
       " 20: 'Community building',\n",
       " 21: 'Competences',\n",
       " 22: 'Corpus linguistics',\n",
       " 23: 'Critical edition',\n",
       " 24: 'Cœur du Hainaut',\n",
       " 25: 'DBMS',\n",
       " 26: 'Database design',\n",
       " 27: 'Digital Heritage',\n",
       " 28: 'Digital Humanities',\n",
       " 29: 'Digitisation',\n",
       " 30: 'Distance intertextuelle',\n",
       " 31: 'Document Understanding',\n",
       " 32: 'Early Modern History',\n",
       " 33: 'Editing',\n",
       " 34: 'Egyptian Language',\n",
       " 35: 'Electronic publishing',\n",
       " 36: 'Encoding',\n",
       " 37: 'Encoding of complex writing systems',\n",
       " 38: 'Etiquetage des textes',\n",
       " 39: 'Evaluations',\n",
       " 40: 'Expertise',\n",
       " 41: 'File formats',\n",
       " 42: 'French SMS',\n",
       " 43: 'Georeferencing',\n",
       " 44: 'Hagiographie',\n",
       " 45: 'Handwritten Text Recognition of historical documents',\n",
       " 46: 'Heritage',\n",
       " 47: 'History and memory',\n",
       " 48: 'Humanities',\n",
       " 49: 'Humanities and Arts',\n",
       " 50: 'Information_retrieval',\n",
       " 51: 'Intellectual property rights',\n",
       " 52: 'Latin',\n",
       " 53: 'Latin language',\n",
       " 54: 'Legal Deposit',\n",
       " 55: 'Lemmatisation et analyse morpho-syntaxique',\n",
       " 56: 'Long Nineteenth Century',\n",
       " 57: 'Manuscripts',\n",
       " 58: 'Mapping',\n",
       " 59: 'Mediaeval Studies',\n",
       " 60: 'Mediaeval Studies / Working group',\n",
       " 61: 'Medieval Authors',\n",
       " 62: 'Medieval History',\n",
       " 63: 'Medieval Textual Tradition',\n",
       " 64: 'Mediterranean',\n",
       " 65: 'Meta-Search',\n",
       " 66: 'Modern History',\n",
       " 67: 'Mons',\n",
       " 68: 'Moyen Âge',\n",
       " 69: 'Natural Language Processing',\n",
       " 70: 'Natural Language Processing.',\n",
       " 71: 'Network analysis',\n",
       " 72: 'OAI',\n",
       " 73: 'OAI-PMH',\n",
       " 74: 'Observatory',\n",
       " 75: 'Open-access',\n",
       " 76: 'Optical Character Recognition',\n",
       " 77: 'Ortolang',\n",
       " 78: 'POS Tagging > Analysis-Structural Analysis',\n",
       " 79: 'POS-Tagging > Analysis-Structural Analysis',\n",
       " 80: 'POT tagging > Analysis-Structural Analysis',\n",
       " 81: 'POT-Tagging > Analysis-Structural Analysis',\n",
       " 82: 'Pattern Recognition > Analysis-Relational Analysis',\n",
       " 83: 'Philological reconstruction',\n",
       " 84: 'Photography',\n",
       " 85: 'Preservation - Metadata > Storage - Preservation',\n",
       " 86: 'Preservation Metadata',\n",
       " 87: 'Preservation Metadata > Storage - Preservation',\n",
       " 88: 'Preservation Metadata > Storage-Preservation',\n",
       " 89: 'Preservation_metadata',\n",
       " 90: 'Principal Component Analysis',\n",
       " 91: 'Promotional material',\n",
       " 92: 'Proofreading',\n",
       " 93: 'Prosopography',\n",
       " 94: 'RDF',\n",
       " 95: 'Regional History',\n",
       " 96: 'Renaissance',\n",
       " 97: 'Replication',\n",
       " 98: 'Replication > Storage - Preservation',\n",
       " 99: 'Replication > Storage Preservations',\n",
       " 100: 'Replication > Storage-Preservation',\n",
       " 101: 'SPARQL',\n",
       " 102: 'SPARQL end point',\n",
       " 103: 'Scanning',\n",
       " 104: 'Searching',\n",
       " 105: 'Sentiment Analysis > Analysis-Content Analysis',\n",
       " 106: 'Sentiment Analysis >Analysis-Content Analysis',\n",
       " 107: 'Seraching',\n",
       " 108: 'Social Network Analysis (SNA)',\n",
       " 109: 'Social reform',\n",
       " 110: 'Social regulation',\n",
       " 111: 'Social research methods',\n",
       " 112: 'Sociology of Knowledge',\n",
       " 113: 'Software localisation',\n",
       " 114: 'Statistics',\n",
       " 115: 'Storage > Preservation',\n",
       " 116: 'TEI XML',\n",
       " 117: 'Technology - Preservation > Storage - Preservation',\n",
       " 118: 'Technology > Storage - Preservation',\n",
       " 119: 'Technology Preservation > Storage - Preservation',\n",
       " 120: 'Technology Preservation > Storage-Preservation',\n",
       " 121: 'Technology-Preservation > Storage-Preservation',\n",
       " 122: 'Technology_preservation',\n",
       " 123: 'Text edition',\n",
       " 124: 'Texts',\n",
       " 125: 'Textual Traditions',\n",
       " 126: 'Textual analysis',\n",
       " 127: 'Tools',\n",
       " 128: 'Topic modeling > Analysis-Content Analysis',\n",
       " 129: 'Town planning',\n",
       " 130: 'Transnational History',\n",
       " 131: 'Transnational Networks',\n",
       " 132: 'Urbain History',\n",
       " 133: 'Urban Archaeology',\n",
       " 134: 'User guides',\n",
       " 135: 'VRE-SI',\n",
       " 136: 'Versioning > Storage-Preservation',\n",
       " 137: 'Virtual Research Environment Service Infrastructure',\n",
       " 138: 'Web Cra',\n",
       " 139: 'Web Crawling > Capture - Gathering',\n",
       " 140: 'Web Crawling > Capture-Gathering',\n",
       " 141: 'Web-Crawling > Capture-Gathering',\n",
       " 142: 'Working group',\n",
       " 143: 'XML-MEI',\n",
       " 144: 'XML-TEI',\n",
       " 145: 'advice',\n",
       " 146: 'aggregation',\n",
       " 147: 'alignment',\n",
       " 148: 'annotation',\n",
       " 149: 'anonymisation',\n",
       " 150: 'art and art history',\n",
       " 151: 'benefits',\n",
       " 152: 'best practices',\n",
       " 153: 'bibliography',\n",
       " 154: 'bilingualism',\n",
       " 155: 'citability',\n",
       " 156: 'codicology',\n",
       " 157: 'collection',\n",
       " 158: 'collections',\n",
       " 159: 'colonial history',\n",
       " 160: 'commenting',\n",
       " 161: 'community',\n",
       " 162: 'community engagement',\n",
       " 163: 'contemporary architecture',\n",
       " 164: 'coordination',\n",
       " 165: 'course',\n",
       " 166: 'crawling',\n",
       " 167: 'cultural innovation',\n",
       " 168: 'database design',\n",
       " 169: 'database management system (DBMS)',\n",
       " 170: 'diasporas',\n",
       " 171: 'dictionary building',\n",
       " 172: 'digital curation',\n",
       " 173: 'digital edition',\n",
       " 174: 'digital humanities',\n",
       " 175: 'digital publishing',\n",
       " 176: 'digital repository',\n",
       " 177: 'diplomatics',\n",
       " 178: 'dissemination',\n",
       " 179: 'documentary portal',\n",
       " 180: 'drama',\n",
       " 181: 'embedded metadata',\n",
       " 182: 'ethical issues',\n",
       " 183: 'expertise',\n",
       " 184: 'federation of identity',\n",
       " 185: 'french literature',\n",
       " 186: 'geographical name',\n",
       " 187: 'handle',\n",
       " 188: 'heraldry',\n",
       " 189: 'historical cartography',\n",
       " 190: 'history',\n",
       " 191: 'iconography',\n",
       " 192: 'indexing',\n",
       " 193: 'information',\n",
       " 194: 'institution',\n",
       " 195: 'institutions',\n",
       " 196: 'integration',\n",
       " 197: 'interactive visualization',\n",
       " 198: 'interoperability',\n",
       " 199: 'knowledge management',\n",
       " 200: 'knowledge sharing',\n",
       " 201: 'law and justice',\n",
       " 202: 'law and justice history',\n",
       " 203: 'library',\n",
       " 204: 'linguistic',\n",
       " 205: 'linguistic resources',\n",
       " 206: 'magistrates',\n",
       " 207: 'mediated electronic discourse',\n",
       " 208: 'migration',\n",
       " 209: 'migration.',\n",
       " 210: 'modern architecture',\n",
       " 211: 'monuments',\n",
       " 212: 'multilingualism',\n",
       " 213: 'multimedia',\n",
       " 214: 'museum documentation',\n",
       " 215: 'network analysis',\n",
       " 216: 'networking',\n",
       " 217: 'numerical catalogues',\n",
       " 218: 'old english language and literature',\n",
       " 219: 'ontologies',\n",
       " 220: 'ontology',\n",
       " 221: 'open access',\n",
       " 222: 'open archive',\n",
       " 223: 'palaeography',\n",
       " 224: 'persistent identifier',\n",
       " 225: 'platform',\n",
       " 226: 'presentation',\n",
       " 227: 'preservation',\n",
       " 228: 'prosopography',\n",
       " 229: 'publications',\n",
       " 230: 'publishing software',\n",
       " 231: 'reference data registries',\n",
       " 232: 'registries',\n",
       " 233: 'repression',\n",
       " 234: 'research',\n",
       " 235: 'research archives',\n",
       " 236: 'resources',\n",
       " 237: 'rhetoric',\n",
       " 238: 'romanization of Arabic',\n",
       " 239: 'scholarly content',\n",
       " 240: 'scientific sources',\n",
       " 241: 'semantic linking',\n",
       " 242: 'semantic searc',\n",
       " 243: 'semantic search',\n",
       " 244: 'semantic structuring',\n",
       " 245: 'semantic web',\n",
       " 246: 'social actors',\n",
       " 247: 'social media',\n",
       " 248: 'social network',\n",
       " 249: 'sound archives',\n",
       " 250: 'statistics',\n",
       " 251: 'studies',\n",
       " 252: 'survey',\n",
       " 253: 'taxonomy',\n",
       " 254: 'terminology systems',\n",
       " 255: 'text encoding',\n",
       " 256: 'the tool doesn\\'t show some of the \"Disciplines Associated\" \"TaDiRAH Research techniques\" that should be available',\n",
       " 257: 'thesauri',\n",
       " 258: 'thesaurus',\n",
       " 259: 'toponymy',\n",
       " 260: 'training',\n",
       " 261: 'transcoding',\n",
       " 262: 'transcription',\n",
       " 263: 'translation',\n",
       " 264: 'triple store',\n",
       " 265: 'urbanism',\n",
       " 266: 'virtual environment',\n",
       " 267: 'visualisation',\n",
       " 268: 'web',\n",
       " 269: 'web of data',\n",
       " 270: 'workshop'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueDict['keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploration\n",
    "\n",
    "The process has finished, but here is space to explore the data, in order to find patterns, regularities, and, more importantly, *irregularities*.\n",
    "\n",
    "First step: create csv files of the data and combine them into an excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EXPORT_DIR = os.path.expanduser('~/Downloads')\n",
    "EXPORT_ORIG = '{}/contribFromFileMaker.xlsx'.format(EXPORT_DIR)\n",
    "EXPORT_MONGO = '{}/contribInMongoDB.xlsx'.format(EXPORT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook(EXPORT_ORIG, {'strings_to_urls': False})\n",
    "for mt in rawData:\n",
    "    worksheet = workbook.add_worksheet(mt)\n",
    "    for (f, field) in enumerate(rawFields[mt]):\n",
    "            worksheet.write(0, f, field)\n",
    "    for (r, row) in enumerate(rawData[mt]):\n",
    "        for (f, field) in enumerate(rawFields[mt]):\n",
    "            val = row[field]\n",
    "            val = [] if val == None else val if type(val) is list else [val]\n",
    "            val = '|'.join(val)\n",
    "            worksheet.write(r+1, f, val)\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook(EXPORT_MONGO, {'strings_to_urls': False})\n",
    "for mt in allData:\n",
    "    worksheet = workbook.add_worksheet(mt)\n",
    "    fields = sorted(allFields[mt])\n",
    "    for (f, field) in enumerate(fields):\n",
    "            worksheet.write(0, f, field)\n",
    "    for (r, row) in enumerate(allData[mt]):\n",
    "        for (f, field) in enumerate(fields):\n",
    "            fmt = None\n",
    "            val = row.get(field, [])\n",
    "            (ftype, fmult) = allFields[mt][field]\n",
    "            val = [] if val == None else [val] if type(val) is not list else val\n",
    "            exportVal = []\n",
    "            for v in val:\n",
    "                if type(v) is dict:\n",
    "                    exportVal.append(','.join(str(vv) for vv in v.values()))\n",
    "                elif ftype == 'date' or ftype == 'datetime':\n",
    "                    exportVal.append(v if type(v) is str else v.isoformat())\n",
    "                else:\n",
    "                    exportVal.append(str(v))\n",
    "            worksheet.write(r+1, f, ' | '.join(exportVal))\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assessment\n",
      "                 approved: bool       (1)\n",
      "               contrib_id: id         (1)\n",
      "             dateApproved: datetime   (8)\n",
      "          dateApprovedCIO: datetime   (1)\n",
      "         reviewerDecision: bool       (2)\n",
      "            reviewerNames: text       (2)\n",
      "                submitted: bool       (1)\n",
      "              vccApproval: bool       (1)\n",
      "              vccDecision: bool       (8)\n",
      "           vccDisApproval: bool       (1)\n",
      "contrib\n",
      "       contactPersonEmail: email      (4)\n",
      "        contactPersonName: text       (1)\n",
      "          costDescription: text       (1)\n",
      "                costTotal: valuta     (1)\n",
      "                  country: text       (1)\n",
      "                  creator: text       (1)\n",
      "              dateCreated: datetime   (1)\n",
      "             dateModified: datetime   (1)\n",
      "              description: text       (1)\n",
      "              disciplines: text       (2)\n",
      "                 keywords: text       (2)\n",
      "               modifiedBy: text       (1)\n",
      "        tadirahActivities: text       (2)\n",
      "           tadirahObjects: text       (2)\n",
      "        tadirahTechniques: text       (2)\n",
      "                    title: text       (1)\n",
      "         typeContribution: text       (1)\n",
      "    typeContributionOther: text       (3)\n",
      "              urlAcademic: text       (3)\n",
      "          urlContribution: text       (3)\n",
      "                      vcc: text       (2)\n",
      "                     year: text       (1)\n",
      "country\n",
      "                      _id: id         (1)\n",
      "                 isMember: bool       (1)\n",
      "                      iso: string     (1)\n",
      "                 latitude: float      (1)\n",
      "                longitude: float      (1)\n",
      "                     name: text       (1)\n",
      "countryExtra\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n",
      "disciplines\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n",
      "groups\n",
      "                      _id: id         (1)\n",
      "                authority: string     (1)\n",
      "                     eppn: string     (1)\n",
      "                    group: string     (1)\n",
      "keywords\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n",
      "tadirahActivities\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n",
      "tadirahObjects\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n",
      "tadirahTechniques\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n",
      "typeContribution\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n",
      "users\n",
      "                      _id: id         (1)\n",
      "                authority: string     (1)\n",
      "                    email: email      (1)\n",
      "                     eppn: string     (1)\n",
      "                firstName: string     (1)\n",
      "                 lastName: string     (1)\n",
      "                 mayLogin: bool       (1)\n",
      "vcc\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n",
      "year\n",
      "                      _id: id         (1)\n",
      "                    value: string     (1)\n"
     ]
    }
   ],
   "source": [
    "showFields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "_id=58a6dcad2179c01d8f0dd64d\n",
      "contactPersonEmail=['roberto.scopigno@isti.cnr.it']\n",
      "contactPersonName=['Roberto Scopigno']\n",
      "costDescription=['The labour effort is related to maintenance of all software tools and resources shared with the community (see also the others in the following excel shett lines); it includes one full-time researcher (the responsible person for maintenance and management of the MeshLab tool, that is the most complex among our tools and the one with the widest distribution, with more than 350,000 downloads in 2015) and the (part-time) contribution of several other VClab staff (contributing to the other tools).']\n",
      "costTotal=[34280.0]\n",
      "country=[{'_id': ObjectId('58a6dcad2179c01d8f0dd9f5'), 'iso': 'IT', 'value': 'Italy'}]\n",
      "creator=[{'_id': ObjectId('58a6dcad2179c01d8f0dda1f')}]\n",
      "dateCreated=[datetime.datetime(2016, 4, 26, 12, 1, 5)]\n",
      "dateModified=[datetime.datetime(2016, 7, 6, 13, 59, 52)]\n",
      "description=['3DHOP (3D Heritage Online Presenter) is an open-source tool for the creation of multimedia interactive Web presentations of digital cultural artifacts. 3DHOP target audience range from the museum curators with some IT experience to the experienced Web designers who wants to embed 3D contents in their creations. Based on WebGL, works on almost all platforms, without plugin or a dedicated server, directly inside HTML pages and is capable of streaming multiresolution 3D meshes over HTTP, supporting the exploration of huge 3D models on commodity computers and standard internet connections. IT has been downloaded and used by more than 1700 colleagues.']\n",
      "disciplines=[{'_id': ObjectId('58a6dcad2179c01d8f0dda27'), 'value': 'Archaeology and Prehistory'}, {'_id': ObjectId('58a6dcad2179c01d8f0dda29'), 'value': 'Art and art history'}, {'_id': ObjectId('58a6dcad2179c01d8f0dda2a'), 'value': 'Biological anthropology'}, {'_id': ObjectId('58a6dcad2179c01d8f0dda2d'), 'value': 'Cultural heritage and museology'}, {'_id': ObjectId('58a6dcad2179c01d8f0dda30'), 'value': 'Education'}]\n",
      "keywords=[{'_id': ObjectId('58a6dcad2179c01d8f0dda43'), 'value': ''}, {'_id': ObjectId('58a6dcad2179c01d8f0ddaaa'), 'value': 'Scanning'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb43'), 'value': 'the tool doesn\\'t show some of the \"Disciplines Associated\" \"TaDiRAH Research techniques\" that should be available'}]\n",
      "modifiedBy=[{'_id': ObjectId('58a6dcad2179c01d8f0dda10')}]\n",
      "tadirahActivities=[{'_id': ObjectId('58a6dcad2179c01d8f0ddb52'), 'value': 'Capture'}]\n",
      "tadirahObjects=[{'_id': ObjectId('58a6dcad2179c01d8f0ddb5a'), 'value': 'Artifacts'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb5d'), 'value': 'Computers'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb5f'), 'value': 'Digital Humanities'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb62'), 'value': 'Images'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb63'), 'value': 'Images (3D)'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb6d'), 'value': 'Multimedia'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb72'), 'value': 'Research'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb73'), 'value': 'Research Process'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb74'), 'value': 'Research Results'}, {'_id': ObjectId('58a6dcad2179c01d8f0ddb7b'), 'value': 'Tools'}]\n",
      "tadirahTechniques=[]\n",
      "title=['3DHOP']\n",
      "typeContribution=[{'_id': ObjectId('58a6dcad2179c01d8f0ddba4'), 'value': 'Tools and Software'}]\n",
      "typeContributionOther=[]\n",
      "urlAcademic=['www.isti.cnr.it/']\n",
      "urlContribution=['http://3dhop.net/']\n",
      "vcc=[{'_id': ObjectId('58a6dcad2179c01d8f0ddbad'), 'value': 'VCC1'}]\n",
      "year=[{'_id': ObjectId('58a6dcad2179c01d8f0ddbb4'), 'value': '2016'}]\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "dbm = client.dariah\n",
    "for d in dbm.contrib.find({'title': '3DHOP'}).limit(2):\n",
    "    print('=' * 50)\n",
    "    for f in sorted(d):\n",
    "        print('{}={}'.format(f, d[f]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here is a query to get all 'type_of_inkind' values for contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 1, 'value': 'Access'}\n",
      "{'_id': 6, 'value': 'Event'}\n",
      "{'_id': 12, 'value': 'DARIAH Coordination'}\n",
      "{'_id': 9, 'value': 'Cooperation'}\n",
      "{'_id': 2, 'value': 'Expertise'}\n",
      "{'_id': 5, 'value': 'Tools and Software'}\n",
      "{'_id': 8, 'value': 'Summer School'}\n",
      "{'_id': 7, 'value': 'Training'}\n",
      "{'_id': 11, 'value': 'Data'}\n",
      "{'_id': 10, 'value': 'Educational Resources'}\n",
      "{'_id': 4, 'value': 'Content Hosting'}\n",
      "{'_id': 3, 'value': 'Interoperability'}\n"
     ]
    }
   ],
   "source": [
    "for c in dbm.contrib.distinct('typeContribution', {}):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here are the users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 1, 'eppn': 'ATNC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 2, 'eppn': 'BENC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 3, 'eppn': 'CIO01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 4, 'eppn': 'CIO02', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 5, 'eppn': 'CIOHenk', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 6, 'eppn': 'CIOLisa', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 7, 'eppn': 'DENC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 8, 'eppn': 'DGA', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 9, 'eppn': 'FRNC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 10, 'eppn': 'FRNC02', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 11, 'eppn': 'GRNC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 12, 'eppn': 'HRNC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 13, 'eppn': 'Henk Harmsen', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 14, 'eppn': 'IENC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 15, 'eppn': 'ITNC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 16, 'eppn': 'LUNC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 17, 'eppn': 'NLNC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 18, 'eppn': 'PLNC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 19, 'eppn': 'SINC01', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 20, 'eppn': 'VCC11', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 21, 'eppn': 'VCC12', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 22, 'eppn': 'VCC22', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 23, 'eppn': 'VCC42', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 24, 'eppn': 'admin', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 25, 'eppn': 'consult', 'mayLogin': False, 'authority': 'legacy'}\n",
      "{'_id': 26, 'eppn': 'suzan', 'email': 'suzan1@test.eu', 'mayLogin': True, 'authority': 'local', 'firstName': 'Suzan', 'lastName': 'Karelse'}\n",
      "{'_id': 27, 'eppn': 'marie', 'email': 'suzan2@test.eu', 'mayLogin': True, 'authority': 'local', 'firstName': 'Marie', 'lastName': 'Pieterse'}\n",
      "{'_id': 28, 'eppn': 'gertjan', 'email': 'gertjan@test.eu', 'mayLogin': False, 'authority': 'local', 'firstName': 'Gert Jan', 'lastName': 'Klein-Holgerink'}\n",
      "{'_id': 29, 'eppn': 'lisa', 'email': 'lisa@test.eu', 'mayLogin': True, 'authority': 'local', 'firstName': 'Lisa', 'lastName': 'de Leeuw'}\n",
      "{'_id': 30, 'eppn': 'dirk', 'email': 'dirk@test.eu', 'mayLogin': True, 'authority': 'local', 'firstName': 'Dirk', 'lastName': 'Roorda'}\n"
     ]
    }
   ],
   "source": [
    "for c in dbm.users.find({}):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here are the countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'AT', 'name': 'Austria', 'isMember': True, 'latitude': '47.7', 'longitude': '15.11'}\n",
      "{'_id': 'BE', 'name': 'Belgium', 'isMember': True, 'latitude': '51.3', 'longitude': '3.1'}\n",
      "{'_id': 'HR', 'name': 'Croatia', 'isMember': True, 'latitude': '44.7', 'longitude': '15.6'}\n",
      "{'_id': 'CY', 'name': 'Cyprus', 'isMember': True, 'latitude': '35.0', 'longitude': '32.8'}\n",
      "{'_id': 'DK', 'name': 'Denmark', 'isMember': True, 'latitude': '55.6', 'longitude': '11.0'}\n",
      "{'_id': 'FR', 'name': 'France', 'isMember': True, 'latitude': '46.5', 'longitude': '1.9'}\n",
      "{'_id': 'DE', 'name': 'Germany', 'isMember': True, 'latitude': '51.0', 'longitude': '10.4'}\n",
      "{'_id': 'GR', 'name': 'Greece', 'isMember': True, 'latitude': '38.0', 'longitude': '23.8'}\n",
      "{'_id': 'IE', 'name': 'Ireland', 'isMember': True, 'latitude': '53.1', 'longitude': '-8.4'}\n",
      "{'_id': 'IT', 'name': 'Italy', 'isMember': True, 'latitude': '41.6', 'longitude': '13.0'}\n",
      "{'_id': 'LU', 'name': 'Luxembourg', 'isMember': True, 'latitude': '49.6', 'longitude': '6.1'}\n",
      "{'_id': 'MT', 'name': 'Malta', 'isMember': True, 'latitude': '35.9', 'longitude': '14.4'}\n",
      "{'_id': 'NL', 'name': 'Netherlands', 'isMember': True, 'latitude': '52.8', 'longitude': '5.8'}\n",
      "{'_id': 'PT', 'name': 'Portugal', 'isMember': True, 'latitude': '38.7', 'longitude': '-9.0'}\n",
      "{'_id': 'RS', 'name': 'Serbia', 'isMember': True, 'latitude': '44.0', 'longitude': '20.8'}\n",
      "{'_id': 'SI', 'name': 'Slovenia', 'isMember': True, 'latitude': '46.2', 'longitude': '14.4'}\n",
      "{'_id': 'PL', 'name': 'Poland', 'isMember': True, 'latitude': '52.3', 'longitude': '19.8'}\n"
     ]
    }
   ],
   "source": [
    "for c in dbm.country.find({'isMember': True}):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'HR', 'value': 'Croatia'}\n",
      "{'_id': 'LU', 'value': 'Luxembourg'}\n",
      "{'_id': 'SI', 'value': 'Slovenia'}\n",
      "{'_id': 'BE', 'value': 'Belgium'}\n",
      "{'_id': 'GR', 'value': 'Greece'}\n",
      "{'_id': 'RS', 'value': 'Serbia'}\n",
      "{'_id': 'AT', 'value': 'Austria'}\n",
      "{'_id': 'IT', 'value': 'Italy'}\n",
      "{'_id': 'FR', 'value': 'France'}\n",
      "{'_id': 'IE', 'value': 'Ireland'}\n",
      "{'_id': 'DE', 'value': 'Germany'}\n",
      "{'_id': 'NL', 'value': 'Netherlands'}\n",
      "{'_id': 'DK', 'value': 'Denmark'}\n",
      "{'_id': 'PL', 'value': 'Poland'}\n"
     ]
    }
   ],
   "source": [
    "for c in dbm.contrib.distinct('country', {}):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us get related data: the type_of_inkind of all contributions. For each contribution we need only the ids of the related type_of_inkind values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 1, 'typeContribution': [{'_id': 1, 'value': 'Access'}]}\n",
      "{'_id': 2, 'typeContribution': [{'_id': 1, 'value': 'Access'}]}\n",
      "{'_id': 3, 'typeContribution': [{'_id': 6, 'value': 'Event'}]}\n",
      "{'_id': 4, 'typeContribution': [{'_id': 12, 'value': 'DARIAH Coordination'}]}\n",
      "{'_id': 5, 'typeContribution': [{'_id': 9, 'value': 'Cooperation'}]}\n",
      "{'_id': 6, 'typeContribution': [{'_id': 1, 'value': 'Access'}]}\n",
      "{'_id': 7, 'typeContribution': [{'_id': 6, 'value': 'Event'}]}\n",
      "{'_id': 8, 'typeContribution': [{'_id': 9, 'value': 'Cooperation'}]}\n",
      "{'_id': 9, 'typeContribution': [{'_id': 1, 'value': 'Access'}]}\n",
      "{'_id': 10, 'typeContribution': [{'_id': 12, 'value': 'DARIAH Coordination'}]}\n"
     ]
    }
   ],
   "source": [
    "for d in dbm.contrib.find({}, {'typeContribution': True}).limit(10):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 1, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 2, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 3, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 4, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 5, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 6, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 7, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 8, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 9, 'country': [{'_id': 'HR', 'value': 'Croatia'}]}\n",
      "{'_id': 10, 'country': [{'_id': 'LU', 'value': 'Luxembourg'}]}\n"
     ]
    }
   ],
   "source": [
    "for d in dbm.contrib.find({}, {'country': True}).limit(10):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dict(_id=5, value='66')\n",
    "y = dict(_id=5, value='66')\n",
    "x == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
