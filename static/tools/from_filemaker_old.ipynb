{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing InKind from FileMaker\n",
    "\n",
    "We use an XML export of the ``inkind`` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge OK\n",
      "Configuration OK\n"
     ]
    }
   ],
   "source": [
    "# Locations\n",
    "\n",
    "HOME_DIR = os.path.expanduser('~').replace('\\\\', '/')\n",
    "BASE_DIR = '{}/projects/has/dacs'.format(HOME_DIR)\n",
    "TEMP_DIR = '{}/tmp'.format(BASE_DIR)\n",
    "RESULT_DIR = '{}/sql'.format(BASE_DIR)\n",
    "INFILE = 'dariah.xml'\n",
    "INPATH = '{}/{}'.format(BASE_DIR, INFILE)\n",
    "FMNS = '{http://www.filemaker.com/fmpxmlresult}'\n",
    "ROW_RAW_FILE = '{}/row_raw_file'.format(TEMP_DIR)\n",
    "ROW_FILE = '{}/row_file'.format(TEMP_DIR)\n",
    "ROW_EXT = 'txt'\n",
    "\n",
    "# data type details\n",
    "\n",
    "MIN_M = 5       # minimum varchar size = 2**MIN_M\n",
    "MAX_M = 13      # maximum varchar size = 2**MAX_M\n",
    "LIMIT_ROWS = 50 # maximum number of rows to be written in one sql insert statement\n",
    "TYPES = {'number', 'text', 'valuta', 'datetime'}\n",
    "DATE_PATTERN = re.compile(\n",
    "    '^\\s*([0-9]{2})/([0-9]{2})/([0-9]{4})\\s+([0-9]{2}):([0-9]{2})(?::([0-9]{2}))?$'\n",
    ")\n",
    "\n",
    "# field management\n",
    "\n",
    "splitters = dict(\n",
    "    generic=re.compile('[ \\t]*[\\n+][ \\t\\n]*'),\n",
    "    generic_comma=re.compile('[ \\t]*[\\n+,][ \\t\\n]*'),\n",
    ")\n",
    "SPLIT_FIELDS = dict(\n",
    "    disciplines_associated=splitters['generic'],\n",
    "    other_keywords=splitters['generic_comma'],\n",
    "    tadirah_research_activities=splitters['generic'],\n",
    "    tadirah_research_objects=splitters['generic'],\n",
    "    tadirah_research_techniques=splitters['generic'],\n",
    "    type_of_inkind=splitters['generic'],\n",
    "    vcc=splitters['generic'],\n",
    ")\n",
    "\n",
    "SKIP_FIELDS = {\n",
    "    'teller',\n",
    "    'whois',\n",
    "}\n",
    "\n",
    "FIELD_TYPE_OVERRIDE = dict(\n",
    "    costs_total='valuta',\n",
    "    total_costs_total='valuta',\n",
    "    whois='text',\n",
    "    creation_date_time='datetime',\n",
    "    modification_date_time='datetime',\n",
    "    dateandtime_approval='datetime',\n",
    "    dateandtime_cioapproval='datetime',\n",
    "    dateandtime_ciozero='datetime',\n",
    ")\n",
    "\n",
    "MERGE_FIELDS = dict(\n",
    "    academic_entity_url=('academic_entity_url_2',),\n",
    "    contribution_url=('contribution_url_2',),\n",
    "    contact_person_mail=('contact_person_mail_2',),\n",
    "    gnewpassword=('gnewpassword2',),\n",
    "    vcc_head_decision_vcc1=('vcc_head_decision_vcc11', 'vcc_head_decision_vcc12'),\n",
    "    vcc_head_decision_vcc2=('vcc_head_decision_vcc21', 'vcc_head_decision_vcc22'),\n",
    "    vcc_head_decision_vcc3=('vcc_head_decision_vcc31', 'vcc_head_decision_vcc32'),\n",
    "    vcc_head_decision_vcc4=('vcc_head_decision_vcc41', 'vcc_head_decision_vcc42'),\n",
    "    vcc_name=(\n",
    "        'vcc11_name', 'vcc12_name', \n",
    "        'vcc21_name', 'vcc22_name',\n",
    "        'vcc31_name', 'vcc32_name',\n",
    "        'vcc41_name', 'vcc42_name',\n",
    "    ),\n",
    ")\n",
    "\n",
    "VALUE_FIELDS = {\n",
    "    'country',\n",
    "}\n",
    "\n",
    "NULL_VALUES = {\n",
    "    'http://',\n",
    "    'https://',\n",
    "}\n",
    "\n",
    "# table organization\n",
    "\n",
    "MAIN_TABLE = 'contrib'\n",
    "\n",
    "UNRELATED_TABLES = {\n",
    "    'help': {'help_text', 'help_description'},\n",
    "}\n",
    "\n",
    "DB_NAME = 'inkind_data'\n",
    "\n",
    "merge_errors = 0\n",
    "merge_fields = {}\n",
    "for (mfhead, mftail) in MERGE_FIELDS.items():\n",
    "    for f in mftail:\n",
    "        if f in merge_fields:\n",
    "            print(\n",
    "                'WARNING: field `{}` already merged into `{}` now to be merged into `{}`'.format(\n",
    "                    f, merge_field[f], mfhead,\n",
    "            ))\n",
    "            merge_errors += 1\n",
    "        merge_fields[f] = mfhead\n",
    "\n",
    "if merge_errors:\n",
    "    print('There were {} merge errors'.format(merge_errors))\n",
    "else:\n",
    "    print('merge OK')\n",
    "\n",
    "good = True\n",
    "for x in [1]:\n",
    "    good = False\n",
    "    if not os.path.exists(BASE_DIR):\n",
    "        print('BASE_DIR does not exist: {}'.format(BASE_DIR))\n",
    "        break\n",
    "    this_good = True\n",
    "    for cdir in (TEMP_DIR, RESULT_DIR):\n",
    "        this_good = False\n",
    "        if not os.path.exists(cdir):\n",
    "            try:\n",
    "                os.makedirs(cdir)\n",
    "            except os.error as e:\n",
    "                print('{} could not be created.'.format(cdir))\n",
    "                break\n",
    "        this_good = True\n",
    "    if not this_good:\n",
    "        break\n",
    "    good = True\n",
    "if not good:\n",
    "    print('There were configuration errors')\n",
    "else:\n",
    "    print('Configuration OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(remove_blank_text=True, ns_clean=True)\n",
    "root = etree.parse(INPATH, parser).getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the fields and their types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGE OK\n",
      "60 fields, some are skipped or merged\n",
      "43 retained fields:\n",
      "text    3 academic_entity_url \n",
      "number  1 approved            \n",
      "text    4 contact_person_mail \n",
      "text    1 contact_person_name \n",
      "text    3 contribution_url    \n",
      "text    1 costs_description   \n",
      "valuta  1 costs_total         \n",
      "text    1 country             \n",
      "datetime1 creation_date_time  \n",
      "text    1 creator             \n",
      "datetime8 dateandtime_approval\n",
      "datetime1 dateandtime_cioapproval\n",
      "datetime1 dateandtime_ciozero \n",
      "text    1 description_of_contribution\n",
      "text    2 disciplines_associated\n",
      "text    2 gnewpassword        \n",
      "text    1 goldpassword        \n",
      "text    1 help_description    \n",
      "text    1 help_text           \n",
      "number  1 ikid                \n",
      "number  1 ikid_base           \n",
      "text    1 last_modifier       \n",
      "text    1 message             \n",
      "datetime1 modification_date_time\n",
      "text    2 other_keywords      \n",
      "text    1 other_type_of_inkind\n",
      "number  1 submit              \n",
      "text    2 tadirah_research_activities\n",
      "text    2 tadirah_research_objects\n",
      "text    2 tadirah_research_techniques\n",
      "text    1 title               \n",
      "valuta  1 total_costs_total   \n",
      "text    2 type_of_inkind      \n",
      "text    2 vcc                 \n",
      "text    8 vcc_head_decision   \n",
      "text    2 vcc_head_decision_vcc1\n",
      "text    2 vcc_head_decision_vcc2\n",
      "text    2 vcc_head_decision_vcc3\n",
      "text    2 vcc_head_decision_vcc4\n",
      "text    8 vcc_name            \n",
      "text    1 vcchead_approval    \n",
      "text    1 vcchead_disapproval \n",
      "text    1 year                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fieldroots = [x for x in root.iter(FMNS+'METADATA')]\n",
    "fieldroot = fieldroots[0]\n",
    "tfields = []\n",
    "field_defs = {}\n",
    "for x in fieldroot.iter(FMNS+'FIELD'):\n",
    "    fname = x.get('NAME').lower().replace(' ','_')\n",
    "    ftype = FIELD_TYPE_OVERRIDE.get(fname, None) or x.get('TYPE').lower()\n",
    "    fmult = int(x.get('MAXREPEAT'))\n",
    "    if fname in SPLIT_FIELDS: fmult += 1\n",
    "    tfields.append(fname)\n",
    "    field_defs[fname] = [ftype, fmult]\n",
    "    if ftype not in TYPES:\n",
    "        print('WARNING: field `{}` has unknown type \"{}\"'.format(fname, ftype))\n",
    "\n",
    "merge_errors = 0\n",
    "for f in merge_fields:\n",
    "    if f not in field_defs:\n",
    "        print(\n",
    "            'WARNING: Cannot merge unknown field `{}`'.format(\n",
    "            f,\n",
    "        ))\n",
    "        merge_errors += 1\n",
    "        continue\n",
    "    ftarget = merge_fields[f]\n",
    "    (ftype, fmult) = field_defs[f]\n",
    "    if ftarget not in field_defs:\n",
    "        field_defs[ftarget] = [ftype, 0]\n",
    "    (ttype, tmult) = field_defs[ftarget]\n",
    "    if ttype != ftype:\n",
    "        print(\n",
    "            'WARNING: field `{}` of type \"{}\" is merged into field `{}` of other type \"{}\"'.format(\n",
    "                f, ftype, ftarget, ttype,\n",
    "        ))\n",
    "        merge_errors += 1\n",
    "    field_defs[ftarget][1] += fmult\n",
    "    del field_defs[f]\n",
    "\n",
    "for f in SKIP_FIELDS: del field_defs[f]\n",
    "\n",
    "fields = sorted({f for f in tfields if f in field_defs} | set(merge_fields.values()))\n",
    "\n",
    "if merge_errors:\n",
    "    print('There were {} merge errors'.format(merge_errors))\n",
    "else:\n",
    "    print('MERGE OK')\n",
    "\n",
    "print('{} fields, some are skipped or merged\\n{} retained fields:\\n{}\\n'.format(\n",
    "    len(tfields), len(fields), \n",
    "    '\\n'.join('{:<8}{} {:<20}'.format(\n",
    "        *field_defs[f], \n",
    "        f, \n",
    "    ) for f in fields)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  309 rows read\n"
     ]
    }
   ],
   "source": [
    "dataroots = [x for x in root.iter(FMNS+'RESULTSET')]\n",
    "dataroot = dataroots[0]\n",
    "rows_raw = []\n",
    "errors = collections.defaultdict(list)\n",
    "    \n",
    "for (i, r) in enumerate(dataroot.iter(FMNS+'ROW')):\n",
    "    row = []\n",
    "    for c in r.iter(FMNS+'COL'):\n",
    "        data = [x.text for x in c.iter(FMNS+'DATA')]\n",
    "        row.append(data)\n",
    "    if len(row) != len(tfields):\n",
    "        errors['Number of fields'].append(i)\n",
    "    rows_raw.append(row)\n",
    "if errors:\n",
    "    for k in sorted(errors):\n",
    "        print('{:<20}: {}'.format(k, ','.join(errors[k])))\n",
    "else:\n",
    "    print('{:>5} rows read'.format(len(rows_raw)))\n",
    "\n",
    "rf = open('{}.{}'.format(ROW_RAW_FILE, ROW_EXT), 'w')\n",
    "for row in rows_raw:\n",
    "    for (fname, values) in zip(tfields, row):\n",
    "        rf.write('@{:>30} = {}\\n'.format(\n",
    "            fname,\n",
    "            ' | '.join('{}'.format(v) for v in values),\n",
    "        ))\n",
    "    rf.write('{}\\n'.format('='*100))\n",
    "rf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table organization OK\n",
      "Table `contrib`:   309 rows\n",
      "Table `help`:     2 rows\n"
     ]
    }
   ],
   "source": [
    "unrelated_fields = {}\n",
    "good = True\n",
    "for ut in UNRELATED_TABLES:\n",
    "    for uf in UNRELATED_TABLES[ut]:\n",
    "        if uf not in field_defs:\n",
    "            print(\n",
    "                'WARNING: unrelated table `{}`: unknown field `{}`'.format(\n",
    "                    ut, uf,\n",
    "            ))\n",
    "            good = False\n",
    "        unrelated_fields[uf] = ut\n",
    "if good:\n",
    "    print('Table organization OK')\n",
    "else:\n",
    "    print('Errors in table organization')\n",
    "\n",
    "def freeze(row): return tuple((x,tuple(sorted(y))) for (x,y) in sorted(row.items()))\n",
    "def unfreeze(row): return dict((x, set(y)) for (x,y) in row)\n",
    "\n",
    "rows_part = collections.defaultdict(list)\n",
    "\n",
    "for row in rows_raw:\n",
    "    row_part = collections.defaultdict(dict)\n",
    "    for (fname, values) in zip(tfields, row):\n",
    "        target_table = unrelated_fields.get(fname, MAIN_TABLE)\n",
    "        row_part[target_table][fname] = values\n",
    "    for t in row_part:\n",
    "        rows_part[t].append(row_part[t])\n",
    "\n",
    "for t in UNRELATED_TABLES:\n",
    "    new_rows = [unfreeze(frow) for frow in {freeze(row) for row in rows_part[t]}]\n",
    "    rows_part[t] = new_rows\n",
    "\n",
    "for t in rows_part:\n",
    "    rf = open('{}_{}.{}'.format(ROW_RAW_FILE, t, ROW_EXT), 'w')\n",
    "    print('Table `{}`: {:>5} rows'.format(t, len(rows_part[t])))\n",
    "    for row in rows_part[t]:\n",
    "        for (fname, values) in sorted(row.items()):\n",
    "            rf.write('@{:>30} = {}\\n'.format(\n",
    "                fname,\n",
    "                ' | '.join('{}'.format(v) for v in values),\n",
    "            ))\n",
    "        rf.write('{}\\n'.format('='*100))\n",
    "    rf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the values\n",
    "\n",
    "Various non-informational values will be converted to NULL.\n",
    "Values will be thinned: \n",
    "Identical values will be reduced to one copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table `contrib`:   309 rows checked\n",
      "Table `help`:     2 rows checked\n"
     ]
    }
   ],
   "source": [
    "def date_repl(match):\n",
    "    [d,m,y,hr,mn,sc] = list(match.groups())\n",
    "    return '{}-{}-{}T{}:{}:{}'.format(y,m,d,hr,mn,sc or '00')\n",
    "    \n",
    "def sq(v_raw):\n",
    "    return \"'{}'\".format(\n",
    "        v_raw.strip().replace(\"'\",\"''\").replace('\\t', '\\\\t').replace('\\n', '\\\\n')\n",
    "    )\n",
    "\n",
    "def num(v_raw, i, fname):\n",
    "    if v_raw.isdigit(): return int(v_raw)\n",
    "    print(\n",
    "        'WARNING: field `{}` record {}: not an integer: \"{}\"'.format(\n",
    "            fname, i, v_raw\n",
    "    ))\n",
    "    return v_raw\n",
    "\n",
    "def money(v_raw, i, fname):\n",
    "    if '€' not in v_raw:\n",
    "        print(\n",
    "            'WARNING: field `{}` record {}: no currency symbol: \"{}\"'.format(\n",
    "                fname, i, v_raw\n",
    "        ))\n",
    "    if ',' in v_raw:\n",
    "        print(\n",
    "            'WARNING: field `{}` record {}: comma in amount: \"{}\"'.format(\n",
    "                fname, i, v_raw\n",
    "        ))\n",
    "    return num(v_raw.replace('€', '').replace('.','').replace(',', ''), i, fname)\n",
    "\n",
    "def dtm(v_raw, i, fname):\n",
    "    if not DATE_PATTERN.match(v_raw):\n",
    "        print(\n",
    "            'WARNING: field `{}` record {}: not a valid date time: \"{}\"'.format(\n",
    "                fname, i, v_raw\n",
    "        ))\n",
    "        return v_raw\n",
    "    return(\"'{}'\".format(DATE_PATTERN.sub(date_repl, v_raw)))\n",
    "\n",
    "def transform_rows(t):\n",
    "    if t not in rows_part:\n",
    "        print('WARNING: Unknown table `{}`'.format(t))\n",
    "    rows = []\n",
    "    for (i, row_raw) in enumerate(rows_part.get(t, [])):\n",
    "        values = {}\n",
    "        for (fname, values_raw) in sorted(row_raw.items()):\n",
    "            if fname in SKIP_FIELDS: continue\n",
    "            sep = SPLIT_FIELDS.get(fname, None)\n",
    "            if sep != None:\n",
    "                values_raw = sorted(reduce(\n",
    "                    set.union, \n",
    "                    [set(sep.split(v)) for v in values_raw if v != None], \n",
    "                    set(),\n",
    "                ))\n",
    "                if '' in values_raw: values_raw.remove('')\n",
    "            ftarget = merge_fields.get(fname, fname)\n",
    "            (ftype, fmult) = field_defs[ftarget]\n",
    "            valset = set()\n",
    "            for v_raw in values_raw:\n",
    "                if v_raw == None or v_raw in NULL_VALUES: v = 'NULL'\n",
    "                elif ftype == 'text': v = sq(v_raw)\n",
    "                elif ftype == 'number': v = num(v_raw, i, fname)\n",
    "                elif ftype == 'valuta': v = money(v_raw, i, fname)\n",
    "                elif ftype == 'datetime': v = dtm(v_raw, i, fname)\n",
    "                else: v = v_raw\n",
    "                valset.add(v)\n",
    "            if fmult > 1: valset.discard('NULL')\n",
    "            these_values = values.setdefault(ftarget, set())\n",
    "            these_values |= valset\n",
    "        rows.append(values)\n",
    "    print('Table `{}`: {:>5} rows checked'.format(t, len(rows)))\n",
    "\n",
    "    rf = open('{}_{}.{}'.format(ROW_FILE, t, ROW_EXT), 'w')\n",
    "    for row in rows:\n",
    "        for (fname, values) in sorted(row.items()):\n",
    "            rf.write('@{:>30} = {}\\n'.format(\n",
    "                fname,\n",
    "                ' | '.join('{}'.format(v) for v in sorted(values)),\n",
    "            ))\n",
    "        rf.write('{}\\n'.format('='*100))\n",
    "    rf.close()\n",
    "    return rows\n",
    "\n",
    "rows = {}\n",
    "for t in rows_part: rows[t] = transform_rows(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn the data into a dict\n",
    "\n",
    "We represent the data with a dictionary. The keys are the field names.\n",
    "The values are dictionaries again, with keys new ids and with values the value that the row with that id has for that field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table `contrib`: 309   records and 41 fields compiled\n",
      "Table `help`: 2     records and 2  fields compiled\n"
     ]
    }
   ],
   "source": [
    "field_data = {}\n",
    "\n",
    "def pprintf(tname, fname):\n",
    "    values_raw = field_data[tname][fname]\n",
    "    values = sorted(v for v in reduce(set.union, values_raw, set()) if v != 'NULL')\n",
    "    print('\\n'.join('{}'.format(v) for v in values))\n",
    "    \n",
    "for t in rows:\n",
    "    for row in rows[t]:\n",
    "        for (fname, values) in sorted(row.items()):\n",
    "            field_data.setdefault(t, {}).setdefault(fname, []).append(values)\n",
    "    print('Table `{}`: {:<5} records and {:<2} fields compiled'.format(\n",
    "        t, len(rows[t]), len(field_data[t]),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "good = True\n",
    "for t in field_data:\n",
    "    for f in field_data[t]:\n",
    "        if len(field_data[t][f]) != len(rows[t]):        \n",
    "            print(\n",
    "                'WARNING: table `{}`, field `{}`: wrong number of records: {} instead of {}'.format(\n",
    "                    t, f, len(field_data[t][f]), len(rows[t]),\n",
    "            ))\n",
    "            good = False\n",
    "if good:\n",
    "    print('OK')\n",
    "else:\n",
    "    print('There were errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Dirk Wintergrün'\n",
      "'Hansmichael Hohenegger'\n",
      "'Hella Hollander'\n",
      "'Marianne Huan'\n",
      "'Sophie David'\n",
      "'Susan Schreibman'\n",
      "'Tibor Kálmán'\n"
     ]
    }
   ],
   "source": [
    "pprintf(MAIN_TABLE, 'vcc_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract related and related tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field `description_of_contribution`: value with length 12856 gets type TEXT\n",
      "SQL written\n"
     ]
    }
   ],
   "source": [
    "def getsize(source, fname):\n",
    "    values = set()\n",
    "    for vals in source: values |= set(vals)\n",
    "    maxlen = max({len(x) for x in values if x != 'NULL'}, default=0)\n",
    "    result = 0\n",
    "    for m in range(MIN_M, MAX_M+1):\n",
    "        if maxlen <= 2**m:\n",
    "            result = m\n",
    "            break\n",
    "    if maxlen > 2**MAX_M:\n",
    "        print(\n",
    "            'Field `{}`: value with length {} gets type TEXT'.format(\n",
    "                fname, maxlen, 2**MAX_M,\n",
    "        ))\n",
    "        return False\n",
    "    return 2**m\n",
    "\n",
    "def getdef(source, fname, newfname, warn_mult=True):\n",
    "    (ft, fmult) = field_defs[fname]\n",
    "    if warn_mult and fmult > 1:\n",
    "        print(\n",
    "            'WARNING: skipping field `{}` because it contains multiple values'.format(\n",
    "                fname,\n",
    "        ))\n",
    "        return None\n",
    "    if ft == 'number':\n",
    "        ftype = 'int'\n",
    "        fsize = '(4)'\n",
    "        fext = ''\n",
    "    elif ft == 'text':\n",
    "        ftype = 'varchar'\n",
    "        fsize_raw = getsize(source, fname)\n",
    "        if not fsize_raw:\n",
    "            ftype = 'text'\n",
    "            fsize = ''\n",
    "        else:\n",
    "            fsize = '({})'.format(fsize_raw)\n",
    "        fext = 'character set utf8'\n",
    "    elif ft == 'valuta':\n",
    "        ftype = 'decimal'\n",
    "        fsize = '(10,2)'\n",
    "        fext = ''\n",
    "    elif ft == 'datetime':\n",
    "        ftype = 'datetime'\n",
    "        fsize = ''\n",
    "        fext = ''\n",
    "    else:\n",
    "        print('WARNING: skipping field `{}` because it has unknown type `{}`'.format(\n",
    "            fname, ft,\n",
    "        ))\n",
    "        return None\n",
    "    return '{} {}{} {}'.format(newfname, ftype, fsize, fext)\n",
    "\n",
    "def getrdef(fname):\n",
    "    return '''{fn}_id int(4),\n",
    "    foreign key ({fn}_id) references {fn}(id)'''.format(fn=fname)\n",
    "\n",
    "def sql_data(df, tname, flist, rows):\n",
    "    head = 'insert into {} ({}) values'.format(tname, ','.join(flist))\n",
    "    for (i, row) in enumerate(rows):\n",
    "        if i % LIMIT_ROWS == 0:\n",
    "            if i > 0: df.write(';')\n",
    "            df.write('\\n')\n",
    "            df.write('select \"table {} row {}\" as \" \";\\n'.format(tname, i))\n",
    "            df.write(head)\n",
    "            sep = ''\n",
    "        df.write('\\n{}\\t'.format(sep))\n",
    "        sep = ','\n",
    "        df.write('({})'.format(','.join(str(x) for x in row)))\n",
    "    df.write(';\\n')\n",
    "        \n",
    "def print_maintables(maindata, reltables, cf, df):\n",
    "    for t in maindata:\n",
    "        fdefs = ['id int(4) primary key']\n",
    "        flist = sorted(maindata[t])\n",
    "        fnewlist = []\n",
    "        for fname in flist:\n",
    "            if unrelated_fields.get(fname, MAIN_TABLE) != t: continue\n",
    "            if fname in reltables:\n",
    "                fdef = getrdef(fname)\n",
    "                fnewname = '{}_id'.format(fname)\n",
    "            else:\n",
    "                fdef = getdef(field_data[t][fname], fname, fname)\n",
    "                fnewname = fname\n",
    "            fdefs.append(fdef)\n",
    "            fnewlist.append(fnewname)\n",
    "        cf.write('''\n",
    "create table {} (\n",
    "    {}\n",
    ");\n",
    "    '''.format(t, ',\\n\\t'.join(fdefs)))\n",
    "        maintable_raw = zip(*(maindata[t][f] for f in flist))\n",
    "        maintable = [\n",
    "            [i]+[sorted(vals)[0] for vals in row] for (i, row) in enumerate(maintable_raw)\n",
    "        ]\n",
    "        sql_data(df, t, ['id'] + fnewlist, maintable)\n",
    "\n",
    "def print_reltables(reltables, relvalues, cf, df):\n",
    "    for tname in sorted(reltables):\n",
    "        fdefs = ['id int(4) primary key']\n",
    "        fdef = getdef([relvalues[tname].keys()], tname, 'val', warn_mult=False)\n",
    "        if fdef == None: continue            \n",
    "        fdefs.append(fdef)\n",
    "        cf.write('''\n",
    "create table {} (\n",
    "    {}\n",
    ");\n",
    "'''.format(tname, ',\\n\\t'.join(fdefs)))\n",
    "        sql_data(df, tname, ['id', 'val'], reltables[tname])\n",
    "\n",
    "def print_relxtables(relxtables, cf, df):\n",
    "    for tname in sorted(relxtables):\n",
    "        tname_rep = '{}_{}'.format(MAIN_TABLE, tname)\n",
    "        main_id = '{}_id'.format(MAIN_TABLE)\n",
    "        val_id = '{}_id'.format(tname)\n",
    "        fdefs = '''\n",
    "    {mi} int(4),\n",
    "    {vi} int(4),\n",
    "    foreign key ({mi}) references {mt}(id),\n",
    "    foreign key ({vi}) references {tn}(id)\n",
    "'''.format(mt=MAIN_TABLE, mi=main_id, tn=tname, vi=val_id)\n",
    "        cf.write('''\n",
    "create table {} ({});\n",
    "'''.format(tname_rep, fdefs))\n",
    "        sql_data(df, tname_rep, [main_id, val_id], relxtables[tname])\n",
    "\n",
    "def extract(maindata, relvalues, relindex, reltables, relxtables, fname):\n",
    "    is_single = field_defs[fname][1] == 1 # single value of multiple values\n",
    "    t = unrelated_fields.get(fname, MAIN_TABLE)\n",
    "    for (i, values) in enumerate(field_data[t][fname]):\n",
    "        for value in values:\n",
    "            vid = relvalues[fname].get(value, None)\n",
    "            if vid == None:\n",
    "                relindex[fname] += 1\n",
    "                vid = relindex[fname]\n",
    "                reltables[fname].append((vid, value))\n",
    "            relvalues[fname][value] = vid\n",
    "            if is_single:\n",
    "                maindata[t][fname][i] = [vid]\n",
    "            else:\n",
    "                relxtables[fname].append((i, vid))\n",
    "    if not is_single: del maindata[t][fname]\n",
    "\n",
    "def model_data(field_list):\n",
    "    maindata = deepcopy(field_data)\n",
    "    relvalues = collections.defaultdict(dict)\n",
    "    relindex = collections.Counter()\n",
    "    reltables = collections.defaultdict(list)\n",
    "    relxtables = collections.defaultdict(list)\n",
    "\n",
    "    for fname in field_list:\n",
    "        if fname not in field_defs:\n",
    "            print('ERROR: wrong field {}'.format(fname))\n",
    "            continue\n",
    "        extract(\n",
    "            maindata, relvalues, relindex, reltables, relxtables, fname,\n",
    "        )\n",
    "    return (maindata, reltables, relxtables, relvalues)\n",
    "\n",
    "def transform_data():\n",
    "    mult_fields = {f for f in fields if field_defs[f][1] > 1}\n",
    "    (maindata, reltables, relxtables, relvalues) = model_data(\n",
    "        VALUE_FIELDS | mult_fields\n",
    "    )\n",
    "    cf = open('{}/create.sql'.format(RESULT_DIR), 'w')\n",
    "    df = open('{}/data.sql'.format(RESULT_DIR), 'w')\n",
    "    df.write('''\n",
    "select \"FILL TABLES OF DATABASE {db}\" as \" \";\n",
    "\n",
    "use {db};\n",
    "\n",
    "'''.format(db=DB_NAME))\n",
    "\n",
    "    cf.write('''\n",
    "select \"CREATE DATABASE {db} AND TABLES\" as \" \";\n",
    "\n",
    "drop database if exists {db};\n",
    "create database {db} character set utf8;\n",
    "use {db};\n",
    "\n",
    "'''.format(db=DB_NAME))\n",
    "    cf.write('/* value tables */\\n')\n",
    "    df.write('\\n/* value tables */\\n')\n",
    "    print_reltables(reltables, relvalues, cf, df)\n",
    "    \n",
    "    cf.write('/* main tables */\\n')\n",
    "    df.write('\\n/* main tables */\\n')\n",
    "    print_maintables(maindata, reltables, cf, df)\n",
    "\n",
    "    cf.write('/* cross tables */\\n')\n",
    "    df.write('\\n/* cross tables */\\n')\n",
    "    print_relxtables(relxtables, cf, df)\n",
    "    \n",
    "    cf.close()\n",
    "    df.close()\n",
    "    print('SQL written')\n",
    "\n",
    "transform_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
