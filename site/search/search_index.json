{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 DARIAH contribution tool This is the documentation for the DARIAH contribution tool, an instrument to register and assess community contributions to the DARIAH . The documentation contains parts that range from functional , conceptual , technical to mundane . About \u00b6 Code base To get an impression of the kind of work behind this app, we reveal how many lines of code have been written in which languages. See also how we managed to keep the code in all those languages tidy. More ... Lessons learned It has taken a lot of time to develop this app. Lots more than I expected from the start. More ... News Every now and then I resume what has happened during development. It is not regular and not comprehensive! More ... Functionality \u00b6 Slides For an impression of the intended functions of this app, see these slides which I made near the end of the project (2017-12-14). Business logic The actual handling of contributions, assessments and reviews is the business logic of this app. More ... Workflow At the highest level of abstraction a workflow engine implements the business logic. More ... Tables Several tables work together with the workflow engine. More ... Legacy data \u00b6 Content This app inherits 800 contributions that have been entered in 2015-2017 into a FileMaker database. We have migrated those to a MongoDB model. More ... Concepts \u00b6 Model The whole app is centered around data: contributions, assessments, reviews and more. We have to organize and specify that data. More ... Architecture This is a complex app. We need a lot of structure to get every bit of data there where it is needed. On time. More ... Routing This is a web app. We need to divide labour between client and server, and define a routing scheme that steers the app by URLs. More ... Server \u00b6 Server The part of the app that guards the data sits at the server. From there it sends it to the web browsers (clients) of the users. More ... Authentication Users are authenticated at the server, and every bit of data that they subsequently receive, has passed a customs control. More ... Client \u00b6 Components The client (web browser) is where the app speaks to the user. The user interface is built up from dozens of components, that mediate between the user and the server. More ... Dux The client collects the actions of the user and the data from the server into an internal state, from which it flows back to the components. More ... Templates Those tables receive custom formatting through a very dynamic templating system. More ... Lib We have developed quite a bit of library functions to assist our components. More ... Technology \u00b6 ES6 We have implemented the client application in ES6, i.e. modern Javascript. That is our glue language. More ... React Our components are written in React, a framework that defines a syntactic sugar right within ES6. More ... Tech index We have listed most of the technology that we have made use of. More ... Integration \u00b6 API The data of the tool is accessible through an API. In fact, this app itself uses that API, whenever the client needs data from the server. More ... Maintenance \u00b6 Deploy Here are the bits and pieces you have to do in order to get a working system out of this. More ... Tests Testing becomes a life saver when your app is growing in complexity. When you add new behaviours you run the risk that existing behaviours break. The remedy is to write tests for all aspects of the behaviours, and run them rigorously after each change and refactoring. That way, you proactively discover your bugs before your users do. More ... Author \u00b6 Dirk Roorda DANS dirk.roorda@dans.knaw.nl 2019-08-06 2019-07-29 2019-03-04 2017-12-14","title":"Home"},{"location":"#home","text":"DARIAH contribution tool This is the documentation for the DARIAH contribution tool, an instrument to register and assess community contributions to the DARIAH . The documentation contains parts that range from functional , conceptual , technical to mundane .","title":"Home"},{"location":"#about","text":"Code base To get an impression of the kind of work behind this app, we reveal how many lines of code have been written in which languages. See also how we managed to keep the code in all those languages tidy. More ... Lessons learned It has taken a lot of time to develop this app. Lots more than I expected from the start. More ... News Every now and then I resume what has happened during development. It is not regular and not comprehensive! More ...","title":"About"},{"location":"#functionality","text":"Slides For an impression of the intended functions of this app, see these slides which I made near the end of the project (2017-12-14). Business logic The actual handling of contributions, assessments and reviews is the business logic of this app. More ... Workflow At the highest level of abstraction a workflow engine implements the business logic. More ... Tables Several tables work together with the workflow engine. More ...","title":"Functionality"},{"location":"#legacy-data","text":"Content This app inherits 800 contributions that have been entered in 2015-2017 into a FileMaker database. We have migrated those to a MongoDB model. More ...","title":"Legacy data"},{"location":"#concepts","text":"Model The whole app is centered around data: contributions, assessments, reviews and more. We have to organize and specify that data. More ... Architecture This is a complex app. We need a lot of structure to get every bit of data there where it is needed. On time. More ... Routing This is a web app. We need to divide labour between client and server, and define a routing scheme that steers the app by URLs. More ...","title":"Concepts"},{"location":"#server","text":"Server The part of the app that guards the data sits at the server. From there it sends it to the web browsers (clients) of the users. More ... Authentication Users are authenticated at the server, and every bit of data that they subsequently receive, has passed a customs control. More ...","title":"Server"},{"location":"#client","text":"Components The client (web browser) is where the app speaks to the user. The user interface is built up from dozens of components, that mediate between the user and the server. More ... Dux The client collects the actions of the user and the data from the server into an internal state, from which it flows back to the components. More ... Templates Those tables receive custom formatting through a very dynamic templating system. More ... Lib We have developed quite a bit of library functions to assist our components. More ...","title":"Client"},{"location":"#technology","text":"ES6 We have implemented the client application in ES6, i.e. modern Javascript. That is our glue language. More ... React Our components are written in React, a framework that defines a syntactic sugar right within ES6. More ... Tech index We have listed most of the technology that we have made use of. More ...","title":"Technology"},{"location":"#integration","text":"API The data of the tool is accessible through an API. In fact, this app itself uses that API, whenever the client needs data from the server. More ...","title":"Integration"},{"location":"#maintenance","text":"Deploy Here are the bits and pieces you have to do in order to get a working system out of this. More ... Tests Testing becomes a life saver when your app is growing in complexity. When you add new behaviours you run the risk that existing behaviours break. The remedy is to write tests for all aspects of the behaviours, and run them rigorously after each change and refactoring. That way, you proactively discover your bugs before your users do. More ...","title":"Maintenance"},{"location":"#author","text":"Dirk Roorda DANS dirk.roorda@dans.knaw.nl 2019-08-06 2019-07-29 2019-03-04 2017-12-14","title":"Author"},{"location":"About/Codebase/","text":"Codebase \u00b6 Statistics \u00b6 Legend The numbers stand for lines of code. 1000 lines is ~ 20 typed A4 pages of text. The statistics have been gathered by the cloc tool . Statistics Formalisms \u00b6 YAML \u00b6 See YAML . A simple plain-text way to convey structured data. What Markdown is to text, YAML is to XML-JSON. In this app we use YAML for configuration details. Usage in this app the conversion of legacy contribution data into MongoDB is steered by a config.yaml . the data model lists all the tables and fields, including how they hang together and how we want to represent them on screen. It also defines access control. If you, as developer, need to add new tables and fields, you can do so by modifying these files: model per table . No extra coding is needed. Markdown \u00b6 See Markdown . A simple plain-text way to write formatted text. See it as a shortcut to writing HTML. It is handy for writing documentation without being distracted by too many formatting options and issues, as you experience when writing in Word or plain HTML. General usage Markdown is usually converted to HTML, but even when it is not converted, it is still very readable. If you use GitHub, one of the first things is to write a README file for your project. This must be a markdown file. If you use other documentation options on GitHub, such as Wiki or Pages, you will also write markdown. Markdown has a sister: YAML , which is used for structured data. Usage in this app all documentation here is written in markdown the app can present markdown documents all big text fields in this app support markdown. JavaScript \u00b6 See JavaScript . The principal scripting language for web applications. It has evolved into a performant language with a beautiful syntax, capable of running on the server and in websites. Usage in this app This app uses JavaScript in the client only. We use it as a work horse which takes care of a copy of data from the database. It reacts to changes by integrating new bits of data into the existing state, a process that is called reducing . JSX \u00b6 See JSX . This is also JavaScript, but with a thin layer of syntactic sugar, by which you can present your code as a collection of React components . Usage in this app In this app we have dozens of JSX files, each containing exactly one component (with a few exceptions). Components are pieces of code that realize parts of the website that you can actually see, and often interact with. They are supported by sophisticated plumbing (dux, ducts) , which connects them to the global state of the app. The state is divided in sections, where individual duct connects such a section with several components. See Architecture for how this hangs together. The plumbing needs some specialized, technical functions, which are collected in the lib section of the app. One of the most crucial is memoization . Python \u00b6 See Python . A general purpose scripting language with excellent data processing facilities. Usage in this app This app uses python (version 3.6.1+) for the web server. The web server itself is Flask , a light-weight framework for handling http(s) requests. We have added a set of controllers . The actual code there is quite lean, but when it comes to database access, the module db does the heavy lifting and tends to become uglier and uglier. CSS \u00b6 See CSS . Styling the app has nightmarish overtones, because the concerns of style often cut right across the concerns of the components. There are several ways to control the resulting mess, and one of the best is to use the modern features of CSS. General usage Cascading style sheets are the ultimate way to paint the final look and feel of the website. By using flex boxes instead of tables we can make the app respond gracefully to changes in the size of the display without resorting to the bureaucracy of overdefining style properties. Note that our app does not use the HTML <table> element any more for aligning pieces of content. Usage in this app We use a lot of the CSS-3 features, including variables , and calc() . This lessens our need for a style sheet preprocessor such as SASS to 0%. Note especially how colour management has become easy: all colour definitions are in variables all colour definitions are in HSLA , which allows a very consistent definition of families of colours. Quote from Mozilla : One advantage of HSLA over RGB is that it is more intuitive: you can guess 1 2 3 at the color you want, and tweak it from there. It is also easier to create a set of matching colors (e.g., by keeping the hue the same, while varying the lightness/darkness and saturation). This is exactly what we do. See vars.css . Shell \u00b6 See Shell . The shell is the interpreter of system level commands. Usage in this app Our app does not use it, but we use it to develop the app. All the development tasks, such as transpiling code, pushing code to GitHub, transporting databases to the production server are done by specialized frameworks. These frameworks must be steered by intricate commands with many options which are easily forgotten. That's why we have a build script. You have to pass it just the name of a task, and the script executes that task with all the sophistication needed. HTML \u00b6 See HTML . The core language of the web. Usage in this app Surprisingly, our code does not contain HTML any more. In JSX there are fragments that look like HTML, but that is exactly what it is, and real HTML it is not. When the browser encounters HTML material, it parses it and stores it in its memory in a certain standard representation: the DOM . But our server does not send HTML any more to the browser, except for a very first short page , that serves to load a bulk of style sheets and JavaScript into the browser. This JavaScript code builds and manipulates the DOM directly, without generating any formal HTML. JSON \u00b6 See JSON . A format to serialize JavaScript objects. General usage In web applications, the program logic happens at two separate places (at least): the server and the client. It is important that data can flow seamlessly from one programming context to the other. JSON achieves that. Usage in this app to send data from server to client configure the main development tools, such as Webpack for building and Mocha for testing. Keeping the code tidy \u00b6 There are three progressive levels of caring for your code. Level 1: code style Adopt a style guide and meticulously keep to it. It is hard, especially if you work in two syntactically and culturally diverse languages such as JavaScript and Python. Add CSS, Markdown and YAML to the mix, and you can feel the need for a next step. Yet this is the fundamental step, it cannot be skipped. Level 2: linters Linters are little programs that observe your code and check it for correctness and style, as far as that is possible without actually running the code. Usually, your editing environment runs them sneakily while you type or when you save, and give you unobtrusive but conspicuous feedback. It saves you a lot of round trips of compiling/building/running/staring at errors. Moreover, it gives you the feedback right where you are typing, so you do not have to lookup files and line numbers. Sometimes linters give you so much feedback that your heart sinks at the thought of going through all those cases and fix them all, even if you have a splendid IDE. That is where the next step comes in. Level 3: formatters Formatters have a lot in common with linters, but they fix the problems. Sometimes they parse your program with the parser of the language and then format the abstract syntax three they've got. That is the end of all style inconsistencies. Tools Here is an overview of tools used in developing this app. Formatters Formatters are not perfect, sometimes they produce code at which the linter balks, especially yapf is doing that. Luckily, you can selectively suppress certain kinds of transformations. language linter formatter JavaScript eslint prettier Python flake8 yapf Markdown remark prettier remark Editor or IDE? For projects like these, you need a good editing environment. IDEs The good old ones like Eclipse are not really suited to the JavaScript and Python environments. There are interesting modern ones such as GitHub's Atom modernized ones such as Microsoft's Visual Studio Code and commercial ones such as Webstorm . Editors You can also choose to work with a text editor, such as the free Vim or the commercial Sublime Text . Vim My choice has been Vim, since I use it from its start in 1991. These are the key reasons for which Vim stands out: it has a compositional command set, like Unix itself. By this you get all your (massive) editing chores done without much remembering and thinking. it has a rich ecosystem of plugins. By this you can turn Vim into an IDE. It is rock solid and performant. You can edit many small files and then some big ones, at the same time. You do not loose data. My Vim setup Just for the record, here is a piece of my .vimrc file (the configuration file, which draws in plugins, and customises the interface). You can find out more about the plugins by clicking on them, they are all GitHub repos: 1 call plug#begin () Plug 'morhetz/gruvbox' Plug 'fenetikm/falcon' Plug 'jelera/vim-javascript-syntax' Plug 'pangloss/vim-javascript' Plug 'mxw/vim-jsx' Plug 'hail2u/vim-css3-syntax' Plug 'nathanaelkane/vim-indent-guides' Plug 'othree/yajs.vim' Plug 'othree/javascript-libraries-syntax.vim' Plug 'scrooloose/nerdtree' Plug 'w0rp/ale' 1 call plug# end () An honourable mention for the ALE plugin. This is an asynchronous plugin that invokes linters for your files while you edit. The beauty is, that if you have installed the linters first outside Vim, ALE is smart enough to detect them and run them for you, asynchronously, and with zero configuration.","title":"Codebase"},{"location":"About/Codebase/#codebase","text":"","title":"Codebase"},{"location":"About/Codebase/#statistics","text":"Legend The numbers stand for lines of code. 1000 lines is ~ 20 typed A4 pages of text. The statistics have been gathered by the cloc tool . Statistics","title":"Statistics"},{"location":"About/Codebase/#formalisms","text":"","title":"Formalisms"},{"location":"About/Codebase/#yaml","text":"See YAML . A simple plain-text way to convey structured data. What Markdown is to text, YAML is to XML-JSON. In this app we use YAML for configuration details. Usage in this app the conversion of legacy contribution data into MongoDB is steered by a config.yaml . the data model lists all the tables and fields, including how they hang together and how we want to represent them on screen. It also defines access control. If you, as developer, need to add new tables and fields, you can do so by modifying these files: model per table . No extra coding is needed.","title":"YAML"},{"location":"About/Codebase/#markdown","text":"See Markdown . A simple plain-text way to write formatted text. See it as a shortcut to writing HTML. It is handy for writing documentation without being distracted by too many formatting options and issues, as you experience when writing in Word or plain HTML. General usage Markdown is usually converted to HTML, but even when it is not converted, it is still very readable. If you use GitHub, one of the first things is to write a README file for your project. This must be a markdown file. If you use other documentation options on GitHub, such as Wiki or Pages, you will also write markdown. Markdown has a sister: YAML , which is used for structured data. Usage in this app all documentation here is written in markdown the app can present markdown documents all big text fields in this app support markdown.","title":"Markdown"},{"location":"About/Codebase/#javascript","text":"See JavaScript . The principal scripting language for web applications. It has evolved into a performant language with a beautiful syntax, capable of running on the server and in websites. Usage in this app This app uses JavaScript in the client only. We use it as a work horse which takes care of a copy of data from the database. It reacts to changes by integrating new bits of data into the existing state, a process that is called reducing .","title":"JavaScript"},{"location":"About/Codebase/#jsx","text":"See JSX . This is also JavaScript, but with a thin layer of syntactic sugar, by which you can present your code as a collection of React components . Usage in this app In this app we have dozens of JSX files, each containing exactly one component (with a few exceptions). Components are pieces of code that realize parts of the website that you can actually see, and often interact with. They are supported by sophisticated plumbing (dux, ducts) , which connects them to the global state of the app. The state is divided in sections, where individual duct connects such a section with several components. See Architecture for how this hangs together. The plumbing needs some specialized, technical functions, which are collected in the lib section of the app. One of the most crucial is memoization .","title":"JSX"},{"location":"About/Codebase/#python","text":"See Python . A general purpose scripting language with excellent data processing facilities. Usage in this app This app uses python (version 3.6.1+) for the web server. The web server itself is Flask , a light-weight framework for handling http(s) requests. We have added a set of controllers . The actual code there is quite lean, but when it comes to database access, the module db does the heavy lifting and tends to become uglier and uglier.","title":"Python"},{"location":"About/Codebase/#css","text":"See CSS . Styling the app has nightmarish overtones, because the concerns of style often cut right across the concerns of the components. There are several ways to control the resulting mess, and one of the best is to use the modern features of CSS. General usage Cascading style sheets are the ultimate way to paint the final look and feel of the website. By using flex boxes instead of tables we can make the app respond gracefully to changes in the size of the display without resorting to the bureaucracy of overdefining style properties. Note that our app does not use the HTML <table> element any more for aligning pieces of content. Usage in this app We use a lot of the CSS-3 features, including variables , and calc() . This lessens our need for a style sheet preprocessor such as SASS to 0%. Note especially how colour management has become easy: all colour definitions are in variables all colour definitions are in HSLA , which allows a very consistent definition of families of colours. Quote from Mozilla : One advantage of HSLA over RGB is that it is more intuitive: you can guess 1 2 3 at the color you want, and tweak it from there. It is also easier to create a set of matching colors (e.g., by keeping the hue the same, while varying the lightness/darkness and saturation). This is exactly what we do. See vars.css .","title":"CSS"},{"location":"About/Codebase/#shell","text":"See Shell . The shell is the interpreter of system level commands. Usage in this app Our app does not use it, but we use it to develop the app. All the development tasks, such as transpiling code, pushing code to GitHub, transporting databases to the production server are done by specialized frameworks. These frameworks must be steered by intricate commands with many options which are easily forgotten. That's why we have a build script. You have to pass it just the name of a task, and the script executes that task with all the sophistication needed.","title":"Shell"},{"location":"About/Codebase/#html","text":"See HTML . The core language of the web. Usage in this app Surprisingly, our code does not contain HTML any more. In JSX there are fragments that look like HTML, but that is exactly what it is, and real HTML it is not. When the browser encounters HTML material, it parses it and stores it in its memory in a certain standard representation: the DOM . But our server does not send HTML any more to the browser, except for a very first short page , that serves to load a bulk of style sheets and JavaScript into the browser. This JavaScript code builds and manipulates the DOM directly, without generating any formal HTML.","title":"HTML"},{"location":"About/Codebase/#json","text":"See JSON . A format to serialize JavaScript objects. General usage In web applications, the program logic happens at two separate places (at least): the server and the client. It is important that data can flow seamlessly from one programming context to the other. JSON achieves that. Usage in this app to send data from server to client configure the main development tools, such as Webpack for building and Mocha for testing.","title":"JSON"},{"location":"About/Codebase/#keeping-the-code-tidy","text":"There are three progressive levels of caring for your code. Level 1: code style Adopt a style guide and meticulously keep to it. It is hard, especially if you work in two syntactically and culturally diverse languages such as JavaScript and Python. Add CSS, Markdown and YAML to the mix, and you can feel the need for a next step. Yet this is the fundamental step, it cannot be skipped. Level 2: linters Linters are little programs that observe your code and check it for correctness and style, as far as that is possible without actually running the code. Usually, your editing environment runs them sneakily while you type or when you save, and give you unobtrusive but conspicuous feedback. It saves you a lot of round trips of compiling/building/running/staring at errors. Moreover, it gives you the feedback right where you are typing, so you do not have to lookup files and line numbers. Sometimes linters give you so much feedback that your heart sinks at the thought of going through all those cases and fix them all, even if you have a splendid IDE. That is where the next step comes in. Level 3: formatters Formatters have a lot in common with linters, but they fix the problems. Sometimes they parse your program with the parser of the language and then format the abstract syntax three they've got. That is the end of all style inconsistencies. Tools Here is an overview of tools used in developing this app. Formatters Formatters are not perfect, sometimes they produce code at which the linter balks, especially yapf is doing that. Luckily, you can selectively suppress certain kinds of transformations. language linter formatter JavaScript eslint prettier Python flake8 yapf Markdown remark prettier remark Editor or IDE? For projects like these, you need a good editing environment. IDEs The good old ones like Eclipse are not really suited to the JavaScript and Python environments. There are interesting modern ones such as GitHub's Atom modernized ones such as Microsoft's Visual Studio Code and commercial ones such as Webstorm . Editors You can also choose to work with a text editor, such as the free Vim or the commercial Sublime Text . Vim My choice has been Vim, since I use it from its start in 1991. These are the key reasons for which Vim stands out: it has a compositional command set, like Unix itself. By this you get all your (massive) editing chores done without much remembering and thinking. it has a rich ecosystem of plugins. By this you can turn Vim into an IDE. It is rock solid and performant. You can edit many small files and then some big ones, at the same time. You do not loose data. My Vim setup Just for the record, here is a piece of my .vimrc file (the configuration file, which draws in plugins, and customises the interface). You can find out more about the plugins by clicking on them, they are all GitHub repos: 1 call plug#begin () Plug 'morhetz/gruvbox' Plug 'fenetikm/falcon' Plug 'jelera/vim-javascript-syntax' Plug 'pangloss/vim-javascript' Plug 'mxw/vim-jsx' Plug 'hail2u/vim-css3-syntax' Plug 'nathanaelkane/vim-indent-guides' Plug 'othree/yajs.vim' Plug 'othree/javascript-libraries-syntax.vim' Plug 'scrooloose/nerdtree' Plug 'w0rp/ale' 1 call plug# end () An honourable mention for the ALE plugin. This is an asynchronous plugin that invokes linters for your files while you edit. The beauty is, that if you have installed the linters first outside Vim, ALE is smart enough to detect them and run them for you, asynchronously, and with zero configuration.","title":"Keeping the code tidy"},{"location":"About/Diagrams/","text":"Diagrams \u00b6 Architecture Authentication Business Components Dux Routing Workflow","title":"Diagrams"},{"location":"About/Diagrams/#diagrams","text":"Architecture Authentication Business Components Dux Routing Workflow","title":"Diagrams"},{"location":"About/Lessons/","text":"Lessons \u00b6 Because it took so long to develop this tool, and because it has grown so big, I started reflecting on the choices I've made, and the things I've learned. What follows can be read as a self-assessment of the development process. \"Best\" practices \u00b6 The tool has been built using modern, top-notch, popular frameworks and tools, such as React, MongoDb, Python, modern Javascript (ES6), and its documentation is in Markdown on Github. But it is a complex beast, and it will be hard for other developers to dive in. Developers that want to upgrade this tool, should be seasoned React developers, or they should be willing and have time to enter a steep learning curve. This approach - alternative approaches \u00b6 A quick glance at the statistics of the code base makes clear the amount of thought that has gone into the tool. I have asked myself the question: why do we need so much programming for such a mundane task? Is it really necessary to build something this big for it? The answer: to my best knowledge, yes, but I'm open to be contradicted. What could we have done differently? More classical framework: Django We could have used Django, but then we would have missed the opportunity to engage in real modern web application programming. The Javascript world is brewing with dynamics and innovation, and we would have skipped all that. Besides, also a Django application would contain a considerable amount of custom programming. Generic app/framework We could have used an app like Trello or Basecamp, or even GitHub itself, or a content management system that has not been designed to support a specific workflow like this. We would have had several disadvantages: an extra dependency on a Silicon-Valley service the struggle to customize the service the need to instruct the users to use the system according to the intended workflow. This approach: from the ground up What we have now, is something that has been built from the ground up. We have total control over all aspects of the app, its data, and the servers at which it runs. We can connect it to other apps, define new microservices around it quite easily. So, the price has been high, much higher than I expected (and promised), but I think we've got something to build on. The learning curve (for what it is worth) \u00b6 When I started writing, I had the experience of developing SHEBANQ . At first, the tools I used for SHEBANQ were a model for developing this contrib tool. From the start it was clear that the contrib tool needed more profound underpinnings. I started out to write those underpinnings myself, programmed in pure, modern Javascript. That worked to a certain extent, but I doubted whether it was strong enough to carry the weight of the full app. After a while I started a big search, trying Google's Angular, Facebook's React, and various solutions that combined these frameworks in so-called full-stack setups, such as Meteor and MERN . Here is a selection of 10 lessons I learned during what followed. Lesson 1: exit full-stack Without any experience in React or Angular, it was simply too hard to get started with any of the combined solutions. They were cutting edge, evolving in a rapid sequence of versions, and examples on the internet almost never worked because of being outdated already. Without having an understanding already of the intention, I found it impossible to overcome the discrepancies between theory and practice. Lesson 2: Angular versus react I had to choose between Angular and React, and I choose React because: it had more limited goals, combined better with the other parts of the app, was more popular among developers, and was a natural continuation of the work I had already done in my self-made framework. Angular had just moved to version 2, the learning curve had steepened, and I heard developers say that at first it worked like a charm, but that it was very hard to move beyond tutorial level. Lesson 3: Beyond vanilla React React was not enough. After achieving a lot of functionality, I reached a stage where I encountered bugs that I could not solve. My app became too big for vanilla React, and I needed Redux , an add-on that provides an app-wide data structure (central state). Lesson 4: Grokking Redux To get started with Redux I needed a course. Without it, I could not get to grips with it. I watched 30 online video's by the maker of it, Dan Abramov, also developer at Facebook for React. After the videos I could not remember how I could NOT understand it. Lesson 5: Idiomatic Redux and code organization After using Redux throughout the app, the code started to look much better, and I got much better control over the workings of the app. On the internet, this is called: \"idiomatic Redux\". It is a kind of Javascript that old fashioned web programmers hardly recognise as Javascript! It is very important to follow up all the best practices that are advised here, because the performance and correctness of the app depend crucially on them all. What also helped is a hint by Erik Ras, creator of redux-form , to organize your redux code in files: the concept of ducks . Lesson 6: CRUD layer Some operations are so ubiquitous, that you have to program them once and for all: create/update/delete/read of database items (CRUD), all subject to user permissions. All things that are particular to specific tables and fields must be specified as configuration, all actions must read the configs and carry out generic code. Lesson 7: Custom Workflow layer You cannot do all the business logic this way, without overloading your nice generic system. So the app has two layers of abstraction: level 1 for CRUD, level 2 for additional workflow. It is level 2 that your users will interact with most. Lesson 8: Hooks and config for workflow instead of applying workflow functions in an add-hoc manner, you should add hooks at key points of the CRUD code. Only at those hooks the workflow functions are given a say in the matter. These workflow functions should again be programmed in a generic way, with the particulars moved to an other level of configuration. Lesson 9: Build tools: Webpack To be able to run the app and to ship it to the outside world, your build-system should be top-of-the bill. I started with just a little script of my own to massage the code into a web-app bundle. Then I moved to Gulp and used it for a long time. I saw that the React people were using Webpack all the time, but I could barely understand Webpack, let alone get it working. In the end, I decided that I wanted Webpack no matter what, and got it working, including all the niceties it had to offer. The result: for production I can ship very compact code, in such a way that the client web browsers load it very fast; for development, I have a very easy and short feedback loop: when I save my code, it is automatically rebuilt, and in a fraction of a second the updated modules reload in the browser, and when there are errors, I get pointed to the exact line in the code where it went wrong. Lesson 10: Trust React React is really well-designed, it does not let you down, you do not have to look under the hood, and it gives very helpful debug messages. The contrib app is growing and contains dozens of components, but the performance remains excellent. Before I used idiomatic Redux, the performance was worrying at times.","title":"Lessons"},{"location":"About/Lessons/#lessons","text":"Because it took so long to develop this tool, and because it has grown so big, I started reflecting on the choices I've made, and the things I've learned. What follows can be read as a self-assessment of the development process.","title":"Lessons"},{"location":"About/Lessons/#best-practices","text":"The tool has been built using modern, top-notch, popular frameworks and tools, such as React, MongoDb, Python, modern Javascript (ES6), and its documentation is in Markdown on Github. But it is a complex beast, and it will be hard for other developers to dive in. Developers that want to upgrade this tool, should be seasoned React developers, or they should be willing and have time to enter a steep learning curve.","title":"\"Best\" practices"},{"location":"About/Lessons/#this-approach-alternative-approaches","text":"A quick glance at the statistics of the code base makes clear the amount of thought that has gone into the tool. I have asked myself the question: why do we need so much programming for such a mundane task? Is it really necessary to build something this big for it? The answer: to my best knowledge, yes, but I'm open to be contradicted. What could we have done differently? More classical framework: Django We could have used Django, but then we would have missed the opportunity to engage in real modern web application programming. The Javascript world is brewing with dynamics and innovation, and we would have skipped all that. Besides, also a Django application would contain a considerable amount of custom programming. Generic app/framework We could have used an app like Trello or Basecamp, or even GitHub itself, or a content management system that has not been designed to support a specific workflow like this. We would have had several disadvantages: an extra dependency on a Silicon-Valley service the struggle to customize the service the need to instruct the users to use the system according to the intended workflow. This approach: from the ground up What we have now, is something that has been built from the ground up. We have total control over all aspects of the app, its data, and the servers at which it runs. We can connect it to other apps, define new microservices around it quite easily. So, the price has been high, much higher than I expected (and promised), but I think we've got something to build on.","title":"This approach - alternative approaches"},{"location":"About/Lessons/#the-learning-curve-for-what-it-is-worth","text":"When I started writing, I had the experience of developing SHEBANQ . At first, the tools I used for SHEBANQ were a model for developing this contrib tool. From the start it was clear that the contrib tool needed more profound underpinnings. I started out to write those underpinnings myself, programmed in pure, modern Javascript. That worked to a certain extent, but I doubted whether it was strong enough to carry the weight of the full app. After a while I started a big search, trying Google's Angular, Facebook's React, and various solutions that combined these frameworks in so-called full-stack setups, such as Meteor and MERN . Here is a selection of 10 lessons I learned during what followed. Lesson 1: exit full-stack Without any experience in React or Angular, it was simply too hard to get started with any of the combined solutions. They were cutting edge, evolving in a rapid sequence of versions, and examples on the internet almost never worked because of being outdated already. Without having an understanding already of the intention, I found it impossible to overcome the discrepancies between theory and practice. Lesson 2: Angular versus react I had to choose between Angular and React, and I choose React because: it had more limited goals, combined better with the other parts of the app, was more popular among developers, and was a natural continuation of the work I had already done in my self-made framework. Angular had just moved to version 2, the learning curve had steepened, and I heard developers say that at first it worked like a charm, but that it was very hard to move beyond tutorial level. Lesson 3: Beyond vanilla React React was not enough. After achieving a lot of functionality, I reached a stage where I encountered bugs that I could not solve. My app became too big for vanilla React, and I needed Redux , an add-on that provides an app-wide data structure (central state). Lesson 4: Grokking Redux To get started with Redux I needed a course. Without it, I could not get to grips with it. I watched 30 online video's by the maker of it, Dan Abramov, also developer at Facebook for React. After the videos I could not remember how I could NOT understand it. Lesson 5: Idiomatic Redux and code organization After using Redux throughout the app, the code started to look much better, and I got much better control over the workings of the app. On the internet, this is called: \"idiomatic Redux\". It is a kind of Javascript that old fashioned web programmers hardly recognise as Javascript! It is very important to follow up all the best practices that are advised here, because the performance and correctness of the app depend crucially on them all. What also helped is a hint by Erik Ras, creator of redux-form , to organize your redux code in files: the concept of ducks . Lesson 6: CRUD layer Some operations are so ubiquitous, that you have to program them once and for all: create/update/delete/read of database items (CRUD), all subject to user permissions. All things that are particular to specific tables and fields must be specified as configuration, all actions must read the configs and carry out generic code. Lesson 7: Custom Workflow layer You cannot do all the business logic this way, without overloading your nice generic system. So the app has two layers of abstraction: level 1 for CRUD, level 2 for additional workflow. It is level 2 that your users will interact with most. Lesson 8: Hooks and config for workflow instead of applying workflow functions in an add-hoc manner, you should add hooks at key points of the CRUD code. Only at those hooks the workflow functions are given a say in the matter. These workflow functions should again be programmed in a generic way, with the particulars moved to an other level of configuration. Lesson 9: Build tools: Webpack To be able to run the app and to ship it to the outside world, your build-system should be top-of-the bill. I started with just a little script of my own to massage the code into a web-app bundle. Then I moved to Gulp and used it for a long time. I saw that the React people were using Webpack all the time, but I could barely understand Webpack, let alone get it working. In the end, I decided that I wanted Webpack no matter what, and got it working, including all the niceties it had to offer. The result: for production I can ship very compact code, in such a way that the client web browsers load it very fast; for development, I have a very easy and short feedback loop: when I save my code, it is automatically rebuilt, and in a fraction of a second the updated modules reload in the browser, and when there are errors, I get pointed to the exact line in the code where it went wrong. Lesson 10: Trust React React is really well-designed, it does not let you down, you do not have to look under the hood, and it gives very helpful debug messages. The contrib app is growing and contains dozens of components, but the performance remains excellent. Before I used idiomatic Redux, the performance was worrying at times.","title":"The learning curve (for what it is worth)"},{"location":"About/News/","text":"News \u00b6 2019-07-06 \u00b6 Consolidation is implemented: upon (de)selection of a contribution, a consolidated document is made and stored in the database. This record can be viewed by authorized people. Overhaul of documentation. 2019-05-03 \u00b6 The overview page lead to a server error in some circumstances. The critical error is fixed, maybe there is an other root cause to discover. 2019-04-24 \u00b6 The info page with tables that give an overview of the DARIAH contributions now have a button to download the overview to Excel. The Excel data is based on the same data as the overview. The format is csv (technically: in utf-16-le with BOM mark). This format can be opened without questions by Excel and Numbers. 2019-03-04 \u00b6 Bottle has been replaced by Flask also online 2018-12-11 \u00b6 Bottle has been replaced by Flask (not yet online) 2017-12-14 \u00b6 The workflow functions have developed into a serious engine, that can be configured from within the data model. Templates are the prime consumers of this information. The review workflow is implemented. Not yet in all fullness, but the basics such as advice by the first reviewer, decision by the second reviewer work, as well as marking a successfully reviewed contribution as DARIAH approved. For Python, Javascript and Markdown I have started using code formatters. So the exact formatting of all these sources are not my doing, but the work of carefully configured software tools. That brings a bit more consistency in the sources. I have done a lot of documentation updates. 2017-09-22 \u00b6 There is now a templating mechanism in place by which I can design the display of detail records and related records within the display of another record. I use this to customise the criteriaEntry records within an assessment, as well as the contribution record within an assessment. Specific workflow code has factored out of the generic code, both in the client app as well as in the server modules. The server documentation has been updated. Bugs have been fixed, and probably more have been introduced. 2017-09-21 \u00b6 The presentation of assessment is developing to much more useful layouts. Lots of issues of an information-logistic nature had to be solved. Talking of which: the conversion of legacy content has now improved. The import is repeatable, and will not disturb data that has been added later, using the contribution tool itself. Read more . 2017-07-01 \u00b6 Functionally \u00b6 The app can now create assessments and populate an assessment with the relevant criteria based on the type of the contribution being assessed and the current package. A version of a few dozen real world criteria and their scoring has been added to the database. Technically \u00b6 We count the lines of code in all formats used. See the codebase page. Many changes in the table area: lists and items and filters. It has become more generic. Master-detail relations can be defined and utilized. New custom business logic is being introduced. The reducers work better, and leave more parts of the state untouched if they have not changed. The replacement of lodash/merge by Immutability-Helper plays a big part in this. Merging and reducing are now being unit-tested. We have put the Mocha test framework to use and built hundreds of tests. The documentation has been reworked extensively. 2017-05-19 \u00b6 Fixed subtle issues in form entry: FieldEdit and InputMulti .","title":"News"},{"location":"About/News/#news","text":"","title":"News"},{"location":"About/News/#2019-07-06","text":"Consolidation is implemented: upon (de)selection of a contribution, a consolidated document is made and stored in the database. This record can be viewed by authorized people. Overhaul of documentation.","title":"2019-07-06"},{"location":"About/News/#2019-05-03","text":"The overview page lead to a server error in some circumstances. The critical error is fixed, maybe there is an other root cause to discover.","title":"2019-05-03"},{"location":"About/News/#2019-04-24","text":"The info page with tables that give an overview of the DARIAH contributions now have a button to download the overview to Excel. The Excel data is based on the same data as the overview. The format is csv (technically: in utf-16-le with BOM mark). This format can be opened without questions by Excel and Numbers.","title":"2019-04-24"},{"location":"About/News/#2019-03-04","text":"Bottle has been replaced by Flask also online","title":"2019-03-04"},{"location":"About/News/#2018-12-11","text":"Bottle has been replaced by Flask (not yet online)","title":"2018-12-11"},{"location":"About/News/#2017-12-14","text":"The workflow functions have developed into a serious engine, that can be configured from within the data model. Templates are the prime consumers of this information. The review workflow is implemented. Not yet in all fullness, but the basics such as advice by the first reviewer, decision by the second reviewer work, as well as marking a successfully reviewed contribution as DARIAH approved. For Python, Javascript and Markdown I have started using code formatters. So the exact formatting of all these sources are not my doing, but the work of carefully configured software tools. That brings a bit more consistency in the sources. I have done a lot of documentation updates.","title":"2017-12-14"},{"location":"About/News/#2017-09-22","text":"There is now a templating mechanism in place by which I can design the display of detail records and related records within the display of another record. I use this to customise the criteriaEntry records within an assessment, as well as the contribution record within an assessment. Specific workflow code has factored out of the generic code, both in the client app as well as in the server modules. The server documentation has been updated. Bugs have been fixed, and probably more have been introduced.","title":"2017-09-22"},{"location":"About/News/#2017-09-21","text":"The presentation of assessment is developing to much more useful layouts. Lots of issues of an information-logistic nature had to be solved. Talking of which: the conversion of legacy content has now improved. The import is repeatable, and will not disturb data that has been added later, using the contribution tool itself. Read more .","title":"2017-09-21"},{"location":"About/News/#2017-07-01","text":"","title":"2017-07-01"},{"location":"About/News/#functionally","text":"The app can now create assessments and populate an assessment with the relevant criteria based on the type of the contribution being assessed and the current package. A version of a few dozen real world criteria and their scoring has been added to the database.","title":"Functionally"},{"location":"About/News/#technically","text":"We count the lines of code in all formats used. See the codebase page. Many changes in the table area: lists and items and filters. It has become more generic. Master-detail relations can be defined and utilized. New custom business logic is being introduced. The reducers work better, and leave more parts of the state untouched if they have not changed. The replacement of lodash/merge by Immutability-Helper plays a big part in this. Merging and reducing are now being unit-tested. We have put the Mocha test framework to use and built hundreds of tests. The documentation has been reworked extensively.","title":"Technically"},{"location":"About/News/#2017-05-19","text":"Fixed subtle issues in form entry: FieldEdit and InputMulti .","title":"2017-05-19"},{"location":"About/Stats/","text":"cloc github.com/AlDanial/cloc v 1.82 T=1.18 s (167.5 files/s, 34200.8 lines/s) Language files blank comment code JavaScript 34 464 394 9698 Markdown 39 2709 0 8763 JSX 58 307 45 5257 Python 15 605 306 4473 YAML 20 192 12 3978 CSS 18 82 22 1625 Jupyter Notebook 2 0 636 249 Bourne Shell 6 45 63 201 JSON 2 0 0 173 HTML 4 3 0 117 -------- -------- -------- -------- -------- SUM: 198 4407 1478 34534","title":"Stats"},{"location":"Client/Components/","text":"Components (React) \u00b6 These are the React components, that make up the part of the app that is visible in the browser. They lean on the dux that work for them in the background. Click on the names in the titles to view their source code on GitHub. Standard props \u00b6 Components get properties as input (we call them props ). For each component we mention the props they expect and what type of data they represent. However, some props occur over and over again, and we name them consistently. Here is a list of those props and their types. When we mention these props later on, we omit the types. List of standard props name type description alter object a slice of the state from getAltSection ; Group of settings for components with alternative renderings: these settings tell which alternative has been chosen for each of those components; alterSection string name of a section of the alter state; such a section contains the choice of alternative for a bunch of components that are relevant to the present component; each component that requests data from alter only gets data for a single section; in this way components will not be dependent on too big a part of the state; those dependencies may cause spurious re-renderings; alterTag string name that lives within a section of the alter state; this functions as the address of a component that needs to expand or collapse; the triggering event will change the alter state, keyed by alterSection and then by alterTag ; amounts object for a faceted filter: contains the amount of items that match each facet; see computeFiltering ; children components a special prop defined by React itself; it contains the material that has been put in the component; you find it in the render function of the component; it is everything between <Component> and </Component> ; className string a class name to be put in the top level element of the rendered component; compact bool whether the component should minimize the real estate on the screen that it uses; detailFragments array of object the information on the basis of which the detail records of an item can be rendered; every entry in the array corresponds to a detail table that may contain detail records of the master record that is being dealt with; ultimately computed by makeDetails and then passed to child components; dirty bool whether a field or item has been changed on the interface but not saved to the database dispatch function this function belongs to the store that holds the state; it is generally injected into the props of a component by connect ing a component to the store; this only happens if connect() is called with zero or one argument (the MapDispatchToProps argument should be undefined); the dispatch function enables the component to trigger an action that changes the state; where you would call setState() in vanilla-React you put dispatch(action) if your app uses Redux; eId string the MongoDB id of an entity that is being dealt with; * field string ; the name of a field that is being dealt with; fieldFragments array an array with instructions per field how to render it; ultimately computed by makeFields and then passed to child components; filtered bool whether the list should be accompanied by filters; the specification of the filters themselves is in the data model ; fields objects defines a subset of all fields: these are the fields that the component has to deal with; filteredAmount number the number of items that pass all filters; see computeFiltering ; filteredAmountOthers object for each filter, the amount of items that passes all filters except that one filter; see computeFiltering ; filterField string the name of the field that the current filter is acting upon; (as in the data model ; filterRelField string the name of the related field that the current filter is acting upon; this is relevant for fields that point to a related table: you can filter on the values of a specific field in the related table; (as in the data model ; filterId number the sequence number of a specific filter which identifies it among all filters for the same table; filterLabel string the user-facing name of the filter; filters object a slice of the state from getFilters ; contains the actual filter settings, i.e. what the user has entered in search boxes and which facets the user has clicked; organized by table and then by filterTag and then by filterId ; filterSettings object a slice of the state, sub-slice of filters , corresponding to the filters of a single filterTag of a single table ; filterSetting object or string a slice of the state, sub-slice of filterSetting , corresponding to a single filter, identified by filterId ; whether this is an object or a string, depends on the nature of the filter: for a Fulltext filter it is a string (the search text), for a ByValue filter it is an object, containing the status (boolean) of all its facet checkboxes; filterTag string identifies a group of filters for a single table; tables may have multiple incarnations; a table can be a main table, but also a detail table for a specific record; the filters for a table when it displays details may be distinct from the filters of the same table when it is displayed as the main table; we separate those cases by means of a filterTag prop; fixed boolean when modifying records, this attribute can veto the change; it indicates that the record needs to be kept immutable; item array the English word for the kind of thing in question. item[0] is the word in the singular, item[1] is the word in the plural. linkField string when rendering a list of records that are details of some master record, this is the field of the detail records that holds the masterId ; in this way the detail record links to its master record; when the component creates a new detail record, it will pre-fill this field with the current masterId ; listIds array of string a sequence of strings which are essentially MongoDB identifiers of entities in a table; components that display lists use this prop to determine which entities must be actually appear on the screen and in what order; see also the prop filteredIds ; masterId string when rendering a list of records that are details of some master record, this holds the MongoDB id of the master record; masterTable string when rendering a list of records that are details of some master record, this holds the name of the table in which the master record resides; me object a slice of the state from getMe ; the information about the currently logged-in user, fetched from the server; mode string either list or grid ; whether the list of items should render as a list of expandable headings, or as a grid with full field information; myValues object ultimately extracted from the tables slice of the state; it contains the values of the fields of the entity that is being dealt with; perm object Holds permissions for a record: whether deleting is allowed, and per field whether updating is allowed; select string sometimes a list is fetched as a whole, sometimes only my own records are displayed and yet other times only records that are the details of some master record must be shown; this property indicates which is which; settings object a slice of the state from getSettings ; settings are pieces of custom information that are relevant to many components of the app; table string name of the table that the component must deal with; submitValues function a callback that is used to save form values to the database; used for components that supply edit controls for form values: they can call submitValues after a change or upon loss of focus; it is basically the handleSubmit from Redux-Form, with a specific first argument passed ( toDb ) that saves values to the database; tables object a slice of the state from getTables ; all data that comes from database tables; organized by table name; for each table there is spec information and actual entity data; win { width number , height number } a slice of the state from getWinDim ; contains the physical dimensions of the window at any time. workflow object slice of the state that contains workflow information. roots \u00b6 main \u00b6 See main . connected via roots Task Entry point of the client side app. Contains the routing , wrapped in a Root component, that sets up the store in which the central state lives. Root \u00b6 See Root . presents roots Props Standard props : children Task Top-level wrapping component to set up the central store. It does so by configuring the store, calling configureStore , and passing it to the special Provider component of Redux. Then it wraps the whole remaining app in a Window component for detecting some global UI events. settings \u00b6 Tooltip \u00b6 See Tooltip . (life cycle) connected via settings Task A dynamic tooltip, based on CSS3 techniques. The tooltip is initially put as content with an absolute position and with opcaity 0. A lot can happen on the page: scrolling, re-rendering of components, and they may all cause changes in the positions of elements. So the position of the invisible tooltip is not where it should be, most of the time. That does not matter, as long as we adjust it just in time, before it becomes visible. When that happens, the positioning of the tooltip will be adjusted to the current position of the element. The trigger to make a tooltip visible is a focus event or a mouse-over event. It is possible to switch all tooltips off. This is governed by showTooltips , a boolean setting in settings . Apart from this, the tooltip machinery does not use special React/Redux mechanisms. All is done at DOM level and with CSS3. Props Standard props : settings Specific props: name type description tip string or fragment the content of the tooltip. Any content will do at string the position of the tooltip relative to its target. Should be one of top bottom left right focusOnly boolean whether the tooltip should be triggered by focus actions only, or hovering as well. Handy for text input elements ( <input type=\"text\"> or <textarea> ) if you want to show editing help, but only if the user is actually typing in the field className string an additional CSS class to pass on to the <Tooltip> outermost element classTip string an additional CSS class to pass on to the element that holds the tooltip classArrow string an additional CSS class to pass on to the element that holds the little arrow of the tooltip. Positioning The positioning algorithm looks whether there is sufficient room for the tooltip. If not, it will change top to bottom and vice versa, and left to right` and vice versa. It will also shift the tooltip so that it does not extends beyond the page. TooltipSwitch \u00b6 See TooltipSwitch . connected via settings Props Standard props : settings dispatch Task Switches tooltips on or off, globally. workflow \u00b6 ScoreBox \u00b6 See ScoreBox . presents workflow Props Specific props: name type description score object contains several score quantities, relevant to the scoring of assessments Task The server computes the scores, and delivers it as workflow attributes with contribution and assessment records. Displays the score of an assessment, and can be expanded to show a derivation of that score. It should be used in templates that have access to workflow attributes. See the mainAction templates of contrib and assessment . WorkflowInfo \u00b6 See WorkflowInfo . presents workflow Props name type description resets object information about the (manual) workflow resets after the last startup of the webserver stats object contains several statistical quantities about the workflow attributes total number the number of records that have workflow information associated with them Task Present overview information about the workflow information that is currently in use. Offer a control to reset the workflow information (i.e. recompute it). See manageWorkflow . me \u00b6 Login \u00b6 See Login . (life cycle) connected via me Props Standard props : me dispatch Task The main task of Login is to fetch the current authentication status: is there an authenticated user, and if so, what is his/her name? SubApp \u00b6 See SubApp . presents win Props Standard props : me table children Specific props: name type description routes components these are objects passed by React-Router . From this the navigation route that the user has followed to arrive here, can be read Task This is one of the components just below App . It contains a set of panes and navigation links to main subcomponents to display in those panes. Most of those subcomponents are linked to a main table, which is passed in the table prop. win \u00b6 App \u00b6 See App . connected via win Props Standard props : children win Task As far as the logic of the web page is concerned, this is the top level component. App is always in view and consists of the top navigation bar with logo, Login ; Notification ; static links to documentation. It is only used to display the height and the width somewhere on the screen. Window \u00b6 See Window . (life cycle) connected via win Task Detects window resize events and passes the resulting height and width of the main window to the state. On mounting an event listener is installed, and on unmounting the event handler is removed. During resizing, the frequency of emitted events is throttled to one per second, in order to prevent screen flicker. docs \u00b6 Doc \u00b6 See Doc . presents docs Props Specific props: name type description location object from this object the property pathname will be read, which will be split into directory, file and extension parts. The extension is used to switch to the component for that type of documents Task Handles the display of documents. Depending on the type of document (markdown, html, pdf) it delegates work to specialized document components: DocMd , DocHtml and DocPdf . DocHtml \u00b6 See DocHtml . presents docs Props Specific props: name type description docDir string the directory of the document container docName string the filename of the document container docExt string the extension of the document container Task Displays an HTML document by linking to it in an IFRAME. DocMd \u00b6 See DocMd . (life cycle) connected via docs Props Standard props : alter alterSection dispatch name type description docName string the name of the document. text string from getDoc , the raw content of the document Task Show Markdown text, coming from files on the server. The conversion to HTML is done client side, and the user gets a control to switch between Markdown source and formatted HTML. A function RouterLink is defined to wrap local links into Link components when transforming the markdown to html. It makes it possible to write Markdown documents with internal links to this application. A full link (with protocol http ( s ) is translated to a plain HTML a element, so clicking it will leave this application. DocPdf \u00b6 See DocPdf . presents docs Props Specific props: name type description docDir string the directory of the document container docName string the filename of the document container docExt string the extension of the document container Task Displays a PDF document by linking to it in an OBJECT. iOS On iOS this does not work well, only the first page of the PDF gets shown, we work around it by just displaying a link to open the PDF in a new tab. We only do that when we detect an iOS browser. notes \u00b6 Notification \u00b6 See Notification . (life cycle) connected via notes Props Standard props : dispatch Specific props: Injected The following properties are injected from the state by getNotes : name type description messages array of objects the list of notifications that have been issued since the beginning of the session or since the last time that the user has cleared the messages busy number the amount of asynchronous actions that are still pending show boolean whether the panel should be hidden lastMsg number index of last message lastNote number index of last notable message lastKind string kind of last notable message, one of error , warning , special . Only the kind info is non-special. When the notifications are displayed, the panel will be scrolled to the last notable message if there is one, otherwise to the last message. Task Component that receives notifications and displays them in a little panel with fixed position on the screen. The panel is hidden by default and pops up if there is an important notification. The user can click it away and also clear the notifications. There is also a progress indicator, a little circle fixed at the top right corner of the screen. It hints at the current status of asynchronous operations. A click on it will show the notifications panel. tables \u00b6 EditControl \u00b6 See EditControl . Task A component that shows the current edit status of a record. It is presented as a button that can be clicked to submit and save a form. It can only be used as descendant of a redux-form -enabled <form> -carrying component. See also EditStatus . Uses the library function editControl . EditDelete \u00b6 See EditDelete . presentational Props Standard props : perm workflow fixed Specific props: name type description keep object per table the entities that are related with the record to delete; if this is not empty the record cannot be deleted button string CSS class name for styling the button onClick event handler called when the button is clicked, should trigger the delete action Task Button to delete the record that is displayed with it. The component is rather dumb, it needs to be passed an onClick handler that will perform the delete action. EditHelp \u00b6 See EditHelp . Props Standard props : dirty Specific props: name type description type string the type of field that is documented Task Information panel below input fields and markdown fields, telling how to save and cancel, and showing the markdown constructs. EditInsert \u00b6 See EditInsert . Props Standard props : settings me tables select masterTable masterId perm fixed item Specific props: name type description nItems number amount of current items in the list in which the new item is to be inserted button string CSS class name for styling the button onInsert event handler called when the button is clicked, should trigger the insert action Task Button to insert a blank record into the currently displayed table. The component is rather dumb, it needs to be passed an onInsert handler that will perform the insert action. EditStatus \u00b6 See EditStatus . Task A component that shows the current edit status of a record. It is presented as a <span> that looks exactly as an EditControl , but it cannot be clicked to submit and save values. It can be used everywhere, and it is itself enhanced by redux-form . Because it is outside a <form> context, submitting will not work. Uses the library function editControl . FieldEdit \u00b6 See FieldEdit . connected via tables Props Standard props : alter tables table eId field dispatch submitValues Specific props: name type description allowed array entity-ids that are the allowed elements when the field is a multiple choice field Note In most cases a multiple choice is between members of a value list or related table, but sometimes we want to restrict the set of choices further, especially when we are offering a choice in a detail record. Then the master record might contain information that constrains the option for some fields in the detail records. For example, the criteriaEntry record contains a multiple choice field to choose between a bunch of scores. However, not all scores of the score table are valid choices, only those scores that belong to the criteria record referred by the criteriaEntry record. ...props There are many more props that get passed to FieldEdit . They have been injected by the wrapper redux-form() into ItemForm , the parent of this component, and they will be passed on to Field and FieldArray , so that they can do their magic. Task Edit control for an editable field. Depending on the type of the field and the multiplicity, it presents the right control. Basically, this component produces one or more Field or FieldArray components (which are provided by redux-form . Note that we do not pass the actual values to these components. They know how to get the current values from the state, and what actions must be dispatched to change them. However, both <Field /> and <FieldArray /> still do not actually present the edit control. They only do the plumbing. For the actual presentation, you can plug in a component of choice. We will use <input type=\"...\" /> , <textarea>...</textarea> elements and our own custom component RelSelect for multi-select controls. We enhance textareas by offering markdown previews of their content. See MarkdownArea . We wrap multiple *input*s in InputMulti and single inputs in Input . The extra level of wrapping of these presentational components is needed for showing validation errors. Problems solved In order to get everything working correctly, two problems had to be solved. Both turned out to be related to Redux-Form. The component that you pass to the component prop of Field and FieldArray must not be dynamically composed in the render() function that produces Field(Array) . Because in that case, the Field(Array) is re-rendered too often, and effect for the user is that he loses focus after entering the first character, which is very annoying. So, the value for component must be a static function. But what if this function needs dynamically determined arguments? How can they be passed to it? The solution is simple: pass them as props to Field(Array) , and they will be passed on to the component function by redux-form. This is actually documented in the redux-form docs. You need this , section 2. A stateless function You must define the stateless function outside of your render() method, or else it will be recreated on every render and will force the Field to re-render because its component prop will be different. If you are defining your stateless function inside of render(), it will not only be slower, but your input will lose focus whenever the entire form component re-renders. and this : Any custom props passed to Field will be merged into the props object on the same level as the input and meta objects. When navigating between forms for several records, the onChange callback, that should be bound to the proper form, becomes bound to the wrong form. As far as I can see, all other things work as expected, so it was difficult to see why this occurred. The explanation is in a GitHub issue . Summarized: the construction of the onChange function is effectively memoized. It is determined upon mounting of the component, but not on updating it. The workaround is easy: add an extra key property to the form. Another cause for the same problem I encountered in InputMulti , where I had memoized the callbacks for adding and removing values to/from a sequence. FieldRead \u00b6 See FieldRead . connected via tables Props Standard props : settings tables table myValues field Task Presents the value(s) of a read-only field, based on initial values . Note that value of type textarea will be rendered as formatted markdown. FieldSet \u00b6 See FieldSet . presents tables Props Standard props : submitValues Specific props: name type description input object contains the attribute onChange by which the form value of this field can be changed widget function a function that when passed a handler, will return a React fragment. When this fragment receives a click, the event handler will be called setValue any value the value that will be passed to the handler of widget , when it receives a click Task This is a form input component meant to be passed to a Field component, like Input . But unlike an Input , it only handles a click event, upon which it will change the value in the field to setValue , and save the form to the database. Input \u00b6 See Input . presents tables Props Standard props : submitValues Specific props: name type description meta object contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? input object contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> type string the type of <input type=\"...\" /> . It will go to the place of the dots Task Shows an <input type=\"...\" /> control, and shows validation errors if the value entered by the user does not validate. It is a controlled component . InputMulti \u00b6 See InputMulti . presents tables Props Standard props : submitValues table eId fields Specific props: name type description componentSingle function the edit component that has to be rendered multiple times validateSingle function validation function. Takes a value and return undefined if all is well, and otherwise a reason why not normalizeSingle function transforms the entered value into a normalized value for saving fields array the names of the individual fields. If the collective name of this field is foo , than this array contains foo[0] , foo[1] , etc., as many as their are values. These names are just strings meta object contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? ...props There are many more props that must be passed to Field . They have been injected by the wrapper reduxForm() into ItemForm , the uncle ( InputMulti is passed as attribute to Field which is a child of FieldEdit ) of this component, and they are just passed on to Field and FieldArray , so that they can do their magic. Task Renders a sequence of Field components on behalf of a FieldArray component. There are controls to remove values, and to add fresh, empty values. Validation and normalization are done per individual Field . It is a controlled component . Insert \u00b6 See Insert . (life cycle) connected via tables Props Specific props: name type description thing string English name for the thing to insert Task Button to insert a blank record into a table. Unlike EditInsert , this does not have to be a currently displayed table. After insertion the app will navigate to the table in which the item has been inserted, and it will open the freshly created item. ItemAction \u00b6 See ItemAction . connected via tables Props Standard props : settings tables table eId linkField fieldFragments dispatch name type description handleSubmit function a function that is invoked when the form is submitted. This function is passed from redux-form and handles all the form submission machinery. See ItemEdit Injected props These are all the properties that ItemForm gets from its parent and from its connection with the state. But we wrap ItemForm in reduxForm() and this will inject a number of other properties into it. We list the few that we visibly use. There are more injected properties, and these we pass carefully on to other components. Task Manages the display of a single record, but only as far as an ActionTemplate has been provided for that table. The action template may contain controls that modify fields and save them to the database, exactly as ItemEdit . The component does not show save and reset buttons. It is meant for controls that save changed values on their own. This component is meant for stuff that needs to be present both in read-only view and in edit-view. Using templates This component uses applyEditTemplate to see whether there is an action template defined in Templates . If yes, that template will be applied, if no, nothing will be rendered. ItemContainer \u00b6 See ItemContainer . (life cycle) connected via tables Props Standard props : settings tables table eId filters dispatch Task Container for a single record in a table. This component is responsible for fetching the item data from the database (if needed), but not form input. ItemDetails \u00b6 See ItemDetails . connected via tables Props Standard props : alter alterSection tables table eId filters detailFragments dispatch Task Presents a list of detail items of a master record. ItemEdit \u00b6 See ItemEdit . connected via tables Props Standard props : tables table eId fieldFragments dispatch Specific props: name type description nextAlt function this function can be used to switch this component from read-only view to edit view and back. It will be passed on to the widget that also has the edit controls for submitting and resetting the form Injected props These are all the properties that ItemForm gets from its parent and from its connection with the state. But we wrap ItemForm in reduxForm() and this will inject a number of other properties into it. We list the few that we visibly use. There are more injected properties, and these we pass carefully on to other components. name type description dirty boolean whether the form contains changed, unsaved values in any of its fields. invalid boolean whether the form contains invalid, values in any of its fields. error object object that contains the reasons for validation errors submitting boolean whether a submit action of the form is pending reset boolean a function that can reset the form. Resetting means: changing all edited values back to the initialValues handleSubmit function a function that is invoked when the form is submitted. Two kinds of validation synchronous: on every keystroke, the current value will be subjected to a validation function on submit: the submitted values will be validated on the server, and if that fails, the reasons for failure will be reported in exactly the same way as for synchronous validation. handleSubmit This function is passed from redux-form and handles all the form submission machinery. It also calls a function that you can pass to it as first argument. We pass it our toDb(table, eId, mod) function. This is a function that takes a values object, and calls mod(table, eId, values) , where mod is the function that dispatches a server action: the values are sent to the server, where they are used to update the record eId in table . Task Manages the display and editing of a single record. It is only used if there are editable field. If that is not the case, ItemRead is being used. We do this to avoid to invoke the costly machinery of editable forms when it is not needed. Buttons The component also shows save and reset buttons (if appropriate). Readonly and Edit view The component has two render modes: read-only view and edit-view. When a user has edited the form, he can switch to the read only view to see the result. In read-only view, markdown fields are rendered as formatted text, and tags in select controls do not open the choice when you click on it. Instead such a click takes to an item view of that value in its own table. Using Redux-Form We use redux-form for displaying forms, filling them out, submitting them, sending the values to the database, validating and normalizing values. Although redux-form has an awesome functionality, it is far from trivial to get it integrated. The work horses are the Field and FieldArray components. These elements can be put in an arbitrary component, under a <form/> element. The resulting component is enhanced by the reduxForm() function. Information flow we read the values of a record from the state and pass them to the redux-form component as initial values ; redux-form manages its own slice of the state ( form ) and has its own set of actions to respond to user interactions; when the user interacts with the form, the work ends up in the form slice of the state; when the form is submitted : the current values are sent to the database, and the updated record is read back from the database; the updated values are passed to the form as new initial values the form re-initializes itself, and the user can start again; when the user interrupts editing the form, and switches to another component, nothing is lost: the edits are saved in the state; when the form is mounted again, not only the initial values are fetched back, but also the edit state is restored; submitting happens with auto save : whenever an input field looses focus, the form is submitted; submitting happens also for those fields in which you can not have a cursor: whenever a field value is changed by a click, the form is submitted. Hence it is easy to edit two forms at the same time, which can be handy if the user edits two contributions that need to have a consistent wording. It is also possible to edit the same records in multiple components on the interface. Both refer to the same underlying state. Implementation The construction of the actual fields is done by a function makeFields() , that generates an array of fragments, one for each field. An editable field will be handled by a FieldEdit component, and a read-only field by a FieldRead component. Using templates Before setting up the fields of an item, applyEditTemplate is called. If it finds a suitable template in Templates it will be applied. If not, all fields will be displayed in a generic presentation. ItemForm \u00b6 See ItemForm . connected via tables Props Standard props : alter alterSection tables table eId filters fields perm fieldFragments detailFragments dispatch Specific props: name type description initialValues object an object with the initial values of all fields that are being managed by the form as a whole isactive string a CSS class name to add extra formatting if the record in question is deemed inactive . The notion of active items is defined in the duct workflow Task This is the component that can open an item and show its fields, either for reading or for editing. Every list rendering component that want to display an individual item full view, will use this component. Full view means: as a vertical table of field labels and field values. ItemRead \u00b6 See ItemRead . connected via tables Props Standard props : tables eId fieldFragments Task Manages the display (read-only) of a single record. It is used if no fields need to be edited. For editing records, ItemEdit is being used. You might wonder why table is missing in the props. The fieldFragment s prop contains that information. Before setting up the fields of an item, applyTemplate is called. If it finds a suitable template in Templates it will be applied. If not, all fields will be displayed in a generic presentation. ItemRow \u00b6 See ItemRow . connected via tables Props Standard props : tables table eId fields perm filters widthStyles Specific props: name type description initialValues object an object with the initial values of all fields that are being managed by the form as a whole widthStyles object since this component has to render records in a grid view, it must know something about the widths of the columns. That information is contained in this prop, as a CSS style per column alt bool the component must know whether it is an ordinary grid row, or whether the fields should be expanded into a vertical form nextAlt function this function can be used by a control by which the user can switch between row view and vertical view of the record isactive string a CSS class name to add extra formatting if the record in question is deemed inactive . The notion of active items is defined in the duct workflow Task This component displays a record in row form, so that it fits in a grid view of the whole table. See ListGrid . ListContainer \u00b6 See ListContainer . (life cycle) connected via tables Props Standard props : tables table eId select mode filtered dispatch Task Manages a table. Responsible for fetching data from the server. The display of the (filtered) table is left to other components, such as ListFilter . It can be instructed to navigate to a specific item. This is used when the id of the item to navigate to is contained in the URL. The eId prop is the one that contains the item to navigate to. ListFilter \u00b6 See ListFilter . (life cycle) connected via tables and filters Props Standard props : filteredAmount filteredAmountOthers amounts Specific props: name type description initialized bool whether the filters have been initialized init function is [setupFiltering](Du callback to initialize filtering Task Parent component of a table and all its filters. The table must be present. Fetching tables is done by other components, such as ListContainer . This component is for processing user interaction on the filters. The filters and the list of filtered items are shown in separate Pane s. ListGrid \u00b6 See ListGrid . connected via tables Props Standard props : alter alterSection settings tables table listIds select filters perm masterId linkField dispatch Specific props: name type description grid object slice of the state, obtained with getGrid , which holds sorting information of table grids gridTag string key under which the component finds its information about which columns are sorted in what order and direction Task This component shows a table as a grid. It uses CSS flex-box for the grid layout. There is also CSS grid but at the time of writing this app, browser support for grid was substantially inferior to browser support for flex. The grid can be sorted by column, in ascending and descending order. You can sort on one column first and then on another and so on. Every grid remembers its sorting state in the grid slice of the state, where it is available under a key. ListPlain \u00b6 See ListPlain . (life cycle) connected via tables Props Standard props : alter alterSection tables table listIds select filters perm masterId linkField dispatch Specific props: name type description navItem string the item to navigate to, by its MongoDB id. It will be opened and scrolled into view Task Displays a list of items from a table. Every items is represented as a heading, usually consisting of the title field of the item. If the user has permission to see more, there is a control on each item to expand the heading into the fields and values of the item. If the user has edit permissions, he can edit the item from here. If the user inserts a new item, the component will navigate to that item. ListStats \u00b6 See ListStats . (life cycle) connected via tables Props Standard props : settings tables table Task Displays aggregated management information about contributions, assessments and reviews. MarkdownArea \u00b6 See MarkdownArea . connected via tables Props Standard props : alter alterSection table eId dispatch submitValues Specific props: name type description meta object contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? input object contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> Task An edit control for bigger chunks of text. It is basically a <textarea>...</textarea> but it is enhanced to convert to the text to markdown and to display a formatted preview of the text. What is saved to the database is the raw markdown. The formatted text is ephemeral, its only function is for the pleasure of the user. Note that in read-only view these values will be also rendered as formatted text. OpenCloseAll \u00b6 See OpenCloseAll . Props Standard props : alter laterSection table listIds item Specific props: name type description button string CSS class name for styling the button nAlts number number of alternative states. In practice: 2 : open and closed Task A control by which you can close all currently open records in a list. If the list is a detail records list, there is also a control to open all items in the list. But in general, a complete list cannot massively be opened in this way. The real work is done by the functions handleOpenAll , handleCloseAll in tables . filters \u00b6 CheckboxI \u00b6 See CheckboxI . (life cycle) connected via filters Props Standard props : table filterTag filterId filterSetting dispatch Task Displays a collective checkbox for a facet filter with many facets. Clicking on this box will collectively check and uncheck all associate checkboxes. The component invokes the method handleCheck upon clicking the checkbox. This checkbox can have an indeterminate state, if some but not all of the associate checkboxes are checked. We have to resort to a DOM manipulation after rendering to get the indeterminate state across. EUMap \u00b6 See EUMap . (life cycle) connected via filters Props Standard props : alter alterSection tables table filterTag filterSetting filterId filterField filterLabel listIds dispatch Note These are the same props as ByValue Task A complex component! It is a facet filter for the field country , using ByValue for that. It also contains a map of Europe, visualizing by means of markers, how the filter result is distributed over the DARIAH countries. Both ingredients of this component are brought together not by class extension but by including a <ByValue/> component in the rendering of the <EUMap/> component. The map is a Leaflet module on a blank pane, with a geojson file of country boundaries laid out on it. The map is not React-aware, it will be rendered in its own <div/> . The life cycle methods of this component set up the map and update when new filter settings have been applied. Compute Marker Radius When we know the filter results per country, we can put markers on them with a radius in proportion to their scores. However, if the scores are very far apart, either the small markers get invisible, or the big markers get too big. We mitigate this effect, by using proportional radii only for values below a certain threshold ( LEVEL_OFF ). For higher values we essentially take the square root. ByValue \u00b6 See ByValue . connected via filters Props Standard props : alter alterSection tables table filterTag filterSetting filterId filterField filterRelField filterLabel filteredAmount filteredAmountOthers listIds compact dispatch Specific props: name type description maxCols number the maximum number of columns in which the facets have to be stacked expanded bool whether the facets should be initially expanded or collapsed (hidden) Task A widget by which the user can click the facet s associated with one field. There is also a collective checkbox , by which the user can check or uncheck all facets in one go. All values that occur are displayed, with statistics in the form subtotal of total . Facet \u00b6 See Facet . connected via filters Props Standard props : table filterTag filterId filterSetting className dispatch Specific props: name type description valueId string the id of the value that is associated to this facet valueRep string the string representation of the value that is associated to this facet Task Displays a single facet. Just a checkbox and a value representation. Note that we use the strategy of controlled components here. Filter \u00b6 See Filter . connected via filters Props Standard props : tables table listIds filters filterTag filteredAmount filteredAmountOthers amounts compact Task A control to filter a list of items. The following types of filters are implemented. Fulltext : Search in a textual field for a pattern. The pattern is entered by the user, the search is incremental, after each keystroke the results are updated. ByValue : Faceted search for values of a specific field. EUMap : Faceted search on country, together with a map visualization The list of the available filter types and their characteristics are not configured on the client, but come from the server. This generic component merely calls the specialized filter components with the right props for each filter associated with a table. Whereas the incoming props contain information for all filters, each individual specialized filter is passed only the slice that is relevant to that one filter. Fulltext \u00b6 See Fulltext . connected via filters Props Standard props : table filterTag filterId filterLabel filterSetting filteredAmount filteredAmountOthers compact dispatch Task Displays a full text search input field. The characters entered in this field are passed upwards by means of a callback. This is incremental search. Not only the full text search, but also all other filters are computed upon each character entered. Note that we use the strategy of controlled components here. Stat \u00b6 See Stat . presents filters Props Standard props : className Specific props: name type description subtotal number subtotal to display total number total to display Task Displays a string of the form subTotal of total . If one of the two is missing, the of will not display. select \u00b6 RelSelect \u00b6 See RelSelect . presents select Props Standard props : settings tables table select field dispatch submitValues Specific props: name type description multiple bool whether to display a select widget where the user can make multi-selections or only single selections allowNew bool whether to allow the user to add new options selectTag string a key under which this component stores its data on the select slice of the global state. This is about whether the options have popped up and what search text the user has entered in the filter box activeItems array the notion of active items is defined in the duct workflow isactive string a CSS class name to add extra formatting if the record in question is deemed inactive allowed object an array of entity ids that are the allowed elements when the field is a multiple choice field input object contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> Task An implementation of multi-select widgets. There is a fairly complete react-select component on GitHub. However, it has some flaws that prevents a successful usage of it in our app. That is why I have written this component. The capabilities of this widget are: single select or multi-select, depending on the property multiple ; fixed list of values or the possibility to create new values on the fly, depending on the prop allowNew ; options can be filtered by a full text filter; only one copy of an option can be chosen; selected options are removed from the list of selectable options; plays well with Redux-Form ; facilitates disabling some options and presenting options in custom ways alter \u00b6 Expand \u00b6 See Expand . presents alter Props Standard props : alter alterSection alterTag className Specific props: name type description initAlt number initial expand/collapse state headActive string clickable part of the component headLine string part of the component that is visible in both states full component part of the component that is visible in the expanded state only iconOpen component icon, clickable, to trigger expansion iconClose component icon, clickable, to trigger collapse titleOpen string tooltip for the expansion trigger titleClose string tooltip for the collapse trigger Task Shows a expandable / collapsable component, together with controls to trigger these actions. In expanded form, only the headActive and headLine are visible. The headActive is the part that the user can click on to trigger expansion and collapse. The headActive is combined with iconOpen and iconClose , which are indicators for the state of the component. All this is wrapped in a Tooltip components, that display the titleOpen and titleClose texts. In the full form, also the full is visible. Sometimes you need more distance between the control and the material of the component. So we export related components as well: ExpandHead \u00b6 Props Works with the same args as Expand , minus full . Task This component presents the headline part, including the clickable part to trigger the actions. ExpandBody \u00b6 Props Works with the same args as Expand , minus alter , alterSection , alterTag , initAlt , className . Task This component presents the fully expanded part if the states indicate so, or else nothing. Miscellaneous \u00b6 Bool3 \u00b6 See Bool3 . (life cycle) Props input meta submitValues (provided by Redux-From, because this component is wrapped in a Field Task Displays a 3-valued checkbox that represents true , false or null . We have to resort to a DOM manipulation after rendering to get the indeterminate state across. ErrorBoundary \u00b6 See ErrorBoundary . Task Generic component, using new error handling functionality of React 16. We use it to wrap components inside which errors may occur. Those errors are then propagated to an enclosing ErrorBoundary , where they will be catched. The console will log the error, and at the ErrorBoundary will be rendered in place of its normal contents. Currently we render the error boundary as a red block with a single diagnostic message. NavLink \u00b6 See NavLink . presents none Props Standard props : Specific props: name type description activeClassName string the CSS class to be used when the navigation link has been clicked ...props All other props are passed to the wrapped <Link/> component. Task Displays a navigation link that is sensitive to routing. That means: it is a link that can activate a component, and, when clicked, it will become highlighted. NotFound \u00b6 See NotFound . presents none Props Specific props: name type description splat string the text to display on the 404 page Task Displays a 404 if no route in main matches. Overview \u00b6 See Overview . Task Under construction. Meant to become a customized dashboard for the back office functions. Static \u00b6 See Static . presents none Task Displays navigation links to some static resources.","title":"Components"},{"location":"Client/Components/#components-react","text":"These are the React components, that make up the part of the app that is visible in the browser. They lean on the dux that work for them in the background. Click on the names in the titles to view their source code on GitHub.","title":"Components (React)"},{"location":"Client/Components/#standard-props","text":"Components get properties as input (we call them props ). For each component we mention the props they expect and what type of data they represent. However, some props occur over and over again, and we name them consistently. Here is a list of those props and their types. When we mention these props later on, we omit the types. List of standard props name type description alter object a slice of the state from getAltSection ; Group of settings for components with alternative renderings: these settings tell which alternative has been chosen for each of those components; alterSection string name of a section of the alter state; such a section contains the choice of alternative for a bunch of components that are relevant to the present component; each component that requests data from alter only gets data for a single section; in this way components will not be dependent on too big a part of the state; those dependencies may cause spurious re-renderings; alterTag string name that lives within a section of the alter state; this functions as the address of a component that needs to expand or collapse; the triggering event will change the alter state, keyed by alterSection and then by alterTag ; amounts object for a faceted filter: contains the amount of items that match each facet; see computeFiltering ; children components a special prop defined by React itself; it contains the material that has been put in the component; you find it in the render function of the component; it is everything between <Component> and </Component> ; className string a class name to be put in the top level element of the rendered component; compact bool whether the component should minimize the real estate on the screen that it uses; detailFragments array of object the information on the basis of which the detail records of an item can be rendered; every entry in the array corresponds to a detail table that may contain detail records of the master record that is being dealt with; ultimately computed by makeDetails and then passed to child components; dirty bool whether a field or item has been changed on the interface but not saved to the database dispatch function this function belongs to the store that holds the state; it is generally injected into the props of a component by connect ing a component to the store; this only happens if connect() is called with zero or one argument (the MapDispatchToProps argument should be undefined); the dispatch function enables the component to trigger an action that changes the state; where you would call setState() in vanilla-React you put dispatch(action) if your app uses Redux; eId string the MongoDB id of an entity that is being dealt with; * field string ; the name of a field that is being dealt with; fieldFragments array an array with instructions per field how to render it; ultimately computed by makeFields and then passed to child components; filtered bool whether the list should be accompanied by filters; the specification of the filters themselves is in the data model ; fields objects defines a subset of all fields: these are the fields that the component has to deal with; filteredAmount number the number of items that pass all filters; see computeFiltering ; filteredAmountOthers object for each filter, the amount of items that passes all filters except that one filter; see computeFiltering ; filterField string the name of the field that the current filter is acting upon; (as in the data model ; filterRelField string the name of the related field that the current filter is acting upon; this is relevant for fields that point to a related table: you can filter on the values of a specific field in the related table; (as in the data model ; filterId number the sequence number of a specific filter which identifies it among all filters for the same table; filterLabel string the user-facing name of the filter; filters object a slice of the state from getFilters ; contains the actual filter settings, i.e. what the user has entered in search boxes and which facets the user has clicked; organized by table and then by filterTag and then by filterId ; filterSettings object a slice of the state, sub-slice of filters , corresponding to the filters of a single filterTag of a single table ; filterSetting object or string a slice of the state, sub-slice of filterSetting , corresponding to a single filter, identified by filterId ; whether this is an object or a string, depends on the nature of the filter: for a Fulltext filter it is a string (the search text), for a ByValue filter it is an object, containing the status (boolean) of all its facet checkboxes; filterTag string identifies a group of filters for a single table; tables may have multiple incarnations; a table can be a main table, but also a detail table for a specific record; the filters for a table when it displays details may be distinct from the filters of the same table when it is displayed as the main table; we separate those cases by means of a filterTag prop; fixed boolean when modifying records, this attribute can veto the change; it indicates that the record needs to be kept immutable; item array the English word for the kind of thing in question. item[0] is the word in the singular, item[1] is the word in the plural. linkField string when rendering a list of records that are details of some master record, this is the field of the detail records that holds the masterId ; in this way the detail record links to its master record; when the component creates a new detail record, it will pre-fill this field with the current masterId ; listIds array of string a sequence of strings which are essentially MongoDB identifiers of entities in a table; components that display lists use this prop to determine which entities must be actually appear on the screen and in what order; see also the prop filteredIds ; masterId string when rendering a list of records that are details of some master record, this holds the MongoDB id of the master record; masterTable string when rendering a list of records that are details of some master record, this holds the name of the table in which the master record resides; me object a slice of the state from getMe ; the information about the currently logged-in user, fetched from the server; mode string either list or grid ; whether the list of items should render as a list of expandable headings, or as a grid with full field information; myValues object ultimately extracted from the tables slice of the state; it contains the values of the fields of the entity that is being dealt with; perm object Holds permissions for a record: whether deleting is allowed, and per field whether updating is allowed; select string sometimes a list is fetched as a whole, sometimes only my own records are displayed and yet other times only records that are the details of some master record must be shown; this property indicates which is which; settings object a slice of the state from getSettings ; settings are pieces of custom information that are relevant to many components of the app; table string name of the table that the component must deal with; submitValues function a callback that is used to save form values to the database; used for components that supply edit controls for form values: they can call submitValues after a change or upon loss of focus; it is basically the handleSubmit from Redux-Form, with a specific first argument passed ( toDb ) that saves values to the database; tables object a slice of the state from getTables ; all data that comes from database tables; organized by table name; for each table there is spec information and actual entity data; win { width number , height number } a slice of the state from getWinDim ; contains the physical dimensions of the window at any time. workflow object slice of the state that contains workflow information.","title":"Standard props"},{"location":"Client/Components/#roots","text":"","title":"roots"},{"location":"Client/Components/#main","text":"See main . connected via roots Task Entry point of the client side app. Contains the routing , wrapped in a Root component, that sets up the store in which the central state lives.","title":"main"},{"location":"Client/Components/#root","text":"See Root . presents roots Props Standard props : children Task Top-level wrapping component to set up the central store. It does so by configuring the store, calling configureStore , and passing it to the special Provider component of Redux. Then it wraps the whole remaining app in a Window component for detecting some global UI events.","title":"Root"},{"location":"Client/Components/#settings","text":"","title":"settings"},{"location":"Client/Components/#tooltip","text":"See Tooltip . (life cycle) connected via settings Task A dynamic tooltip, based on CSS3 techniques. The tooltip is initially put as content with an absolute position and with opcaity 0. A lot can happen on the page: scrolling, re-rendering of components, and they may all cause changes in the positions of elements. So the position of the invisible tooltip is not where it should be, most of the time. That does not matter, as long as we adjust it just in time, before it becomes visible. When that happens, the positioning of the tooltip will be adjusted to the current position of the element. The trigger to make a tooltip visible is a focus event or a mouse-over event. It is possible to switch all tooltips off. This is governed by showTooltips , a boolean setting in settings . Apart from this, the tooltip machinery does not use special React/Redux mechanisms. All is done at DOM level and with CSS3. Props Standard props : settings Specific props: name type description tip string or fragment the content of the tooltip. Any content will do at string the position of the tooltip relative to its target. Should be one of top bottom left right focusOnly boolean whether the tooltip should be triggered by focus actions only, or hovering as well. Handy for text input elements ( <input type=\"text\"> or <textarea> ) if you want to show editing help, but only if the user is actually typing in the field className string an additional CSS class to pass on to the <Tooltip> outermost element classTip string an additional CSS class to pass on to the element that holds the tooltip classArrow string an additional CSS class to pass on to the element that holds the little arrow of the tooltip. Positioning The positioning algorithm looks whether there is sufficient room for the tooltip. If not, it will change top to bottom and vice versa, and left to right` and vice versa. It will also shift the tooltip so that it does not extends beyond the page.","title":"Tooltip"},{"location":"Client/Components/#tooltipswitch","text":"See TooltipSwitch . connected via settings Props Standard props : settings dispatch Task Switches tooltips on or off, globally.","title":"TooltipSwitch"},{"location":"Client/Components/#workflow","text":"","title":"workflow"},{"location":"Client/Components/#scorebox","text":"See ScoreBox . presents workflow Props Specific props: name type description score object contains several score quantities, relevant to the scoring of assessments Task The server computes the scores, and delivers it as workflow attributes with contribution and assessment records. Displays the score of an assessment, and can be expanded to show a derivation of that score. It should be used in templates that have access to workflow attributes. See the mainAction templates of contrib and assessment .","title":"ScoreBox"},{"location":"Client/Components/#workflowinfo","text":"See WorkflowInfo . presents workflow Props name type description resets object information about the (manual) workflow resets after the last startup of the webserver stats object contains several statistical quantities about the workflow attributes total number the number of records that have workflow information associated with them Task Present overview information about the workflow information that is currently in use. Offer a control to reset the workflow information (i.e. recompute it). See manageWorkflow .","title":"WorkflowInfo"},{"location":"Client/Components/#me","text":"","title":"me"},{"location":"Client/Components/#login","text":"See Login . (life cycle) connected via me Props Standard props : me dispatch Task The main task of Login is to fetch the current authentication status: is there an authenticated user, and if so, what is his/her name?","title":"Login"},{"location":"Client/Components/#subapp","text":"See SubApp . presents win Props Standard props : me table children Specific props: name type description routes components these are objects passed by React-Router . From this the navigation route that the user has followed to arrive here, can be read Task This is one of the components just below App . It contains a set of panes and navigation links to main subcomponents to display in those panes. Most of those subcomponents are linked to a main table, which is passed in the table prop.","title":"SubApp"},{"location":"Client/Components/#win","text":"","title":"win"},{"location":"Client/Components/#app","text":"See App . connected via win Props Standard props : children win Task As far as the logic of the web page is concerned, this is the top level component. App is always in view and consists of the top navigation bar with logo, Login ; Notification ; static links to documentation. It is only used to display the height and the width somewhere on the screen.","title":"App"},{"location":"Client/Components/#window","text":"See Window . (life cycle) connected via win Task Detects window resize events and passes the resulting height and width of the main window to the state. On mounting an event listener is installed, and on unmounting the event handler is removed. During resizing, the frequency of emitted events is throttled to one per second, in order to prevent screen flicker.","title":"Window"},{"location":"Client/Components/#docs","text":"","title":"docs"},{"location":"Client/Components/#doc","text":"See Doc . presents docs Props Specific props: name type description location object from this object the property pathname will be read, which will be split into directory, file and extension parts. The extension is used to switch to the component for that type of documents Task Handles the display of documents. Depending on the type of document (markdown, html, pdf) it delegates work to specialized document components: DocMd , DocHtml and DocPdf .","title":"Doc"},{"location":"Client/Components/#dochtml","text":"See DocHtml . presents docs Props Specific props: name type description docDir string the directory of the document container docName string the filename of the document container docExt string the extension of the document container Task Displays an HTML document by linking to it in an IFRAME.","title":"DocHtml"},{"location":"Client/Components/#docmd","text":"See DocMd . (life cycle) connected via docs Props Standard props : alter alterSection dispatch name type description docName string the name of the document. text string from getDoc , the raw content of the document Task Show Markdown text, coming from files on the server. The conversion to HTML is done client side, and the user gets a control to switch between Markdown source and formatted HTML. A function RouterLink is defined to wrap local links into Link components when transforming the markdown to html. It makes it possible to write Markdown documents with internal links to this application. A full link (with protocol http ( s ) is translated to a plain HTML a element, so clicking it will leave this application.","title":"DocMd"},{"location":"Client/Components/#docpdf","text":"See DocPdf . presents docs Props Specific props: name type description docDir string the directory of the document container docName string the filename of the document container docExt string the extension of the document container Task Displays a PDF document by linking to it in an OBJECT. iOS On iOS this does not work well, only the first page of the PDF gets shown, we work around it by just displaying a link to open the PDF in a new tab. We only do that when we detect an iOS browser.","title":"DocPdf"},{"location":"Client/Components/#notes","text":"","title":"notes"},{"location":"Client/Components/#notification","text":"See Notification . (life cycle) connected via notes Props Standard props : dispatch Specific props: Injected The following properties are injected from the state by getNotes : name type description messages array of objects the list of notifications that have been issued since the beginning of the session or since the last time that the user has cleared the messages busy number the amount of asynchronous actions that are still pending show boolean whether the panel should be hidden lastMsg number index of last message lastNote number index of last notable message lastKind string kind of last notable message, one of error , warning , special . Only the kind info is non-special. When the notifications are displayed, the panel will be scrolled to the last notable message if there is one, otherwise to the last message. Task Component that receives notifications and displays them in a little panel with fixed position on the screen. The panel is hidden by default and pops up if there is an important notification. The user can click it away and also clear the notifications. There is also a progress indicator, a little circle fixed at the top right corner of the screen. It hints at the current status of asynchronous operations. A click on it will show the notifications panel.","title":"Notification"},{"location":"Client/Components/#tables","text":"","title":"tables"},{"location":"Client/Components/#editcontrol","text":"See EditControl . Task A component that shows the current edit status of a record. It is presented as a button that can be clicked to submit and save a form. It can only be used as descendant of a redux-form -enabled <form> -carrying component. See also EditStatus . Uses the library function editControl .","title":"EditControl"},{"location":"Client/Components/#editdelete","text":"See EditDelete . presentational Props Standard props : perm workflow fixed Specific props: name type description keep object per table the entities that are related with the record to delete; if this is not empty the record cannot be deleted button string CSS class name for styling the button onClick event handler called when the button is clicked, should trigger the delete action Task Button to delete the record that is displayed with it. The component is rather dumb, it needs to be passed an onClick handler that will perform the delete action.","title":"EditDelete"},{"location":"Client/Components/#edithelp","text":"See EditHelp . Props Standard props : dirty Specific props: name type description type string the type of field that is documented Task Information panel below input fields and markdown fields, telling how to save and cancel, and showing the markdown constructs.","title":"EditHelp"},{"location":"Client/Components/#editinsert","text":"See EditInsert . Props Standard props : settings me tables select masterTable masterId perm fixed item Specific props: name type description nItems number amount of current items in the list in which the new item is to be inserted button string CSS class name for styling the button onInsert event handler called when the button is clicked, should trigger the insert action Task Button to insert a blank record into the currently displayed table. The component is rather dumb, it needs to be passed an onInsert handler that will perform the insert action.","title":"EditInsert"},{"location":"Client/Components/#editstatus","text":"See EditStatus . Task A component that shows the current edit status of a record. It is presented as a <span> that looks exactly as an EditControl , but it cannot be clicked to submit and save values. It can be used everywhere, and it is itself enhanced by redux-form . Because it is outside a <form> context, submitting will not work. Uses the library function editControl .","title":"EditStatus"},{"location":"Client/Components/#fieldedit","text":"See FieldEdit . connected via tables Props Standard props : alter tables table eId field dispatch submitValues Specific props: name type description allowed array entity-ids that are the allowed elements when the field is a multiple choice field Note In most cases a multiple choice is between members of a value list or related table, but sometimes we want to restrict the set of choices further, especially when we are offering a choice in a detail record. Then the master record might contain information that constrains the option for some fields in the detail records. For example, the criteriaEntry record contains a multiple choice field to choose between a bunch of scores. However, not all scores of the score table are valid choices, only those scores that belong to the criteria record referred by the criteriaEntry record. ...props There are many more props that get passed to FieldEdit . They have been injected by the wrapper redux-form() into ItemForm , the parent of this component, and they will be passed on to Field and FieldArray , so that they can do their magic. Task Edit control for an editable field. Depending on the type of the field and the multiplicity, it presents the right control. Basically, this component produces one or more Field or FieldArray components (which are provided by redux-form . Note that we do not pass the actual values to these components. They know how to get the current values from the state, and what actions must be dispatched to change them. However, both <Field /> and <FieldArray /> still do not actually present the edit control. They only do the plumbing. For the actual presentation, you can plug in a component of choice. We will use <input type=\"...\" /> , <textarea>...</textarea> elements and our own custom component RelSelect for multi-select controls. We enhance textareas by offering markdown previews of their content. See MarkdownArea . We wrap multiple *input*s in InputMulti and single inputs in Input . The extra level of wrapping of these presentational components is needed for showing validation errors. Problems solved In order to get everything working correctly, two problems had to be solved. Both turned out to be related to Redux-Form. The component that you pass to the component prop of Field and FieldArray must not be dynamically composed in the render() function that produces Field(Array) . Because in that case, the Field(Array) is re-rendered too often, and effect for the user is that he loses focus after entering the first character, which is very annoying. So, the value for component must be a static function. But what if this function needs dynamically determined arguments? How can they be passed to it? The solution is simple: pass them as props to Field(Array) , and they will be passed on to the component function by redux-form. This is actually documented in the redux-form docs. You need this , section 2. A stateless function You must define the stateless function outside of your render() method, or else it will be recreated on every render and will force the Field to re-render because its component prop will be different. If you are defining your stateless function inside of render(), it will not only be slower, but your input will lose focus whenever the entire form component re-renders. and this : Any custom props passed to Field will be merged into the props object on the same level as the input and meta objects. When navigating between forms for several records, the onChange callback, that should be bound to the proper form, becomes bound to the wrong form. As far as I can see, all other things work as expected, so it was difficult to see why this occurred. The explanation is in a GitHub issue . Summarized: the construction of the onChange function is effectively memoized. It is determined upon mounting of the component, but not on updating it. The workaround is easy: add an extra key property to the form. Another cause for the same problem I encountered in InputMulti , where I had memoized the callbacks for adding and removing values to/from a sequence.","title":"FieldEdit"},{"location":"Client/Components/#fieldread","text":"See FieldRead . connected via tables Props Standard props : settings tables table myValues field Task Presents the value(s) of a read-only field, based on initial values . Note that value of type textarea will be rendered as formatted markdown.","title":"FieldRead"},{"location":"Client/Components/#fieldset","text":"See FieldSet . presents tables Props Standard props : submitValues Specific props: name type description input object contains the attribute onChange by which the form value of this field can be changed widget function a function that when passed a handler, will return a React fragment. When this fragment receives a click, the event handler will be called setValue any value the value that will be passed to the handler of widget , when it receives a click Task This is a form input component meant to be passed to a Field component, like Input . But unlike an Input , it only handles a click event, upon which it will change the value in the field to setValue , and save the form to the database.","title":"FieldSet"},{"location":"Client/Components/#input","text":"See Input . presents tables Props Standard props : submitValues Specific props: name type description meta object contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? input object contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> type string the type of <input type=\"...\" /> . It will go to the place of the dots Task Shows an <input type=\"...\" /> control, and shows validation errors if the value entered by the user does not validate. It is a controlled component .","title":"Input"},{"location":"Client/Components/#inputmulti","text":"See InputMulti . presents tables Props Standard props : submitValues table eId fields Specific props: name type description componentSingle function the edit component that has to be rendered multiple times validateSingle function validation function. Takes a value and return undefined if all is well, and otherwise a reason why not normalizeSingle function transforms the entered value into a normalized value for saving fields array the names of the individual fields. If the collective name of this field is foo , than this array contains foo[0] , foo[1] , etc., as many as their are values. These names are just strings meta object contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? ...props There are many more props that must be passed to Field . They have been injected by the wrapper reduxForm() into ItemForm , the uncle ( InputMulti is passed as attribute to Field which is a child of FieldEdit ) of this component, and they are just passed on to Field and FieldArray , so that they can do their magic. Task Renders a sequence of Field components on behalf of a FieldArray component. There are controls to remove values, and to add fresh, empty values. Validation and normalization are done per individual Field . It is a controlled component .","title":"InputMulti"},{"location":"Client/Components/#insert","text":"See Insert . (life cycle) connected via tables Props Specific props: name type description thing string English name for the thing to insert Task Button to insert a blank record into a table. Unlike EditInsert , this does not have to be a currently displayed table. After insertion the app will navigate to the table in which the item has been inserted, and it will open the freshly created item.","title":"Insert"},{"location":"Client/Components/#itemaction","text":"See ItemAction . connected via tables Props Standard props : settings tables table eId linkField fieldFragments dispatch name type description handleSubmit function a function that is invoked when the form is submitted. This function is passed from redux-form and handles all the form submission machinery. See ItemEdit Injected props These are all the properties that ItemForm gets from its parent and from its connection with the state. But we wrap ItemForm in reduxForm() and this will inject a number of other properties into it. We list the few that we visibly use. There are more injected properties, and these we pass carefully on to other components. Task Manages the display of a single record, but only as far as an ActionTemplate has been provided for that table. The action template may contain controls that modify fields and save them to the database, exactly as ItemEdit . The component does not show save and reset buttons. It is meant for controls that save changed values on their own. This component is meant for stuff that needs to be present both in read-only view and in edit-view. Using templates This component uses applyEditTemplate to see whether there is an action template defined in Templates . If yes, that template will be applied, if no, nothing will be rendered.","title":"ItemAction"},{"location":"Client/Components/#itemcontainer","text":"See ItemContainer . (life cycle) connected via tables Props Standard props : settings tables table eId filters dispatch Task Container for a single record in a table. This component is responsible for fetching the item data from the database (if needed), but not form input.","title":"ItemContainer"},{"location":"Client/Components/#itemdetails","text":"See ItemDetails . connected via tables Props Standard props : alter alterSection tables table eId filters detailFragments dispatch Task Presents a list of detail items of a master record.","title":"ItemDetails"},{"location":"Client/Components/#itemedit","text":"See ItemEdit . connected via tables Props Standard props : tables table eId fieldFragments dispatch Specific props: name type description nextAlt function this function can be used to switch this component from read-only view to edit view and back. It will be passed on to the widget that also has the edit controls for submitting and resetting the form Injected props These are all the properties that ItemForm gets from its parent and from its connection with the state. But we wrap ItemForm in reduxForm() and this will inject a number of other properties into it. We list the few that we visibly use. There are more injected properties, and these we pass carefully on to other components. name type description dirty boolean whether the form contains changed, unsaved values in any of its fields. invalid boolean whether the form contains invalid, values in any of its fields. error object object that contains the reasons for validation errors submitting boolean whether a submit action of the form is pending reset boolean a function that can reset the form. Resetting means: changing all edited values back to the initialValues handleSubmit function a function that is invoked when the form is submitted. Two kinds of validation synchronous: on every keystroke, the current value will be subjected to a validation function on submit: the submitted values will be validated on the server, and if that fails, the reasons for failure will be reported in exactly the same way as for synchronous validation. handleSubmit This function is passed from redux-form and handles all the form submission machinery. It also calls a function that you can pass to it as first argument. We pass it our toDb(table, eId, mod) function. This is a function that takes a values object, and calls mod(table, eId, values) , where mod is the function that dispatches a server action: the values are sent to the server, where they are used to update the record eId in table . Task Manages the display and editing of a single record. It is only used if there are editable field. If that is not the case, ItemRead is being used. We do this to avoid to invoke the costly machinery of editable forms when it is not needed. Buttons The component also shows save and reset buttons (if appropriate). Readonly and Edit view The component has two render modes: read-only view and edit-view. When a user has edited the form, he can switch to the read only view to see the result. In read-only view, markdown fields are rendered as formatted text, and tags in select controls do not open the choice when you click on it. Instead such a click takes to an item view of that value in its own table. Using Redux-Form We use redux-form for displaying forms, filling them out, submitting them, sending the values to the database, validating and normalizing values. Although redux-form has an awesome functionality, it is far from trivial to get it integrated. The work horses are the Field and FieldArray components. These elements can be put in an arbitrary component, under a <form/> element. The resulting component is enhanced by the reduxForm() function. Information flow we read the values of a record from the state and pass them to the redux-form component as initial values ; redux-form manages its own slice of the state ( form ) and has its own set of actions to respond to user interactions; when the user interacts with the form, the work ends up in the form slice of the state; when the form is submitted : the current values are sent to the database, and the updated record is read back from the database; the updated values are passed to the form as new initial values the form re-initializes itself, and the user can start again; when the user interrupts editing the form, and switches to another component, nothing is lost: the edits are saved in the state; when the form is mounted again, not only the initial values are fetched back, but also the edit state is restored; submitting happens with auto save : whenever an input field looses focus, the form is submitted; submitting happens also for those fields in which you can not have a cursor: whenever a field value is changed by a click, the form is submitted. Hence it is easy to edit two forms at the same time, which can be handy if the user edits two contributions that need to have a consistent wording. It is also possible to edit the same records in multiple components on the interface. Both refer to the same underlying state. Implementation The construction of the actual fields is done by a function makeFields() , that generates an array of fragments, one for each field. An editable field will be handled by a FieldEdit component, and a read-only field by a FieldRead component. Using templates Before setting up the fields of an item, applyEditTemplate is called. If it finds a suitable template in Templates it will be applied. If not, all fields will be displayed in a generic presentation.","title":"ItemEdit"},{"location":"Client/Components/#itemform","text":"See ItemForm . connected via tables Props Standard props : alter alterSection tables table eId filters fields perm fieldFragments detailFragments dispatch Specific props: name type description initialValues object an object with the initial values of all fields that are being managed by the form as a whole isactive string a CSS class name to add extra formatting if the record in question is deemed inactive . The notion of active items is defined in the duct workflow Task This is the component that can open an item and show its fields, either for reading or for editing. Every list rendering component that want to display an individual item full view, will use this component. Full view means: as a vertical table of field labels and field values.","title":"ItemForm"},{"location":"Client/Components/#itemread","text":"See ItemRead . connected via tables Props Standard props : tables eId fieldFragments Task Manages the display (read-only) of a single record. It is used if no fields need to be edited. For editing records, ItemEdit is being used. You might wonder why table is missing in the props. The fieldFragment s prop contains that information. Before setting up the fields of an item, applyTemplate is called. If it finds a suitable template in Templates it will be applied. If not, all fields will be displayed in a generic presentation.","title":"ItemRead"},{"location":"Client/Components/#itemrow","text":"See ItemRow . connected via tables Props Standard props : tables table eId fields perm filters widthStyles Specific props: name type description initialValues object an object with the initial values of all fields that are being managed by the form as a whole widthStyles object since this component has to render records in a grid view, it must know something about the widths of the columns. That information is contained in this prop, as a CSS style per column alt bool the component must know whether it is an ordinary grid row, or whether the fields should be expanded into a vertical form nextAlt function this function can be used by a control by which the user can switch between row view and vertical view of the record isactive string a CSS class name to add extra formatting if the record in question is deemed inactive . The notion of active items is defined in the duct workflow Task This component displays a record in row form, so that it fits in a grid view of the whole table. See ListGrid .","title":"ItemRow"},{"location":"Client/Components/#listcontainer","text":"See ListContainer . (life cycle) connected via tables Props Standard props : tables table eId select mode filtered dispatch Task Manages a table. Responsible for fetching data from the server. The display of the (filtered) table is left to other components, such as ListFilter . It can be instructed to navigate to a specific item. This is used when the id of the item to navigate to is contained in the URL. The eId prop is the one that contains the item to navigate to.","title":"ListContainer"},{"location":"Client/Components/#listfilter","text":"See ListFilter . (life cycle) connected via tables and filters Props Standard props : filteredAmount filteredAmountOthers amounts Specific props: name type description initialized bool whether the filters have been initialized init function is [setupFiltering](Du callback to initialize filtering Task Parent component of a table and all its filters. The table must be present. Fetching tables is done by other components, such as ListContainer . This component is for processing user interaction on the filters. The filters and the list of filtered items are shown in separate Pane s.","title":"ListFilter"},{"location":"Client/Components/#listgrid","text":"See ListGrid . connected via tables Props Standard props : alter alterSection settings tables table listIds select filters perm masterId linkField dispatch Specific props: name type description grid object slice of the state, obtained with getGrid , which holds sorting information of table grids gridTag string key under which the component finds its information about which columns are sorted in what order and direction Task This component shows a table as a grid. It uses CSS flex-box for the grid layout. There is also CSS grid but at the time of writing this app, browser support for grid was substantially inferior to browser support for flex. The grid can be sorted by column, in ascending and descending order. You can sort on one column first and then on another and so on. Every grid remembers its sorting state in the grid slice of the state, where it is available under a key.","title":"ListGrid"},{"location":"Client/Components/#listplain","text":"See ListPlain . (life cycle) connected via tables Props Standard props : alter alterSection tables table listIds select filters perm masterId linkField dispatch Specific props: name type description navItem string the item to navigate to, by its MongoDB id. It will be opened and scrolled into view Task Displays a list of items from a table. Every items is represented as a heading, usually consisting of the title field of the item. If the user has permission to see more, there is a control on each item to expand the heading into the fields and values of the item. If the user has edit permissions, he can edit the item from here. If the user inserts a new item, the component will navigate to that item.","title":"ListPlain"},{"location":"Client/Components/#liststats","text":"See ListStats . (life cycle) connected via tables Props Standard props : settings tables table Task Displays aggregated management information about contributions, assessments and reviews.","title":"ListStats"},{"location":"Client/Components/#markdownarea","text":"See MarkdownArea . connected via tables Props Standard props : alter alterSection table eId dispatch submitValues Specific props: name type description meta object contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? input object contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> Task An edit control for bigger chunks of text. It is basically a <textarea>...</textarea> but it is enhanced to convert to the text to markdown and to display a formatted preview of the text. What is saved to the database is the raw markdown. The formatted text is ephemeral, its only function is for the pleasure of the user. Note that in read-only view these values will be also rendered as formatted text.","title":"MarkdownArea"},{"location":"Client/Components/#opencloseall","text":"See OpenCloseAll . Props Standard props : alter laterSection table listIds item Specific props: name type description button string CSS class name for styling the button nAlts number number of alternative states. In practice: 2 : open and closed Task A control by which you can close all currently open records in a list. If the list is a detail records list, there is also a control to open all items in the list. But in general, a complete list cannot massively be opened in this way. The real work is done by the functions handleOpenAll , handleCloseAll in tables .","title":"OpenCloseAll"},{"location":"Client/Components/#filters","text":"","title":"filters"},{"location":"Client/Components/#checkboxi","text":"See CheckboxI . (life cycle) connected via filters Props Standard props : table filterTag filterId filterSetting dispatch Task Displays a collective checkbox for a facet filter with many facets. Clicking on this box will collectively check and uncheck all associate checkboxes. The component invokes the method handleCheck upon clicking the checkbox. This checkbox can have an indeterminate state, if some but not all of the associate checkboxes are checked. We have to resort to a DOM manipulation after rendering to get the indeterminate state across.","title":"CheckboxI"},{"location":"Client/Components/#eumap","text":"See EUMap . (life cycle) connected via filters Props Standard props : alter alterSection tables table filterTag filterSetting filterId filterField filterLabel listIds dispatch Note These are the same props as ByValue Task A complex component! It is a facet filter for the field country , using ByValue for that. It also contains a map of Europe, visualizing by means of markers, how the filter result is distributed over the DARIAH countries. Both ingredients of this component are brought together not by class extension but by including a <ByValue/> component in the rendering of the <EUMap/> component. The map is a Leaflet module on a blank pane, with a geojson file of country boundaries laid out on it. The map is not React-aware, it will be rendered in its own <div/> . The life cycle methods of this component set up the map and update when new filter settings have been applied. Compute Marker Radius When we know the filter results per country, we can put markers on them with a radius in proportion to their scores. However, if the scores are very far apart, either the small markers get invisible, or the big markers get too big. We mitigate this effect, by using proportional radii only for values below a certain threshold ( LEVEL_OFF ). For higher values we essentially take the square root.","title":"EUMap"},{"location":"Client/Components/#byvalue","text":"See ByValue . connected via filters Props Standard props : alter alterSection tables table filterTag filterSetting filterId filterField filterRelField filterLabel filteredAmount filteredAmountOthers listIds compact dispatch Specific props: name type description maxCols number the maximum number of columns in which the facets have to be stacked expanded bool whether the facets should be initially expanded or collapsed (hidden) Task A widget by which the user can click the facet s associated with one field. There is also a collective checkbox , by which the user can check or uncheck all facets in one go. All values that occur are displayed, with statistics in the form subtotal of total .","title":"ByValue"},{"location":"Client/Components/#facet","text":"See Facet . connected via filters Props Standard props : table filterTag filterId filterSetting className dispatch Specific props: name type description valueId string the id of the value that is associated to this facet valueRep string the string representation of the value that is associated to this facet Task Displays a single facet. Just a checkbox and a value representation. Note that we use the strategy of controlled components here.","title":"Facet"},{"location":"Client/Components/#filter","text":"See Filter . connected via filters Props Standard props : tables table listIds filters filterTag filteredAmount filteredAmountOthers amounts compact Task A control to filter a list of items. The following types of filters are implemented. Fulltext : Search in a textual field for a pattern. The pattern is entered by the user, the search is incremental, after each keystroke the results are updated. ByValue : Faceted search for values of a specific field. EUMap : Faceted search on country, together with a map visualization The list of the available filter types and their characteristics are not configured on the client, but come from the server. This generic component merely calls the specialized filter components with the right props for each filter associated with a table. Whereas the incoming props contain information for all filters, each individual specialized filter is passed only the slice that is relevant to that one filter.","title":"Filter"},{"location":"Client/Components/#fulltext","text":"See Fulltext . connected via filters Props Standard props : table filterTag filterId filterLabel filterSetting filteredAmount filteredAmountOthers compact dispatch Task Displays a full text search input field. The characters entered in this field are passed upwards by means of a callback. This is incremental search. Not only the full text search, but also all other filters are computed upon each character entered. Note that we use the strategy of controlled components here.","title":"Fulltext"},{"location":"Client/Components/#stat","text":"See Stat . presents filters Props Standard props : className Specific props: name type description subtotal number subtotal to display total number total to display Task Displays a string of the form subTotal of total . If one of the two is missing, the of will not display.","title":"Stat"},{"location":"Client/Components/#select","text":"","title":"select"},{"location":"Client/Components/#relselect","text":"See RelSelect . presents select Props Standard props : settings tables table select field dispatch submitValues Specific props: name type description multiple bool whether to display a select widget where the user can make multi-selections or only single selections allowNew bool whether to allow the user to add new options selectTag string a key under which this component stores its data on the select slice of the global state. This is about whether the options have popped up and what search text the user has entered in the filter box activeItems array the notion of active items is defined in the duct workflow isactive string a CSS class name to add extra formatting if the record in question is deemed inactive allowed object an array of entity ids that are the allowed elements when the field is a multiple choice field input object contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> Task An implementation of multi-select widgets. There is a fairly complete react-select component on GitHub. However, it has some flaws that prevents a successful usage of it in our app. That is why I have written this component. The capabilities of this widget are: single select or multi-select, depending on the property multiple ; fixed list of values or the possibility to create new values on the fly, depending on the prop allowNew ; options can be filtered by a full text filter; only one copy of an option can be chosen; selected options are removed from the list of selectable options; plays well with Redux-Form ; facilitates disabling some options and presenting options in custom ways","title":"RelSelect"},{"location":"Client/Components/#alter","text":"","title":"alter"},{"location":"Client/Components/#expand","text":"See Expand . presents alter Props Standard props : alter alterSection alterTag className Specific props: name type description initAlt number initial expand/collapse state headActive string clickable part of the component headLine string part of the component that is visible in both states full component part of the component that is visible in the expanded state only iconOpen component icon, clickable, to trigger expansion iconClose component icon, clickable, to trigger collapse titleOpen string tooltip for the expansion trigger titleClose string tooltip for the collapse trigger Task Shows a expandable / collapsable component, together with controls to trigger these actions. In expanded form, only the headActive and headLine are visible. The headActive is the part that the user can click on to trigger expansion and collapse. The headActive is combined with iconOpen and iconClose , which are indicators for the state of the component. All this is wrapped in a Tooltip components, that display the titleOpen and titleClose texts. In the full form, also the full is visible. Sometimes you need more distance between the control and the material of the component. So we export related components as well:","title":"Expand"},{"location":"Client/Components/#expandhead","text":"Props Works with the same args as Expand , minus full . Task This component presents the headline part, including the clickable part to trigger the actions.","title":"ExpandHead"},{"location":"Client/Components/#expandbody","text":"Props Works with the same args as Expand , minus alter , alterSection , alterTag , initAlt , className . Task This component presents the fully expanded part if the states indicate so, or else nothing.","title":"ExpandBody"},{"location":"Client/Components/#miscellaneous","text":"","title":"Miscellaneous"},{"location":"Client/Components/#bool3","text":"See Bool3 . (life cycle) Props input meta submitValues (provided by Redux-From, because this component is wrapped in a Field Task Displays a 3-valued checkbox that represents true , false or null . We have to resort to a DOM manipulation after rendering to get the indeterminate state across.","title":"Bool3"},{"location":"Client/Components/#errorboundary","text":"See ErrorBoundary . Task Generic component, using new error handling functionality of React 16. We use it to wrap components inside which errors may occur. Those errors are then propagated to an enclosing ErrorBoundary , where they will be catched. The console will log the error, and at the ErrorBoundary will be rendered in place of its normal contents. Currently we render the error boundary as a red block with a single diagnostic message.","title":"ErrorBoundary"},{"location":"Client/Components/#navlink","text":"See NavLink . presents none Props Standard props : Specific props: name type description activeClassName string the CSS class to be used when the navigation link has been clicked ...props All other props are passed to the wrapped <Link/> component. Task Displays a navigation link that is sensitive to routing. That means: it is a link that can activate a component, and, when clicked, it will become highlighted.","title":"NavLink"},{"location":"Client/Components/#notfound","text":"See NotFound . presents none Props Specific props: name type description splat string the text to display on the 404 page Task Displays a 404 if no route in main matches.","title":"NotFound"},{"location":"Client/Components/#overview","text":"See Overview . Task Under construction. Meant to become a customized dashboard for the back office functions.","title":"Overview"},{"location":"Client/Components/#static","text":"See Static . presents none Task Displays navigation links to some static resources.","title":"Static"},{"location":"Client/Dux/","text":"Dux (Appliances) \u00b6 Dux (ducts) are appliances within the app, i.e. sets of components that all work with the same slice of the state A dux is a connector between a slice of the state and the components that work with that slice. As such, it is a piece of plumbing, hidden behind the walls and under the floors. Organization A dux is organized as one file that contains its actions , reducer , selectors and helpers ; reducer Programmed as an object of flows . For each action , there is a flow with the same name, which is a function that produces a new state on the basis of that action. Associated components A dux is associated a number of React components that make use of it by importing its actions , selectors , and/or helpers . Many-many relationship between dux and components However, life is complicated, and the interplay between dux and components is no exception. Sometimes actions will be fired that affect more than one slice of the state. filters, alter For example, in order to set up filters for a table, both the tables slice and the filters slice are needed. And when the user expands a table row into a record form, the alter state is changed to cater for the expand action, and the tables slice is changed by receiving additional data for that record. In Redux, the slices of the state are not sealed off from each other. In the end, there is one and only one reducer, that examines every dispatched action for its type property, and hands it over to a sub-reducer that has \"subscribed\" to handle actions for that type. It is perfectly possible that multiple sub-reducers will deal with a single action. detail records A good example is when a record is displayed with multiple detail records, displayed as a list of titles. There is a button \"Open All\" on the interface. When it is pressed, data for all detail records is fetched, and the titles expand into full record views for those details. The way it is implemented, is that pressing \"Open All\" leads to the dispatch of an action with type fetchItems , and with payload the list of ids of the entities that must be fetched. To this action, the tables sub-reducer reacts by fetching the corresponding entity data from the server, and the alter sub-reducer reacts by expanding the corresponding entity titles into full records. Whenever you are tempted to write complicated, time-sensitive logic to orchestrate what happens at multiple slices of the state, all that is needed is in fact just an extra response of an other sub-reducer. alter \u00b6 See alter . Explanation A mechanism for switching between alternative representations of a component, such as: expanded / collapsed, editable / read-only. It is a bit more general than that: you can supply n alternatives and n controls, and let the user cycle through the alternatives by clicking the controls. Components that work with alternatives must collect them in a group. The name of that group is passed as a prop called alterSection . Component that are passed this prop, have access to the state of the alternatives in this group. To get the state information for a single alternative, another key must be supplied, usually called alterTag . The component that displays the alternatives need not be the same component that presents the controls to switch alternatives. actions All/ actions below work relative an alterSection and alterTag . nextAlt Switch to the next alternative. This action must specify the total number of alternatives and an optional initial value. If there is not yet a state for this instantiation, the initial value will be used to start from. setAlt Switch to specified alternative. setItems This function is used to switch a bunch of records from an open to a closed state or vice versa. reducer Increases the index of the alternative by one, cyclically, and puts it under the right keys in the state.. selectors getAltSection Delivers the numbers of the current alternatives as far as they are registered under the alterSection key in the alter slice of the state. helpers compileAlternatives A component that wants to work with the alternatives, of a group of components, must call compileAlternatives() with the right parameters. Think of a List component that wants to provide child items with a control to expand themselves. It is more efficient that the List connects to the alter state, than that each item connects to that state individually. This function is a factory function that, given an alterTag , delivers an object with functions for getting and setting the alternatives of that particular instance. all alternatives together It is tempting to make one alterSection for all components in the app that need alternatives. The flip side of doing so is that all those components will be triggered for re-render whenever any single one of them switches alternatives. That is why we offer the possibility of grouping related components under the same alterSection and be shielded from updates in the components that belong to other alterSections . docs \u00b6 See docs . Explanation Manages Markdown documents. Fetches raw source from the server and stores it into the state, under a key, which is the path information of the document. The DocMd provides a widget for such documents. actions fetchDoc Fetches a document from the server asynchronously. reducer Stores the fetched raw document source into the state. selectors getDoc Retrieves the stored data for the specified document. helpers needDoc Check whether a component contains the data for its document. changedDoc Check whether a component has new props in such a way that a new document should be fetched. filters \u00b6 See filters . Explanation Supports the display of filtered lists, where there is a bunch of filters and a list with items filtered by those. Lists and filters form a complex system of components, involving fetching list data from the server, fetching filter specifications fetching the metadata that is used by the filtering handling the user interactions with the filters supporting special effects such as a map of European countries with markers having a radius indicative of the number of filtered items by that country. multiple slices This dux not only needs data from the filters slice, but also from the tables slice! actions changeFulltext Responds to a change in the search text in a Fulltext search widget. changeFacet Responds to a click in the checkbox of a facet Facet . changeFacetAll Responds to a click to (de)select all facets of a field. initFiltering Initializes filtering for a table. This action also looks at the tables slice of the state, which is managed by tables . The actual work is done by a memoized helper function compileFieldIds() below. On the basis of this, initial settings of facet filters can be made. This is done by the helper function initFilterSettings() below and these settings are to be added to the filters slice of the state under the key table and then under a key filterTag . In this way you can set up various kinds of filtering for the same table. reducer Transforms the state in response to dispatched actions, notably the filters slice and within that a sliced keyed by table . selectors Abstract Filter information is being translated from the state to props that can be consumed by components. getFilters Reads the current settings of a filter and injects it as filters into the props of the receiving components, which are typically the filter widgets that receive user interaction: Fulltext Facet , and also CheckboxI , EUMap . helpers compileValues For every field that is chosen for faceted browsing, the list of values will be compiled. The result is used by ByValue . This component is responsible for all the facets of a field. memoization It is useful to store the results of this compilation, but where? We do not store it in the state, because it is derived data, and we adhere to the principle that the state is a normalized single source of truth . Selectors are invoked upon each rendering, but in this case we do not want to redo the compilation all the time. The solution is to use a memoized function . I have created my own memoizer . computeFiltering Applies the filters, according to the current filter settings. Applying means: determine the subset of filtered items ( filteredData ), and provide statistics for the facets. Every faceted field displays as total the amount of items filtered by all other filters ( filteredAmountOthers ). For each of its facets, it displays how many items of this relative total correspond to that facet ( amounts ). So this function delivers exactly that: filteredData , filteredAmountOthers , amounts . It is also a costly function, but it does need to be invoked upon each rendering caused by a click or a key press. makeTag Makes a filterTag , depending on the situation of the List of items that needs the filtering. The most fundamental issue is: is the list showing all items in the table, or my items only, or is it a list of detail records of some master record in an other table? testAllChecks Looks if all facets are checked, or all unchecked, of none of both. Used to steer the collective checkbox that governs all facets. forms \u00b6 See forms . Explanation The forms slice of the state is under control of the Redux-Form module. It contains all current form data of components where the user is interacting with forms. Some other components might want to know whether a component is engaged in data entry or not, without fully connecting to all form state properties of redux-form. This dux gives that information and that information only. reducer No reducer, because Redux-Form has its own reducer and we include it in our overall reducer. selectors getForms Returns the set of keys of the forms slice of the state. It calls a memoized function to turn the keys into a set. So, if the set of keys is asked repeatedly without having been changed, exactly the same set object is being returned. grid \u00b6 See grid . Explanation This dux support grid views of tables, by managing sorting information of the grid columns. Every grid table must identify itself with a gridTag and its data resides on the grid slice of the state under that tag. actions resetSort Removes all sorting information under a gridTag . addColumn Adds a sorting column. Grids can be sorted by multiple columns. delColumn Deletes a sorting column. turnColumn Toggles the sort method between ascending and descending for a specified column. reducer Applies the state changes, defined by the actions, to the grid slice, under the key gridTag . selectors getGrid Returns the grid slice of the state. helpers compileSortedData This function actually applies a given sort order to a list of ids of items from a table. me \u00b6 See me . Explanation Powers the login widget, top right on the screen, realized by the component Login . The login procedure caters for shibboleth logins. Upon successful login, the server sends information about the currently logged in user to the client. The main task of Login is to fetch the current authentication status: is there an authenticated user, and if so, what is his/her name? How the client knows the user name Because of the federated login, the username and password are not entered in any form in this app. So the client does not know who the user is, except by asking the server. The current user can be retrieved by /api/db/who/ami . actions fetchMe Fetches data about me , the logged in user. It is actually handled by the helper server . reducer Transforms the state in response to dispatched ticket, notably the me slice. It just contains the known attributes of a single user, the one that is logged in. selectors getMe Plainly hand over the attributes of the currently logged in user. At the moment only the Login component is interested in it. notes \u00b6 See notes . Explanation Powers the notification widget, top right on the screen, realized by the component Notification . A notification has a kind and a text . The kind is one of error , warning , special , info . All non-info messages are considered important. Normally, the notification panel is hidden, but it can be called up by clicking on the progress circle in the top-right of the screen. The panel also shows up if there is a new important message, and it will scroll to the last important one. The user can click away the panel and hide the messages. actions notify Issues its payload, which consists of an array of messages, as notifications. clear Clears the existing list of notifications. display Turns the visibility of notification panel on or off. Other components can issue notifications easily, either by importing these actions, or by dispatching the right actions themselves. The helper function accessData can issue notifications. These notifications are given the type async and convey a status pending , success , or error . reducer Transforms the state in response to dispatched ticket, notably the notes slice. The state maintains a counter busy , which is the number of currently asynchronously pending operations. A notification widget can show a progress spinner if busy > 0 . selectors getNotes The notification widget gets the notifications from the state, including busy and show , the latter indicating whether the notification panel should be hidden or not. For the convenience of the Notification component, the index of the last important notification message is also computed, and its kind. roots \u00b6 See roots . Explanation Top level management of the state: initialization and combination of all the other dux. actions configureStore Root does not have proper actions of its own. But it does set up the store, and passes it on to the main component. reducer Combines all slices of the state and combines all reducers that work their own slice of the state into the root reducer , that operates on the whole state. select \u00b6 See select . Explanation Manages the UI-state of the RelSelect component. Every RelSelect instance must be identified by a tag, so that the states of the select controls do not get confused. The most obvious choice for a tag value is a composition of the table name, the entity id, and the field name. actions setSearch When a user types something in the search input field associated with the select control, the search string is sent to the state. setPopUp Parts of the interface of the select widget will pop up after a user action, or disappear after an other user action. This action sets the popped up state categorically to true or false , depending on a parameter. togglePopUp Toggles the popped up state of the relevant part of the widget. reducer Straightforward merge of the payload of pop up actions and search string updates into the state. selectors getSelect Retrieves all state information of a specific select control, i.e. an instance identified by a tag. helpers compileOptions Initializes the state for a specific select control. This is an initialization per tag . server \u00b6 See server . Explanation Here all interaction with the server is managed. All activity that involves waiting for a server, will eventually reach out to actions here. The actions below only are concerned with requesting a server response, waiting for it, and reporting success or failure. Before a request is made, it is checked whether that request has been submitted before and is still pending. In that case, the request counter will be increased, and no new request will be made. request counters that are non-zero correspond to requests that are either pending, or have ended in failure; pending requests have positive request counters, the number represents the number of requests the app has tried to make so far (only 1 request will be issued effectively); successful request have their request counter set to 0 again. actions accessData Asynchronous action to fetch data from the server, and also to send data to it. A task object specifies what to fetch, and can contain data to send to the server. It can be used for database queries or file content. During the stages of a request, notify actions will be dispatched. progress This action represents the situation that a request is offered multiple times before the first one has been completed. The request will not be made, but the request counter will be increased. ask Just before a request is made, this action sets the request counter to 1. err When a request returns failure, the request counter is set to -1. succeed When a request returns success, the request counter is set to 0. reducer Manages the request counter and puts it under a key under the server slice of the state. The key is identical to the path of the request (the URL that is fired to the server). triggering of notes reducer All actions except accessData are also picked up by the notes reducer, where they result in notifications. settings \u00b6 See settings . Explanation Cross cutting settings for the app are defined here. The settings slice of the state is just a store of keys and values. actions set Adds a key value pair. reducer Straightforward reducer. selectors getSettings Returns the settings slice of the state. tables \u00b6 See tables . Explanation Manages database data from the server. It keeps a normalized copy of the data. When different components fetch the bits and pieces they need, it all lands here, properly organized. This reduces the amount of fetching that is needed, and it improves consistency, because all data consuming components look at the same data. Principal data consuming components are ListContainer and Items . filters In order to do the job properly, a fair amount of metadata about tables and fields is also fetched and stored. In particular, tables specify which filters can be used on which fields. This filter setup is not hard-wired into the client app, but comes from the server, where it is configured in the data model . actions fetchTable Fetches a complete table, but only the title fields and the fields needed for filtering. fetchTables Fetches a list of tables by successively calling fetchTable . fetchItem Fetches a single rows from a table, all fields. The server decides which fields I am allowed to retrieve. If fields refer to other tables for their values, the above actions will fetch these tables as well. fetchItems Fetches a selection of rows from a table, all fields. The selection is given by a list of _id s to fetch. The server decides which fields may be retrieved. modItem Sends a request to update an item to the server, and merges the answer (the updated values) into the state. insertItem Sends a request to insert an item to the server, and merges the answer (the inserted item) into the state. delItem Sends a request to delete an item to the server, and updates the state to reflect the deletion of that item. reducer The actions above potentially receive overlapping data. The reducer takes care that all gets sorted out, and that every bit ends up in its proper place. entities A table is stored under its name as key. The table information is an object of entities (rows), keyed by their database id. For each id there is an object containing the field values, an object that contains the workflow information, and an object that contains the permissions for that record. The entities themselves have a values object, with all the field values, keyed by field name. Next to the values there is an attribute complete that tells whether all fields for this entity have been fetched, or only the core fields. order Array of ids that specifies the order. my If only my rows are being retrieved, this array contains the ids of the retrieved entities in the right order. fields The fields of a table. fieldOrder The display order of the fields. fieldSpecs The specifications of a field: data type, multiplicity, related table, permissions (table wide). details An array of objects that describe the tables where the detail records of the main records are. detailOrder The display order of the lists of detail records. complete Whether the table has been retireved complete, or only the titles of the records. filterList An array of filters that are in force. valueLists An array of lists of values that this table refers to. my items As an example, consider the scenario that first the complete list of items is fetched, then the my items. The question is: after fetching the my items, will the full table that has been fetched before, be disturbed? The answer is of course no. Because the reducer merges the my entities with the existing entities. So the non- my entities are untouched. But what about order ? Well, when reducing a my-fetch action, there is no incoming order array but a my array instead, and the order that already exists on the state is not touched. single item and then full list As a second example, consider the scenario where a single item is fetched first, with all its fields, and then the full list of items, but with only title fields. The question is: will the previously fetched item loose its extra fields? The answer is of course no. Because the reducer merges the new entities' values with existing entities' values. the art of merging Of all dux, this is the best example of what proper reducing is and what it achieves. It might look hard to take care of this merging, under the constraint that only those branches of the state should be touched that are actually updated. But the lodash mergeWith makes this a breeze. Unfortunately, this library does not always leave unchanged values untouched, which results in unnecessary re-renderings of components. The best solution turned out to be Immutability-Helper . If you want to dive deeper into this issue, see the tests about merging , which includes tests that makes this issue crystal clear. The methods of the Immutability-Helper have a syntax inspired by the MongoDB commands, which is a nice reduction of cognitive load, since we use MongoDB at the server side. Have a look again at the reducer source code and see how straightforward it is to code one of the most tricky reducers in this app. This reducer actively covered by tests . Have a look at them to get more feeling of how table actions cause state transitions. selectors getTables Return the whole tables slice of the state. helpers entityHead Computes the title for an item, based on the data model or on specialized functions, defined here. See also repr . needTable Checks if sufficient table data is available in the state. needTables Checks a list of table names to see if sufficient data is available in the state. needValues Checks a single entity in a single table to see if it contains values for all fields. listValues Gives the list of all values of a specified field in a table. presentUser Presents a user, by means of name, email address, and/or eppn , depending on what information is available, which also depends on what information may be shared with the currently logged in user. changedItem Checks if properties have changed in such a few that new data should be fetched. headEntity The head line of a record, based on its title field and/or other data. For some specific tables custom logic is used. repr Makes a streamlined string representation out of a field value. It looks up ids in related value list tables. For some tables, special representation functions will be invoked. (users, countries, etc.). toDb Dispatches an item modification action to the store. handleOpenAll When a user clicks on an Open All button, this function is invoked to fetch the corresponding records (if needed). handleCloseAll When a user clicks on an Close All button, this function is invoked to collapse the corresponding records and remove the _id s of the previously open records from the URL, using browserHistory . win \u00b6 See win . Explanation Reacts to window resizing by the user. It will deliver the new window size after resizing. Useful for components that care about the window size, such as App . actions changeWinDim Responds to window resizing, as set up in Window.md . It is just a matter of storing the height and the width of the window into the state. Note that the event emitter in Window.md is being throttled, so that it does not run too frequently during the actual resizing. reducer Transforms the win slice of the state in response to resize events. selectors getWinDim Returns the win slice of the state, which is just the current width and height of the browser window. workflow \u00b6 See workflow . Explanation A lot of the logic of showing lists, items, related items and fields is purely generic and driven by the data model . But there is considerably more to an app than this kind of generic logic. The workflow dux is the entry point for additional, non-trivial business logic. It is still in development. Active items The package table determines a lot about the assessment process. It has records with a specified startDate end endDate. The packages that have started and are not yet passed there endDate are the active packages. Normally there will be exactly one package. From the active package derive a number of other active concepts: the contribution types listed in the typeContribution field of the active package are the active types the criteria that are details of the active package are active criteria . The generic List and Item components can be made sensitive to this notion of activity. Active items can be formatted specially, and likewise the non-active items, which can also be disabled in some contexts. The way (in)active items are displayed is controlled by the data model . See for example the field typeContribution in the tables package and criteria . actions fetchWorkflow Fetch the info about the workflow information from the server, in particular the reset history since the last startup of the web server. resetWorkflow Fetch the same information as fetchWorkflow does, but add ?reset=true to the URL that is used to query this information from the server. This will instruct the server to perform a workflow reset. reducer The reducer is simple, it only has to perform one action: put incoming workflow data unto the state. No sophisticated merging is needed, because this workflow meta information is only needed for one component, WorkflowInfo , which is meant for sysadmins only. uses tables reducer The workflow data moves from server to client on the shoulders of the tables reducer. selectors getWorkflow Returns the workflow slice of the state. helpers compileActiveItems Computes the active packages, types and criteria and deliver them in an object, keyed by kind of item and containing an array of active item MongoDB ids for that kind. decisions Most of the contents of the decision table, in the form of objects by which you can find various user-facing strings associated with the three possible review decisions: accept , revise , and reject . finalDecision From workflow attributes that contain reviewers and reviews respectively, find out whether there has been a final decision by reviewer 2, and if so, what it was. getItem Peels out items of data from a workflow attribute that has fetched arrays of data from other records. isReviewerType Computes whether a given author is the first or second reviewer. loadExtra This is a configuration object that specifies which extra tables should be fetched from the server along with particular other tables. For example, the app can only perform its business logic on contributions, if the tables package , criteria , typeContribution , and decision are all present on the state. processStatus Produce a string that contains the current assessment status and review status of an assessment. This function can be called from a contribution, an assessment and a review. So for all these kinds of record we can produce a short overview of the state they have reached in the assessment / review process. The outcome has a bit that reveals the assessment status and a bit about the review status. When it is run on behalf of a user with marginal rights, it delivers either the empty string, or the outcome of the final review, but only if there has been a positive outcome. For users with more rights: assessment status: \u25b6 if the assessment has been (re)submitted; \u270d otherwise; the assessment score review status: empty string if there review has not reached a final decision; \u2714 on accept ; \u270b on revise ; \u2718 on reject . reviewerRole Object that maps the acronyms E and F to appropriate labels designating first and second reviewer.","title":"Dux"},{"location":"Client/Dux/#dux-appliances","text":"Dux (ducts) are appliances within the app, i.e. sets of components that all work with the same slice of the state A dux is a connector between a slice of the state and the components that work with that slice. As such, it is a piece of plumbing, hidden behind the walls and under the floors. Organization A dux is organized as one file that contains its actions , reducer , selectors and helpers ; reducer Programmed as an object of flows . For each action , there is a flow with the same name, which is a function that produces a new state on the basis of that action. Associated components A dux is associated a number of React components that make use of it by importing its actions , selectors , and/or helpers . Many-many relationship between dux and components However, life is complicated, and the interplay between dux and components is no exception. Sometimes actions will be fired that affect more than one slice of the state. filters, alter For example, in order to set up filters for a table, both the tables slice and the filters slice are needed. And when the user expands a table row into a record form, the alter state is changed to cater for the expand action, and the tables slice is changed by receiving additional data for that record. In Redux, the slices of the state are not sealed off from each other. In the end, there is one and only one reducer, that examines every dispatched action for its type property, and hands it over to a sub-reducer that has \"subscribed\" to handle actions for that type. It is perfectly possible that multiple sub-reducers will deal with a single action. detail records A good example is when a record is displayed with multiple detail records, displayed as a list of titles. There is a button \"Open All\" on the interface. When it is pressed, data for all detail records is fetched, and the titles expand into full record views for those details. The way it is implemented, is that pressing \"Open All\" leads to the dispatch of an action with type fetchItems , and with payload the list of ids of the entities that must be fetched. To this action, the tables sub-reducer reacts by fetching the corresponding entity data from the server, and the alter sub-reducer reacts by expanding the corresponding entity titles into full records. Whenever you are tempted to write complicated, time-sensitive logic to orchestrate what happens at multiple slices of the state, all that is needed is in fact just an extra response of an other sub-reducer.","title":"Dux (Appliances)"},{"location":"Client/Dux/#alter","text":"See alter . Explanation A mechanism for switching between alternative representations of a component, such as: expanded / collapsed, editable / read-only. It is a bit more general than that: you can supply n alternatives and n controls, and let the user cycle through the alternatives by clicking the controls. Components that work with alternatives must collect them in a group. The name of that group is passed as a prop called alterSection . Component that are passed this prop, have access to the state of the alternatives in this group. To get the state information for a single alternative, another key must be supplied, usually called alterTag . The component that displays the alternatives need not be the same component that presents the controls to switch alternatives. actions All/ actions below work relative an alterSection and alterTag . nextAlt Switch to the next alternative. This action must specify the total number of alternatives and an optional initial value. If there is not yet a state for this instantiation, the initial value will be used to start from. setAlt Switch to specified alternative. setItems This function is used to switch a bunch of records from an open to a closed state or vice versa. reducer Increases the index of the alternative by one, cyclically, and puts it under the right keys in the state.. selectors getAltSection Delivers the numbers of the current alternatives as far as they are registered under the alterSection key in the alter slice of the state. helpers compileAlternatives A component that wants to work with the alternatives, of a group of components, must call compileAlternatives() with the right parameters. Think of a List component that wants to provide child items with a control to expand themselves. It is more efficient that the List connects to the alter state, than that each item connects to that state individually. This function is a factory function that, given an alterTag , delivers an object with functions for getting and setting the alternatives of that particular instance. all alternatives together It is tempting to make one alterSection for all components in the app that need alternatives. The flip side of doing so is that all those components will be triggered for re-render whenever any single one of them switches alternatives. That is why we offer the possibility of grouping related components under the same alterSection and be shielded from updates in the components that belong to other alterSections .","title":"alter"},{"location":"Client/Dux/#docs","text":"See docs . Explanation Manages Markdown documents. Fetches raw source from the server and stores it into the state, under a key, which is the path information of the document. The DocMd provides a widget for such documents. actions fetchDoc Fetches a document from the server asynchronously. reducer Stores the fetched raw document source into the state. selectors getDoc Retrieves the stored data for the specified document. helpers needDoc Check whether a component contains the data for its document. changedDoc Check whether a component has new props in such a way that a new document should be fetched.","title":"docs"},{"location":"Client/Dux/#filters","text":"See filters . Explanation Supports the display of filtered lists, where there is a bunch of filters and a list with items filtered by those. Lists and filters form a complex system of components, involving fetching list data from the server, fetching filter specifications fetching the metadata that is used by the filtering handling the user interactions with the filters supporting special effects such as a map of European countries with markers having a radius indicative of the number of filtered items by that country. multiple slices This dux not only needs data from the filters slice, but also from the tables slice! actions changeFulltext Responds to a change in the search text in a Fulltext search widget. changeFacet Responds to a click in the checkbox of a facet Facet . changeFacetAll Responds to a click to (de)select all facets of a field. initFiltering Initializes filtering for a table. This action also looks at the tables slice of the state, which is managed by tables . The actual work is done by a memoized helper function compileFieldIds() below. On the basis of this, initial settings of facet filters can be made. This is done by the helper function initFilterSettings() below and these settings are to be added to the filters slice of the state under the key table and then under a key filterTag . In this way you can set up various kinds of filtering for the same table. reducer Transforms the state in response to dispatched actions, notably the filters slice and within that a sliced keyed by table . selectors Abstract Filter information is being translated from the state to props that can be consumed by components. getFilters Reads the current settings of a filter and injects it as filters into the props of the receiving components, which are typically the filter widgets that receive user interaction: Fulltext Facet , and also CheckboxI , EUMap . helpers compileValues For every field that is chosen for faceted browsing, the list of values will be compiled. The result is used by ByValue . This component is responsible for all the facets of a field. memoization It is useful to store the results of this compilation, but where? We do not store it in the state, because it is derived data, and we adhere to the principle that the state is a normalized single source of truth . Selectors are invoked upon each rendering, but in this case we do not want to redo the compilation all the time. The solution is to use a memoized function . I have created my own memoizer . computeFiltering Applies the filters, according to the current filter settings. Applying means: determine the subset of filtered items ( filteredData ), and provide statistics for the facets. Every faceted field displays as total the amount of items filtered by all other filters ( filteredAmountOthers ). For each of its facets, it displays how many items of this relative total correspond to that facet ( amounts ). So this function delivers exactly that: filteredData , filteredAmountOthers , amounts . It is also a costly function, but it does need to be invoked upon each rendering caused by a click or a key press. makeTag Makes a filterTag , depending on the situation of the List of items that needs the filtering. The most fundamental issue is: is the list showing all items in the table, or my items only, or is it a list of detail records of some master record in an other table? testAllChecks Looks if all facets are checked, or all unchecked, of none of both. Used to steer the collective checkbox that governs all facets.","title":"filters"},{"location":"Client/Dux/#forms","text":"See forms . Explanation The forms slice of the state is under control of the Redux-Form module. It contains all current form data of components where the user is interacting with forms. Some other components might want to know whether a component is engaged in data entry or not, without fully connecting to all form state properties of redux-form. This dux gives that information and that information only. reducer No reducer, because Redux-Form has its own reducer and we include it in our overall reducer. selectors getForms Returns the set of keys of the forms slice of the state. It calls a memoized function to turn the keys into a set. So, if the set of keys is asked repeatedly without having been changed, exactly the same set object is being returned.","title":"forms"},{"location":"Client/Dux/#grid","text":"See grid . Explanation This dux support grid views of tables, by managing sorting information of the grid columns. Every grid table must identify itself with a gridTag and its data resides on the grid slice of the state under that tag. actions resetSort Removes all sorting information under a gridTag . addColumn Adds a sorting column. Grids can be sorted by multiple columns. delColumn Deletes a sorting column. turnColumn Toggles the sort method between ascending and descending for a specified column. reducer Applies the state changes, defined by the actions, to the grid slice, under the key gridTag . selectors getGrid Returns the grid slice of the state. helpers compileSortedData This function actually applies a given sort order to a list of ids of items from a table.","title":"grid"},{"location":"Client/Dux/#me","text":"See me . Explanation Powers the login widget, top right on the screen, realized by the component Login . The login procedure caters for shibboleth logins. Upon successful login, the server sends information about the currently logged in user to the client. The main task of Login is to fetch the current authentication status: is there an authenticated user, and if so, what is his/her name? How the client knows the user name Because of the federated login, the username and password are not entered in any form in this app. So the client does not know who the user is, except by asking the server. The current user can be retrieved by /api/db/who/ami . actions fetchMe Fetches data about me , the logged in user. It is actually handled by the helper server . reducer Transforms the state in response to dispatched ticket, notably the me slice. It just contains the known attributes of a single user, the one that is logged in. selectors getMe Plainly hand over the attributes of the currently logged in user. At the moment only the Login component is interested in it.","title":"me"},{"location":"Client/Dux/#notes","text":"See notes . Explanation Powers the notification widget, top right on the screen, realized by the component Notification . A notification has a kind and a text . The kind is one of error , warning , special , info . All non-info messages are considered important. Normally, the notification panel is hidden, but it can be called up by clicking on the progress circle in the top-right of the screen. The panel also shows up if there is a new important message, and it will scroll to the last important one. The user can click away the panel and hide the messages. actions notify Issues its payload, which consists of an array of messages, as notifications. clear Clears the existing list of notifications. display Turns the visibility of notification panel on or off. Other components can issue notifications easily, either by importing these actions, or by dispatching the right actions themselves. The helper function accessData can issue notifications. These notifications are given the type async and convey a status pending , success , or error . reducer Transforms the state in response to dispatched ticket, notably the notes slice. The state maintains a counter busy , which is the number of currently asynchronously pending operations. A notification widget can show a progress spinner if busy > 0 . selectors getNotes The notification widget gets the notifications from the state, including busy and show , the latter indicating whether the notification panel should be hidden or not. For the convenience of the Notification component, the index of the last important notification message is also computed, and its kind.","title":"notes"},{"location":"Client/Dux/#roots","text":"See roots . Explanation Top level management of the state: initialization and combination of all the other dux. actions configureStore Root does not have proper actions of its own. But it does set up the store, and passes it on to the main component. reducer Combines all slices of the state and combines all reducers that work their own slice of the state into the root reducer , that operates on the whole state.","title":"roots"},{"location":"Client/Dux/#select","text":"See select . Explanation Manages the UI-state of the RelSelect component. Every RelSelect instance must be identified by a tag, so that the states of the select controls do not get confused. The most obvious choice for a tag value is a composition of the table name, the entity id, and the field name. actions setSearch When a user types something in the search input field associated with the select control, the search string is sent to the state. setPopUp Parts of the interface of the select widget will pop up after a user action, or disappear after an other user action. This action sets the popped up state categorically to true or false , depending on a parameter. togglePopUp Toggles the popped up state of the relevant part of the widget. reducer Straightforward merge of the payload of pop up actions and search string updates into the state. selectors getSelect Retrieves all state information of a specific select control, i.e. an instance identified by a tag. helpers compileOptions Initializes the state for a specific select control. This is an initialization per tag .","title":"select"},{"location":"Client/Dux/#server","text":"See server . Explanation Here all interaction with the server is managed. All activity that involves waiting for a server, will eventually reach out to actions here. The actions below only are concerned with requesting a server response, waiting for it, and reporting success or failure. Before a request is made, it is checked whether that request has been submitted before and is still pending. In that case, the request counter will be increased, and no new request will be made. request counters that are non-zero correspond to requests that are either pending, or have ended in failure; pending requests have positive request counters, the number represents the number of requests the app has tried to make so far (only 1 request will be issued effectively); successful request have their request counter set to 0 again. actions accessData Asynchronous action to fetch data from the server, and also to send data to it. A task object specifies what to fetch, and can contain data to send to the server. It can be used for database queries or file content. During the stages of a request, notify actions will be dispatched. progress This action represents the situation that a request is offered multiple times before the first one has been completed. The request will not be made, but the request counter will be increased. ask Just before a request is made, this action sets the request counter to 1. err When a request returns failure, the request counter is set to -1. succeed When a request returns success, the request counter is set to 0. reducer Manages the request counter and puts it under a key under the server slice of the state. The key is identical to the path of the request (the URL that is fired to the server). triggering of notes reducer All actions except accessData are also picked up by the notes reducer, where they result in notifications.","title":"server"},{"location":"Client/Dux/#settings","text":"See settings . Explanation Cross cutting settings for the app are defined here. The settings slice of the state is just a store of keys and values. actions set Adds a key value pair. reducer Straightforward reducer. selectors getSettings Returns the settings slice of the state.","title":"settings"},{"location":"Client/Dux/#tables","text":"See tables . Explanation Manages database data from the server. It keeps a normalized copy of the data. When different components fetch the bits and pieces they need, it all lands here, properly organized. This reduces the amount of fetching that is needed, and it improves consistency, because all data consuming components look at the same data. Principal data consuming components are ListContainer and Items . filters In order to do the job properly, a fair amount of metadata about tables and fields is also fetched and stored. In particular, tables specify which filters can be used on which fields. This filter setup is not hard-wired into the client app, but comes from the server, where it is configured in the data model . actions fetchTable Fetches a complete table, but only the title fields and the fields needed for filtering. fetchTables Fetches a list of tables by successively calling fetchTable . fetchItem Fetches a single rows from a table, all fields. The server decides which fields I am allowed to retrieve. If fields refer to other tables for their values, the above actions will fetch these tables as well. fetchItems Fetches a selection of rows from a table, all fields. The selection is given by a list of _id s to fetch. The server decides which fields may be retrieved. modItem Sends a request to update an item to the server, and merges the answer (the updated values) into the state. insertItem Sends a request to insert an item to the server, and merges the answer (the inserted item) into the state. delItem Sends a request to delete an item to the server, and updates the state to reflect the deletion of that item. reducer The actions above potentially receive overlapping data. The reducer takes care that all gets sorted out, and that every bit ends up in its proper place. entities A table is stored under its name as key. The table information is an object of entities (rows), keyed by their database id. For each id there is an object containing the field values, an object that contains the workflow information, and an object that contains the permissions for that record. The entities themselves have a values object, with all the field values, keyed by field name. Next to the values there is an attribute complete that tells whether all fields for this entity have been fetched, or only the core fields. order Array of ids that specifies the order. my If only my rows are being retrieved, this array contains the ids of the retrieved entities in the right order. fields The fields of a table. fieldOrder The display order of the fields. fieldSpecs The specifications of a field: data type, multiplicity, related table, permissions (table wide). details An array of objects that describe the tables where the detail records of the main records are. detailOrder The display order of the lists of detail records. complete Whether the table has been retireved complete, or only the titles of the records. filterList An array of filters that are in force. valueLists An array of lists of values that this table refers to. my items As an example, consider the scenario that first the complete list of items is fetched, then the my items. The question is: after fetching the my items, will the full table that has been fetched before, be disturbed? The answer is of course no. Because the reducer merges the my entities with the existing entities. So the non- my entities are untouched. But what about order ? Well, when reducing a my-fetch action, there is no incoming order array but a my array instead, and the order that already exists on the state is not touched. single item and then full list As a second example, consider the scenario where a single item is fetched first, with all its fields, and then the full list of items, but with only title fields. The question is: will the previously fetched item loose its extra fields? The answer is of course no. Because the reducer merges the new entities' values with existing entities' values. the art of merging Of all dux, this is the best example of what proper reducing is and what it achieves. It might look hard to take care of this merging, under the constraint that only those branches of the state should be touched that are actually updated. But the lodash mergeWith makes this a breeze. Unfortunately, this library does not always leave unchanged values untouched, which results in unnecessary re-renderings of components. The best solution turned out to be Immutability-Helper . If you want to dive deeper into this issue, see the tests about merging , which includes tests that makes this issue crystal clear. The methods of the Immutability-Helper have a syntax inspired by the MongoDB commands, which is a nice reduction of cognitive load, since we use MongoDB at the server side. Have a look again at the reducer source code and see how straightforward it is to code one of the most tricky reducers in this app. This reducer actively covered by tests . Have a look at them to get more feeling of how table actions cause state transitions. selectors getTables Return the whole tables slice of the state. helpers entityHead Computes the title for an item, based on the data model or on specialized functions, defined here. See also repr . needTable Checks if sufficient table data is available in the state. needTables Checks a list of table names to see if sufficient data is available in the state. needValues Checks a single entity in a single table to see if it contains values for all fields. listValues Gives the list of all values of a specified field in a table. presentUser Presents a user, by means of name, email address, and/or eppn , depending on what information is available, which also depends on what information may be shared with the currently logged in user. changedItem Checks if properties have changed in such a few that new data should be fetched. headEntity The head line of a record, based on its title field and/or other data. For some specific tables custom logic is used. repr Makes a streamlined string representation out of a field value. It looks up ids in related value list tables. For some tables, special representation functions will be invoked. (users, countries, etc.). toDb Dispatches an item modification action to the store. handleOpenAll When a user clicks on an Open All button, this function is invoked to fetch the corresponding records (if needed). handleCloseAll When a user clicks on an Close All button, this function is invoked to collapse the corresponding records and remove the _id s of the previously open records from the URL, using browserHistory .","title":"tables"},{"location":"Client/Dux/#win","text":"See win . Explanation Reacts to window resizing by the user. It will deliver the new window size after resizing. Useful for components that care about the window size, such as App . actions changeWinDim Responds to window resizing, as set up in Window.md . It is just a matter of storing the height and the width of the window into the state. Note that the event emitter in Window.md is being throttled, so that it does not run too frequently during the actual resizing. reducer Transforms the win slice of the state in response to resize events. selectors getWinDim Returns the win slice of the state, which is just the current width and height of the browser window.","title":"win"},{"location":"Client/Dux/#workflow","text":"See workflow . Explanation A lot of the logic of showing lists, items, related items and fields is purely generic and driven by the data model . But there is considerably more to an app than this kind of generic logic. The workflow dux is the entry point for additional, non-trivial business logic. It is still in development. Active items The package table determines a lot about the assessment process. It has records with a specified startDate end endDate. The packages that have started and are not yet passed there endDate are the active packages. Normally there will be exactly one package. From the active package derive a number of other active concepts: the contribution types listed in the typeContribution field of the active package are the active types the criteria that are details of the active package are active criteria . The generic List and Item components can be made sensitive to this notion of activity. Active items can be formatted specially, and likewise the non-active items, which can also be disabled in some contexts. The way (in)active items are displayed is controlled by the data model . See for example the field typeContribution in the tables package and criteria . actions fetchWorkflow Fetch the info about the workflow information from the server, in particular the reset history since the last startup of the web server. resetWorkflow Fetch the same information as fetchWorkflow does, but add ?reset=true to the URL that is used to query this information from the server. This will instruct the server to perform a workflow reset. reducer The reducer is simple, it only has to perform one action: put incoming workflow data unto the state. No sophisticated merging is needed, because this workflow meta information is only needed for one component, WorkflowInfo , which is meant for sysadmins only. uses tables reducer The workflow data moves from server to client on the shoulders of the tables reducer. selectors getWorkflow Returns the workflow slice of the state. helpers compileActiveItems Computes the active packages, types and criteria and deliver them in an object, keyed by kind of item and containing an array of active item MongoDB ids for that kind. decisions Most of the contents of the decision table, in the form of objects by which you can find various user-facing strings associated with the three possible review decisions: accept , revise , and reject . finalDecision From workflow attributes that contain reviewers and reviews respectively, find out whether there has been a final decision by reviewer 2, and if so, what it was. getItem Peels out items of data from a workflow attribute that has fetched arrays of data from other records. isReviewerType Computes whether a given author is the first or second reviewer. loadExtra This is a configuration object that specifies which extra tables should be fetched from the server along with particular other tables. For example, the app can only perform its business logic on contributions, if the tables package , criteria , typeContribution , and decision are all present on the state. processStatus Produce a string that contains the current assessment status and review status of an assessment. This function can be called from a contribution, an assessment and a review. So for all these kinds of record we can produce a short overview of the state they have reached in the assessment / review process. The outcome has a bit that reveals the assessment status and a bit about the review status. When it is run on behalf of a user with marginal rights, it delivers either the empty string, or the outcome of the final review, but only if there has been a positive outcome. For users with more rights: assessment status: \u25b6 if the assessment has been (re)submitted; \u270d otherwise; the assessment score review status: empty string if there review has not reached a final decision; \u2714 on accept ; \u270b on revise ; \u2718 on reject . reviewerRole Object that maps the acronyms E and F to appropriate labels designating first and second reviewer.","title":"workflow"},{"location":"Client/Lib/","text":"Library \u00b6 Lower level functions called by various reducers, selectors, helpers and components. datatypes \u00b6 See datatypes . Explanation Elementary operations on data that comes in basic types, such as strings, numbers and dates. This file contains also the functions that normalize and validate values. getDateTime Convert a datetime object or string into a numerical value, so you can make comparisons. If absent, yield negative infinity for start dates and positive infinity for end dates. Used in workflow . normalization An object with normalization functions, named after the types of the values they normalize. All functions take a value, and return a normalized value. sortStringTemplate Compare function for sorting. Wraps the values to be compared in a template before actually comparing them. Used in workflow . sortTimeInterval Sort by time interval. Sorting by time intervals should works as follows: if both intervals are fully specified, the interval with the earlier start date comes first; if the start dates are equal, the one with the LATER end date comes first, in this way, containing intervals come before contained intervals; if the start date is missing, the start date is assumed to be in the infinite past; if the end date is missing, the end date is assumed to be in the infinite future. Used in workflow . trimDate Removes the milliseconds from an ISO string representing a datetime. Can also remove the whole time part from a datetime. This essentially presents a datetime as a date. validation An object with validation functions, named after the types of the values they validate. All functions take a value, and return undefined if the value passes validation or is itself undefined. If a value does not pass validation, a simple string expressing the reason is returned. details \u00b6 See details . Explanation These functions help by setting up lists of detail records for master records. The carry out what has been specified in the data model config files under the keys detail and detailOrder . getMasterTable Given a table and the name of a field that links to an other, related, table, if finds the name of that related table. If that other table list this table as a details table, and marks this field as the link field, then the related table is indeed the master table. But this function is indifferent to that. It merely consults the fieldSpec of field in table . makeDetails Prepare lists of details for an item of a table. Collect the specs and put all information in an array of objects, each corresponding to a details list, from which components can easily construct a widget for handling lists of details makeKeepInfo Collects information on the basis of which it can be decided whether a record may be deleted or not. A record may be deleted if it has no detail records, except those that will be deleted as well. Those are the details which are marked as cascade in the data model . This function returns a list of all non-cascade detail tables that have records linking to the record in question. Example ItemForm edit \u00b6 See edit . Explanation Helpers for presenting edit controls, such as a save button. editClass Returns the proper CSS class for styling content that is being edited, depending on the state it may be in: dirty : a changed value that has not been saved to the database yet, and/or invalid : a value that does not pass validation. editControl This is nearly a React component, except it needs a boolean parameter canSubmit , to direct it into one behaviour or another. The basic function of this component is to give an indication of the edit status of a record. Whether values have changed ( dirty ), values are invalid , or values are being submitted . If this component is put inside a <form> element under the control of redux-form , it is also capable to trigger a submit and save action. canSubmit = true The component EditControl calls this function with submit capacity. It also has to provide the resulting component with typical form properties, such as dirty , valid , handleSubmit . Because in this case the component lives inside a component that is already enhanced with reduxForm , namely ItemEdit , these properties have been injected higher up in the component tree and can be passed down as props. canSubmit = false The the component EditStatus calls this function without submit capacity. The typical form properties are now obtained by enhancing this very component with reduxForm . However, because this component is not assumed to be within a <form> context, it cannot perform a submit. makeChangeSave Produces a function, that when triggered by a value, will submit that value (after a short delay). See makeSubmitTime . This is used when an input field fires an event with a value entered by the user. makeChangeSaveVal Produces a function, with a value baked in. When called, this function will submit that value (after a short delay). This is used when the user clicks a button, like submit review in which case a specific field has to be set to a specific value, in this example: submitted = true . makeReset Composes an attribute that sets up an onKeyUp handler for an input field. It will react to the Esc key, and reset the input field to its pristine value, i.e. the value it had before the user started interacting with it. makeSubmit Produces a submit action or a null-returning function, depending on parameters. The parameters tell whether some record is dirty, valid and not currently submitting. In that case, the result is a submit function (which is also passed as parameter). This function is used in those cases where an input field looses focus. It then generates a submit action if all is well. makeSubmitTime Given a (submit)-function, transforms it into the same function that will be invoked with a small delay. This can be used after events that change a form, without a blur event. The event should trigger a submit and save, but first the triggering action should have done its work. Example Input onSubmitSuccess Needed in a workaround for an issue in redux-form . Example ItemEdit europe.geo \u00b6 See europe.geo . Explanation Representing the European country borders. countryBorders Object that contains the borders of the European countries plus a bit of additional information in geojson format. Example Jupyter notebook shows where this data comes from and how it has been tweaked for this website. fields \u00b6 See fields . Explanation Functions to deal with field specifications. checkDisabled Checks whether a certain value is inactive and should be disabled. See workflow logic . Used in component RelSelect . dealWithProvenance Remove provenance fields if current settings require that. See settings . Used in component ItemContainer and others. itemEditField Render an edit field in standard presentation, like ItemEdit does it. In fact, ItemEdit uses this very function to render its editable fields. This function can be conveniently used in custom templates to render some fields in the standard way. Example Templates itemReadField Render an read-only field in standard presentation, like ItemRead does it. In fact, ItemRead uses this very function to render its read-only fields. This function can be conveniently used in custom templates to render some fields in the standard way. Example Templates makeFields Prepare field components for an item of a table. Collect the specs from the fieldOrder and fieldSpecs fields of the data model and put all information in an array objects, each corresponding to a field, from which components can easily construct a widget for showing or editing that field. Example ItemForm someEditable Checks whether a list of fields contains at least one that the current user may edit. Example ItemForm toFieldInfo Reduces the information in the fragments produced by makeFields to a simple object with only the value(s) of that field. Example ItemRead to pass an argument to applyTemplate handle \u00b6 See handle . Explanation Construct event handle functions. Why do this? It is tempting to pass callbacks to React components as arrow functions, like this: 1 2 3 < MyComp onClick = { event => handle ( event )} /> The problem with this is that the event => handle(event) creates a brand new function object every time <MyComp/> is being rendered. This is not incorrect, but it is a burden for the garbage collector, especially when your component is part of a list item in a big list. It is much better to defined a fixed function elsewhere, and pass it to <MyComp> . But what if the callback is dependent on some parameters, that depend on its instances? For example, if the callback has to be passed to the items of a list, and cause the showing of hiding of individual list items? You could do it like this: 1 2 3 4 5 6 7 const handleItem = item => event => handle ( event , item ) items . map ( item => < MyComp onClick = { handleItem ( item )} /> ) As it stands, this suffers from the same problem, because for every item a fresh bound function object is allocated. And if the list is rendered twice, the second time results in completely new function objects. The solution is to use a memoized version of handleItem . The following functions are conveniences for doing exactly that. handle Arguments: (dispatch, actionCreator, actionArgs) This is a memoized action creator wrapper. It return a function, that can be called with an event. After receiving the event, the passed actionCreator will be called with the given arguments to produce an action. Subsequently, this action will be dispatched to the store that holds the state, which will result in the intended state change. This particular function handle will not use the information in the event. It takes trouble to neutralize the event instead. If there is relevant information in the event, use one of the following functions. handlE Like handle , and the information in the event is not used, but the default behaviour of the event and its propagation are not suppressed. handlEV Like handle , but now the event.target.value is passed the actionCreator as final argument. memo \u00b6 See memo . Explanation Our home-grown memoization function. makeSet We use plain objects, including Array s for all things on the state. But what if your component prefers the data as a Set ? Well, it is easy to turn an object into a Set . But if you do it twice, based on an identical state, you get two copies of the same set, which is a waste. Here memoization is a solution. makeSet is a memoized function that takes an array and returns its values as a Set . memoize Turns the function f into a memoized function memF that yields the same results for the same parameters. It stores computed results under a key dependent on the parameters for which the result is computed. When the function is called with the same parameters again, it delivers its result from cache, rather than to recompute it. In development mode, if you call the memoized function without arguments, it sends usage information to the console: the number of times it has computed a result and the number of times it has retrieved a result from cache. Comparison with reselect In many cases, the reselect library is all we need for the memoization of selector functions . However, if you want to bind a callback function to concrete arguments, e.g. in InputMulti , you need more powerful memoization, such as memoize here. from arguments to key However, a naive implementation of memoize has a big drawback. In order to store a function result obtained when computing the function on the basis of a list of arguments, you need to come up with key under which to store those results. This key must be computed from the list of arguments, and the computation of the key should not take more time than bluntly computing the function in question. The most common way of computing a key from arguments is to JSON.stringify them. However, many of the functions we need to memoize, take a slice of the state as argument. That can be a big object, e.g. tables , which hold all data that the app has downloaded from the server in the current section. In those cases it will not do to stringify the argument. Rather we fall back on object identity: we use a WeakMap , which seems to have been designed exactly for this purpose. However, it is not immediately obvious how to use this solution if you have more than one argument, and if you mix non-object values and functions with real objects. These problems can be solved, and memoize() has evolved into a flexible memoizer for all kinds of situations. What you can do with it is to stringify a shallow to-level structure of an object, to a given depth, and from then on work with object identity and WeakMaps. You can also forego object identity altogether and use solely stringify, which is often the most efficient solution. tests We have built quite a few tests to verify the logic and the performance of this memoizer. cache clearing The flip-side of a memoizer is that you end-up with a lot of obsolete function results, that will never be used again. Especially when one of the arguments is a slice of the state, the corresponding result will be outdated as soon as that slice of the state has undergone an update. Even if it will revert to the same state later on, it will be a different object. To prevent a needless clutter of obsolete computation results, the cache will be emptied periodically. By default, every result will live at most 30 minutes after having been created, but this is configurable. why WeakMap? This brings us to the reason why we use WeakMap and not the more versatile Map data structure. For Map does not suffer the constraint that keys must be objects, so if your arguments are a mixture of objects and non-objects, Map seems the obvious choice. However, if your Map key is a big object, the object can not be garbage collected as long as it is part of the map. That is a pity, because the only information we need of this object is its identity as an object, not its complete value. Think again of the tables slice of the state. It keeps changing when users fetch or change data, so memoized functions that use tables will cling to many successive copies of this state. Despite the fact that these copies share most of their data, this hampers a smooth garbage collection process. WeakMaps do not cling to the objects that act as their keys. They somehow store the identity of their key objects, without claiming the continued existence of them. Usage 1 2 3 4 5 6 const baseFunction = ( x , y , z ) => expensiveResult const memBaseFunction = memoize ( baseFunction , levels , config ) memBaseFunction ( a , b , c ) // computes baseFunction(a, b, c) memBaseFunction ( a , b , c ) // retrieves baseFunction(a, b, c) from cache instead of computing it level If the level paramter is null or undefined , all arguments will be stringified in one go. If levels is an empty object, all object arguments will be treated by object identity. Otherwise, levels should be an object, keyed by argument position and valued by level. If you specify a level for argument n , it means that argument n contributes to the memo key in the following way: level -1 : JSON stringify it level 0 : use the object identity of it as key in a WeakMap level i+i : JSON stringify the top i levels of it; everything from level i+1 onwards is treated by object identity. function arguments N.B: Function arguments can not be stringified, they always go by way of object identitiy. Example test suite config The config parameter takes the following keys: clearCache : time in seconds that a key is being retained in the memCache debug : string : when the memoized function computes a result, retrieves it from cache, or cleares it from cache, the debug string will be output through console.warn . Only in development mode! It is also possible to add extra bits of debugging information, by adapting the debugStyle object in the source code . big parameters If you memoize a function that takes big objects as parameters, and you forget to specify that those arguments must be treated by object identity, you may hit a murderous performance penalty. I did forget it and the function involved computed related values for given identifiers, and in order to find those values it needed to receive the tables slice of the state. As a consequence, opening a contribution record within the list of all contributions, took a full 3 seconds. It took me long to pinpoint the memoizer as the root cause of this particular slowness. The built-in profiler in Chrome showed it to me. templates \u00b6 See templates . Explanation This library contains templates that customize the presentation of records and fields. See Templates for how the template system is structured. This library contains the functions to apply templates. applyInsertTemplate Applies a template for the insert record button for a list. This template cannot have field values, because it is for a whole list of records. However, it is invoked by lists that are detail lists, and hence there is a master record. This template has access to the fields of that master record. It is invoked in EditInsert components. applyTemplate Applies a read only template. You can merge a template with FieldRead components. applyEditTemplate Applies an edit template. There is a bit of extra data here compared to read-only templates, namely whether fields are editable or not. You can merge a template with FieldRead components, as well as with FieldEdit components. Examples : ItemRead ItemEdit See also Templates . editMode This function computes a test function for a record, and the test function is customized per table, in the same way as templates are customized per table. Per table you can define any function, and in doing so you are given the information which fields are empty. In practice we use this function to determine whether we start the presentation of a record in read-only mode or in edit mode. Example In ListPlain we invoke this function to determine the startMode function, which computes for each record a choice between alternatives (edit mode or read-only mode), called thisStartMode . When ListPlain is called to display the criteriaEntry detail records of an assessment record, a test function is invoked, defined in criteriaEntry telling to return 1 if the score is empty or if the evidence is empty. Alternative 1 corresponds to edit mode. So, whenever a criteriaEntry record is certainly incomplete, it will be opened in edit mode. If it is possibly complete, it will be opened in read-only mode. utils \u00b6 See utils . Explanation Lower level utility functions. combineSelectors Arguments: (...selectors) Given a list of selector functions, creates a combined selector that returns an object containing the results of the individual selectors. This function uses the reselect's createSelector . We use it quite often when components need multiple sections of the state. emptyX (S A O F) name thing emptyA Array emptyF Function emptyO Object emptyS String emptySet Set Explanation Many objects get created during rendering and re-rendering. If we render a list of thousand entries, and we pass each item component a property with a value like 1 details = { details || {}} then thousand instances of an empty object will be created and need to be garbage collected soon after that. But if we are interested in the value of the empty object, without an intention to modify it, this is an utter waste. Therefore we declare a few empty concepts: We also 1 [ freeze ]( https : //developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze) them, so that we cannot inadvertently mutate them. The contract with ourselves is: do not ever use one of 1 2 3 4 '' [] {} x => x if you need an empty value, but use an empty X ( X in S , A , O , F ) instead. getUrlParts Analyse URLs in order to extract a part /item/ itemID from it (if present). This is needed if we open and close items in a list and want the URL to reflect that. Example ListPlain jString When we need the value of an object as a key, for example when we memoize functions, the most straightforward way is to JSON.stringify that object (if it is not forbiddingly large). But this has one defect: the order in which the keys of objects are serialized is not fixed. So two results of a stringify of objects with the same value can be different, due to different orders of keys. Our function jString fixes that. It is a bit more expensive to run than the plain JSON.stringify , but the penalty of not using it has the consequence that we fail to detect the equality of objects, which results in spurious re-rendering of components. If that happens too often, the cost adds up or even multiplies quickly. makeReducer Arguments: (flows, init) Given an object of flows and an initial state, returns a reducer function. The flows is an object with functions, named after actions . These functions define how a new state must be produced when an action has been dispatched . This function helps to write down complex reducer function as small components with a clean syntax. max Returns the maximum of an array of numbers. If the array is empty, return negative infinity. min Returns the minimum of an array of numbers. If the array is empty, return positive infinity. propsChanged Arguments: (newProps, need, oldProps, keyPropNames) Determines whether newProps differ significantly from oldProps , based on the props with keyPropNames only. If the props are sufficiently changed, it uses the need function to finally determine whether the change should result in an action. sum Returns the sum of an array of numbers. If the array is empty, return 0 . updateAuto The update() function of the Immutability-Helper module is great. But one thing is a bit clumsy: it does not have auto-vivification . The documentation points to a way out , but the code for that becomes tedious quickly. The idea, however, is right, and this function is a variant of the update() function with auto vivification. withParams Arguments: (Component) Higher order function that turns a Component (which is a function) into another component. The outgoing component is identical to the incoming one, except that you can offer the outgoing component its properties in a slightly different form. Instead of offering properties foo , bar , it is also possible to offer it property { params: { foo, bar } } . Put otherwise: the resulting component spreads its params alongside the rest of its properties. We also do this for route , like params . This function is useful for components that occur as component on a route in main on the one hand, but are also used as ordinary children that receive props from parents. In the first case, it receives some properties as params . When we write our components, we do not want to care about this, hence we wrap them as withParams(Component) . values \u00b6 See values . Explanation This is a library of functions that produce formatted representations of values from the database. composeAttributes When composing a Field component for an item, compute attributes telling whether the item is active or not, and merge them into the other attributes. Used in component RelSelect . getValType Arguments: (valType) For a given value type, such as text , URL , number , return a component and subtype for handling the input of such values, e.g. <input type=\"URL\" /> . Example FieldEdit wrappedRepr Produces a representation for a field value, complete with surrounding elements and attributes. Values of link fields will be wrapped in <a href=\"...\"> elements, Used in FieldRead .","title":"Lib"},{"location":"Client/Lib/#library","text":"Lower level functions called by various reducers, selectors, helpers and components.","title":"Library"},{"location":"Client/Lib/#datatypes","text":"See datatypes . Explanation Elementary operations on data that comes in basic types, such as strings, numbers and dates. This file contains also the functions that normalize and validate values. getDateTime Convert a datetime object or string into a numerical value, so you can make comparisons. If absent, yield negative infinity for start dates and positive infinity for end dates. Used in workflow . normalization An object with normalization functions, named after the types of the values they normalize. All functions take a value, and return a normalized value. sortStringTemplate Compare function for sorting. Wraps the values to be compared in a template before actually comparing them. Used in workflow . sortTimeInterval Sort by time interval. Sorting by time intervals should works as follows: if both intervals are fully specified, the interval with the earlier start date comes first; if the start dates are equal, the one with the LATER end date comes first, in this way, containing intervals come before contained intervals; if the start date is missing, the start date is assumed to be in the infinite past; if the end date is missing, the end date is assumed to be in the infinite future. Used in workflow . trimDate Removes the milliseconds from an ISO string representing a datetime. Can also remove the whole time part from a datetime. This essentially presents a datetime as a date. validation An object with validation functions, named after the types of the values they validate. All functions take a value, and return undefined if the value passes validation or is itself undefined. If a value does not pass validation, a simple string expressing the reason is returned.","title":"datatypes"},{"location":"Client/Lib/#details","text":"See details . Explanation These functions help by setting up lists of detail records for master records. The carry out what has been specified in the data model config files under the keys detail and detailOrder . getMasterTable Given a table and the name of a field that links to an other, related, table, if finds the name of that related table. If that other table list this table as a details table, and marks this field as the link field, then the related table is indeed the master table. But this function is indifferent to that. It merely consults the fieldSpec of field in table . makeDetails Prepare lists of details for an item of a table. Collect the specs and put all information in an array of objects, each corresponding to a details list, from which components can easily construct a widget for handling lists of details makeKeepInfo Collects information on the basis of which it can be decided whether a record may be deleted or not. A record may be deleted if it has no detail records, except those that will be deleted as well. Those are the details which are marked as cascade in the data model . This function returns a list of all non-cascade detail tables that have records linking to the record in question. Example ItemForm","title":"details"},{"location":"Client/Lib/#edit","text":"See edit . Explanation Helpers for presenting edit controls, such as a save button. editClass Returns the proper CSS class for styling content that is being edited, depending on the state it may be in: dirty : a changed value that has not been saved to the database yet, and/or invalid : a value that does not pass validation. editControl This is nearly a React component, except it needs a boolean parameter canSubmit , to direct it into one behaviour or another. The basic function of this component is to give an indication of the edit status of a record. Whether values have changed ( dirty ), values are invalid , or values are being submitted . If this component is put inside a <form> element under the control of redux-form , it is also capable to trigger a submit and save action. canSubmit = true The component EditControl calls this function with submit capacity. It also has to provide the resulting component with typical form properties, such as dirty , valid , handleSubmit . Because in this case the component lives inside a component that is already enhanced with reduxForm , namely ItemEdit , these properties have been injected higher up in the component tree and can be passed down as props. canSubmit = false The the component EditStatus calls this function without submit capacity. The typical form properties are now obtained by enhancing this very component with reduxForm . However, because this component is not assumed to be within a <form> context, it cannot perform a submit. makeChangeSave Produces a function, that when triggered by a value, will submit that value (after a short delay). See makeSubmitTime . This is used when an input field fires an event with a value entered by the user. makeChangeSaveVal Produces a function, with a value baked in. When called, this function will submit that value (after a short delay). This is used when the user clicks a button, like submit review in which case a specific field has to be set to a specific value, in this example: submitted = true . makeReset Composes an attribute that sets up an onKeyUp handler for an input field. It will react to the Esc key, and reset the input field to its pristine value, i.e. the value it had before the user started interacting with it. makeSubmit Produces a submit action or a null-returning function, depending on parameters. The parameters tell whether some record is dirty, valid and not currently submitting. In that case, the result is a submit function (which is also passed as parameter). This function is used in those cases where an input field looses focus. It then generates a submit action if all is well. makeSubmitTime Given a (submit)-function, transforms it into the same function that will be invoked with a small delay. This can be used after events that change a form, without a blur event. The event should trigger a submit and save, but first the triggering action should have done its work. Example Input onSubmitSuccess Needed in a workaround for an issue in redux-form . Example ItemEdit","title":"edit"},{"location":"Client/Lib/#europegeo","text":"See europe.geo . Explanation Representing the European country borders. countryBorders Object that contains the borders of the European countries plus a bit of additional information in geojson format. Example Jupyter notebook shows where this data comes from and how it has been tweaked for this website.","title":"europe.geo"},{"location":"Client/Lib/#fields","text":"See fields . Explanation Functions to deal with field specifications. checkDisabled Checks whether a certain value is inactive and should be disabled. See workflow logic . Used in component RelSelect . dealWithProvenance Remove provenance fields if current settings require that. See settings . Used in component ItemContainer and others. itemEditField Render an edit field in standard presentation, like ItemEdit does it. In fact, ItemEdit uses this very function to render its editable fields. This function can be conveniently used in custom templates to render some fields in the standard way. Example Templates itemReadField Render an read-only field in standard presentation, like ItemRead does it. In fact, ItemRead uses this very function to render its read-only fields. This function can be conveniently used in custom templates to render some fields in the standard way. Example Templates makeFields Prepare field components for an item of a table. Collect the specs from the fieldOrder and fieldSpecs fields of the data model and put all information in an array objects, each corresponding to a field, from which components can easily construct a widget for showing or editing that field. Example ItemForm someEditable Checks whether a list of fields contains at least one that the current user may edit. Example ItemForm toFieldInfo Reduces the information in the fragments produced by makeFields to a simple object with only the value(s) of that field. Example ItemRead to pass an argument to applyTemplate","title":"fields"},{"location":"Client/Lib/#handle","text":"See handle . Explanation Construct event handle functions. Why do this? It is tempting to pass callbacks to React components as arrow functions, like this: 1 2 3 < MyComp onClick = { event => handle ( event )} /> The problem with this is that the event => handle(event) creates a brand new function object every time <MyComp/> is being rendered. This is not incorrect, but it is a burden for the garbage collector, especially when your component is part of a list item in a big list. It is much better to defined a fixed function elsewhere, and pass it to <MyComp> . But what if the callback is dependent on some parameters, that depend on its instances? For example, if the callback has to be passed to the items of a list, and cause the showing of hiding of individual list items? You could do it like this: 1 2 3 4 5 6 7 const handleItem = item => event => handle ( event , item ) items . map ( item => < MyComp onClick = { handleItem ( item )} /> ) As it stands, this suffers from the same problem, because for every item a fresh bound function object is allocated. And if the list is rendered twice, the second time results in completely new function objects. The solution is to use a memoized version of handleItem . The following functions are conveniences for doing exactly that. handle Arguments: (dispatch, actionCreator, actionArgs) This is a memoized action creator wrapper. It return a function, that can be called with an event. After receiving the event, the passed actionCreator will be called with the given arguments to produce an action. Subsequently, this action will be dispatched to the store that holds the state, which will result in the intended state change. This particular function handle will not use the information in the event. It takes trouble to neutralize the event instead. If there is relevant information in the event, use one of the following functions. handlE Like handle , and the information in the event is not used, but the default behaviour of the event and its propagation are not suppressed. handlEV Like handle , but now the event.target.value is passed the actionCreator as final argument.","title":"handle"},{"location":"Client/Lib/#memo","text":"See memo . Explanation Our home-grown memoization function. makeSet We use plain objects, including Array s for all things on the state. But what if your component prefers the data as a Set ? Well, it is easy to turn an object into a Set . But if you do it twice, based on an identical state, you get two copies of the same set, which is a waste. Here memoization is a solution. makeSet is a memoized function that takes an array and returns its values as a Set . memoize Turns the function f into a memoized function memF that yields the same results for the same parameters. It stores computed results under a key dependent on the parameters for which the result is computed. When the function is called with the same parameters again, it delivers its result from cache, rather than to recompute it. In development mode, if you call the memoized function without arguments, it sends usage information to the console: the number of times it has computed a result and the number of times it has retrieved a result from cache. Comparison with reselect In many cases, the reselect library is all we need for the memoization of selector functions . However, if you want to bind a callback function to concrete arguments, e.g. in InputMulti , you need more powerful memoization, such as memoize here. from arguments to key However, a naive implementation of memoize has a big drawback. In order to store a function result obtained when computing the function on the basis of a list of arguments, you need to come up with key under which to store those results. This key must be computed from the list of arguments, and the computation of the key should not take more time than bluntly computing the function in question. The most common way of computing a key from arguments is to JSON.stringify them. However, many of the functions we need to memoize, take a slice of the state as argument. That can be a big object, e.g. tables , which hold all data that the app has downloaded from the server in the current section. In those cases it will not do to stringify the argument. Rather we fall back on object identity: we use a WeakMap , which seems to have been designed exactly for this purpose. However, it is not immediately obvious how to use this solution if you have more than one argument, and if you mix non-object values and functions with real objects. These problems can be solved, and memoize() has evolved into a flexible memoizer for all kinds of situations. What you can do with it is to stringify a shallow to-level structure of an object, to a given depth, and from then on work with object identity and WeakMaps. You can also forego object identity altogether and use solely stringify, which is often the most efficient solution. tests We have built quite a few tests to verify the logic and the performance of this memoizer. cache clearing The flip-side of a memoizer is that you end-up with a lot of obsolete function results, that will never be used again. Especially when one of the arguments is a slice of the state, the corresponding result will be outdated as soon as that slice of the state has undergone an update. Even if it will revert to the same state later on, it will be a different object. To prevent a needless clutter of obsolete computation results, the cache will be emptied periodically. By default, every result will live at most 30 minutes after having been created, but this is configurable. why WeakMap? This brings us to the reason why we use WeakMap and not the more versatile Map data structure. For Map does not suffer the constraint that keys must be objects, so if your arguments are a mixture of objects and non-objects, Map seems the obvious choice. However, if your Map key is a big object, the object can not be garbage collected as long as it is part of the map. That is a pity, because the only information we need of this object is its identity as an object, not its complete value. Think again of the tables slice of the state. It keeps changing when users fetch or change data, so memoized functions that use tables will cling to many successive copies of this state. Despite the fact that these copies share most of their data, this hampers a smooth garbage collection process. WeakMaps do not cling to the objects that act as their keys. They somehow store the identity of their key objects, without claiming the continued existence of them. Usage 1 2 3 4 5 6 const baseFunction = ( x , y , z ) => expensiveResult const memBaseFunction = memoize ( baseFunction , levels , config ) memBaseFunction ( a , b , c ) // computes baseFunction(a, b, c) memBaseFunction ( a , b , c ) // retrieves baseFunction(a, b, c) from cache instead of computing it level If the level paramter is null or undefined , all arguments will be stringified in one go. If levels is an empty object, all object arguments will be treated by object identity. Otherwise, levels should be an object, keyed by argument position and valued by level. If you specify a level for argument n , it means that argument n contributes to the memo key in the following way: level -1 : JSON stringify it level 0 : use the object identity of it as key in a WeakMap level i+i : JSON stringify the top i levels of it; everything from level i+1 onwards is treated by object identity. function arguments N.B: Function arguments can not be stringified, they always go by way of object identitiy. Example test suite config The config parameter takes the following keys: clearCache : time in seconds that a key is being retained in the memCache debug : string : when the memoized function computes a result, retrieves it from cache, or cleares it from cache, the debug string will be output through console.warn . Only in development mode! It is also possible to add extra bits of debugging information, by adapting the debugStyle object in the source code . big parameters If you memoize a function that takes big objects as parameters, and you forget to specify that those arguments must be treated by object identity, you may hit a murderous performance penalty. I did forget it and the function involved computed related values for given identifiers, and in order to find those values it needed to receive the tables slice of the state. As a consequence, opening a contribution record within the list of all contributions, took a full 3 seconds. It took me long to pinpoint the memoizer as the root cause of this particular slowness. The built-in profiler in Chrome showed it to me.","title":"memo"},{"location":"Client/Lib/#templates","text":"See templates . Explanation This library contains templates that customize the presentation of records and fields. See Templates for how the template system is structured. This library contains the functions to apply templates. applyInsertTemplate Applies a template for the insert record button for a list. This template cannot have field values, because it is for a whole list of records. However, it is invoked by lists that are detail lists, and hence there is a master record. This template has access to the fields of that master record. It is invoked in EditInsert components. applyTemplate Applies a read only template. You can merge a template with FieldRead components. applyEditTemplate Applies an edit template. There is a bit of extra data here compared to read-only templates, namely whether fields are editable or not. You can merge a template with FieldRead components, as well as with FieldEdit components. Examples : ItemRead ItemEdit See also Templates . editMode This function computes a test function for a record, and the test function is customized per table, in the same way as templates are customized per table. Per table you can define any function, and in doing so you are given the information which fields are empty. In practice we use this function to determine whether we start the presentation of a record in read-only mode or in edit mode. Example In ListPlain we invoke this function to determine the startMode function, which computes for each record a choice between alternatives (edit mode or read-only mode), called thisStartMode . When ListPlain is called to display the criteriaEntry detail records of an assessment record, a test function is invoked, defined in criteriaEntry telling to return 1 if the score is empty or if the evidence is empty. Alternative 1 corresponds to edit mode. So, whenever a criteriaEntry record is certainly incomplete, it will be opened in edit mode. If it is possibly complete, it will be opened in read-only mode.","title":"templates"},{"location":"Client/Lib/#utils","text":"See utils . Explanation Lower level utility functions. combineSelectors Arguments: (...selectors) Given a list of selector functions, creates a combined selector that returns an object containing the results of the individual selectors. This function uses the reselect's createSelector . We use it quite often when components need multiple sections of the state. emptyX (S A O F) name thing emptyA Array emptyF Function emptyO Object emptyS String emptySet Set Explanation Many objects get created during rendering and re-rendering. If we render a list of thousand entries, and we pass each item component a property with a value like 1 details = { details || {}} then thousand instances of an empty object will be created and need to be garbage collected soon after that. But if we are interested in the value of the empty object, without an intention to modify it, this is an utter waste. Therefore we declare a few empty concepts: We also 1 [ freeze ]( https : //developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze) them, so that we cannot inadvertently mutate them. The contract with ourselves is: do not ever use one of 1 2 3 4 '' [] {} x => x if you need an empty value, but use an empty X ( X in S , A , O , F ) instead. getUrlParts Analyse URLs in order to extract a part /item/ itemID from it (if present). This is needed if we open and close items in a list and want the URL to reflect that. Example ListPlain jString When we need the value of an object as a key, for example when we memoize functions, the most straightforward way is to JSON.stringify that object (if it is not forbiddingly large). But this has one defect: the order in which the keys of objects are serialized is not fixed. So two results of a stringify of objects with the same value can be different, due to different orders of keys. Our function jString fixes that. It is a bit more expensive to run than the plain JSON.stringify , but the penalty of not using it has the consequence that we fail to detect the equality of objects, which results in spurious re-rendering of components. If that happens too often, the cost adds up or even multiplies quickly. makeReducer Arguments: (flows, init) Given an object of flows and an initial state, returns a reducer function. The flows is an object with functions, named after actions . These functions define how a new state must be produced when an action has been dispatched . This function helps to write down complex reducer function as small components with a clean syntax. max Returns the maximum of an array of numbers. If the array is empty, return negative infinity. min Returns the minimum of an array of numbers. If the array is empty, return positive infinity. propsChanged Arguments: (newProps, need, oldProps, keyPropNames) Determines whether newProps differ significantly from oldProps , based on the props with keyPropNames only. If the props are sufficiently changed, it uses the need function to finally determine whether the change should result in an action. sum Returns the sum of an array of numbers. If the array is empty, return 0 . updateAuto The update() function of the Immutability-Helper module is great. But one thing is a bit clumsy: it does not have auto-vivification . The documentation points to a way out , but the code for that becomes tedious quickly. The idea, however, is right, and this function is a variant of the update() function with auto vivification. withParams Arguments: (Component) Higher order function that turns a Component (which is a function) into another component. The outgoing component is identical to the incoming one, except that you can offer the outgoing component its properties in a slightly different form. Instead of offering properties foo , bar , it is also possible to offer it property { params: { foo, bar } } . Put otherwise: the resulting component spreads its params alongside the rest of its properties. We also do this for route , like params . This function is useful for components that occur as component on a route in main on the one hand, but are also used as ordinary children that receive props from parents. In the first case, it receives some properties as params . When we write our components, we do not want to care about this, hence we wrap them as withParams(Component) .","title":"utils"},{"location":"Client/Lib/#values","text":"See values . Explanation This is a library of functions that produce formatted representations of values from the database. composeAttributes When composing a Field component for an item, compute attributes telling whether the item is active or not, and merge them into the other attributes. Used in component RelSelect . getValType Arguments: (valType) For a given value type, such as text , URL , number , return a component and subtype for handling the input of such values, e.g. <input type=\"URL\" /> . Example FieldEdit wrappedRepr Produces a representation for a field value, complete with surrounding elements and attributes. Values of link fields will be wrapped in <a href=\"...\"> elements, Used in FieldRead .","title":"values"},{"location":"Client/Templates/","text":"Templates \u00b6 Introduction \u00b6 For some parts of the application the generic ways of presenting records and fields is just not good enough. We need a deeper customization method. The challenge is to use as much of the generic machinery when we define custom presentations. Our solution here is by using templates . The particulars of our templates are documented in Tables , but you might need to continue reading here first about the power and organization of them. Example In the display of assessments we want to list the criteriaEntry detail records in one big tabular form. Variables in templates \u00b6 The values of fields are natural candidates to act as template variables. Problem Looking up a field value might seem a very innocent operation: you retrieve the appropriate record from the database, look up the field in question, and read out the value that you find there. Alas, there are several complicating factors: That value might be a MongoDB object identifier pointing to a related record. We do not want to display that identifier, but the corresponding record, but not the whole record. Only an informative heading. For that we have to look up additional fields in the related table, and possibly apply logic depending on what we encounter. We should not show fields that the current user is not entitled to view. We should not put in edit controls for fields that the current user is not allowed to edit. We should present active and inactive values differently. Whether records are active is dependent on other data in the database, in particular the package . We have access to that through the workflow machinery. See active items . The first two concerns are built into the generic logic, in the components EditInsert ItemRead ItemEdit FieldRead FieldEdit and we do not want to reimplement this logic when we want to cater for the third concern by means of templates. Solution Our solution is that templates are not static strings into which field values are merged dynamically. Instead, our templates are functions that take a properties object as arguments. The properties are functions that can furnish representations for fields. These functions use the general machinery to fetch all kinds of information, such as field labels, field values, workflow attributes, permissions, ownership of records, etc. See below . Template organization \u00b6 There are several purposes for which we invoke the template mechanism, and for each purpose we have a kind of template. Template purposes The presentation of: headings in lists of records main records related records detail records insert buttons the determination of: edit modes. Template locations All templates can be found in files named after the tables for which they are defined. You can find them in the tables directory. For each table there is an object of template functions, first keyed by their purpose and then, optionally, by the related/detail table they are for. Record kinds There are different kinds of records, depending on their place in the data model as a whole, and for all these kinds we have templates. Main records These are records that correspond to the core of entities, such as contributions, assessments, reviews. They do not contain information in the form of lists of other entities. Related records These are records pointed to by a field in a main record. For example, an assessment record has a field contribution , containing the identifier of the contribution record that the assessment is targeting. Here the assessment record wants to display a contribution record as read-only information. A template for this can be found in the templates file contrib.jsx . This template is only invoked if a contribution record has to be displayed as part of an assessment record. If we need to display it in as part of an other type of record, we can define a separate template for that case. We use these templates for details that want to display a representation of the master inside, or for other cases where records point to other records without an explicit master detail relationship. Detail records These are records that point to another record, called the master record. It is typically used when a piece of information consists of a variable number of items. Some central fields go into a master record, and the other items go into detail records that point to the master. For an example, an assessment record is accompanied by a series of criteriaEntry records. The assessment record has no pointers to the criteriaEntry records. Rather each criteriaEntry record points to an assessment record. These templates become active when records are displayed in the list of records below a master record. Related versus detail: a matter of perspective If record A points to record B, you could say that record B is its master record and A is a detail of it. But in our application, this is not automatically so. For example, a contribution points to a year record, to indicate the year of the contribution. Yet we do not consider a contribution to be a detail of a year. If you want related records to be treated as detail records, you have to say so in the data model . Consolidated records These are records where all information from detail records and related records has been drawn in, and where the links with them have been severed. A consolidated record is immutable, and if formerly related records undergo change, the consolidated record is not affected. We use consolidated records for storing contributions when they have been frozen because of selection decisions. Template kinds We have the following template kinds. head For presentation of record headings in lists. When records are listed, we see a vertical list of record headings. For things that are handled by workflows, such as contributions, assessments and reviews, it is desirable to display some workflow information right in front of the heading. Think of an assessment score for assessments and contributions, or a review status, telling whether the assessment is being reviewed, and if it has been reviewed, what the final decision was. Or whether the item is frozen. for template writers: The result should be a string, not anything that is more complex. If there is no result, do not deliver null , but emptyS (the empty string). for template writers: The workflow status can be obtained by calling the function processStatus() . read: main detail related For presentation of records of those kinds in read-only mode. for template writers: These templates will not be passed the fe template function. The related template get an extra parameter: linkMe , a hyperlink to the main record: linkMe . edit: mainEdit detailEdit For presenting records of those kinds as forms with editable fields. for template writers: These template functions are passed the fe function and editButton , which is a React component that holds the edit/save button for this record. action: mainAction detailAction For presenting actions upon records of those kinds. for template writers: These templates do get the fe function passed. editMode Whether presenting records in edit mode or readonly mode. In some situations you want to open some records in edit mode and others in read mode. A typical situation is where you want to open incomplete records in edit mode, and others not. The template functions of this kind do not deliver templates, but a boolean, which will be used whenever a table is presented to the user as a list. insert For presenting a button to insert a new record. Used where lists of detail records are displayed. This template can also choose not to show the insert button, depending on conditions determined by the master record and the number of items in the detail list. for template writers: This template does not operate on the level of individual items, so it does not get passed the usual functions. What it gets is n : the number of items that already exist (as details of a master record), and a onInsert : a handler to invoke when the instantiated template is clicked. Editable or not? The idea is that the form can switch between Read and Edit by means of a standard control, and that the Action part is independent of that switch: it is always displayed. edit controls In the read part, you cannot have edit controls, but in the edit and action parts you can have them. However, in the action part, you do not have save and reset buttons. This part is meant for action buttons, which change a field to a predefined value and save it immediately. Applying templates \u00b6 Applying a template means feeding a higher order React component with a properties object of field rendering functions. This will result in a concrete React component. Components that apply templates The templates will be applied by EditInsert , ItemRead , ItemEdit , ItemAction , and ListPlain using the functions applyTemplate , applyEditTemplate , applyInsertTemplate , and editMode . Template functions A template is a function that can be passed a props object containing functions that deliver field value information or workflow information: label l(field) Fetches the label for field . empty e(field) Checks whether field has empty values. value v(field) Fetches the raw value of field . workflow w(key) Fetches additional workflow attributes for the record. static value s(field) Fetches the plain string values for field , replacing identifiers into related tables by headings of related records. formatted value f(field) Fetches values for field (with related lookup), and wrap them in FieldRead components. formatted editable value fe(field) Fetches values for field , and wrap them in FieldEdit components, which are controls to let the user edit the value. formatted settable value fs(field) Presents custom controls for field and wrap them in FieldSet components. These respond to click events: upon a click, a baked in value will be saved to the database. number of details n The number of detail records in the list (only for insert templates). active types at The set of the active contribution types. owned o Whether the current record is owned by the user. modifiable m(field) Checks whether field is editable by the current user; this is the case if the user is the owner of the record or if (s)he is in the list of editors; no workflow attributes are taken into account. current user details me all attributes of the logged in user (empty if the user is not logged in). link to value definition linkMe A direct hyperlink to the value as part of its list. editButton A ready-made control for switching edit/read-only mode and saving the values. onInsert A ready-made handler for triggering an insert action. To be associated to the element that receives the trigger to create a new record. See the library module templates .","title":"Templates"},{"location":"Client/Templates/#templates","text":"","title":"Templates"},{"location":"Client/Templates/#introduction","text":"For some parts of the application the generic ways of presenting records and fields is just not good enough. We need a deeper customization method. The challenge is to use as much of the generic machinery when we define custom presentations. Our solution here is by using templates . The particulars of our templates are documented in Tables , but you might need to continue reading here first about the power and organization of them. Example In the display of assessments we want to list the criteriaEntry detail records in one big tabular form.","title":"Introduction"},{"location":"Client/Templates/#variables-in-templates","text":"The values of fields are natural candidates to act as template variables. Problem Looking up a field value might seem a very innocent operation: you retrieve the appropriate record from the database, look up the field in question, and read out the value that you find there. Alas, there are several complicating factors: That value might be a MongoDB object identifier pointing to a related record. We do not want to display that identifier, but the corresponding record, but not the whole record. Only an informative heading. For that we have to look up additional fields in the related table, and possibly apply logic depending on what we encounter. We should not show fields that the current user is not entitled to view. We should not put in edit controls for fields that the current user is not allowed to edit. We should present active and inactive values differently. Whether records are active is dependent on other data in the database, in particular the package . We have access to that through the workflow machinery. See active items . The first two concerns are built into the generic logic, in the components EditInsert ItemRead ItemEdit FieldRead FieldEdit and we do not want to reimplement this logic when we want to cater for the third concern by means of templates. Solution Our solution is that templates are not static strings into which field values are merged dynamically. Instead, our templates are functions that take a properties object as arguments. The properties are functions that can furnish representations for fields. These functions use the general machinery to fetch all kinds of information, such as field labels, field values, workflow attributes, permissions, ownership of records, etc. See below .","title":"Variables in templates"},{"location":"Client/Templates/#template-organization","text":"There are several purposes for which we invoke the template mechanism, and for each purpose we have a kind of template. Template purposes The presentation of: headings in lists of records main records related records detail records insert buttons the determination of: edit modes. Template locations All templates can be found in files named after the tables for which they are defined. You can find them in the tables directory. For each table there is an object of template functions, first keyed by their purpose and then, optionally, by the related/detail table they are for. Record kinds There are different kinds of records, depending on their place in the data model as a whole, and for all these kinds we have templates. Main records These are records that correspond to the core of entities, such as contributions, assessments, reviews. They do not contain information in the form of lists of other entities. Related records These are records pointed to by a field in a main record. For example, an assessment record has a field contribution , containing the identifier of the contribution record that the assessment is targeting. Here the assessment record wants to display a contribution record as read-only information. A template for this can be found in the templates file contrib.jsx . This template is only invoked if a contribution record has to be displayed as part of an assessment record. If we need to display it in as part of an other type of record, we can define a separate template for that case. We use these templates for details that want to display a representation of the master inside, or for other cases where records point to other records without an explicit master detail relationship. Detail records These are records that point to another record, called the master record. It is typically used when a piece of information consists of a variable number of items. Some central fields go into a master record, and the other items go into detail records that point to the master. For an example, an assessment record is accompanied by a series of criteriaEntry records. The assessment record has no pointers to the criteriaEntry records. Rather each criteriaEntry record points to an assessment record. These templates become active when records are displayed in the list of records below a master record. Related versus detail: a matter of perspective If record A points to record B, you could say that record B is its master record and A is a detail of it. But in our application, this is not automatically so. For example, a contribution points to a year record, to indicate the year of the contribution. Yet we do not consider a contribution to be a detail of a year. If you want related records to be treated as detail records, you have to say so in the data model . Consolidated records These are records where all information from detail records and related records has been drawn in, and where the links with them have been severed. A consolidated record is immutable, and if formerly related records undergo change, the consolidated record is not affected. We use consolidated records for storing contributions when they have been frozen because of selection decisions. Template kinds We have the following template kinds. head For presentation of record headings in lists. When records are listed, we see a vertical list of record headings. For things that are handled by workflows, such as contributions, assessments and reviews, it is desirable to display some workflow information right in front of the heading. Think of an assessment score for assessments and contributions, or a review status, telling whether the assessment is being reviewed, and if it has been reviewed, what the final decision was. Or whether the item is frozen. for template writers: The result should be a string, not anything that is more complex. If there is no result, do not deliver null , but emptyS (the empty string). for template writers: The workflow status can be obtained by calling the function processStatus() . read: main detail related For presentation of records of those kinds in read-only mode. for template writers: These templates will not be passed the fe template function. The related template get an extra parameter: linkMe , a hyperlink to the main record: linkMe . edit: mainEdit detailEdit For presenting records of those kinds as forms with editable fields. for template writers: These template functions are passed the fe function and editButton , which is a React component that holds the edit/save button for this record. action: mainAction detailAction For presenting actions upon records of those kinds. for template writers: These templates do get the fe function passed. editMode Whether presenting records in edit mode or readonly mode. In some situations you want to open some records in edit mode and others in read mode. A typical situation is where you want to open incomplete records in edit mode, and others not. The template functions of this kind do not deliver templates, but a boolean, which will be used whenever a table is presented to the user as a list. insert For presenting a button to insert a new record. Used where lists of detail records are displayed. This template can also choose not to show the insert button, depending on conditions determined by the master record and the number of items in the detail list. for template writers: This template does not operate on the level of individual items, so it does not get passed the usual functions. What it gets is n : the number of items that already exist (as details of a master record), and a onInsert : a handler to invoke when the instantiated template is clicked. Editable or not? The idea is that the form can switch between Read and Edit by means of a standard control, and that the Action part is independent of that switch: it is always displayed. edit controls In the read part, you cannot have edit controls, but in the edit and action parts you can have them. However, in the action part, you do not have save and reset buttons. This part is meant for action buttons, which change a field to a predefined value and save it immediately.","title":"Template organization"},{"location":"Client/Templates/#applying-templates","text":"Applying a template means feeding a higher order React component with a properties object of field rendering functions. This will result in a concrete React component. Components that apply templates The templates will be applied by EditInsert , ItemRead , ItemEdit , ItemAction , and ListPlain using the functions applyTemplate , applyEditTemplate , applyInsertTemplate , and editMode . Template functions A template is a function that can be passed a props object containing functions that deliver field value information or workflow information: label l(field) Fetches the label for field . empty e(field) Checks whether field has empty values. value v(field) Fetches the raw value of field . workflow w(key) Fetches additional workflow attributes for the record. static value s(field) Fetches the plain string values for field , replacing identifiers into related tables by headings of related records. formatted value f(field) Fetches values for field (with related lookup), and wrap them in FieldRead components. formatted editable value fe(field) Fetches values for field , and wrap them in FieldEdit components, which are controls to let the user edit the value. formatted settable value fs(field) Presents custom controls for field and wrap them in FieldSet components. These respond to click events: upon a click, a baked in value will be saved to the database. number of details n The number of detail records in the list (only for insert templates). active types at The set of the active contribution types. owned o Whether the current record is owned by the user. modifiable m(field) Checks whether field is editable by the current user; this is the case if the user is the owner of the record or if (s)he is in the list of editors; no workflow attributes are taken into account. current user details me all attributes of the logged in user (empty if the user is not logged in). link to value definition linkMe A direct hyperlink to the value as part of its list. editButton A ready-made control for switching edit/read-only mode and saving the values. onInsert A ready-made handler for triggering an insert action. To be associated to the element that receives the trigger to create a new record. See the library module templates .","title":"Applying templates"},{"location":"Concepts/Architecture/","text":"Architecture \u00b6 Introduction \u00b6 This app consists of many React components. By default React components have a private state where they can store everything that changes in their life courses. That is: user interaction and server data. If many components handle overlapping data, problems arise, and they manifest themselves first as subtle bugs. Hard to reproduce, hard to fix, because they have to do with unpredictable timing of changing entities. That is where Redux comes to the rescue. Redux provides a central state as a single source of truth . Redux itself is a very small library, under 600 lines of code, but using it will have a dramatic effect on all your React components, especially if you use Redux in an idiomatic way. Overview \u00b6 Components \u00b6 See Components and Dux . In Redux, every component may obtain read access to the state, and has indirect write access to it by dispatching actions . The state is held in a store and the store manages all access to the state. When actions are dispatched to the store, the store calls a reducer , which is a function written by the application developer. The reducer is given the action, which has a type and a payload, and on that basis, and that basis alone, it produces a new state from the old state. An app has many concerns, some of which are pretty well separable from others. Such a concern tends to be centred around a specific slice of the state, involving a specific set of actions, and a dedicated partial reducer of that slice. The components involved do not need the whole state, but only this specific slice of the state. Some of the actions may become really specialized, involved, and complex, and for those one writes dedicated helpers . We have organized these concerns into dux (plural of duct or more affectionately: duck ), where a duct is one file of ES6 code that exports: actions action creator functions (one or more as named exports); their names typically start with handle , change , fetch ; fetch as in \"asynchronously fetch data from the server\". reducer a single reducer function (as the default export); selectors selector functions (one or more as named exports); their names always start with get ; get as in: \"get a fragment of the whole state\". helpers helper functions (some of which do not have to be exported); quite often their names start with compile as in \"compile the state data into something that may component can readily consume\". Such a duct ties in very well with the way that React components can be connected to the state. The idiomatic approach is to write your component as a pure, stateless function, even if it needs state. When it does need to read the state, assume that your component will receive that information as properties . And when it needs to modify the state, assume that it will receive callbacks, also as properties , to dispatch actions. See also connect . Dux \u00b6 See Dux . We employ a glue between components and the state : dux . If you have written your component, say MyComp , and you need a piece of the state mySlice that is provided by a selector getMySlice , and you need to dispatch an action handle in response of a user click, and the action creator changeSlice provides that, then you can wrap your component by means of the Redux higher order function connect like this: 1 export connect ( getMySlice , { handle : changeSlice })( MyComp ) In this way, most components that deal with change can still be written as pure functions, relatively easy to understand, while the response to change is expressed in a very simple pattern. This will reduce the potential bugs considerably. Note that all code to make the connection between components and a (slice of the) state are located in a duct. We are talking about the selectors , the actions , and possibly the helpers . The reducer is something that is hidden from the component code. It is only used by the store, via a kind of subscription. The structure of the reducer follows the types of the actions very closely so it really makes sense to have all four things in one file. The dux of this app \u00b6 Currently, these are the dux of this app: alter alter show/hide, cycle through n alternative representations of a piece of user interface; example: widgets that can be expanded and collapsed by the user; docs docs fetch documents, especially markdown ones, and show them in two representations: source and formatted; filters filters the machinery of faceted and full text filtering of entities from tables; forms forms the state of all data entry forms in the app; managed by redux-form ; but other parts of the app need to inspect the form slice of the state as well; grid grid the display state of all lists in grid layout: the sort columns and the directions of sorting; me me data about the currently logged-in user; notes notes the notification system; this is what displays progress and error messages; it can be accessed by the user by clicking the unobtrusive open circle in the upper right corner of the browser window; roots roots combining all the other dux; select select the state of all multi-select widgets in the app; server server handling asynchronous actions and reporting about success, failure and pending requests; it also prevents subsequent requests of data between the first request and the arrival of the data; settings settings cross-cutting operational parameters, such as whether to show or hide the provenance fields (creator, created data, sequence of modified-by records); tables tables manage all database data that has been fetched from the server; in fact, we construct a normalized copy of all tables that contain information that is application needs; when more data is needed, the application fetches it from the server and merges it in tables slice of the state; this slice not only holds the data of the tables, but also the specs of them, such as the fields, their types, the relations between tables, the master-detail structure, etc.; win win react to the resizing of the browser window; earlier stages of the application used this to resize certain areas in the application window; however, by using new CSS features such as flexbox we do not have any real need to make the window size known to the app; this might change when the app acquires new functionality, so for the moment we retain this mechanism. workflow workflow specialized logic for the assessment and review workflow e.g. to determine what are the active contribution types and assessment criteria at a given point in time;","title":"Architecture"},{"location":"Concepts/Architecture/#architecture","text":"","title":"Architecture"},{"location":"Concepts/Architecture/#introduction","text":"This app consists of many React components. By default React components have a private state where they can store everything that changes in their life courses. That is: user interaction and server data. If many components handle overlapping data, problems arise, and they manifest themselves first as subtle bugs. Hard to reproduce, hard to fix, because they have to do with unpredictable timing of changing entities. That is where Redux comes to the rescue. Redux provides a central state as a single source of truth . Redux itself is a very small library, under 600 lines of code, but using it will have a dramatic effect on all your React components, especially if you use Redux in an idiomatic way.","title":"Introduction"},{"location":"Concepts/Architecture/#overview","text":"","title":"Overview"},{"location":"Concepts/Architecture/#components","text":"See Components and Dux . In Redux, every component may obtain read access to the state, and has indirect write access to it by dispatching actions . The state is held in a store and the store manages all access to the state. When actions are dispatched to the store, the store calls a reducer , which is a function written by the application developer. The reducer is given the action, which has a type and a payload, and on that basis, and that basis alone, it produces a new state from the old state. An app has many concerns, some of which are pretty well separable from others. Such a concern tends to be centred around a specific slice of the state, involving a specific set of actions, and a dedicated partial reducer of that slice. The components involved do not need the whole state, but only this specific slice of the state. Some of the actions may become really specialized, involved, and complex, and for those one writes dedicated helpers . We have organized these concerns into dux (plural of duct or more affectionately: duck ), where a duct is one file of ES6 code that exports: actions action creator functions (one or more as named exports); their names typically start with handle , change , fetch ; fetch as in \"asynchronously fetch data from the server\". reducer a single reducer function (as the default export); selectors selector functions (one or more as named exports); their names always start with get ; get as in: \"get a fragment of the whole state\". helpers helper functions (some of which do not have to be exported); quite often their names start with compile as in \"compile the state data into something that may component can readily consume\". Such a duct ties in very well with the way that React components can be connected to the state. The idiomatic approach is to write your component as a pure, stateless function, even if it needs state. When it does need to read the state, assume that your component will receive that information as properties . And when it needs to modify the state, assume that it will receive callbacks, also as properties , to dispatch actions. See also connect .","title":"Components"},{"location":"Concepts/Architecture/#dux","text":"See Dux . We employ a glue between components and the state : dux . If you have written your component, say MyComp , and you need a piece of the state mySlice that is provided by a selector getMySlice , and you need to dispatch an action handle in response of a user click, and the action creator changeSlice provides that, then you can wrap your component by means of the Redux higher order function connect like this: 1 export connect ( getMySlice , { handle : changeSlice })( MyComp ) In this way, most components that deal with change can still be written as pure functions, relatively easy to understand, while the response to change is expressed in a very simple pattern. This will reduce the potential bugs considerably. Note that all code to make the connection between components and a (slice of the) state are located in a duct. We are talking about the selectors , the actions , and possibly the helpers . The reducer is something that is hidden from the component code. It is only used by the store, via a kind of subscription. The structure of the reducer follows the types of the actions very closely so it really makes sense to have all four things in one file.","title":"Dux"},{"location":"Concepts/Architecture/#the-dux-of-this-app","text":"Currently, these are the dux of this app: alter alter show/hide, cycle through n alternative representations of a piece of user interface; example: widgets that can be expanded and collapsed by the user; docs docs fetch documents, especially markdown ones, and show them in two representations: source and formatted; filters filters the machinery of faceted and full text filtering of entities from tables; forms forms the state of all data entry forms in the app; managed by redux-form ; but other parts of the app need to inspect the form slice of the state as well; grid grid the display state of all lists in grid layout: the sort columns and the directions of sorting; me me data about the currently logged-in user; notes notes the notification system; this is what displays progress and error messages; it can be accessed by the user by clicking the unobtrusive open circle in the upper right corner of the browser window; roots roots combining all the other dux; select select the state of all multi-select widgets in the app; server server handling asynchronous actions and reporting about success, failure and pending requests; it also prevents subsequent requests of data between the first request and the arrival of the data; settings settings cross-cutting operational parameters, such as whether to show or hide the provenance fields (creator, created data, sequence of modified-by records); tables tables manage all database data that has been fetched from the server; in fact, we construct a normalized copy of all tables that contain information that is application needs; when more data is needed, the application fetches it from the server and merges it in tables slice of the state; this slice not only holds the data of the tables, but also the specs of them, such as the fields, their types, the relations between tables, the master-detail structure, etc.; win win react to the resizing of the browser window; earlier stages of the application used this to resize certain areas in the application window; however, by using new CSS features such as flexbox we do not have any real need to make the window size known to the app; this might change when the app acquires new functionality, so for the moment we retain this mechanism. workflow workflow specialized logic for the assessment and review workflow e.g. to determine what are the active contribution types and assessment criteria at a given point in time;","title":"The dux of this app"},{"location":"Concepts/Model/","text":"Model \u00b6 This application contains a generic engine to display MongoDB data according to any specified data model, respecting access privileges. MongoDB \u00b6 We store the data in a MongoDB . Data as documents A MongoDB does not work with a fixed schema. A MongoDB collection consists of documents , which are essentially JSON-like structures, arbitrarily large and arbitrarily nested. That makes it easy to add new kinds of data to documents and collections when the need arises to do so. This will not break the existing code. MongoDB is optimized to read quickly, at the cost of more expensive data manipulation operations. Its documentation favours storing related data inside the main document. This increases the redundancy of the data and may lead to consistency problems, unless the application tries to enforce consistency somehow. In this app, with a limited amount of data, we use MongoDB primarily for its flexibility. We still adhere largely to SQL-like practices when we deal with related tables. So instead of storing the information of related documents directly inside the main document, we only store references to related documents inside the main documents. Terminology Because our treatment of data is still very relational, we prefer wording derived from SQL databases, at least in the present documentation: MongoDB SQL collection table document record Configuration \u00b6 The model and the files in table are YAML configuration files, and by tweaking them you can achieve a lot of customization. Data model \u00b6 The data model has a generic part and a table specific part. Generic part \u00b6 See model.yaml . Here we define structures and values that are relevant for the system as a whole and/or for all tables: defaults Defaults for table models. Whenever a table misses one of the keys listed here, the value here will be filled in for that table. The defaults are suited to tables that act as value lists, of which we have quite a bunch. All these tables need a very short own specification. The meaning of these keys are explained in table configuration . provenance Fields for recording the edit history of a record. provenanceOrder Field names for provenance fields in a specific order. provenanceSpecs Field specifications for the provenance fields. We have these fields: editors List of ids of non-owner users that may edit this record, even if their group permissions do not allow it. creator Id of the user that created the record. dateCreated Datetime when the record was created. modified Trail of modification events, each event has the name of the user who caused the change and the datetime when it happened. The trail will be weeded out over time. The field \"editors\" may be changed by the owner of a record, and by people with higher powers such as the backoffice, not by the editors themselves (unless they also have higher power). All other fields cannot be modified by users, not even by users with higher powers. Only the system itself will write and update these fields. Backdoors A person with access to the underlying Mongo DB can do with the data what (s)he wants. This requires a direct interaction with the machine on which the database resides. Webaccess is not sufficient. generic A few values for the system: systemFields The list of provenance fields that the system must manage after each change to a record. Specs These fields must still be specified in the tables where they occur, including their types. noTitle The default title of a record if the title is not given in any other way. permissions The mechanics of the group-based permissions system is defined here. See permission model below. workflow See workflow engine . names Used in name handling . Table model \u00b6 Everything that the app needs to know about a table is in the table model. For each table that needs specs beyond the default, there is a corresponding model file in the model directory . Here we describe the keys in the table models. title The name of the field that will be used as title when records are listed. item A display name by which we call individual entities, with a value for singular and plural. E.g. for the table country we have as item: country and countries . sort A list of sort keys. A sort key is a pair consisting of a field, and a direction (-1: descending, 1: ascending). fieldOrder A list of the fields, in the order by which will we displayed when the interface presents a record. fieldSpecs A dictionary of the fields and their characteristics, needed to accommodate the display and manipulation of its values. Field names are the keys, the values are themselves dictionaries, containing: label A user-friendly display name of the field. multiple Whether there is only one value allowed for this field, or a list of values. valType The data type of the field and its other behavioural characteristics. Direct values If a field contains an explicit value or list of values, i.e. a value that stands on its own and does not refer to other records, valType is just a string that specifies the type of the field. If the field may contain a list of values ( multiple=true ), valType specifies the type of a single value. Possible types are: bool true or false . datetime A date time, mostly represented in its ISO 8601 format. number An integer or real number. text A string of characters, usually just a one-liner. url A syntactically valid URL: i.e. a string of text that can be interpreted as a URL. A validation routine will check this. email A syntactically valid email address. A validation routine will check this. textarea A string of characters, which may extend to several pages. It is assumed that this is Markdown text, and its formatted version will be shown on the interface, see MarkdownArea . Related values When a field refers to other records, there is much more to specify. In this case valType is a dictionary with the following information: relTable The table that contains the related records. allowNew Whether the user is allowed to enter new records in the related table. popUpIfEmpty ( optional: default: false ) If an edit view on a record having an empty value for this field is shown, a widget to choose a value will pop up immediately. Otherwise there will be just a control button, inviting you to enter a value. Score See the field score in criteriaEntry.yaml . select A criterion on records in the related table. Only the records that satisfy the criterion specified in select , are allowed values. The criterion may be an arbitrary MongoDb selction constraint. Country The country field in the contrib table has isMember: true . 1 2 3 4 5 6 7 8 9 10 11 12 country : perm : list : public read : public update : edit label : Country valType : relTable : country select : isMember : true allowNew : false multiple : false So when we choose a country for a contribution, we will be presented with a choice between those countries that are a member of DARIAH. Reviewer The reviewerE field in the assessment table points to the user table, but it has a select condition: 1 2 3 4 5 6 7 8 9 10 11 12 13 reviewerE : perm : list : auth read : auth update : office label : Reviewer (1) valType : select : authority : $ne : legacy relTable : user allowNew : email multiple : false That means, only users for which the authority field is not legacy can be chosen as reviewer. fixed ( optional, default: false ) Whether the value of this field is fixed after it has been assigned initially. A fixed field can be assigned a value, and after that it is frozen. If a field is fixed, the user interface will be informed to not provide edit controls for it, and the server will be instructed not to modify this field. assessmentType When an assessment record is created for a contribution, its field assessmentType is copied from the typeContribution field of the master contribution record. Based on that, a fixed set of criteriaEntry records are assembled as details to the assessment record. If the contribution type is changed in a later stage, the assessmentType still shows the type on which the assembly of criteriaEntry records is based. If we would allow the assessmentType to be changed, we have no way to see the type on which the criteria entries are based, therefore, we require it to be immutable after having received its initial value. Way out How to proceed out of such a situation? The system should not delete or change the criteria entry records, because the user may have entered data in it. If the contribution really needs an other type, the best way to proceed is to create a new blank assessment, copy the relevant information over from the old assessment, and then remove the old assessment. inactive ( optional ) This field relates to active / inactive items, defined in Workflow . Inactive items may have to be rendered in such a way that the user is alerted to the fact that these items are currently a form of legacy content. The inactive dictionary instructs what to do with inactive items: disabled If true, do not present inactive items in choice widgets: so if you modify the value, you cannot choose inactive values. attributes e.g. a CSS className and a HTML title attribute (tooltip) that will be put on the element that renders the item. Any set of valid attributes will do, there are no additional constraints. typeContribution The typeContribution field of a contrib record may be obsolete, because it is not specified in the current package (see Workflow . In the valType for this field we see the following specification: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 typeContribution : perm : list : public read : public update : edit label : Type valType : relTable : typeContribution allowNew : false inactive : attributes : className : inactive title : this value does not belong to the current package disabled : true multiple : false This is the rendered HTML for this value: 1 2 3 4 < a href = \"/data/typeContribution/list/item/00000000cca4bbd9fe00000b\" class = \"tag disabled inactive\" > Tools and Software </ a > Listing related records When we need to show a related record as a single value, we use its title field. Missing title field? The name of the title field is specified by the title entry in the table model, if present, otherwise we look it up from generic dictionary under noTitle . Custom code for titles The client code may have implemented special code for certain tables, such as user , and country . This happens in this piece of code 1 2 3 4 5 6 7 const headSwitch = { user : headUser , country : headCountry , typeContribution : headType , score : headScore , default : headRelated , } in tables.js . Value lists In many cases, the related table is a value list : every record consists of an _id field (the standard MongoDB identifier field) and a field called rep , which contains the representation of the value. Value lists may or may not specify custom table information. The default table information in generic is such that the value lists are covered by it. Permissions In all cases, the permissions model is also consulted, because the permissions model has a say in which fields are allowed to reach the client. Creator If a non-authenticated user is shown the creator of a record, (s)he sees information from the user table. But the permissions are such that (s)he may not see the email address of that user. So the email address does not even reach the client. grid Specifies how to lay out the table in a grid by means of CSS flex attributes: width The intended width of the column in which this field is presented; grow ( optional: default: 0 ) The degree by which the column width is allowed to increase. shrink ( optional: default: 0 ) The degree by which the column width is allowed to decrease. Country The list of countries is typically displayed in a grid. The country model lays out its columns as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 iso : ... grid : width : 2em grow : 0 name : ... grid : width : 10em grow : 1 isMember : ... grid : width : 4em grow : 0 latitude : ... grid : width : 4em grow : 0.5 shrink : 0 longitude : ... grid : width : 4em grow : 0.5 shrink : 0 valid The name of a client-side validation function by which new and modified values for this field are validated. The validators are exposed in fields.js as member functions of a validation object. Country The field iso in the country table is subjected to the isoCountry() validation function: 1 2 3 4 5 6 7 8 9 10 11 12 iso : perm : list : public read : public update : office label : ISO(2) valType : text valid : isoCountry multiple : false grid : width : 2em grow : 0 This function can be found in datatypes.js as a member of the (exported) validation object. Server validation The server carries out extensive, non-customizable validation as well, in order to protect the integrity of the database. details Specification of detail records: where are they and how are they connected to their masters? master-detail A record may have detail records associated with it. We call such a record a master record with respect to its details. Details are records, usually in another table, having a field that points to their master record by means of an _id value. multiple kinds of details A master record may have multiple kinds of detail records, i.e. detail records from several distinct tables. It is also possible to specify multiple kinds from one and the same originating table. To each kind of detail, a name is given, often this name is the same as the name of table in which the details are found. Detail display When a master record is presented in full view, all of its fields are expanded with their values. Below that there are lists of head lines of detail records, sorted by their kind. The detail specifications consist of: table The name of the originating table. linkField The name of the field in the originating table that links to the master record. mode The display mode of the detal records: name meaning list plain list of record head lines grid table of full records in grid view filtered Whether the detais of this kind should have filter controls. If yes, the filters are taken from the specification of the originating table. expand ( optional, default: false ) If this is true, all detail records of this kind will be immediately expanded. Normally, detail records are presented as head lines initially. border ( optional, default: read: true, edit: true ) Whether to put a border around each individual detail record of this kind. This feature must be specified for the read-only presentation and the editable presentation separately, by means of the keys read and edit . criteriaEntry The criteriaEntry details of an assessment record will be displayed without borders, thereby strengthening the impression that they constitute a single form. 1 2 3 4 5 6 7 8 9 10 11 12 13 details : criteriaEntry : table : criteriaEntry linkField : assessment expand : own mode : list border : { read : false , edit : false , } filtered : true cascade : true fixed : true cascade ( optional, default: false ) When the master record is deleted, its details have a dangling reference to a non-existing master record. In some cases it is desirable to delete the detail records as well. If cascade: true , the detail records of this kind will be deleted together with the master record. criteriaEntry In the assessment model it is stated that criteriaEntry records are deleted with their master record. 1 2 3 4 5 6 7 8 9 10 11 12 13 details : criteriaEntry : table : criteriaEntry linkField : assessment expand : own mode : list border : { read : false , edit : false , } filtered : true cascade : true fixed : true criteria In the package model it is stated that criteria records are not deleted with their master record, bacause there is no cascade: true . 1 2 3 4 5 6 details : criteria : table : criteria linkField : package mode : list filtered : true fixed ( optional, default: false ) Whether the list of details of this kind is fixed. Details of a kind are fixed, if, after having been created, no details may be added or removed. Individual details may still be modified. Assessments and criteria entries Once an assessment record for a contribution has been created, a special workflow takes care to lookup the list of criteria that apply to this contribution, based on its typeContribution field. read from package This mapping is read from the criteria detail records of the currently active package records). For each criterion a criteriaEntry detail record is added to the master assessment record. After that, the list of criteriaEntries for this assessment record may not change anymore. But the user is still be able to fill out the criteriaEntry records. This is accomplished by fixed: true in 1 2 3 4 5 6 7 8 9 10 11 12 13 details : criteriaEntry : table : criteriaEntry linkField : assessment expand : own mode : list border : { read : false , edit : false , } filtered : true cascade : true fixed : true See the assessment model . detailOrder The order in which details are displayed below their master record is given in the key detailOrder . needMaster optional: default: false . Some tables act as containers for detail records exclusively, and it makes no sense to create a detail record if there is no master record to point to. If that is the case, specify needMaster: true , otherwise, leave it out. Presentation If needMaster: true , there will be no plus button (insert item) when the records are displayed as a main list. Only when they are displayed as a list of details to some master record, the plus button will appear. Assessment Assessments can only be created as detail of a contribution . 1 needMaster : true See the assessment model . Package Packages can be seen as details of typeContribution , in the sense that for each contribution type, there is a list of packages to tell when that contribution type was valid and which criteria were associated with it. Yet a package record makes sense on its own. When you create it, you do not have to select a contribution type first. Rather, you create a package, and in its typeContribution field you select a number of contribution types. filters A list of filters by which to constrain the set of records to be displayed. There are fulltext filters and faceted filters. Each filter is a dictionary with the following information: field The name of the field to be filtered. relField ( optional ) If field has values that are identifiers pointing to a related tables, relField specifies which field in the related table should be filtered. criteriaEntry If you want to filter criteriaEntry records on their score , you are faced with the fact that scores live in a separate table. The criteriaEntry records contain just an _id into the table score . The actual score is contained in the field score of that table. Hence, if we want to filter on actual scores, we say 1 2 3 4 5 6 7 filters : - field : score relField : score label : score type : ByValue maxCols : 1 expanded : true See the criteriaEntry model . label A user friendly name for the filter, usually the label of the field to be filtered. type The type of filter: filter type widget ByValue faceted browsing EUMap faceted, plus a visualisation on the map of Europe Fulltext full text search in the field values maxCols ( not needed for Fulltext filters ) Facets are displayed in a table with at most this amount of columns. expanded ( not needed for Fulltext filters ) Whether the table of facets is initially expanded or collapsed. Permission model \u00b6 The authorization system is built on the basis of groups and permission levels. Users are assigned to groups, and things require permission levels. When a user wants to act upon a thing, his/her group will be compared to the permission level of the thing, and based on the outcome of the comparison, the action will be allowed or forbidden. The configuration of the permissions system as a whole is in model , under the key permissions , and the table-specific permissions are under the perm keys of the table model files . Groups (informally) Groups are attributes of users, as an indication of the power they have. Informally, we need to distinguish between: Nobody A group without users, and if there were users, they could not do anything. Useful in cases where you want to state that something is not permitted to anybody. The public Unidentified an unauthenticated users. They can only list/read public information and have no right to edit anything and can do no actions that change anything in the database. Authenticated users DARIAH users authenticated by the DARIAH Identity provider. This is the default group for logged-in users. They can see DARIAH internal information (within limits) an can add items and then modify/delete them, within limits. National coordinators DARIAH users that coordinate the DARIAH outputs for an entire member country. They can (de)select contributions and see their cost fields but only for contributions in the countries they coordinate. Backoffice employees Users that work for the DARIAH ERIC office. They can modify records created by others (within limits), but cannot perform technical actions that affect the system. System managers Users that control the system, not only through the interface of the app, but also with low-level access to the database and the machine that serves the app. Can modify system-technical records, within limits. root One user that can bootstrap the system. Complete rights. Still there are untouchable things, that would compromise the integrity of the system. Even root cannot modify those from within the system. Root is the owner of the system, and can assign people to the roles of system managers and backoffice employees. From there on, these latter groups can do everything that is needed for the day-to-day operation of the functions that the system is designed to fulfill. Pseudo groups In some cases, the identity of the user is relevant, namely when users have a special relationship to the records they want to modify, such as ownership , editorship , etc. When those relationships apply, users are put in a pseudo group such own or edit . In yet other cases, when users change the permission levels of users, the permission levels of both users need to be taken into account. Assigning users to groups Once users are in a group, their permissions are known. But there are also permissions to regulate who may assign groups to users. These permissions derive from the groups as well, with a few additional rules: nobody can assign anybody to the group nobody ; a person can only add people to groups that have at most his/her own power; a person can only assign groups to people that have less power than him/herself. Example If you are office , you cannot promote yourself or anyone else to system or root . If you are office , you cannot demote another member of office to the group auth . You cannot demote/promote your peers, or the ones above you. You can demote yourself, but not promote yourself. You can demote people below you. You can promote people below you, but only up to your own level. Groups (formally) Authenticated versus unauthenticated users The keys auth and unauth point to the names the groups to which authenticated and unauthenticated users are assigned by default (respectively). Under the key groups the groups and pseudo groups are given, with a short description. group is pseudo description public no user, not logged in auth no authenticated user our yes authenticated user and mentioned in a specific field of records in question edit yes authenticated user and editor of records in question own yes authenticated user and creator of records in question coord no national coordinator office no back office user system no system administrator root no full control nobody no deliberately empty: no user is member of this group our the user is mentioned in specific fields of the record. Which fields? See the ourFields key in the yaml file for that table. assessments assessment.yaml Levels Levels are attributes of things: methods, tables, records, fields, as an indication of the power needed to act upon them. Under the key levels the levels are given, in the order: more powerful before less powerful. public auth our OUR edit EDIT own OWN coord office system root nobody Capitalized pseudo groups The levels correspond largely to the groups, but there are a few capitalized variants of the pseudo groups. They come into play when users with higher powers want to access items. For example, a backoffice user is entitled to edit items which require level own for that, even if they are other people's items. This is because the power of a backoffice user exceeds the level own . But if you want to display a button my items , which lists the items own ed by the current user. The obvious thing to do, is to assign a permission level own to the action list . That works fine for normal, authenticated users. But a backoffice user will see all items nevertheless. This is where OWN comes in. The capitalized form states that the own ership condition outweighs the office potential. Thus, if the list action reuqires OWN permission, only records whose owner is the current user are listed. The same logic applies to OUR and EDIT . ownLT This is a very special pseudo-level. It requires that the user acting on the item is either the owner or is more powerful than the owner of the record. This is only applicable to the group field in the user table. In this way it is enforced that lower power users can not affect what higher power users can do. Actions Methods give rise to actions , listed in under the key actions : action description insert create item list read item title read read item set give item initial value update update item delete delete item read versus list An item may allow list to public but not read . In that case, unauthenticated users may see the list of items, usually their titles, but they cannot drill down to see the full details of records. set versus update The set action changes a value from null , None , or undefined to a defined value. It cannot change a defined value into another value. So set is a limited update action. update can change any value, including an undefined value, into any other value, including an undefined value. Things These are the things that may require permission levels: Methods If a user needs to do something, (s)he interacts with the user interface at the client. That will lead to an API call to the server, which will translate into the invocation of a method . At that point, the first check will be made: is this user allowed to invoke this method? The check is performed on the basis of the methods table, which is a dictionary of method names. For each method name a description is given, and the level required to invoke that method. method level description mylist EDIT list my items ourlist OUR list our items list public list all items view public details of an item mod edit modify (insert/update/delete) an item resetwf system reset the workflow information Tables and fields For every table and every field in it, we specify access levels. That means: for every action on that field we state the required access level. Authorization logic the access level for invoking the method is checked; if allowed, the actions that the method is going to perform on which tables are considered; for every (table-action) combination a row filter and a field filter is constructed, restricting the action to only those rows and fields that are permitted to the user; this might be an empty set; if the set is not empty, the action is executed on those rows and those fields that pass the filters. Row and field filters The perm key in the model file of a particular table states the permission level for actions on that table as a whole. This will be checked first. From this a row filter is computed, selecting those rows that may undergo the action. Then there is also a perm section in the field specification for each field in the table. From this a field filter is co,puted, selecting those fields that may undergo the action. Authorization Actions may proceed if the user shows a group that matches somehow the level required by the action and the things affected. The matches somehow is specified by a table whose first key is the group, whose second key is the level, and whose value is a number. If the number is 0 , or if the combination of group and level is missing, the action is not allowed. If the number is positive, it is always 1 , and the action is allowed. If the number is negative, the action maybe allowed, depending on subsequent conditions, indicated by the value of the nagative number. Subsequent conditions value condition -1 only if the user is owner of the record -2 only if the user is editor of the record -3 only if the user is mentioned in some specific fields of the record -4 only if the user is from the same country as the country field in the record Authorization table The mapping is under the key authorize . group level authorization public public 1 auth public 1 auth auth 1 auth coord 0 auth our -3 auth OUR -3 auth edit -2 auth EDIT -2 auth own -1 auth OWN -1 auth ownLT -1 coord public 1 coord auth 1 coord coord -4 coord our -3 coord OUR -3 coord edit -2 coord EDIT -2 coord own -1 coord OWN -1 coord ownLT -1 office public 1 office auth 1 office coord 1 office our 1 office OUR -3 office edit 1 office EDIT -2 office own 1 office OWN -1 office ownLT 1 office office 1 system public 1 system auth 1 system coord 1 system our 1 system OUR -3 system edit 1 system EDIT -2 system own 1 system OWN -1 system ownLT 1 system office 1 system system 1 root public 1 root auth 1 root coord 1 root our 1 root OUR -3 root edit 1 root EDIT -2 root own 1 root OWN -1 root ownLT 1 root office 1 root system 1 nobody Note that users in group nobody have no rights. There should be no users in that group, but if by misconfiguration there is a user in that group, (s)he can do nothing. root A consequence of the promotion/demotion rules is that if there is no user in the group root , nobody can be made root from within the system. When importing data into the system by means of load.sh you can specify to make a specific user root . Which user that is, is specified in config.yaml , see rootUser . Once the root user is in place, (s)he can assign system admins and back office people. Once those are in place, the daily governance of the system can take place. Name handling \u00b6 The problem There are a lot of names in these yaml files. The most obvious way to use them in our programs (Python on the server, JavaScript on the client) is by just mentioning them as strings, e.g.: 1 title = DM [ 'tables' ][ 'permissionGroup' ][ 'title' ] and 1 title = DM . tables . permissionGroup . title or 1 const { tables : { permissionGroup : { title } } } = DM But then the question arises: how can we use these names in our programs in such a way that we are protected agains typos? Partial solution We tackle this problem in the server code, but not in the client code. Python Well, we convert the .yaml model files to Python modules that expose the same model, but now as Python data structure. This is done by means of the compile.py script, just before starting the server. That enables us to collect the names and generate some code. Every part of the .yaml files that may act as a name, is collected. We generate a module names.py that defined an object N that contains a member name = ' name ' for each name . This module of names will be imported whenever the models are imported. So whenever we want to refer to a name in one of the models, we have a Python variable in our name space that is equal to that name prepended with N. . By consequently using N. names instead of plain strings, we guard ourselves against typos, because the Python parser will complain about undefined variables. Moreover, the same compile.py module also checks all the code in the controllers directory for names: whether every N. name is defined in the names.py and if there are occurrences of plain strings for which an N. name is defined. This solves the case for the Python server code. Javascript For the client JavaScript code we do not have such measures. We could do the same approach, but that would severely uglify the code: 1 title = DM [ N . tables ][ N . permissionGroup ][ N . title ] or 1 const { [ N . tables ] : { [ N . permissionGroup ] : { [ N . title ] : title } } } = DM Especially the replacement of 1 { name } by 1 { [ N . name ] : name } really hurts. So we do not do anything here, and rely on debugging away the typos the hard way.","title":"Model"},{"location":"Concepts/Model/#model","text":"This application contains a generic engine to display MongoDB data according to any specified data model, respecting access privileges.","title":"Model"},{"location":"Concepts/Model/#mongodb","text":"We store the data in a MongoDB . Data as documents A MongoDB does not work with a fixed schema. A MongoDB collection consists of documents , which are essentially JSON-like structures, arbitrarily large and arbitrarily nested. That makes it easy to add new kinds of data to documents and collections when the need arises to do so. This will not break the existing code. MongoDB is optimized to read quickly, at the cost of more expensive data manipulation operations. Its documentation favours storing related data inside the main document. This increases the redundancy of the data and may lead to consistency problems, unless the application tries to enforce consistency somehow. In this app, with a limited amount of data, we use MongoDB primarily for its flexibility. We still adhere largely to SQL-like practices when we deal with related tables. So instead of storing the information of related documents directly inside the main document, we only store references to related documents inside the main documents. Terminology Because our treatment of data is still very relational, we prefer wording derived from SQL databases, at least in the present documentation: MongoDB SQL collection table document record","title":"MongoDB"},{"location":"Concepts/Model/#configuration","text":"The model and the files in table are YAML configuration files, and by tweaking them you can achieve a lot of customization.","title":"Configuration"},{"location":"Concepts/Model/#data-model","text":"The data model has a generic part and a table specific part.","title":"Data model"},{"location":"Concepts/Model/#generic-part","text":"See model.yaml . Here we define structures and values that are relevant for the system as a whole and/or for all tables: defaults Defaults for table models. Whenever a table misses one of the keys listed here, the value here will be filled in for that table. The defaults are suited to tables that act as value lists, of which we have quite a bunch. All these tables need a very short own specification. The meaning of these keys are explained in table configuration . provenance Fields for recording the edit history of a record. provenanceOrder Field names for provenance fields in a specific order. provenanceSpecs Field specifications for the provenance fields. We have these fields: editors List of ids of non-owner users that may edit this record, even if their group permissions do not allow it. creator Id of the user that created the record. dateCreated Datetime when the record was created. modified Trail of modification events, each event has the name of the user who caused the change and the datetime when it happened. The trail will be weeded out over time. The field \"editors\" may be changed by the owner of a record, and by people with higher powers such as the backoffice, not by the editors themselves (unless they also have higher power). All other fields cannot be modified by users, not even by users with higher powers. Only the system itself will write and update these fields. Backdoors A person with access to the underlying Mongo DB can do with the data what (s)he wants. This requires a direct interaction with the machine on which the database resides. Webaccess is not sufficient. generic A few values for the system: systemFields The list of provenance fields that the system must manage after each change to a record. Specs These fields must still be specified in the tables where they occur, including their types. noTitle The default title of a record if the title is not given in any other way. permissions The mechanics of the group-based permissions system is defined here. See permission model below. workflow See workflow engine . names Used in name handling .","title":"Generic part"},{"location":"Concepts/Model/#table-model","text":"Everything that the app needs to know about a table is in the table model. For each table that needs specs beyond the default, there is a corresponding model file in the model directory . Here we describe the keys in the table models. title The name of the field that will be used as title when records are listed. item A display name by which we call individual entities, with a value for singular and plural. E.g. for the table country we have as item: country and countries . sort A list of sort keys. A sort key is a pair consisting of a field, and a direction (-1: descending, 1: ascending). fieldOrder A list of the fields, in the order by which will we displayed when the interface presents a record. fieldSpecs A dictionary of the fields and their characteristics, needed to accommodate the display and manipulation of its values. Field names are the keys, the values are themselves dictionaries, containing: label A user-friendly display name of the field. multiple Whether there is only one value allowed for this field, or a list of values. valType The data type of the field and its other behavioural characteristics. Direct values If a field contains an explicit value or list of values, i.e. a value that stands on its own and does not refer to other records, valType is just a string that specifies the type of the field. If the field may contain a list of values ( multiple=true ), valType specifies the type of a single value. Possible types are: bool true or false . datetime A date time, mostly represented in its ISO 8601 format. number An integer or real number. text A string of characters, usually just a one-liner. url A syntactically valid URL: i.e. a string of text that can be interpreted as a URL. A validation routine will check this. email A syntactically valid email address. A validation routine will check this. textarea A string of characters, which may extend to several pages. It is assumed that this is Markdown text, and its formatted version will be shown on the interface, see MarkdownArea . Related values When a field refers to other records, there is much more to specify. In this case valType is a dictionary with the following information: relTable The table that contains the related records. allowNew Whether the user is allowed to enter new records in the related table. popUpIfEmpty ( optional: default: false ) If an edit view on a record having an empty value for this field is shown, a widget to choose a value will pop up immediately. Otherwise there will be just a control button, inviting you to enter a value. Score See the field score in criteriaEntry.yaml . select A criterion on records in the related table. Only the records that satisfy the criterion specified in select , are allowed values. The criterion may be an arbitrary MongoDb selction constraint. Country The country field in the contrib table has isMember: true . 1 2 3 4 5 6 7 8 9 10 11 12 country : perm : list : public read : public update : edit label : Country valType : relTable : country select : isMember : true allowNew : false multiple : false So when we choose a country for a contribution, we will be presented with a choice between those countries that are a member of DARIAH. Reviewer The reviewerE field in the assessment table points to the user table, but it has a select condition: 1 2 3 4 5 6 7 8 9 10 11 12 13 reviewerE : perm : list : auth read : auth update : office label : Reviewer (1) valType : select : authority : $ne : legacy relTable : user allowNew : email multiple : false That means, only users for which the authority field is not legacy can be chosen as reviewer. fixed ( optional, default: false ) Whether the value of this field is fixed after it has been assigned initially. A fixed field can be assigned a value, and after that it is frozen. If a field is fixed, the user interface will be informed to not provide edit controls for it, and the server will be instructed not to modify this field. assessmentType When an assessment record is created for a contribution, its field assessmentType is copied from the typeContribution field of the master contribution record. Based on that, a fixed set of criteriaEntry records are assembled as details to the assessment record. If the contribution type is changed in a later stage, the assessmentType still shows the type on which the assembly of criteriaEntry records is based. If we would allow the assessmentType to be changed, we have no way to see the type on which the criteria entries are based, therefore, we require it to be immutable after having received its initial value. Way out How to proceed out of such a situation? The system should not delete or change the criteria entry records, because the user may have entered data in it. If the contribution really needs an other type, the best way to proceed is to create a new blank assessment, copy the relevant information over from the old assessment, and then remove the old assessment. inactive ( optional ) This field relates to active / inactive items, defined in Workflow . Inactive items may have to be rendered in such a way that the user is alerted to the fact that these items are currently a form of legacy content. The inactive dictionary instructs what to do with inactive items: disabled If true, do not present inactive items in choice widgets: so if you modify the value, you cannot choose inactive values. attributes e.g. a CSS className and a HTML title attribute (tooltip) that will be put on the element that renders the item. Any set of valid attributes will do, there are no additional constraints. typeContribution The typeContribution field of a contrib record may be obsolete, because it is not specified in the current package (see Workflow . In the valType for this field we see the following specification: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 typeContribution : perm : list : public read : public update : edit label : Type valType : relTable : typeContribution allowNew : false inactive : attributes : className : inactive title : this value does not belong to the current package disabled : true multiple : false This is the rendered HTML for this value: 1 2 3 4 < a href = \"/data/typeContribution/list/item/00000000cca4bbd9fe00000b\" class = \"tag disabled inactive\" > Tools and Software </ a > Listing related records When we need to show a related record as a single value, we use its title field. Missing title field? The name of the title field is specified by the title entry in the table model, if present, otherwise we look it up from generic dictionary under noTitle . Custom code for titles The client code may have implemented special code for certain tables, such as user , and country . This happens in this piece of code 1 2 3 4 5 6 7 const headSwitch = { user : headUser , country : headCountry , typeContribution : headType , score : headScore , default : headRelated , } in tables.js . Value lists In many cases, the related table is a value list : every record consists of an _id field (the standard MongoDB identifier field) and a field called rep , which contains the representation of the value. Value lists may or may not specify custom table information. The default table information in generic is such that the value lists are covered by it. Permissions In all cases, the permissions model is also consulted, because the permissions model has a say in which fields are allowed to reach the client. Creator If a non-authenticated user is shown the creator of a record, (s)he sees information from the user table. But the permissions are such that (s)he may not see the email address of that user. So the email address does not even reach the client. grid Specifies how to lay out the table in a grid by means of CSS flex attributes: width The intended width of the column in which this field is presented; grow ( optional: default: 0 ) The degree by which the column width is allowed to increase. shrink ( optional: default: 0 ) The degree by which the column width is allowed to decrease. Country The list of countries is typically displayed in a grid. The country model lays out its columns as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 iso : ... grid : width : 2em grow : 0 name : ... grid : width : 10em grow : 1 isMember : ... grid : width : 4em grow : 0 latitude : ... grid : width : 4em grow : 0.5 shrink : 0 longitude : ... grid : width : 4em grow : 0.5 shrink : 0 valid The name of a client-side validation function by which new and modified values for this field are validated. The validators are exposed in fields.js as member functions of a validation object. Country The field iso in the country table is subjected to the isoCountry() validation function: 1 2 3 4 5 6 7 8 9 10 11 12 iso : perm : list : public read : public update : office label : ISO(2) valType : text valid : isoCountry multiple : false grid : width : 2em grow : 0 This function can be found in datatypes.js as a member of the (exported) validation object. Server validation The server carries out extensive, non-customizable validation as well, in order to protect the integrity of the database. details Specification of detail records: where are they and how are they connected to their masters? master-detail A record may have detail records associated with it. We call such a record a master record with respect to its details. Details are records, usually in another table, having a field that points to their master record by means of an _id value. multiple kinds of details A master record may have multiple kinds of detail records, i.e. detail records from several distinct tables. It is also possible to specify multiple kinds from one and the same originating table. To each kind of detail, a name is given, often this name is the same as the name of table in which the details are found. Detail display When a master record is presented in full view, all of its fields are expanded with their values. Below that there are lists of head lines of detail records, sorted by their kind. The detail specifications consist of: table The name of the originating table. linkField The name of the field in the originating table that links to the master record. mode The display mode of the detal records: name meaning list plain list of record head lines grid table of full records in grid view filtered Whether the detais of this kind should have filter controls. If yes, the filters are taken from the specification of the originating table. expand ( optional, default: false ) If this is true, all detail records of this kind will be immediately expanded. Normally, detail records are presented as head lines initially. border ( optional, default: read: true, edit: true ) Whether to put a border around each individual detail record of this kind. This feature must be specified for the read-only presentation and the editable presentation separately, by means of the keys read and edit . criteriaEntry The criteriaEntry details of an assessment record will be displayed without borders, thereby strengthening the impression that they constitute a single form. 1 2 3 4 5 6 7 8 9 10 11 12 13 details : criteriaEntry : table : criteriaEntry linkField : assessment expand : own mode : list border : { read : false , edit : false , } filtered : true cascade : true fixed : true cascade ( optional, default: false ) When the master record is deleted, its details have a dangling reference to a non-existing master record. In some cases it is desirable to delete the detail records as well. If cascade: true , the detail records of this kind will be deleted together with the master record. criteriaEntry In the assessment model it is stated that criteriaEntry records are deleted with their master record. 1 2 3 4 5 6 7 8 9 10 11 12 13 details : criteriaEntry : table : criteriaEntry linkField : assessment expand : own mode : list border : { read : false , edit : false , } filtered : true cascade : true fixed : true criteria In the package model it is stated that criteria records are not deleted with their master record, bacause there is no cascade: true . 1 2 3 4 5 6 details : criteria : table : criteria linkField : package mode : list filtered : true fixed ( optional, default: false ) Whether the list of details of this kind is fixed. Details of a kind are fixed, if, after having been created, no details may be added or removed. Individual details may still be modified. Assessments and criteria entries Once an assessment record for a contribution has been created, a special workflow takes care to lookup the list of criteria that apply to this contribution, based on its typeContribution field. read from package This mapping is read from the criteria detail records of the currently active package records). For each criterion a criteriaEntry detail record is added to the master assessment record. After that, the list of criteriaEntries for this assessment record may not change anymore. But the user is still be able to fill out the criteriaEntry records. This is accomplished by fixed: true in 1 2 3 4 5 6 7 8 9 10 11 12 13 details : criteriaEntry : table : criteriaEntry linkField : assessment expand : own mode : list border : { read : false , edit : false , } filtered : true cascade : true fixed : true See the assessment model . detailOrder The order in which details are displayed below their master record is given in the key detailOrder . needMaster optional: default: false . Some tables act as containers for detail records exclusively, and it makes no sense to create a detail record if there is no master record to point to. If that is the case, specify needMaster: true , otherwise, leave it out. Presentation If needMaster: true , there will be no plus button (insert item) when the records are displayed as a main list. Only when they are displayed as a list of details to some master record, the plus button will appear. Assessment Assessments can only be created as detail of a contribution . 1 needMaster : true See the assessment model . Package Packages can be seen as details of typeContribution , in the sense that for each contribution type, there is a list of packages to tell when that contribution type was valid and which criteria were associated with it. Yet a package record makes sense on its own. When you create it, you do not have to select a contribution type first. Rather, you create a package, and in its typeContribution field you select a number of contribution types. filters A list of filters by which to constrain the set of records to be displayed. There are fulltext filters and faceted filters. Each filter is a dictionary with the following information: field The name of the field to be filtered. relField ( optional ) If field has values that are identifiers pointing to a related tables, relField specifies which field in the related table should be filtered. criteriaEntry If you want to filter criteriaEntry records on their score , you are faced with the fact that scores live in a separate table. The criteriaEntry records contain just an _id into the table score . The actual score is contained in the field score of that table. Hence, if we want to filter on actual scores, we say 1 2 3 4 5 6 7 filters : - field : score relField : score label : score type : ByValue maxCols : 1 expanded : true See the criteriaEntry model . label A user friendly name for the filter, usually the label of the field to be filtered. type The type of filter: filter type widget ByValue faceted browsing EUMap faceted, plus a visualisation on the map of Europe Fulltext full text search in the field values maxCols ( not needed for Fulltext filters ) Facets are displayed in a table with at most this amount of columns. expanded ( not needed for Fulltext filters ) Whether the table of facets is initially expanded or collapsed.","title":"Table model"},{"location":"Concepts/Model/#permission-model","text":"The authorization system is built on the basis of groups and permission levels. Users are assigned to groups, and things require permission levels. When a user wants to act upon a thing, his/her group will be compared to the permission level of the thing, and based on the outcome of the comparison, the action will be allowed or forbidden. The configuration of the permissions system as a whole is in model , under the key permissions , and the table-specific permissions are under the perm keys of the table model files . Groups (informally) Groups are attributes of users, as an indication of the power they have. Informally, we need to distinguish between: Nobody A group without users, and if there were users, they could not do anything. Useful in cases where you want to state that something is not permitted to anybody. The public Unidentified an unauthenticated users. They can only list/read public information and have no right to edit anything and can do no actions that change anything in the database. Authenticated users DARIAH users authenticated by the DARIAH Identity provider. This is the default group for logged-in users. They can see DARIAH internal information (within limits) an can add items and then modify/delete them, within limits. National coordinators DARIAH users that coordinate the DARIAH outputs for an entire member country. They can (de)select contributions and see their cost fields but only for contributions in the countries they coordinate. Backoffice employees Users that work for the DARIAH ERIC office. They can modify records created by others (within limits), but cannot perform technical actions that affect the system. System managers Users that control the system, not only through the interface of the app, but also with low-level access to the database and the machine that serves the app. Can modify system-technical records, within limits. root One user that can bootstrap the system. Complete rights. Still there are untouchable things, that would compromise the integrity of the system. Even root cannot modify those from within the system. Root is the owner of the system, and can assign people to the roles of system managers and backoffice employees. From there on, these latter groups can do everything that is needed for the day-to-day operation of the functions that the system is designed to fulfill. Pseudo groups In some cases, the identity of the user is relevant, namely when users have a special relationship to the records they want to modify, such as ownership , editorship , etc. When those relationships apply, users are put in a pseudo group such own or edit . In yet other cases, when users change the permission levels of users, the permission levels of both users need to be taken into account. Assigning users to groups Once users are in a group, their permissions are known. But there are also permissions to regulate who may assign groups to users. These permissions derive from the groups as well, with a few additional rules: nobody can assign anybody to the group nobody ; a person can only add people to groups that have at most his/her own power; a person can only assign groups to people that have less power than him/herself. Example If you are office , you cannot promote yourself or anyone else to system or root . If you are office , you cannot demote another member of office to the group auth . You cannot demote/promote your peers, or the ones above you. You can demote yourself, but not promote yourself. You can demote people below you. You can promote people below you, but only up to your own level. Groups (formally) Authenticated versus unauthenticated users The keys auth and unauth point to the names the groups to which authenticated and unauthenticated users are assigned by default (respectively). Under the key groups the groups and pseudo groups are given, with a short description. group is pseudo description public no user, not logged in auth no authenticated user our yes authenticated user and mentioned in a specific field of records in question edit yes authenticated user and editor of records in question own yes authenticated user and creator of records in question coord no national coordinator office no back office user system no system administrator root no full control nobody no deliberately empty: no user is member of this group our the user is mentioned in specific fields of the record. Which fields? See the ourFields key in the yaml file for that table. assessments assessment.yaml Levels Levels are attributes of things: methods, tables, records, fields, as an indication of the power needed to act upon them. Under the key levels the levels are given, in the order: more powerful before less powerful. public auth our OUR edit EDIT own OWN coord office system root nobody Capitalized pseudo groups The levels correspond largely to the groups, but there are a few capitalized variants of the pseudo groups. They come into play when users with higher powers want to access items. For example, a backoffice user is entitled to edit items which require level own for that, even if they are other people's items. This is because the power of a backoffice user exceeds the level own . But if you want to display a button my items , which lists the items own ed by the current user. The obvious thing to do, is to assign a permission level own to the action list . That works fine for normal, authenticated users. But a backoffice user will see all items nevertheless. This is where OWN comes in. The capitalized form states that the own ership condition outweighs the office potential. Thus, if the list action reuqires OWN permission, only records whose owner is the current user are listed. The same logic applies to OUR and EDIT . ownLT This is a very special pseudo-level. It requires that the user acting on the item is either the owner or is more powerful than the owner of the record. This is only applicable to the group field in the user table. In this way it is enforced that lower power users can not affect what higher power users can do. Actions Methods give rise to actions , listed in under the key actions : action description insert create item list read item title read read item set give item initial value update update item delete delete item read versus list An item may allow list to public but not read . In that case, unauthenticated users may see the list of items, usually their titles, but they cannot drill down to see the full details of records. set versus update The set action changes a value from null , None , or undefined to a defined value. It cannot change a defined value into another value. So set is a limited update action. update can change any value, including an undefined value, into any other value, including an undefined value. Things These are the things that may require permission levels: Methods If a user needs to do something, (s)he interacts with the user interface at the client. That will lead to an API call to the server, which will translate into the invocation of a method . At that point, the first check will be made: is this user allowed to invoke this method? The check is performed on the basis of the methods table, which is a dictionary of method names. For each method name a description is given, and the level required to invoke that method. method level description mylist EDIT list my items ourlist OUR list our items list public list all items view public details of an item mod edit modify (insert/update/delete) an item resetwf system reset the workflow information Tables and fields For every table and every field in it, we specify access levels. That means: for every action on that field we state the required access level. Authorization logic the access level for invoking the method is checked; if allowed, the actions that the method is going to perform on which tables are considered; for every (table-action) combination a row filter and a field filter is constructed, restricting the action to only those rows and fields that are permitted to the user; this might be an empty set; if the set is not empty, the action is executed on those rows and those fields that pass the filters. Row and field filters The perm key in the model file of a particular table states the permission level for actions on that table as a whole. This will be checked first. From this a row filter is computed, selecting those rows that may undergo the action. Then there is also a perm section in the field specification for each field in the table. From this a field filter is co,puted, selecting those fields that may undergo the action. Authorization Actions may proceed if the user shows a group that matches somehow the level required by the action and the things affected. The matches somehow is specified by a table whose first key is the group, whose second key is the level, and whose value is a number. If the number is 0 , or if the combination of group and level is missing, the action is not allowed. If the number is positive, it is always 1 , and the action is allowed. If the number is negative, the action maybe allowed, depending on subsequent conditions, indicated by the value of the nagative number. Subsequent conditions value condition -1 only if the user is owner of the record -2 only if the user is editor of the record -3 only if the user is mentioned in some specific fields of the record -4 only if the user is from the same country as the country field in the record Authorization table The mapping is under the key authorize . group level authorization public public 1 auth public 1 auth auth 1 auth coord 0 auth our -3 auth OUR -3 auth edit -2 auth EDIT -2 auth own -1 auth OWN -1 auth ownLT -1 coord public 1 coord auth 1 coord coord -4 coord our -3 coord OUR -3 coord edit -2 coord EDIT -2 coord own -1 coord OWN -1 coord ownLT -1 office public 1 office auth 1 office coord 1 office our 1 office OUR -3 office edit 1 office EDIT -2 office own 1 office OWN -1 office ownLT 1 office office 1 system public 1 system auth 1 system coord 1 system our 1 system OUR -3 system edit 1 system EDIT -2 system own 1 system OWN -1 system ownLT 1 system office 1 system system 1 root public 1 root auth 1 root coord 1 root our 1 root OUR -3 root edit 1 root EDIT -2 root own 1 root OWN -1 root ownLT 1 root office 1 root system 1 nobody Note that users in group nobody have no rights. There should be no users in that group, but if by misconfiguration there is a user in that group, (s)he can do nothing. root A consequence of the promotion/demotion rules is that if there is no user in the group root , nobody can be made root from within the system. When importing data into the system by means of load.sh you can specify to make a specific user root . Which user that is, is specified in config.yaml , see rootUser . Once the root user is in place, (s)he can assign system admins and back office people. Once those are in place, the daily governance of the system can take place.","title":"Permission model"},{"location":"Concepts/Model/#name-handling","text":"The problem There are a lot of names in these yaml files. The most obvious way to use them in our programs (Python on the server, JavaScript on the client) is by just mentioning them as strings, e.g.: 1 title = DM [ 'tables' ][ 'permissionGroup' ][ 'title' ] and 1 title = DM . tables . permissionGroup . title or 1 const { tables : { permissionGroup : { title } } } = DM But then the question arises: how can we use these names in our programs in such a way that we are protected agains typos? Partial solution We tackle this problem in the server code, but not in the client code. Python Well, we convert the .yaml model files to Python modules that expose the same model, but now as Python data structure. This is done by means of the compile.py script, just before starting the server. That enables us to collect the names and generate some code. Every part of the .yaml files that may act as a name, is collected. We generate a module names.py that defined an object N that contains a member name = ' name ' for each name . This module of names will be imported whenever the models are imported. So whenever we want to refer to a name in one of the models, we have a Python variable in our name space that is equal to that name prepended with N. . By consequently using N. names instead of plain strings, we guard ourselves against typos, because the Python parser will complain about undefined variables. Moreover, the same compile.py module also checks all the code in the controllers directory for names: whether every N. name is defined in the names.py and if there are occurrences of plain strings for which an N. name is defined. This solves the case for the Python server code. Javascript For the client JavaScript code we do not have such measures. We could do the same approach, but that would severely uglify the code: 1 title = DM [ N . tables ][ N . permissionGroup ][ N . title ] or 1 const { [ N . tables ] : { [ N . permissionGroup ] : { [ N . title ] : title } } } = DM Especially the replacement of 1 { name } by 1 { [ N . name ] : name } really hurts. So we do not do anything here, and rely on debugging away the typos the hard way.","title":"Name handling"},{"location":"Concepts/Routing/","text":"Routing \u00b6 Routing is the task to map urls to functions of the app. It requires logic at the client side and at the server side. Client \u00b6 For this we use the React Router . Entry point At the client side, the app starts in main . The first priority is to create a Redux Provider component, which will be ancestor to all other components. Routing The second priority is to set up the routes configuration, i.e. the way URLs give rise to activating certain components. In previous versions of React-Router this tended to be done inside one or two components, but in the current version it is better done by calling Route components from the components that need it, i.e. a more distributed approach. These are the components that use functionality of the router: component task main use a router based on the HTML5 history API App navigate to /login , /logout etc DocMd navigate to parts of the app from within documents rendered by a markdown component Insert wrap the component so that it can navigate to the affected table ListPlain wrap the component so that it can use the browser history object to navigate programmatically OpenCloseAll wrap the component so that it can use the browser history object to navigate programmatically Static make static links to components of the app SubApp make routes to components of the app Server \u00b6 At the server there are other rules that link URLs to behaviour. Here are a few rules that capture how routing works in a Single Page App (SPA) like the DARIAH app, as visualized by the diagram above. Fall-back behaviour The server responds to any URL with sending the index page, which also causes the bundled app in dist to load. The server's rules are very simple: no matter what the URL, respond with the whole app. The response is static, it is always the same. The client has to figure out what component(s) of the app to show and where, based on the details of the URL. This behaviour is needed to cater for the case that the user hits the browser's refresh button. At that moment, the current URL might be a deep path, and we cannot expect the server to know those paths. The best the server can do is to send the whole app again. Special behaviour There are a few special patterns, though: Static files If the URL points to a static file, i.e. a file under /static/ , the server will respond with the file contents. Otherwise there was no way to serve the static JavaScript app in the first place. Api requests If the URL points to /api/ , the server will respond in a variety of ways, depending on the rest of the URL. By means of these /api/ URLs the client can ask for additional data services, from file system or database. The server side routing in index.py maps these URLs to specific controllers that fetch and assemble the requested data. Not only the client app can access this api , you can too.","title":"Routing"},{"location":"Concepts/Routing/#routing","text":"Routing is the task to map urls to functions of the app. It requires logic at the client side and at the server side.","title":"Routing"},{"location":"Concepts/Routing/#client","text":"For this we use the React Router . Entry point At the client side, the app starts in main . The first priority is to create a Redux Provider component, which will be ancestor to all other components. Routing The second priority is to set up the routes configuration, i.e. the way URLs give rise to activating certain components. In previous versions of React-Router this tended to be done inside one or two components, but in the current version it is better done by calling Route components from the components that need it, i.e. a more distributed approach. These are the components that use functionality of the router: component task main use a router based on the HTML5 history API App navigate to /login , /logout etc DocMd navigate to parts of the app from within documents rendered by a markdown component Insert wrap the component so that it can navigate to the affected table ListPlain wrap the component so that it can use the browser history object to navigate programmatically OpenCloseAll wrap the component so that it can use the browser history object to navigate programmatically Static make static links to components of the app SubApp make routes to components of the app","title":"Client"},{"location":"Concepts/Routing/#server","text":"At the server there are other rules that link URLs to behaviour. Here are a few rules that capture how routing works in a Single Page App (SPA) like the DARIAH app, as visualized by the diagram above. Fall-back behaviour The server responds to any URL with sending the index page, which also causes the bundled app in dist to load. The server's rules are very simple: no matter what the URL, respond with the whole app. The response is static, it is always the same. The client has to figure out what component(s) of the app to show and where, based on the details of the URL. This behaviour is needed to cater for the case that the user hits the browser's refresh button. At that moment, the current URL might be a deep path, and we cannot expect the server to know those paths. The best the server can do is to send the whole app again. Special behaviour There are a few special patterns, though: Static files If the URL points to a static file, i.e. a file under /static/ , the server will respond with the file contents. Otherwise there was no way to serve the static JavaScript app in the first place. Api requests If the URL points to /api/ , the server will respond in a variety of ways, depending on the rest of the URL. By means of these /api/ URLs the client can ask for additional data services, from file system or database. The server side routing in index.py maps these URLs to specific controllers that fetch and assemble the requested data. Not only the client app can access this api , you can too.","title":"Server"},{"location":"Functionality/Business/","text":"Business Logic \u00b6 Here we document the functionality of the app from the perspective of the users and stakeholders. We focus on the scenarios that are supported. Status of implementation The DARIAH contribution tool is a big experiment in accounting for research releated output of institutions that cooperate in a European Research Infrastructure with limited funding. The development of this tool so far has been a significant amount of work, in a landscape that has been changing in several respects: the underlying goals and expectations the business logic that is needed the technology on which all is based It is likely that further developments will lead to simpler goals, easier business logic, and a simpler implementation. That is why we do not implement all of the initial specs. Some of the not-implemented items we mark with: (\u2717) a single \u2717: but expected to be implemented at some point in the future. (\u2717\u2717) a double \u2717: unsure if it will ever be be impemented. Business content \u00b6 All information regarding the assessment and review of contributions, is in so-called back-office tables: packages , criteria , types . Source of business rules The business tables have been compiled under guidance of the HaS project by Lisa de Leeuw. Dirk Roorda has entered them into a big back office configuration file which will be read by an import script and transported into the MongoDB database. Contributions \u00b6 A contribution is a piece of work in Digital Humanities, delivered by a person or institute, and potentially relevant to the European DARIAH research infrastructure. Selection by National Coordinators The National Coordinators of DARIAH may add such a contribution to their agreed budget of in-kind contributions to DARIAH as a whole. This makes it necessary to assess contributions against a set of well-defined criteria. Assessment scenario \u00b6 Contributions may represent diverse efforts such as consultancy, workshops, software development, and hosting services. Diversification and time dependency This asks for a diversification of contribution types and associated criteria. The assessor of a contribution (from now on called applicant ) needs to state how that contribution scores for each relevant criterion, and for each score, evidence must be given. Moreover, types and criteria may change over time, but during an assessment and review cycle they should be fixed. Packages, types, criteria Contribution types and their associated assessment criteria are represented by a package record. What is a package? A package is a fixed constellation of types and criteria; it defines a set of contribution types, and a set of criteria, and a mapping between criteria and types. Every criterion is linked to a number of contribution types, meaning that the criterion is relevant to contributions of those types and no others. Every criterion is associated with exactly one package, hence the package ultimately determines the mapping between types and criteria. Active packages At any point in time there are one or more active packages, usually just one. Validity interval A package has a validity interval, i.e. a start date and an end date. A package is active at a point in time, if that point in time is inside the validity interval. The types of an active package are the active types, and its criteria are the active criteria. Technically, more than one package can be valid at the same time. In that case, the sets of active types and criteria are the union of the sets of types and criteria for each active package. But the intention is that there is always exactly one active package. Workflow looks at active packages Other components may call workflow functions in order to determine what the active packages, types and criteria are, so they can render inactive and active ones in different ways. Moreover, workflow will prevent certain actions for inactive items. Inactive contribution type Contributions with an inactive type cannot be assessed. If there are already assessments of such a contribution in the system, they will remain in the system, but workflow will mark them as stalled , and they can no longer be edited. In order to assess such a contribution, you have to change its type to an active contribution type. Rationale Time dependent packages of types and criteria allow evolution of insights. If the current classification of contributions into types appears to have shortcomings, it is possible to remedy the types. Also, criteria can be tweaked and rewritten. Evolution of packages If the current package has trivial mistakes, e.g. in wording or spelling, you can modify its criteria and type records. However, the best way to change a package for significant changes is by creating a new package, and associate new types and criteria to it, leaving the current package unchanged. Then set the validity interval to a suitable value. You can let the old and new package overlap for testing purposes. During that interval, the old and new types and criteria are valid. After that, you can terminate the old package by adjusting its validity interval. Assessments \u00b6 Applicants with write-access to a contribution can add a self-assessment to a contribution. A self assessment is a record in the assessment table, and consists of a few metadata fields. Criteria and criteria entry records When an assessment record is created, additional detail records will be created as well. These are criteriaEntry records. For each assessment, there is a fixed set of criteriaEntry records. This set is determined by the currently active set of criteria: one criteriaEntry record will be created per active criterion. A criteriaEntry record has a field for choosing a score and a text field for entering the evidence. Scores are defined in yet another type of record. Assessment scoring \u00b6 Score records The scores for a criterion are entered in with the help of score records, which are detail records of criteria. Scores have a number, typically 0 , 2 , 4 , and a short description, typically None , Partial , Full , but the number and nature of scores may vary freely between criteria. The score of an assessment as a whole is the sum of the individual scores expressed as percentage of the total amount of points that can be assigned. A temporary overall score is obtained by treating unfilled scores as having value 0 . Non applicable scores Some criteria may allow scores with a value -1 (non-applicable). If an assessment assigns that score to a criterion, 0 points are added, but points missed from this criterion will be subtracted from the total score, so that this criterion will not be counted in the average. Example Suppose there are four criteria, A, B, C, D. A, B, and C have scores 0 , 2 , and 4 . D has scores -1 , 0 , 2 , 4 . Now there are two contributions U and V, with scores as follows: Criterion contrib U contrib V A 4 4 B 4 4 C 4 4 D -1 0 sum 12 12 total 12 16 score 100% 75% See how U does better than V although they have an equal number of points. But for U criterion D does not count, while for V it counts, but the score is 0. Note Not all criteria will allow -1 values! Review scenario \u00b6 After a contributor has filled out an assessment, (s)he can submit it for review. The office will select two reviewers, and they will get access to the self-assessment. Upon asking for review, the assessment and the contribution will be locked. Reviewer roles The two reviewers have distinct roles: reviewer 1 (expert) inspects the assessment closely and advises a decision; reviewer 2(final say) makes the decision. (\u2717\u2717) Both reviewers can enter comments in a comment stream, which are detail records of the assessment. The advice/decision that can be made by the reviewers is approve End of review process with positive outcome. The assessment will remain locked. The assessment score will be made public. reject End of review process with negative outcome. The assessment will remain locked. No assessment score will be made public. (\u2717\u2717) The applicant may enter an objection. In that case the back office will ask a second opinion and take appropriate action, which might lead to a change of decision, e.g. towards revise , or to a new review by other reviewers. revise The assessment and contribution will be unlocked, and the applicant can modify both of them in response to comments by the reviewers. When (s)he is finished, the applicant can resubmit the modified version. Selection scenario \u00b6 The National Coordinator of a country can select contributions from his/her country as in-kind contribution of his country to DARIAH for a specific year. Selection may overrule Ideally, only contributions that have been well-reviewed will be selected. But the app also supports the selection of contributions in whatever stage of the assessment/review process. Selection states The national coordinator can select or deselect a contribution. Deselect means: explicitly reject . (S)he can also refrain from making a decision. As a consequence, there are three possible selection states for a contribution: selected deselected undecided Selection interface The contribution record has a button for selecting it. Only NCs and backoffice people can see/use it. There is also an overview page for contributions which show the selected state of them. NCs can use this overview to (de)select the contributions of their country. Revoking selection decisions Once a NC makes a selection decision, (s)he cannot revoke it. As a last resort, a backoffice member can undo a decision, after which the NC gets a new chance to decide. Selection workflow There are no preconditions for selecting a contribution other than that a contribution is not already selected or deselected. After (de)selection, a contribution gets the workflow attribute frozen , which prevents all modifications of that contribution, except changing its selected field (only by backoffice personnel). Also, all its assessments and reviews, including their criteria entry records and review entry records get frozen . Moreover, the contribution will be consolidated, displayable on the interface, (\u2717) and a pdf report can be generated from the consolidated record on demand. Consolidation \u00b6 A consolidated contribution record contains the information of the contribution, its assessments (if any), and its reviews (if any). What is consolidated? It means that all links to related records have been replaced by the concrete values found in those records at that time. Consolidated records do not contain fields that point to other records, only concrete text/number/datetime values. Storage Consolidated contributions are stored in the database as complex documents in the contrib_consolidated collection. The image below shows how this tree ends up in the client, on the application state. It is shown by the console of the web page, in development mode. PDF generation It is not completely trivial to distil a nice, well-readable document out of this. What we need is a consolidation template , that grabs the relevant data from this mini-database. From that template, we can produce first HTML and then PDF. Rather than a single template, we should make templates for each of the tables involved. (\u2717) PDF reports based on consolidated records can be generated on the fly but will not be stored. Consolidated contributions can be shown on the interface, by means of a very basic function that wraps it into HTML. From there they can be saved as PDF if the user exports the webpage to PDF, using browser funnctionality. (\u2717) There should be a button that calls a HTMP2PDF converter and downloads the result to the user. Selection of contribs in unfinished scenarios Selection may take place even if assessments and reviews have not been completed. After selection, no work on self-assessments and no review work can take place anymore. Consolidation will grab the information in assessments and reviews as they have proceeded so far, without attempting to complete that information in any way. Trails \u00b6 After an assessment/review/selection process, the system contains a trail of all that has gone on in the following form: live contribution The contribution record is still in place, frozen, and contains the actual situation live assessment The assessment record is still in place, frozen. (\u2717\u2717) comments trail (\u2717\u2717) live comments trail (\u2717\u2717) by reviewers: comments and suggestions for modification (\u2717\u2717) by the applicant: to state an objection consolidated contribution A snapshot of the contribution, assessments and reviews at the moment of (de)selection. Management information \u00b6 The app compiles management information of a statistical nature, both to the public and authenticated users. Access rights The quantity of information given is dependent on user rights. The public can see contributions, but not assessments and reviews, except the ones that are finalized with outcome \"accept\". In those cases, the assessment score is also visible. National coordinators NCs can (se)select contributions from this overview, but only the ones that belong to the country for which they are national coordinator. Left-overs \u00b6 (\u2717\u2717) Email notification It might be handy to send emails to users involved in assessing and reviewing to notify them that a key event has occurred, such as the submission of an assessment, the appointment of reviewers, the decisions by reviewers. Currently, the app does not send mail. password mail Users are able to request a password reset, and will get a mail with a password link. These emails are not sent by the app, but by the DARIAH Authentication Infrastructure. (\u2717\u2717) Concurrent access When multiple users work on the same item, or one user works on the same item in multiple browsers/browser windows/browser tabs, save conflicts may occur. These save conflicts are not handled graciously. The last saver wins. This problem is hard to solve, but it can be mitigated. One way of mitigation is already in the app: whenever a user leaves a field (s)he has been editing, it will be saved to the database. However, in those cases the whole record will be saved, which may lead to more data loss than is strictly necessary. A data loss scenario A user opens a browser tab to edit a contribution record, with the aim to add a keyword. The contribution has no description yet. Before assigning the label, the same user opens the same contribution in another tab and starts writing a lengthy description, and saves it. Then (s)he returns to the first tab and assigns a keyword. Upon saving, the whole record will be saved, including the description, which is still empty. This will overwrite the description saved in the second tab, a moment before. Push notifications An other problem is that important actions such as submission or selection maybe triggered from one tab, without other tabs being aware of that. In such cases, it would be desirable to send push notifications to all browsers that have that record open so that the user can refresh the page. I know it can be done ( socket , python-socket ) but it requires a bit of research to find the best way to do it. Alternatives \u00b6 This app has become super flexible, but also super complicated. Consider to call it a day We strongly advice to not develop this app further, but to simplify the requirements and to reimplement the app, if needed. Also, think again whether the whole assessment/review process is best served by an app that codes all details of the business logic. It could be that other approaches serve the goals equally well and prove far more effective. GitHub as contribution tool Define a document format for contribution metadata and for outcomes of the review and selection proces. Add a contribution metadata document to the GitHub repository of a contribution. Use GitHub issues for assessing, reviewing and selecting contributions, and store the outcomes in a document in the same repository. Use the GitHub API to query repositories that contain contributions and obtain their status. Even if contributions that are not stored in GitHub repositories, it is very easy to create a repo for them. For long term preservation, rely on generic services such as Zenodo and the Software Heritage Archive . See also the Lessons .","title":"Business"},{"location":"Functionality/Business/#business-logic","text":"Here we document the functionality of the app from the perspective of the users and stakeholders. We focus on the scenarios that are supported. Status of implementation The DARIAH contribution tool is a big experiment in accounting for research releated output of institutions that cooperate in a European Research Infrastructure with limited funding. The development of this tool so far has been a significant amount of work, in a landscape that has been changing in several respects: the underlying goals and expectations the business logic that is needed the technology on which all is based It is likely that further developments will lead to simpler goals, easier business logic, and a simpler implementation. That is why we do not implement all of the initial specs. Some of the not-implemented items we mark with: (\u2717) a single \u2717: but expected to be implemented at some point in the future. (\u2717\u2717) a double \u2717: unsure if it will ever be be impemented.","title":"Business Logic"},{"location":"Functionality/Business/#business-content","text":"All information regarding the assessment and review of contributions, is in so-called back-office tables: packages , criteria , types . Source of business rules The business tables have been compiled under guidance of the HaS project by Lisa de Leeuw. Dirk Roorda has entered them into a big back office configuration file which will be read by an import script and transported into the MongoDB database.","title":"Business content"},{"location":"Functionality/Business/#contributions","text":"A contribution is a piece of work in Digital Humanities, delivered by a person or institute, and potentially relevant to the European DARIAH research infrastructure. Selection by National Coordinators The National Coordinators of DARIAH may add such a contribution to their agreed budget of in-kind contributions to DARIAH as a whole. This makes it necessary to assess contributions against a set of well-defined criteria.","title":"Contributions"},{"location":"Functionality/Business/#assessment-scenario","text":"Contributions may represent diverse efforts such as consultancy, workshops, software development, and hosting services. Diversification and time dependency This asks for a diversification of contribution types and associated criteria. The assessor of a contribution (from now on called applicant ) needs to state how that contribution scores for each relevant criterion, and for each score, evidence must be given. Moreover, types and criteria may change over time, but during an assessment and review cycle they should be fixed. Packages, types, criteria Contribution types and their associated assessment criteria are represented by a package record. What is a package? A package is a fixed constellation of types and criteria; it defines a set of contribution types, and a set of criteria, and a mapping between criteria and types. Every criterion is linked to a number of contribution types, meaning that the criterion is relevant to contributions of those types and no others. Every criterion is associated with exactly one package, hence the package ultimately determines the mapping between types and criteria. Active packages At any point in time there are one or more active packages, usually just one. Validity interval A package has a validity interval, i.e. a start date and an end date. A package is active at a point in time, if that point in time is inside the validity interval. The types of an active package are the active types, and its criteria are the active criteria. Technically, more than one package can be valid at the same time. In that case, the sets of active types and criteria are the union of the sets of types and criteria for each active package. But the intention is that there is always exactly one active package. Workflow looks at active packages Other components may call workflow functions in order to determine what the active packages, types and criteria are, so they can render inactive and active ones in different ways. Moreover, workflow will prevent certain actions for inactive items. Inactive contribution type Contributions with an inactive type cannot be assessed. If there are already assessments of such a contribution in the system, they will remain in the system, but workflow will mark them as stalled , and they can no longer be edited. In order to assess such a contribution, you have to change its type to an active contribution type. Rationale Time dependent packages of types and criteria allow evolution of insights. If the current classification of contributions into types appears to have shortcomings, it is possible to remedy the types. Also, criteria can be tweaked and rewritten. Evolution of packages If the current package has trivial mistakes, e.g. in wording or spelling, you can modify its criteria and type records. However, the best way to change a package for significant changes is by creating a new package, and associate new types and criteria to it, leaving the current package unchanged. Then set the validity interval to a suitable value. You can let the old and new package overlap for testing purposes. During that interval, the old and new types and criteria are valid. After that, you can terminate the old package by adjusting its validity interval.","title":"Assessment scenario"},{"location":"Functionality/Business/#assessments","text":"Applicants with write-access to a contribution can add a self-assessment to a contribution. A self assessment is a record in the assessment table, and consists of a few metadata fields. Criteria and criteria entry records When an assessment record is created, additional detail records will be created as well. These are criteriaEntry records. For each assessment, there is a fixed set of criteriaEntry records. This set is determined by the currently active set of criteria: one criteriaEntry record will be created per active criterion. A criteriaEntry record has a field for choosing a score and a text field for entering the evidence. Scores are defined in yet another type of record.","title":"Assessments"},{"location":"Functionality/Business/#assessment-scoring","text":"Score records The scores for a criterion are entered in with the help of score records, which are detail records of criteria. Scores have a number, typically 0 , 2 , 4 , and a short description, typically None , Partial , Full , but the number and nature of scores may vary freely between criteria. The score of an assessment as a whole is the sum of the individual scores expressed as percentage of the total amount of points that can be assigned. A temporary overall score is obtained by treating unfilled scores as having value 0 . Non applicable scores Some criteria may allow scores with a value -1 (non-applicable). If an assessment assigns that score to a criterion, 0 points are added, but points missed from this criterion will be subtracted from the total score, so that this criterion will not be counted in the average. Example Suppose there are four criteria, A, B, C, D. A, B, and C have scores 0 , 2 , and 4 . D has scores -1 , 0 , 2 , 4 . Now there are two contributions U and V, with scores as follows: Criterion contrib U contrib V A 4 4 B 4 4 C 4 4 D -1 0 sum 12 12 total 12 16 score 100% 75% See how U does better than V although they have an equal number of points. But for U criterion D does not count, while for V it counts, but the score is 0. Note Not all criteria will allow -1 values!","title":"Assessment scoring"},{"location":"Functionality/Business/#review-scenario","text":"After a contributor has filled out an assessment, (s)he can submit it for review. The office will select two reviewers, and they will get access to the self-assessment. Upon asking for review, the assessment and the contribution will be locked. Reviewer roles The two reviewers have distinct roles: reviewer 1 (expert) inspects the assessment closely and advises a decision; reviewer 2(final say) makes the decision. (\u2717\u2717) Both reviewers can enter comments in a comment stream, which are detail records of the assessment. The advice/decision that can be made by the reviewers is approve End of review process with positive outcome. The assessment will remain locked. The assessment score will be made public. reject End of review process with negative outcome. The assessment will remain locked. No assessment score will be made public. (\u2717\u2717) The applicant may enter an objection. In that case the back office will ask a second opinion and take appropriate action, which might lead to a change of decision, e.g. towards revise , or to a new review by other reviewers. revise The assessment and contribution will be unlocked, and the applicant can modify both of them in response to comments by the reviewers. When (s)he is finished, the applicant can resubmit the modified version.","title":"Review scenario"},{"location":"Functionality/Business/#selection-scenario","text":"The National Coordinator of a country can select contributions from his/her country as in-kind contribution of his country to DARIAH for a specific year. Selection may overrule Ideally, only contributions that have been well-reviewed will be selected. But the app also supports the selection of contributions in whatever stage of the assessment/review process. Selection states The national coordinator can select or deselect a contribution. Deselect means: explicitly reject . (S)he can also refrain from making a decision. As a consequence, there are three possible selection states for a contribution: selected deselected undecided Selection interface The contribution record has a button for selecting it. Only NCs and backoffice people can see/use it. There is also an overview page for contributions which show the selected state of them. NCs can use this overview to (de)select the contributions of their country. Revoking selection decisions Once a NC makes a selection decision, (s)he cannot revoke it. As a last resort, a backoffice member can undo a decision, after which the NC gets a new chance to decide. Selection workflow There are no preconditions for selecting a contribution other than that a contribution is not already selected or deselected. After (de)selection, a contribution gets the workflow attribute frozen , which prevents all modifications of that contribution, except changing its selected field (only by backoffice personnel). Also, all its assessments and reviews, including their criteria entry records and review entry records get frozen . Moreover, the contribution will be consolidated, displayable on the interface, (\u2717) and a pdf report can be generated from the consolidated record on demand.","title":"Selection scenario"},{"location":"Functionality/Business/#consolidation","text":"A consolidated contribution record contains the information of the contribution, its assessments (if any), and its reviews (if any). What is consolidated? It means that all links to related records have been replaced by the concrete values found in those records at that time. Consolidated records do not contain fields that point to other records, only concrete text/number/datetime values. Storage Consolidated contributions are stored in the database as complex documents in the contrib_consolidated collection. The image below shows how this tree ends up in the client, on the application state. It is shown by the console of the web page, in development mode. PDF generation It is not completely trivial to distil a nice, well-readable document out of this. What we need is a consolidation template , that grabs the relevant data from this mini-database. From that template, we can produce first HTML and then PDF. Rather than a single template, we should make templates for each of the tables involved. (\u2717) PDF reports based on consolidated records can be generated on the fly but will not be stored. Consolidated contributions can be shown on the interface, by means of a very basic function that wraps it into HTML. From there they can be saved as PDF if the user exports the webpage to PDF, using browser funnctionality. (\u2717) There should be a button that calls a HTMP2PDF converter and downloads the result to the user. Selection of contribs in unfinished scenarios Selection may take place even if assessments and reviews have not been completed. After selection, no work on self-assessments and no review work can take place anymore. Consolidation will grab the information in assessments and reviews as they have proceeded so far, without attempting to complete that information in any way.","title":"Consolidation"},{"location":"Functionality/Business/#trails","text":"After an assessment/review/selection process, the system contains a trail of all that has gone on in the following form: live contribution The contribution record is still in place, frozen, and contains the actual situation live assessment The assessment record is still in place, frozen. (\u2717\u2717) comments trail (\u2717\u2717) live comments trail (\u2717\u2717) by reviewers: comments and suggestions for modification (\u2717\u2717) by the applicant: to state an objection consolidated contribution A snapshot of the contribution, assessments and reviews at the moment of (de)selection.","title":"Trails"},{"location":"Functionality/Business/#management-information","text":"The app compiles management information of a statistical nature, both to the public and authenticated users. Access rights The quantity of information given is dependent on user rights. The public can see contributions, but not assessments and reviews, except the ones that are finalized with outcome \"accept\". In those cases, the assessment score is also visible. National coordinators NCs can (se)select contributions from this overview, but only the ones that belong to the country for which they are national coordinator.","title":"Management information"},{"location":"Functionality/Business/#left-overs","text":"(\u2717\u2717) Email notification It might be handy to send emails to users involved in assessing and reviewing to notify them that a key event has occurred, such as the submission of an assessment, the appointment of reviewers, the decisions by reviewers. Currently, the app does not send mail. password mail Users are able to request a password reset, and will get a mail with a password link. These emails are not sent by the app, but by the DARIAH Authentication Infrastructure. (\u2717\u2717) Concurrent access When multiple users work on the same item, or one user works on the same item in multiple browsers/browser windows/browser tabs, save conflicts may occur. These save conflicts are not handled graciously. The last saver wins. This problem is hard to solve, but it can be mitigated. One way of mitigation is already in the app: whenever a user leaves a field (s)he has been editing, it will be saved to the database. However, in those cases the whole record will be saved, which may lead to more data loss than is strictly necessary. A data loss scenario A user opens a browser tab to edit a contribution record, with the aim to add a keyword. The contribution has no description yet. Before assigning the label, the same user opens the same contribution in another tab and starts writing a lengthy description, and saves it. Then (s)he returns to the first tab and assigns a keyword. Upon saving, the whole record will be saved, including the description, which is still empty. This will overwrite the description saved in the second tab, a moment before. Push notifications An other problem is that important actions such as submission or selection maybe triggered from one tab, without other tabs being aware of that. In such cases, it would be desirable to send push notifications to all browsers that have that record open so that the user can refresh the page. I know it can be done ( socket , python-socket ) but it requires a bit of research to find the best way to do it.","title":"Left-overs"},{"location":"Functionality/Business/#alternatives","text":"This app has become super flexible, but also super complicated. Consider to call it a day We strongly advice to not develop this app further, but to simplify the requirements and to reimplement the app, if needed. Also, think again whether the whole assessment/review process is best served by an app that codes all details of the business logic. It could be that other approaches serve the goals equally well and prove far more effective. GitHub as contribution tool Define a document format for contribution metadata and for outcomes of the review and selection proces. Add a contribution metadata document to the GitHub repository of a contribution. Use GitHub issues for assessing, reviewing and selecting contributions, and store the outcomes in a document in the same repository. Use the GitHub API to query repositories that contain contributions and obtain their status. Even if contributions that are not stored in GitHub repositories, it is very easy to create a repo for them. For long term preservation, rely on generic services such as Zenodo and the Software Heritage Archive . See also the Lessons .","title":"Alternatives"},{"location":"Functionality/Tables/","text":"Tables with templates \u00b6 Here are the particulars of our templates. Below you find all tables for which we do have specialized templates. Consult Templates to read how the mechanism of applying templates works. Kinds of templates Each table specifies several kinds of templates, corresponding for the situations in which records must be presented. See template organization . contrib \u00b6 See contrib . data model mainAction The status of the assessment/review process is translated into big, clear panels that state whether you are prevented to edit this record and why. It also presents the assessment score (if any) of the first associated assessment (if any). Secondly, there are action buttons to (de)select this contribution, or to revoke such a decision. These buttons are only displayed if the user has rights to press them. To users without those rights, the selection status is indicated here. related Here is is defined how a contribution record should be presented as part of the presentation of an other record, in this case an assessment . A minimal amount of information is presented, but an url to the origin of the contribution is included. Furthermore, a link to the contribution record itself is included. assessment \u00b6 See assessment . data model main, mainEdit We move a number of fields from the normal record display to the action template. The idea is that we want to present the user clear workflow buttons, to perform a next step in the workflow, instead of the minute standard controls. mainAction A lot happens here, in terms of reading workflow attributes and triggering the display of workflow buttons and info panels. Assessment score In particular the current score of the assessment is presented here. The score is computed server-side by the workflow function assessmentScore . Not only the score is presented, but also its derivation. Submission It is presented whether the assessment currently counts as submitted for review, and if yes, also the date-time of the last submission. In this case there is also a button to withdraw the assessment from review. If the assessment does not count as submitted, a submit button is presented. Permissions This is not the whole truth, the presence of these action buttons is dependent on additional constraints, such as whether the current user has rights to submit, and whether the assessment is complete. It can also be the case that the assessment has been reviewed with outcome revise . In that case, the submit button changes into an Enter revisions button, and later to Submit for review (again) . Stalled If the contribution has received an other type since the creation of this assessment, this assessment will count as stalled , and cannot be used for review. In this case, the criteria of the assessment are not the criteria by which the contribution should be assessed. So the system stalls this assessment. It is doomed, it can never be submitted. Unless you decide to change back the type of the contribution. If that is not an option, the best thing to do is to copy the worthwhile material from this assessment into a fresh assessment. insert This template is used when other records, such as contrib need to present a control to add an assessment. Care must be taken whether this is the only assessment or an additional assessment. criteriaEntry \u00b6 See criteriaEntry . data model detail, detailEdit These records are meant to be shown as detail records of an assessment. As such, they are part of a big form. Each record is a row in that form in which the user can enter a score and state evidence for that score. The display of the rows is such that completed entries are clearly differentiated from incomplete ones. review \u00b6 See review . data model main, mainEdit The biggest task for review templates is to show the reviews of both reviewers side by side, and to make the review editable for the corresponding reviewer. In doing so, the app needs to know the exact stage the review process is in, to be able to temporarily lock reviews when they are considered by the final reviewer. mainAction This is responsible to present the reviewers with controls to make their decisions, and present to other users the effects of those decisions. insert This template is used when other records, such as assessment need to present a control to add a review. Care must be taken whether this is a primary or secondary review. reviewEntry \u00b6 See reviewEntry . data model detail, detailEdit These records are meant to be shown as detail records of a review. As such, they are part of a big form. Each record is a row in that form in which the user can enter review comments.","title":"Tables"},{"location":"Functionality/Tables/#tables-with-templates","text":"Here are the particulars of our templates. Below you find all tables for which we do have specialized templates. Consult Templates to read how the mechanism of applying templates works. Kinds of templates Each table specifies several kinds of templates, corresponding for the situations in which records must be presented. See template organization .","title":"Tables with templates"},{"location":"Functionality/Tables/#contrib","text":"See contrib . data model mainAction The status of the assessment/review process is translated into big, clear panels that state whether you are prevented to edit this record and why. It also presents the assessment score (if any) of the first associated assessment (if any). Secondly, there are action buttons to (de)select this contribution, or to revoke such a decision. These buttons are only displayed if the user has rights to press them. To users without those rights, the selection status is indicated here. related Here is is defined how a contribution record should be presented as part of the presentation of an other record, in this case an assessment . A minimal amount of information is presented, but an url to the origin of the contribution is included. Furthermore, a link to the contribution record itself is included.","title":"contrib"},{"location":"Functionality/Tables/#assessment","text":"See assessment . data model main, mainEdit We move a number of fields from the normal record display to the action template. The idea is that we want to present the user clear workflow buttons, to perform a next step in the workflow, instead of the minute standard controls. mainAction A lot happens here, in terms of reading workflow attributes and triggering the display of workflow buttons and info panels. Assessment score In particular the current score of the assessment is presented here. The score is computed server-side by the workflow function assessmentScore . Not only the score is presented, but also its derivation. Submission It is presented whether the assessment currently counts as submitted for review, and if yes, also the date-time of the last submission. In this case there is also a button to withdraw the assessment from review. If the assessment does not count as submitted, a submit button is presented. Permissions This is not the whole truth, the presence of these action buttons is dependent on additional constraints, such as whether the current user has rights to submit, and whether the assessment is complete. It can also be the case that the assessment has been reviewed with outcome revise . In that case, the submit button changes into an Enter revisions button, and later to Submit for review (again) . Stalled If the contribution has received an other type since the creation of this assessment, this assessment will count as stalled , and cannot be used for review. In this case, the criteria of the assessment are not the criteria by which the contribution should be assessed. So the system stalls this assessment. It is doomed, it can never be submitted. Unless you decide to change back the type of the contribution. If that is not an option, the best thing to do is to copy the worthwhile material from this assessment into a fresh assessment. insert This template is used when other records, such as contrib need to present a control to add an assessment. Care must be taken whether this is the only assessment or an additional assessment.","title":"assessment"},{"location":"Functionality/Tables/#criteriaentry","text":"See criteriaEntry . data model detail, detailEdit These records are meant to be shown as detail records of an assessment. As such, they are part of a big form. Each record is a row in that form in which the user can enter a score and state evidence for that score. The display of the rows is such that completed entries are clearly differentiated from incomplete ones.","title":"criteriaEntry"},{"location":"Functionality/Tables/#review","text":"See review . data model main, mainEdit The biggest task for review templates is to show the reviews of both reviewers side by side, and to make the review editable for the corresponding reviewer. In doing so, the app needs to know the exact stage the review process is in, to be able to temporarily lock reviews when they are considered by the final reviewer. mainAction This is responsible to present the reviewers with controls to make their decisions, and present to other users the effects of those decisions. insert This template is used when other records, such as assessment need to present a control to add a review. Care must be taken whether this is a primary or secondary review.","title":"review"},{"location":"Functionality/Tables/#reviewentry","text":"See reviewEntry . data model detail, detailEdit These records are meant to be shown as detail records of a review. As such, they are part of a big form. Each record is a row in that form in which the user can enter review comments.","title":"reviewEntry"},{"location":"Functionality/Workflow/","text":"Workflow Engine \u00b6 Description \u00b6 The workflow engine of this app is a system to handle business logic. Whereas the database consists of neutral things (fields, records, lists), the workflow engine weaves additional attributes around it, that indicate additional constraints. These additional workflow attributes are computed by the server on the fly, and then stored in a separate table in the database: workflow . From then on the following happens with the workflow attributes: they are sent to client, together with the permission information for each record the client uses the workflow info to show or hide workflow related controls, and to suppress controls that lead to actions that violate the business logic the server uses the workflow info to enforce the business logic; the server updates the workflow attributes after any insert/update/delete action. No matter how good a job the client does in supporting the business logic and prohibiting actions that violate the business logic, the server always has the last word. Every access to bits and pieces in the database is first subjected to the permissions (a lower layer) and then to the additional workflow constraints. Realization \u00b6 Workflow is realized at the server and at the client. To a large extent, its rules are specified in the data model . Client Workflow logic is predominantly used in the templates , which may include workflow buttons and info panels. The workflow attributes are handled in the Dux workflow . There are also helper functions to compute special items based on workflow information. The templates themselves are applied by functions defined in the library templates . These functions are given workflow attributes as arguments that they pass on to the templates. The heart of the workflow code is at the server, in workflow.py . Its functions are called from db.py in many places. The principal functions exported are discussed here. readWorkflow Given a record in some table, this function loads the workflow attributes for that record (if any). The attributes are loaded from the workflow table. That table has records with fields table , eId and attributes , where table and eId specify exactly which the record in question is, and attributes is a dictionary of all workflow data for that record that is currently stored. read or compute If compute=True is passed, the workflow attributes will be computed. In many cases, the workflow attributes can just be read from the workflow table. But if critical data has just been modified, the workflow information has to be recomputed. See adjustWorkflow below how it is configured which data will trigger recomputation of workflow attributes. The determination of workflow attributes is dictated by the data model , in the individual tables , under the key workflow/read . There you find a sequence of instructions by which the system can compute workflow attributes for each record in a table. All instructions specify a list of other records to inspect and a method to compute a value from the inspected records. assessment submission As an example, we show an instruction for a contribution record to inspect related values in its assessment records on the basis of which it delivers the workflow attribute locked . The contrib model specifies: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 workflow : read : - inspect : details method : hasValue linkField : contrib otherTable : assessment otherField : submitted myField : null value : true attribute : name : locked except : - selected desc : has been submitted for review Basically, this instructs the system to look at various other tables and records and fields, and if certain conditions are met the attribute locked is added to the workflow attributes. Note that part of the attribute is a description, which explains the reason why the attribute is set. The client may decide to show this reason on the user interface. Line by line: 1 inspect: details This is an instruction to look into the detail record(s) of the current record. Other possible values are: master , self , with obvious meanings. Inspecting other records below. 1 method: hasValue The name of the method by which the inspected value is taken and turned in either True or False . There is a fixed, limited supply of methods, which are hard-coded in the program, see Computing Attributes below. Not all of the following parameters need to be present for all methods, and there are more possible parameters. The list of parameters is dependent on both the inspect method and the compute method. 1 linkField: contrib This is the name of the field by which detail records point to their master. 1 otherTable: assessment This is the name of the other table (which can be the master table, the details table, or the own table, depending on the value of inspect ). 1 otherField: submitted The name of the field in the other table to look at. 1 myField: null The name of the field in the own table to look at. 1 value: true A reference value to compare the inspected value with. adjustWorkflow Whereas readWorkflow computes all relevant workflow for a given record in a given table, adjustWorkflow delivers a list of other records in other tables, that need new workflow attributes after a change in a given record, whether it be an insert, update or delete. The determination of these attributes is dictated by the data model , in the individual tables , under the key workflow/adjust . Typically, when a record gets workflow attributes based on master or detail records, these attributes must be updated on any change in the master or in one of the details. The system is not clever enough to generate these adjust rules itself. We have to do that. For this, one can specify rules that define triggerFields for sets of related records. When one of those trigger fields get changed, all specified related records will get their workflow attributes recomputed. assessment submission Let us look at the same example, but now at its adjust rule in the assessment table 1 2 3 4 5 6 7 8 adjust : - inspect : master linkField : contrib otherTable : contrib triggerFields : - assessmentType - submitted - reviewerF It says that if an assessment record is changed, some other records are affected, namely its master record in the contrib table. But not all changes in the assessment trigger adjustments, only changes in one of the triggerFields , in this case obviously the field submitted . other trigger fields The other trigger fields, assessmentType and reviewerF are mentioned because of other workflow rules that we have not mentioned here. triggers also on linkField The system adds the linkField silently to the triggerField , because if we, for whatever reason, reassigned this assessment to a different contribution, then that contribution has to know it! enforceWorkflow Finally, the server has to know the consequences of the workflow attributes for behaviour. This is dictated in the generic data model , under the key workflow/prevent/ attribute where attribute is a name such as locked or incomplete , or frozen . For each attribute there are optional constraints for the update and delete actions. 1 2 3 4 prevent : locked : delete : true update : true means that it is forbidden to delete or update a record that carries the locked attribute. relax update constraints We can relax update constraints in several ways: make an exception for some fields 1 2 3 prevent : locked : update : except means that updating is not allowed except for some fields for which has been made an exception. Where to define exception fields? The list of exceptions is defined in the workflow configuration of the table in question, e.g. 1 2 3 4 5 6 7 8 9 10 11 - inspect : self method : hasValue otherField : submitted value : true attribute : name : locked except : - submitted - reviewerE - reviewerF desc : is being reviewed In words, if an assessment has been submitted and is therefore locked, the submitted status and the reviewers can still be changed. prevent certain fields to change 1 2 3 4 prevent : locked : update : submitted : true means that any update that changes the value of the field submitted is forbidden. prevent certain fields to get a specific value Here we take a real example, under attribute stalled instead of locked : 1 2 3 4 5 prevent : stalled : update : submitted : after : true This means that any update that leads to field submitted having value true is forbidden. Explanation Here we have said that a stalled assessment cannot be submitted. Details For the sake of clarity, here is the rule that says when an assessment is stalled : 1 2 3 4 5 6 7 8 9 10 11 12 workflow : read : - inspect : master method : hasDifferent linkField : contrib otherTable : contrib otherField : typeContribution myField : assessmentType value : null workflow : stalled : true stalledReason : assessment type is different from contribution type In words: if an assessment has an assessmentType field with a different value than the contributionType field of its master contribution, then the assessment counts as stalled. manageWorkflow When the web server loads, it makes sure that correct workflow information is stored in the workflow table. It does so by dropping the existing workflow table and recomputing all workflow information from scratch. A sysadmin can also reset the workflow from within the app. Then the workflow table will be cleared (not dropped), and all workflow info will be recomputed. The WorkflowInfo component presents the previous resets since the web server was last started, and gives an overview of the recomputed workflow attributes. Inspecting other records \u00b6 Both readWorkflow and adjustWorkflow have instructions to look up related records and then apply a computing method to all those records. The target records can be specified with these instructions: self Don't look further, look at yourself. The information from which workflow attributes are to be derived, is already present in the record itself. master Look at your master record. A record can have multiple masters, so you have to specify linkField : the field in yourself that points to the master, otherTable : the table in which the master record resides. grandmaster Look at the master of your master record. You have to specify interField : the field in yourself that points to the intermediate master, interTable : the table in which the intermediate master record resides, linkField : the field in the intermediate master that points to the grandmaster, otherTable : the table in which the grandmaster record resides. details Look at your detail records. A record can have multiple kinds of details, so you have to specify otherTable : the table that holds the details, and the linkField : the field in the detail record that points to you. granddetails Look at details of your detail records. You have to specify interTable : the table that holds the intermediate details, interField : the field in the intermediate details that points to you, otherTable : the table that holds the details of the details, and the linkField : the field in the details of the details that points to the intermediate details. siblings Look at records with the same master. You have to specify linkField : the field in yourself and your siblings that points to the master otherTable : the table in which your siblings reside Computing attributes \u00b6 When the other records have been found, it is time to extract information from them, in order to put it into workflow attributes. There is a limited set of functions you can call, they are all listed in worklow.py and their names start with _compute_ . Below we name them without this prefix. In the specifications we refer to the starting record(s) as my record(s) and to the reference records as other record(s) . hasValue Takes otherField : the name of a field in an other record whose value is to be retrieved; value : a reference value. Returns {'on': True } if one of the retrieved values is equal to the reference value. assessment checks whether contribution is selected The assessment model specifies: 1 2 3 4 5 6 7 8 9 - inspect : master method : hasValue linkField : contrib otherTable : contrib otherField : selected value : true attribute : name : frozen desc : contribution has been selected by DARIAH In words: look up the selected field in a master contrib record, and if the value there is true , add the on: true setting to the frozen attribute. If the client sees this attribute, it can put a message on the interface that the assessment is frozen because its contribution has been selected. hasComplete Takes emptyFields : a list of field names in the other record to be checked for emptiness. Returns {'on': True} if all of the other records have no empty field among the emptyFields . review checks whether decision has been taken The review model specifies: 1 2 3 4 5 6 7 8 9 - inspect : self method : hasComplete emptyFields : - decision attribute : name : completed desc : 'verdict has been given' except : - decision In words: a review record inspects its own decision field to see if it is non-empty. If so, it adds the on: true setting to the completed attribute. Note that a completed.on attribute prevents updates, but that in ghis case updates to the decision are still allowed. Other parts of the workflow and the permission system determine which people can change the decision. hasInComplete Takes emptyFields : a list of field names in the other record to be checked for emptiness. Returns {'on': True, 'n': n } if one of the other records has an empty field among the emptyFields . If so, n is the number of such records. assessment checks whether some criteria have not yet been completely filled in The assessment model specifies: 1 2 3 4 5 6 7 8 9 10 - inspect : details method : hasIncomplete linkField : assessment otherTable : criteriaEntry emptyFields : - score - evidence attribute : name : incomplete desc : 'some criteria lack a score or evidence ({n}x)' In words: a review record inspects its own decision field to see if it is non-empty. If so, it adds the on: true setting to the completed attribute. Note that a completed.on attribute prevents updates, but that in ghis case updates to the decision are still allowed. Other parts of the workflow and the permission system determine which people can change the decision. hasDifferent Takes otherField : the name of a field in an other record whose value is to be retrieved; myField : the name of a field in my record whose value is to be retrieved; Returns {'on': True } if a value from an other record is different from a value from my record. ??? example \"assessment checks whether its contribution type agrees with that of its contribution\". 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 The [assessment model](https://github.com/Dans-labs/dariah/blob/master/server/models/tables/assessment.yaml) specifies: ```yaml - inspect: master method: hasDifferent linkField: contrib otherTable: contrib otherField: typeContribution myField: assessmentType attribute: name: stalled desc: assessment type is different from contribution type ``` In words: an assessment record compares its own `assessmentType` with the `typeContribution` of its contribution record. If so, it adds the `on: true` setting to the `stalled` attribute. This assessment may contain important information, but its criteria no longer match the kind of conbtribution, so the worthwhile bits of the assessment have to be entered manually in a newly created assessment based on the current `typeContribution`. getValues Takes otherFields : a list of fields in an other record whose values are to be retrieved; Returns 1 2 3 4 5 6 { 'items' : [ { 'otherField1' : value1a , 'otherField2' : value2a }, { 'otherField1' : value1b , 'otherField2' : value2b }, ... ] } where value1a and value2a are values for the other fields found in the first other record, and value1a and value2a are values for the other fields found in the second other record, and so on for all other records. assessment gathers the creators and decisions of its reviews The assessment model specifies: 1 2 3 4 5 6 7 8 9 10 - inspect : details method : getValues linkField : assessment otherTable : review otherFields : - creator - decision attribute : name : reviews desc : reviews of this same assessment In words: an assessment record looks into its associated review records and reads off their creators and decisions. assessmentScore Takes : nothing Computes the overall score of an assessment, based on its detail criteriaEntry records. Returns: A dictionary with the score details Score details overall : the overall score as percentage of points scored with respect to total of scorable points relevantScore : the sum of the scores for all criteria that have not been scored as -1 (non-applicable) relevantMax : the total of the maximum scores for all criteria that have not been scored as -1 allMax : the total of the maximum scores for all criteria relevantN : the number of criteria that have not been scored as -1 allN : the number of criteria. aId : the id of the assessment in question. See more about the computation in the business logic . contrib gathers the assessment scores of its assessments The contrib model specifies: 1 2 3 4 5 6 7 - inspect : details method : assessmentScore linkField : contrib otherTable : assessment attribute : name : score desc : assessment score In words: a contrib record looks into its associated assessment records and computes their score details and stores the resulting dictionaries in the score workflow attribute. How the score travels to the user interface The workflow engine takes care that the assessment score is computed on the server whenever there is a need to do that. The computed workflow attributes are delivered to the client whenever the client wants to render a contribution. Here is a fragment of the contribution template that reads the workflow information (look at w('score') ; w() is a function to read out workflow attributes for the record in question): 1 2 3 4 5 6 7 8 9 10 11 12 if ( approved ) { const scoreItems = ( w ( 'score' ) || emptyO ). items || emptyA const score = scoreItems . length ? scoreItems [ 0 ] : emptyO resultApproved = ( <> < ScoreBox score = { score } /> < div className = { 'label large workflow good' } > { `This contribution has been reviewed positively.` } < /div> < /> ) } If there are multiple assessments, the score is taken from the first one. If there is a score, it consists of a dictionary with relevant score quantities. They are passed as properties to the ScoreBox component, which produces a nicely rendered representation of the assessment score. Hooks \u00b6 There are a few hard coded workflow functions that perform special actions. They will be hooked in from other parts of the server code, especially data access. getActiveItems() 1 getActiveItems () task Calculates the active package, and from there the active types and criteria, given the current time. This is the backdrop for any assessment and review action. detailInsert() 1 detailInsert ( msgs , table = None , masterRecord = None ) task Hard-coded instruction to add criteriaEntry detail records after inserting an assessment record reviewEntry detail records after inserting an review record In both cases, some business logic is coded to get the right amount of details and to prefill them with sensible values, and to check for error conditions. Details It needs to deliver a dictionary of insertValues (field=value pairs) and a dictionary of detail records, keyed by detail table name. The values are lists of field=value dictionaries. Before db will proceed to insert them, the detail records will get the id of the just inserted main record. This will be used as masterId when the details get inserted. findConsolidated() 1 findConsolidated ( table , record , perm ) task Find consolidated records of the live record in table and return them as a list of records (json-like). Permissions Users that have update rights for record will see the full consolidated record, others see the metadata only. consolidateRecord() 1 consolidateRecord ( table , record , workflow , msgs ) task Hard-coded instruction to consolidate contribution records and all its detail assessment, criteriaEntry, review, and reviewEntry records. This happens only when a contribution is (de)selected by a national coordinator and/or a backoffice person. The relevant workflow attributes are taken into account and serialized. A provenance trail is added to the consolidated record: who (de)selected the contribution and the time of (de)selection and the time of consolidation. Wiring \u00b6 Let us finish with an example, to show the intricate wiring of data that is going on in the workflow system. Explanation Above we see a good deal of the workflow rules that govern contributions and their assessments and reviews, each with their detail records of criteria entries (in the self-assessment) and review entries (in the reviews). records The coloured squares are particular records in the contribution, assessment, review, etc. tables. We only mention the fields that play a role in the workflow. workflow attributes The rounded labels indicate the workflow attributes that are computed for those records. arrows The arrows show which fields are used for which workflow attributes. In fact, the arrows correspond exactly with the workflow/read and workflow/adjust instructions given in the data model . The reading of an arrow is like this: read workflow : whenever a record needs to be sent to the client, compute the indicated workflow labels, based on the information in the fields indicated by following the arrows in the opposite direction; adjust workflow : whenever a record is inserted, deleted, or updated, follow any arrow from any of its fields, and for every record at the opposite end, trigger a recomputation of its workflow, and send that to the client as part of the result op the modification action. effect of the workflow on the user interface In this way, whenever the user changes a record, not only the affected records are reported back, but also the records with updated workflow information. This will ultimately update the user interface in all relevant parts.","title":"Workflow"},{"location":"Functionality/Workflow/#workflow-engine","text":"","title":"Workflow Engine"},{"location":"Functionality/Workflow/#description","text":"The workflow engine of this app is a system to handle business logic. Whereas the database consists of neutral things (fields, records, lists), the workflow engine weaves additional attributes around it, that indicate additional constraints. These additional workflow attributes are computed by the server on the fly, and then stored in a separate table in the database: workflow . From then on the following happens with the workflow attributes: they are sent to client, together with the permission information for each record the client uses the workflow info to show or hide workflow related controls, and to suppress controls that lead to actions that violate the business logic the server uses the workflow info to enforce the business logic; the server updates the workflow attributes after any insert/update/delete action. No matter how good a job the client does in supporting the business logic and prohibiting actions that violate the business logic, the server always has the last word. Every access to bits and pieces in the database is first subjected to the permissions (a lower layer) and then to the additional workflow constraints.","title":"Description"},{"location":"Functionality/Workflow/#realization","text":"Workflow is realized at the server and at the client. To a large extent, its rules are specified in the data model . Client Workflow logic is predominantly used in the templates , which may include workflow buttons and info panels. The workflow attributes are handled in the Dux workflow . There are also helper functions to compute special items based on workflow information. The templates themselves are applied by functions defined in the library templates . These functions are given workflow attributes as arguments that they pass on to the templates. The heart of the workflow code is at the server, in workflow.py . Its functions are called from db.py in many places. The principal functions exported are discussed here. readWorkflow Given a record in some table, this function loads the workflow attributes for that record (if any). The attributes are loaded from the workflow table. That table has records with fields table , eId and attributes , where table and eId specify exactly which the record in question is, and attributes is a dictionary of all workflow data for that record that is currently stored. read or compute If compute=True is passed, the workflow attributes will be computed. In many cases, the workflow attributes can just be read from the workflow table. But if critical data has just been modified, the workflow information has to be recomputed. See adjustWorkflow below how it is configured which data will trigger recomputation of workflow attributes. The determination of workflow attributes is dictated by the data model , in the individual tables , under the key workflow/read . There you find a sequence of instructions by which the system can compute workflow attributes for each record in a table. All instructions specify a list of other records to inspect and a method to compute a value from the inspected records. assessment submission As an example, we show an instruction for a contribution record to inspect related values in its assessment records on the basis of which it delivers the workflow attribute locked . The contrib model specifies: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 workflow : read : - inspect : details method : hasValue linkField : contrib otherTable : assessment otherField : submitted myField : null value : true attribute : name : locked except : - selected desc : has been submitted for review Basically, this instructs the system to look at various other tables and records and fields, and if certain conditions are met the attribute locked is added to the workflow attributes. Note that part of the attribute is a description, which explains the reason why the attribute is set. The client may decide to show this reason on the user interface. Line by line: 1 inspect: details This is an instruction to look into the detail record(s) of the current record. Other possible values are: master , self , with obvious meanings. Inspecting other records below. 1 method: hasValue The name of the method by which the inspected value is taken and turned in either True or False . There is a fixed, limited supply of methods, which are hard-coded in the program, see Computing Attributes below. Not all of the following parameters need to be present for all methods, and there are more possible parameters. The list of parameters is dependent on both the inspect method and the compute method. 1 linkField: contrib This is the name of the field by which detail records point to their master. 1 otherTable: assessment This is the name of the other table (which can be the master table, the details table, or the own table, depending on the value of inspect ). 1 otherField: submitted The name of the field in the other table to look at. 1 myField: null The name of the field in the own table to look at. 1 value: true A reference value to compare the inspected value with. adjustWorkflow Whereas readWorkflow computes all relevant workflow for a given record in a given table, adjustWorkflow delivers a list of other records in other tables, that need new workflow attributes after a change in a given record, whether it be an insert, update or delete. The determination of these attributes is dictated by the data model , in the individual tables , under the key workflow/adjust . Typically, when a record gets workflow attributes based on master or detail records, these attributes must be updated on any change in the master or in one of the details. The system is not clever enough to generate these adjust rules itself. We have to do that. For this, one can specify rules that define triggerFields for sets of related records. When one of those trigger fields get changed, all specified related records will get their workflow attributes recomputed. assessment submission Let us look at the same example, but now at its adjust rule in the assessment table 1 2 3 4 5 6 7 8 adjust : - inspect : master linkField : contrib otherTable : contrib triggerFields : - assessmentType - submitted - reviewerF It says that if an assessment record is changed, some other records are affected, namely its master record in the contrib table. But not all changes in the assessment trigger adjustments, only changes in one of the triggerFields , in this case obviously the field submitted . other trigger fields The other trigger fields, assessmentType and reviewerF are mentioned because of other workflow rules that we have not mentioned here. triggers also on linkField The system adds the linkField silently to the triggerField , because if we, for whatever reason, reassigned this assessment to a different contribution, then that contribution has to know it! enforceWorkflow Finally, the server has to know the consequences of the workflow attributes for behaviour. This is dictated in the generic data model , under the key workflow/prevent/ attribute where attribute is a name such as locked or incomplete , or frozen . For each attribute there are optional constraints for the update and delete actions. 1 2 3 4 prevent : locked : delete : true update : true means that it is forbidden to delete or update a record that carries the locked attribute. relax update constraints We can relax update constraints in several ways: make an exception for some fields 1 2 3 prevent : locked : update : except means that updating is not allowed except for some fields for which has been made an exception. Where to define exception fields? The list of exceptions is defined in the workflow configuration of the table in question, e.g. 1 2 3 4 5 6 7 8 9 10 11 - inspect : self method : hasValue otherField : submitted value : true attribute : name : locked except : - submitted - reviewerE - reviewerF desc : is being reviewed In words, if an assessment has been submitted and is therefore locked, the submitted status and the reviewers can still be changed. prevent certain fields to change 1 2 3 4 prevent : locked : update : submitted : true means that any update that changes the value of the field submitted is forbidden. prevent certain fields to get a specific value Here we take a real example, under attribute stalled instead of locked : 1 2 3 4 5 prevent : stalled : update : submitted : after : true This means that any update that leads to field submitted having value true is forbidden. Explanation Here we have said that a stalled assessment cannot be submitted. Details For the sake of clarity, here is the rule that says when an assessment is stalled : 1 2 3 4 5 6 7 8 9 10 11 12 workflow : read : - inspect : master method : hasDifferent linkField : contrib otherTable : contrib otherField : typeContribution myField : assessmentType value : null workflow : stalled : true stalledReason : assessment type is different from contribution type In words: if an assessment has an assessmentType field with a different value than the contributionType field of its master contribution, then the assessment counts as stalled. manageWorkflow When the web server loads, it makes sure that correct workflow information is stored in the workflow table. It does so by dropping the existing workflow table and recomputing all workflow information from scratch. A sysadmin can also reset the workflow from within the app. Then the workflow table will be cleared (not dropped), and all workflow info will be recomputed. The WorkflowInfo component presents the previous resets since the web server was last started, and gives an overview of the recomputed workflow attributes.","title":"Realization"},{"location":"Functionality/Workflow/#inspecting-other-records","text":"Both readWorkflow and adjustWorkflow have instructions to look up related records and then apply a computing method to all those records. The target records can be specified with these instructions: self Don't look further, look at yourself. The information from which workflow attributes are to be derived, is already present in the record itself. master Look at your master record. A record can have multiple masters, so you have to specify linkField : the field in yourself that points to the master, otherTable : the table in which the master record resides. grandmaster Look at the master of your master record. You have to specify interField : the field in yourself that points to the intermediate master, interTable : the table in which the intermediate master record resides, linkField : the field in the intermediate master that points to the grandmaster, otherTable : the table in which the grandmaster record resides. details Look at your detail records. A record can have multiple kinds of details, so you have to specify otherTable : the table that holds the details, and the linkField : the field in the detail record that points to you. granddetails Look at details of your detail records. You have to specify interTable : the table that holds the intermediate details, interField : the field in the intermediate details that points to you, otherTable : the table that holds the details of the details, and the linkField : the field in the details of the details that points to the intermediate details. siblings Look at records with the same master. You have to specify linkField : the field in yourself and your siblings that points to the master otherTable : the table in which your siblings reside","title":"Inspecting other records"},{"location":"Functionality/Workflow/#computing-attributes","text":"When the other records have been found, it is time to extract information from them, in order to put it into workflow attributes. There is a limited set of functions you can call, they are all listed in worklow.py and their names start with _compute_ . Below we name them without this prefix. In the specifications we refer to the starting record(s) as my record(s) and to the reference records as other record(s) . hasValue Takes otherField : the name of a field in an other record whose value is to be retrieved; value : a reference value. Returns {'on': True } if one of the retrieved values is equal to the reference value. assessment checks whether contribution is selected The assessment model specifies: 1 2 3 4 5 6 7 8 9 - inspect : master method : hasValue linkField : contrib otherTable : contrib otherField : selected value : true attribute : name : frozen desc : contribution has been selected by DARIAH In words: look up the selected field in a master contrib record, and if the value there is true , add the on: true setting to the frozen attribute. If the client sees this attribute, it can put a message on the interface that the assessment is frozen because its contribution has been selected. hasComplete Takes emptyFields : a list of field names in the other record to be checked for emptiness. Returns {'on': True} if all of the other records have no empty field among the emptyFields . review checks whether decision has been taken The review model specifies: 1 2 3 4 5 6 7 8 9 - inspect : self method : hasComplete emptyFields : - decision attribute : name : completed desc : 'verdict has been given' except : - decision In words: a review record inspects its own decision field to see if it is non-empty. If so, it adds the on: true setting to the completed attribute. Note that a completed.on attribute prevents updates, but that in ghis case updates to the decision are still allowed. Other parts of the workflow and the permission system determine which people can change the decision. hasInComplete Takes emptyFields : a list of field names in the other record to be checked for emptiness. Returns {'on': True, 'n': n } if one of the other records has an empty field among the emptyFields . If so, n is the number of such records. assessment checks whether some criteria have not yet been completely filled in The assessment model specifies: 1 2 3 4 5 6 7 8 9 10 - inspect : details method : hasIncomplete linkField : assessment otherTable : criteriaEntry emptyFields : - score - evidence attribute : name : incomplete desc : 'some criteria lack a score or evidence ({n}x)' In words: a review record inspects its own decision field to see if it is non-empty. If so, it adds the on: true setting to the completed attribute. Note that a completed.on attribute prevents updates, but that in ghis case updates to the decision are still allowed. Other parts of the workflow and the permission system determine which people can change the decision. hasDifferent Takes otherField : the name of a field in an other record whose value is to be retrieved; myField : the name of a field in my record whose value is to be retrieved; Returns {'on': True } if a value from an other record is different from a value from my record. ??? example \"assessment checks whether its contribution type agrees with that of its contribution\". 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 The [assessment model](https://github.com/Dans-labs/dariah/blob/master/server/models/tables/assessment.yaml) specifies: ```yaml - inspect: master method: hasDifferent linkField: contrib otherTable: contrib otherField: typeContribution myField: assessmentType attribute: name: stalled desc: assessment type is different from contribution type ``` In words: an assessment record compares its own `assessmentType` with the `typeContribution` of its contribution record. If so, it adds the `on: true` setting to the `stalled` attribute. This assessment may contain important information, but its criteria no longer match the kind of conbtribution, so the worthwhile bits of the assessment have to be entered manually in a newly created assessment based on the current `typeContribution`. getValues Takes otherFields : a list of fields in an other record whose values are to be retrieved; Returns 1 2 3 4 5 6 { 'items' : [ { 'otherField1' : value1a , 'otherField2' : value2a }, { 'otherField1' : value1b , 'otherField2' : value2b }, ... ] } where value1a and value2a are values for the other fields found in the first other record, and value1a and value2a are values for the other fields found in the second other record, and so on for all other records. assessment gathers the creators and decisions of its reviews The assessment model specifies: 1 2 3 4 5 6 7 8 9 10 - inspect : details method : getValues linkField : assessment otherTable : review otherFields : - creator - decision attribute : name : reviews desc : reviews of this same assessment In words: an assessment record looks into its associated review records and reads off their creators and decisions. assessmentScore Takes : nothing Computes the overall score of an assessment, based on its detail criteriaEntry records. Returns: A dictionary with the score details Score details overall : the overall score as percentage of points scored with respect to total of scorable points relevantScore : the sum of the scores for all criteria that have not been scored as -1 (non-applicable) relevantMax : the total of the maximum scores for all criteria that have not been scored as -1 allMax : the total of the maximum scores for all criteria relevantN : the number of criteria that have not been scored as -1 allN : the number of criteria. aId : the id of the assessment in question. See more about the computation in the business logic . contrib gathers the assessment scores of its assessments The contrib model specifies: 1 2 3 4 5 6 7 - inspect : details method : assessmentScore linkField : contrib otherTable : assessment attribute : name : score desc : assessment score In words: a contrib record looks into its associated assessment records and computes their score details and stores the resulting dictionaries in the score workflow attribute. How the score travels to the user interface The workflow engine takes care that the assessment score is computed on the server whenever there is a need to do that. The computed workflow attributes are delivered to the client whenever the client wants to render a contribution. Here is a fragment of the contribution template that reads the workflow information (look at w('score') ; w() is a function to read out workflow attributes for the record in question): 1 2 3 4 5 6 7 8 9 10 11 12 if ( approved ) { const scoreItems = ( w ( 'score' ) || emptyO ). items || emptyA const score = scoreItems . length ? scoreItems [ 0 ] : emptyO resultApproved = ( <> < ScoreBox score = { score } /> < div className = { 'label large workflow good' } > { `This contribution has been reviewed positively.` } < /div> < /> ) } If there are multiple assessments, the score is taken from the first one. If there is a score, it consists of a dictionary with relevant score quantities. They are passed as properties to the ScoreBox component, which produces a nicely rendered representation of the assessment score.","title":"Computing attributes"},{"location":"Functionality/Workflow/#hooks","text":"There are a few hard coded workflow functions that perform special actions. They will be hooked in from other parts of the server code, especially data access. getActiveItems() 1 getActiveItems () task Calculates the active package, and from there the active types and criteria, given the current time. This is the backdrop for any assessment and review action. detailInsert() 1 detailInsert ( msgs , table = None , masterRecord = None ) task Hard-coded instruction to add criteriaEntry detail records after inserting an assessment record reviewEntry detail records after inserting an review record In both cases, some business logic is coded to get the right amount of details and to prefill them with sensible values, and to check for error conditions. Details It needs to deliver a dictionary of insertValues (field=value pairs) and a dictionary of detail records, keyed by detail table name. The values are lists of field=value dictionaries. Before db will proceed to insert them, the detail records will get the id of the just inserted main record. This will be used as masterId when the details get inserted. findConsolidated() 1 findConsolidated ( table , record , perm ) task Find consolidated records of the live record in table and return them as a list of records (json-like). Permissions Users that have update rights for record will see the full consolidated record, others see the metadata only. consolidateRecord() 1 consolidateRecord ( table , record , workflow , msgs ) task Hard-coded instruction to consolidate contribution records and all its detail assessment, criteriaEntry, review, and reviewEntry records. This happens only when a contribution is (de)selected by a national coordinator and/or a backoffice person. The relevant workflow attributes are taken into account and serialized. A provenance trail is added to the consolidated record: who (de)selected the contribution and the time of (de)selection and the time of consolidation.","title":"Hooks"},{"location":"Functionality/Workflow/#wiring","text":"Let us finish with an example, to show the intricate wiring of data that is going on in the workflow system. Explanation Above we see a good deal of the workflow rules that govern contributions and their assessments and reviews, each with their detail records of criteria entries (in the self-assessment) and review entries (in the reviews). records The coloured squares are particular records in the contribution, assessment, review, etc. tables. We only mention the fields that play a role in the workflow. workflow attributes The rounded labels indicate the workflow attributes that are computed for those records. arrows The arrows show which fields are used for which workflow attributes. In fact, the arrows correspond exactly with the workflow/read and workflow/adjust instructions given in the data model . The reading of an arrow is like this: read workflow : whenever a record needs to be sent to the client, compute the indicated workflow labels, based on the information in the fields indicated by following the arrows in the opposite direction; adjust workflow : whenever a record is inserted, deleted, or updated, follow any arrow from any of its fields, and for every record at the opposite end, trigger a recomputation of its workflow, and send that to the client as part of the result op the modification action. effect of the workflow on the user interface In this way, whenever the user changes a record, not only the affected records are reported back, but also the records with updated workflow information. This will ultimately update the user interface in all relevant parts.","title":"Wiring"},{"location":"Integration/API/","text":"API \u00b6 All API calls are structured like this: https://dariah-beta.dans.knaw.nl /api/db/ verb ? parameters Below there is a partial specification of the verbs and their parameters. Permissions Data access is controlled. You only get the data you have rights to access. If you fetch records, it depends on your access level which records and which fields are being returned. The contribution tool itself uses this API to feed itself with data. Source code In those cases where this documentation fails to give the information you need you might want to look into the source code: index.py controller.py list \u00b6 list?table= table name &complete= false or true task Get the records of the table with name table name . Details If complete=false , fetch only the titles of each record. Otherwise, fetch all fields that you are entitled to read. The result is a json object, containing sub objects for the specification of the data model of this table. The actual records are under entities , keyed by their MongoDB _id . Per entity, the fields can be found under the key values . view a table https://dariah-beta.dans.knaw.nl/api/db/list?table=contrib&complete=true view \u00b6 view?table= table name &id= mongoId task Get an individual item from the table with name table name , and identifier mongoId , having all fields you are entitled to read. view an item https://dariah-beta.dans.knaw.nl/api/db/view?table=contrib&id=5bab57edb5dbf5258908b315","title":"API"},{"location":"Integration/API/#api","text":"All API calls are structured like this: https://dariah-beta.dans.knaw.nl /api/db/ verb ? parameters Below there is a partial specification of the verbs and their parameters. Permissions Data access is controlled. You only get the data you have rights to access. If you fetch records, it depends on your access level which records and which fields are being returned. The contribution tool itself uses this API to feed itself with data. Source code In those cases where this documentation fails to give the information you need you might want to look into the source code: index.py controller.py","title":"API"},{"location":"Integration/API/#list","text":"list?table= table name &complete= false or true task Get the records of the table with name table name . Details If complete=false , fetch only the titles of each record. Otherwise, fetch all fields that you are entitled to read. The result is a json object, containing sub objects for the specification of the data model of this table. The actual records are under entities , keyed by their MongoDB _id . Per entity, the fields can be found under the key values . view a table https://dariah-beta.dans.knaw.nl/api/db/list?table=contrib&complete=true","title":"list"},{"location":"Integration/API/#view","text":"view?table= table name &id= mongoId task Get an individual item from the table with name table name , and identifier mongoId , having all fields you are entitled to read. view an item https://dariah-beta.dans.knaw.nl/api/db/view?table=contrib&id=5bab57edb5dbf5258908b315","title":"view"},{"location":"Legacy/Content/","text":"Initial Content \u00b6 There are already 800 contributions in the system. They have been collected in a FileMaker database in the past. Import legacy content We convert this content and use it for an initial filling of the contribution tool. The legacy import is automated and repeatable, even into a database that has been used in production for a while. Legacy contributions \u00b6 The legacy content for this application consists of a FileMaker database. What is in the database? In it there is a web of tables and value lists. The essential content is a contribution table containing 800 contributions. There is also a bit of assessment information. How do we get that data out? From FileMaker to XML We have exported tables and value lists as XML. This is a manual and clumsy process. XML to Mongo DB The machinery for this step is programmed in a Python script, and the configuration details are spelled out in a config . It reads the XML, extracts the field definitions from it, and reads the data from the fields in the rows. We then do the following: adapt the table and field organization; adjust the field types and the values, especially for datetime and currency; generate value tables and cross-tables; add extra information for countries, so that they can be visualized on a map; link values to existing tables; import a moderately denormalized version of the data into MongoDB. Importing and reimporting The source data model is complex, the target data model is complex, and the app as a whole must support a complex workflow. It is impossible to design everything up-front, so we need to be able to retrace our steps and redo the import. As long as the system is not in production, we can just regenerate the database whenever needed, thereby loosing all manual modifications. But there comes a time, and it has arrived now, that people want to experiment with the data. But the app is not finished yet, and maybe there are more design jumps to make. So we need an import script that can reimport the initial data without disturbing the new data. We have written mongoFromFm.py that does exactly this. From transfer to import We started out running the import script in the development situation, populating a MongoDB instance there, dumping its data, and bulk-importing that into the production instance. The problem with that is that the production system will have a different set of users than the development system. Now contributions get tied to users, so if we move over contributions without users, their creator fields will dangle. It turns out to be much better to use the import script also in the production situation. So we ship the FileMaker input for the script to the production server, and run the import there, with slightly different settings. An additional advantage is, that we replace a coarse bulk import by a much more intelligent and sensitive approach: we add the records programmatically, and we have a chance to look before we act. Requirements The task for the import script boils down to these requirements: records that have been manually modified in the target system MAY NOT be overwritten; existing relationships between records MUST be preserved. See later, under Discussion how this is achieved. Usage Production 1 python3 mongoFromFm.py production Development 1 python3 mongoFromFm.py development Extras in development mode In development mode, the following things happen: excel spreadsheets with the original FileMaker data and the resulting MongoDB data are generated; a bunch of test users is added; the ownership of some contributions is changed to the developer, for ease of testing. Discussion \u00b6 The main idea is that all records that come out of the conversion progress, are marked as pristine . Later, when a record is changed under the influence of the tool, this mark is removed. Preventing data loss All records generated by this program will have a field isPristine , set to true . The DARIAH contribution tool will remove this field from a record after it has modified it. This import tool does not delete databases, nor collections, only individual documents. Before import, an inspection is made: the ids of the existing records are retrieved. The ids will be classified: pristine , non-pristine , troublesome . Troublesome means: not pristine, and occurring in the records to be imported. The following will happen: Existing pristine records will be deleted. The import records will be filtered: the ones with troublesome ids will be left out. The filtered import records will be inserted. This guarantees that there is no data loss: no records that have been touched by the application are deleted nor overwritten. Maintaining existing relationships The mongoId creation happens deterministically, with fixed identifiers, generated on the basis of the table name and the record number ONLY. The records are generated in a deterministic order. If the import script has not changed, the results will be identical. If identical records are imported, the results will be identical. If identical records are imported repeatedly, there will be no change after the first time. If the script changes, but the number and order of records that are generated remains the same the generated ids are still the same. Relationships may still break This does not guarantee that no relationships will break. But the only case where things might go wrong are the non-pristine records. If they refer to a value table, and the value table has been reorganized, data may become corrupt. If this happens, ad-hoc remedies are needed. The script will output a clear overview with the number of non-pristine records per table. The user table All production users in the system are not pristine. So they will be untouched. No initial data refers to production users. So the legacy users are disjoint from the production users. The same holds for the test users: they live only on the test system. Nothing in the production system has any link to a test user. The import script creates some group assignments for production users. These links between group and user happen per eppn , not per id. If the receiving database has different assignments in place, they will be non-pristine, and hence will not be overwritten. The import script has stabilized over time, in the sense that it does not change the existing organization of tables, but only adds new data.","title":"Content"},{"location":"Legacy/Content/#initial-content","text":"There are already 800 contributions in the system. They have been collected in a FileMaker database in the past. Import legacy content We convert this content and use it for an initial filling of the contribution tool. The legacy import is automated and repeatable, even into a database that has been used in production for a while.","title":"Initial Content"},{"location":"Legacy/Content/#legacy-contributions","text":"The legacy content for this application consists of a FileMaker database. What is in the database? In it there is a web of tables and value lists. The essential content is a contribution table containing 800 contributions. There is also a bit of assessment information. How do we get that data out? From FileMaker to XML We have exported tables and value lists as XML. This is a manual and clumsy process. XML to Mongo DB The machinery for this step is programmed in a Python script, and the configuration details are spelled out in a config . It reads the XML, extracts the field definitions from it, and reads the data from the fields in the rows. We then do the following: adapt the table and field organization; adjust the field types and the values, especially for datetime and currency; generate value tables and cross-tables; add extra information for countries, so that they can be visualized on a map; link values to existing tables; import a moderately denormalized version of the data into MongoDB. Importing and reimporting The source data model is complex, the target data model is complex, and the app as a whole must support a complex workflow. It is impossible to design everything up-front, so we need to be able to retrace our steps and redo the import. As long as the system is not in production, we can just regenerate the database whenever needed, thereby loosing all manual modifications. But there comes a time, and it has arrived now, that people want to experiment with the data. But the app is not finished yet, and maybe there are more design jumps to make. So we need an import script that can reimport the initial data without disturbing the new data. We have written mongoFromFm.py that does exactly this. From transfer to import We started out running the import script in the development situation, populating a MongoDB instance there, dumping its data, and bulk-importing that into the production instance. The problem with that is that the production system will have a different set of users than the development system. Now contributions get tied to users, so if we move over contributions without users, their creator fields will dangle. It turns out to be much better to use the import script also in the production situation. So we ship the FileMaker input for the script to the production server, and run the import there, with slightly different settings. An additional advantage is, that we replace a coarse bulk import by a much more intelligent and sensitive approach: we add the records programmatically, and we have a chance to look before we act. Requirements The task for the import script boils down to these requirements: records that have been manually modified in the target system MAY NOT be overwritten; existing relationships between records MUST be preserved. See later, under Discussion how this is achieved. Usage Production 1 python3 mongoFromFm.py production Development 1 python3 mongoFromFm.py development Extras in development mode In development mode, the following things happen: excel spreadsheets with the original FileMaker data and the resulting MongoDB data are generated; a bunch of test users is added; the ownership of some contributions is changed to the developer, for ease of testing.","title":"Legacy contributions"},{"location":"Legacy/Content/#discussion","text":"The main idea is that all records that come out of the conversion progress, are marked as pristine . Later, when a record is changed under the influence of the tool, this mark is removed. Preventing data loss All records generated by this program will have a field isPristine , set to true . The DARIAH contribution tool will remove this field from a record after it has modified it. This import tool does not delete databases, nor collections, only individual documents. Before import, an inspection is made: the ids of the existing records are retrieved. The ids will be classified: pristine , non-pristine , troublesome . Troublesome means: not pristine, and occurring in the records to be imported. The following will happen: Existing pristine records will be deleted. The import records will be filtered: the ones with troublesome ids will be left out. The filtered import records will be inserted. This guarantees that there is no data loss: no records that have been touched by the application are deleted nor overwritten. Maintaining existing relationships The mongoId creation happens deterministically, with fixed identifiers, generated on the basis of the table name and the record number ONLY. The records are generated in a deterministic order. If the import script has not changed, the results will be identical. If identical records are imported, the results will be identical. If identical records are imported repeatedly, there will be no change after the first time. If the script changes, but the number and order of records that are generated remains the same the generated ids are still the same. Relationships may still break This does not guarantee that no relationships will break. But the only case where things might go wrong are the non-pristine records. If they refer to a value table, and the value table has been reorganized, data may become corrupt. If this happens, ad-hoc remedies are needed. The script will output a clear overview with the number of non-pristine records per table. The user table All production users in the system are not pristine. So they will be untouched. No initial data refers to production users. So the legacy users are disjoint from the production users. The same holds for the test users: they live only on the test system. Nothing in the production system has any link to a test user. The import script creates some group assignments for production users. These links between group and user happen per eppn , not per id. If the receiving database has different assignments in place, they will be non-pristine, and hence will not be overwritten. The import script has stabilized over time, in the sense that it does not change the existing organization of tables, but only adds new data.","title":"Discussion"},{"location":"Maintenance/Deploy/","text":"Deployment \u00b6 Basic information \u00b6 what where source code GitHub repository https://github.com/Dans-labs/dariah tech doc GitHub Pages https://dans-labs.github.io/dariah/ tech doc source https://github.com/Dans-labs/dariah/blob/master/docs app live https://dariah-beta.dans.knaw.nl Python \u00b6 This app needs Python , version at least 3.6.3. development Install it from https://www.python.org/downloads . The list of Python dependencies to be pip -installed is in requirements.txt . A snapshot of installed modules and versions is in requirements.md . Install them like so: 1 pip3 install pymongo flask production Python can be installed by means of the package manager. 1 2 3 4 5 6 yum install rh-python36 rh-python36-python-pymongo rh-python36-mod_wsgi scl enable rh-python36 bash cp /opt/rh/httpd24/root/usr/lib64/httpd/modules/mod_rh-python36-wsgi.so modules cd /etc/httpd cp /opt/rh/httpd24/root/etc/httpd/conf.modules.d/10-rh-python36-wsgi.conf conf.modules.d/ pip install flask More info about running Python3 in the web server mod_wsgi guide . The website runs with SELinux enforced, and also the updating process works in that mode. Mongo DB \u00b6 This app works with database Mongo DB version 4.0.3 or higher. On the mac Installing 1 brew install MongoDB Upgrading 1 2 3 4 5 brew update brew upgrade MongoDB brew link --overwrite MongoDB brew services stop MongoDB brew services start MongoDB Using Daemon 1 mongod -f /usr/local/etc/mongod.conf Stop it with Ctrl + c Console 1 mongo If the DARIAH data has been loaded, say on the mongo prompt: 1 use dariah and continue with query statements inside the daria collection. In programs Via pymongo (no connection information needed). 1 pip3 install pymongo 1 2 3 4 5 6 from pymongo import MongoClient clientm = MongoClient () MONGO = clientm . dariah contributions = list ( MONGO [ 'contrib' ] . find () Web framework \u00b6 For the server application code we use Flask , a Python3 micro framework to route URLs to functions that perform requests and return responses. It contains a development web server. What the server code does The code for the server is at its heart a mapping between routes (URL patterns) and functions (request => response transformers). The app source code for the server resides in serve.py and other .py files in controllers imported by it. The module index.py defines routes and associates functions to be executed for those routes. These functions take a request, and turn it into a response. Sessions and a secret key The server needs a secret key, we store it in a fixed place. Here is the command to generate and store the key. server 1 2 cd /opt/web-apps date +%s | sha256sum | base64 | head -c 32 > dariah_jwt.secret mac 1 2 cd /opt/web-apps date +%s | shasum -a 256 | base64 | head -c 32 > dariah_jwt.secret production The production web server is httpd (Apache) . Flask connects to it through mod_wsgi (take care to use a version that speaks Python3). This connection is defined in the default config file. See default_example.conf . /etc/httpd/config.d/ default.conf (config for this site) shib.conf (config for shibboleth authentication) ... The app starts/stops when Apache starts/stops. development In development, flask runs its own little web server. You can run the development server by saying, in the top level directory of the repo clone: 1 ./build.sh serve which starts a small web server that listens to localhost on port 8001. In this case a production build of the app is served locally. For real development, it is better to work with a development server for the client as well that can hot-load modified css and javascript. Whenever you save a modified python source file, the server reloads itself. In order to follow that scenario, you should start the server as 1 ./build.sh servehot Caution This does not yet start the client site development server! Client code \u00b6 The client code is done in React using the JSX idiom. We have added Redux to the mix and various other libraries, obtained through npm . Everything is glued together by means of modern JavaScript: ES6 = ES2015 . The build tool is Webpack . Install ??? hint \"Not needed in production Installation is only needed on machines where you want to develop the client application. If you merely want to run the app, this is not needed. Install node from its download page . Then install all JavaScript dependencies in one go by executing 1 2 cd /path/to/dariah/client npm install Build Bundling The JSX and ES6 of client components and helpers will be bundled with other JavaScript sources from node_modules . The result ends up in static/dist . JavaScript for the info.html template resides in static/js and will be included directly by the main html file index.html . Build tool The build tool is webpack . We use our own build.sh to call webpack for various scenarios. You can perform builds, by saying, in the toplevel directory of the GitHub clone: production 1 ./build.sh prod development 1 ./build.sh dev hot development 1 ./build.sh hot Production provides a minified production build. Hot development starts a development server, and produces an incremental development build on every saved change in the source code, with hot-reloading of react modules. building for server and client In order to run the app on a development machine, you need three terminal tabs open: mongo 1 ./build.sh mongo runs the Mongo DB daemon. server production 1 ./build.sh serve development 1 ./build.sh serve hot development 1 ./build.sh servehot client production 1 ./build.sh prod development 1 ./build.sh dev hot development 1 ./build.sh hot Note You can run production builds and development builds on your development machine. Higher level build commands Our build script is much more capable. For example 1 ./build.sh shipcode message builds and publishes the documentation makes a production build of the client code commits the repo with commit message so that after this you can deploy on the server by means of a single call of 1 ./update.sh which pulls the changes from GitHub and restarts Apache. More build.sh commands See the code in build script for an overview of what it can do, or run 1 ./build.sh (without arguments). Cache busting When this app is being developed, and a new version is released, we want browsers to pick up the newer code, instead of serving the older javascript and css from cache. That is why new bundles always have different names. Webpack provides a bit of infrastructure to append hashes after the chunks that make up a bundle. The other thing is to pick those names up in the html template that embodies the Single Page App: index.html . You see that the links to the CSS and the Javascript are variable elements of this template. When the server starts, it may encounter two cases: No dist The /static/dist directory does not exist or is empty. That means that we are in hot development mode running under the webpack dev-server. In this case we do not use hashed names, and the server can use fixed file names for the css and js code. dist non-empty There is a non-empty /static/dist directory. It must contain a webpack generated minimal html file that includes the css and js bundles. The server extracts that info when it starts up and uses it to fill the template variables. See also readBundleNames . User authentication \u00b6 We make use of the DARIAH infrastructure for user authentication AAI (see in particular Integrating Shibboleth Authentication into your Application . Documentation \u00b6 The app itself gives access to documentation: what where live https://dans-labs.github.io/dariah/ source https://github.com/Dans-labs/dariah/blob/master/docs not only for end users, but also for developers and app-designers. The docs are generated as static GitHub pages by mkdocs with a DANS theme which has been customized from mkdocs-material . To get the DANS theme, follow the instructions in mkdocs-dans . File structure \u00b6 By GitHub clone we mean a clone of Dans-labs/dariah . The absolute location is not important. Production server For the production server we assume everything resides in /opt , on the development machine the location does not matter. On production we need in that location: shibboleth Config for the DARIAH identity provider. webapps dariah Root of the GitHub clone. dariah_jwt.secret Secret used for encrypting sessions, can be generated with gen_jwt_secret.sh Development machine On the development machine we need just the GitHub clone and dariah Root of the GitHub clone. /opt/web-apps/dariah_jwt.secret What follows is the structure of the GitHub clone. top level build.sh script for build/development tasks, the options are documented inside, or run it without arguments for help LICENSE license file (MIT) mkdocs.yml documentation config file README.md short description for humans server See server . files compile.py converts yaml model files into python modules gen_jwt_secret.sh Generate a secret for encrypting sessions index.py entry point server.py wsgi entry-point for apache config files default_example.conf example config file for Apache httpd server requirements.txt the list of python packages needed; to be installed with pip3 controllers See controllers . files auth.py handle the login process db.py JSON data from MongoDB file.py JSON data from file system info.py make overviews perm.py permission control user.py handle the user data utils.py low level utilities workflow.py workflow engine models See models . Contains yaml files defining the data model . The yaml files are source files to be compiled to python files in compiled . files model.yaml Generic settings and parameters of the data model and the permission model. compiled See compiled . files (generated) model.py Python datastructure containing the complete data model names.py Python class containing a lot of constant names tables See tables . assessment.yaml contrib.yaml country.yaml criteria.yaml criteriaEntry.yaml decision.yaml discipline.yaml keyword.yaml package.yaml permissionGroup.yaml review.yaml reviewEntry.yaml score.yaml tadirahActivity.yaml tadirahObject.yaml tadirahTechnique.yaml typeContribution.yaml user.yaml vcc.yaml year.yaml templates See templates . files info.html the html template for displaying overviews and stats index.html the html template of the single page app static See static . css See css . files font-awesome.min.css info.css Styling for the info template. leaflet-src.map leaflet.css vars.css Variable settings for the styles for the info template. images See images . For leaflet. dist See dist . JavaScript and css built from client/src . docs See docs . Specific bits of information. files about.md \"about\" text of the contribution tool criteria.docx Specification of criteria (editable in Word). criteria.pdf Specification of criteria (pdf). design.pdf notes on the design of this web app favicons See favicons . Generated set of favicons, based on the logo of the contribution tool, designed in a keynote presentation fonts See fonts . The fonts here come from FontAwesome and Leaflet. images See images . Again favicons and logos. js See js . dariah.js Scripts for the info template. jquery.js Generic toolkit, used by dariah.js tools See tools . These files are not active in the web scenarios, except for documentation. They are helpers to prepare the data for the app. files backoffice.yaml Start package in yaml format. A result from manually transferring the content in criteria.docx to yaml. config.yaml Is used in the conversion that generates initial content. dump.sh copy Filemaker legacy data to production server, as XML export load.sh run Filemaker conversion and import into MongoDB on production server mongoFromFm.py Stand-alone definitive data conversion from FileMaker original to MongoDb removeblank.py Script to remove blank documents from the Mongo Db removeblank.sh Wrapper around removeblank.py to run it on the production server. update.sh script to deploy updates of the web app. Pulls code from the github repo, restarts httpd. country_compose See country_compose . Tool to tweak a map of European countries, result in europe.geo.js files countries.ipynb Jupyter notebook to tweak the European country borders to a lower resolution and export them to json. geojson See geojson . Contains European country borders in files with geojson coordinates. client See client . files mocha-webpack.opts Option file for unit testing with mocha . package-lock.json npm config file used to record the exact javascript module configuration that is in force. package.json npm config file. webpack.common.js Config file for webpack, the build tool. Settings that are common for production and development. webpack.config-test.js Config file for webpack, the build tool. Settings that specific for testing. webpack.dev.js Config file for webpack, the build tool. Settings that specific for development. webpack.prod.js Config file for webpack, the build tool. Settings that specific for production. node_modules See node_modules . JavaScript dependencies, managed by npm . src See src . css See css . files clickables.css custom.css documents.css editing.css filtering.css grid.css main.css nav.css notification.css page.css RelSelect.css stats.css tables.css templates.css tooltip.css vars.css widgets.css workflow.css html See html . files bundle.html Template for the html file that calls the built bundle. That html file will be tweaked for the sake of cache busting of css and js files. js See js . app See app . files main.jsx client-side entry-point for the app components See components . React components in *.jsx files. files App.jsx Bool3.jsx ByValue.jsx CheckboxI.jsx Doc.jsx DocHtml.jsx DocMd.jsx DocPdf.jsx EditControl.jsx EditDelete.jsx EditHelp.jsx EditInsert.jsx EditStatus.jsx ErrorBoundary.jsx EUMap.jsx Expand.jsx Facet.jsx FieldEdit.jsx FieldRead.jsx FieldSet.jsx Filter.jsx Fulltext.jsx Input.jsx InputMulti.jsx Insert.jsx ItemAction.jsx ItemContainer.jsx ItemDetails.jsx ItemEdit.jsx ItemForm.jsx ItemRead.jsx ItemRow.jsx ListContainer.jsx ListFilter.jsx ListGrid.jsx ListPlain.jsx ListStats.jsx Login.jsx MarkdownArea.jsx NotFound.jsx Notification.jsx OpenCloseAll.jsx RelSelect.jsx Root.jsx ScoreBox.jsx Stat.jsx Static.jsx SubApp.jsx Tooltip.jsx TooltipSwitch.jsx Window.jsx WorkflowInfo.jsx dux See dux . Connectors (a.k.a. ducts/dux) between React components and the Redux state. Plain ES6. Every duct handles a specific concern of the app. All are structured with the following sections: actions , reducer , selectors , helpers . files alter.js docs.js filters.js forms.js grid.js me.js notes.js roots.js select.js server.js settings.js tables.js win.js workflow.js tables See tables . Templates (in JSX) for custom formatting some tables . files assessment.jsx contrib.jsx criteriaEntry.jsx review.jsx reviewEntry.jsx lib See lib . files datatypes.js details.js edit.js europe.geo.js fields.js handle.js memo.js templates.js utils.js values.js test See test . Test suites for mocha testing. files Not enumerated.","title":"Deploy"},{"location":"Maintenance/Deploy/#deployment","text":"","title":"Deployment"},{"location":"Maintenance/Deploy/#basic-information","text":"what where source code GitHub repository https://github.com/Dans-labs/dariah tech doc GitHub Pages https://dans-labs.github.io/dariah/ tech doc source https://github.com/Dans-labs/dariah/blob/master/docs app live https://dariah-beta.dans.knaw.nl","title":"Basic information"},{"location":"Maintenance/Deploy/#python","text":"This app needs Python , version at least 3.6.3. development Install it from https://www.python.org/downloads . The list of Python dependencies to be pip -installed is in requirements.txt . A snapshot of installed modules and versions is in requirements.md . Install them like so: 1 pip3 install pymongo flask production Python can be installed by means of the package manager. 1 2 3 4 5 6 yum install rh-python36 rh-python36-python-pymongo rh-python36-mod_wsgi scl enable rh-python36 bash cp /opt/rh/httpd24/root/usr/lib64/httpd/modules/mod_rh-python36-wsgi.so modules cd /etc/httpd cp /opt/rh/httpd24/root/etc/httpd/conf.modules.d/10-rh-python36-wsgi.conf conf.modules.d/ pip install flask More info about running Python3 in the web server mod_wsgi guide . The website runs with SELinux enforced, and also the updating process works in that mode.","title":"Python"},{"location":"Maintenance/Deploy/#mongo-db","text":"This app works with database Mongo DB version 4.0.3 or higher. On the mac Installing 1 brew install MongoDB Upgrading 1 2 3 4 5 brew update brew upgrade MongoDB brew link --overwrite MongoDB brew services stop MongoDB brew services start MongoDB Using Daemon 1 mongod -f /usr/local/etc/mongod.conf Stop it with Ctrl + c Console 1 mongo If the DARIAH data has been loaded, say on the mongo prompt: 1 use dariah and continue with query statements inside the daria collection. In programs Via pymongo (no connection information needed). 1 pip3 install pymongo 1 2 3 4 5 6 from pymongo import MongoClient clientm = MongoClient () MONGO = clientm . dariah contributions = list ( MONGO [ 'contrib' ] . find ()","title":"Mongo DB"},{"location":"Maintenance/Deploy/#web-framework","text":"For the server application code we use Flask , a Python3 micro framework to route URLs to functions that perform requests and return responses. It contains a development web server. What the server code does The code for the server is at its heart a mapping between routes (URL patterns) and functions (request => response transformers). The app source code for the server resides in serve.py and other .py files in controllers imported by it. The module index.py defines routes and associates functions to be executed for those routes. These functions take a request, and turn it into a response. Sessions and a secret key The server needs a secret key, we store it in a fixed place. Here is the command to generate and store the key. server 1 2 cd /opt/web-apps date +%s | sha256sum | base64 | head -c 32 > dariah_jwt.secret mac 1 2 cd /opt/web-apps date +%s | shasum -a 256 | base64 | head -c 32 > dariah_jwt.secret production The production web server is httpd (Apache) . Flask connects to it through mod_wsgi (take care to use a version that speaks Python3). This connection is defined in the default config file. See default_example.conf . /etc/httpd/config.d/ default.conf (config for this site) shib.conf (config for shibboleth authentication) ... The app starts/stops when Apache starts/stops. development In development, flask runs its own little web server. You can run the development server by saying, in the top level directory of the repo clone: 1 ./build.sh serve which starts a small web server that listens to localhost on port 8001. In this case a production build of the app is served locally. For real development, it is better to work with a development server for the client as well that can hot-load modified css and javascript. Whenever you save a modified python source file, the server reloads itself. In order to follow that scenario, you should start the server as 1 ./build.sh servehot Caution This does not yet start the client site development server!","title":"Web framework"},{"location":"Maintenance/Deploy/#client-code","text":"The client code is done in React using the JSX idiom. We have added Redux to the mix and various other libraries, obtained through npm . Everything is glued together by means of modern JavaScript: ES6 = ES2015 . The build tool is Webpack . Install ??? hint \"Not needed in production Installation is only needed on machines where you want to develop the client application. If you merely want to run the app, this is not needed. Install node from its download page . Then install all JavaScript dependencies in one go by executing 1 2 cd /path/to/dariah/client npm install Build Bundling The JSX and ES6 of client components and helpers will be bundled with other JavaScript sources from node_modules . The result ends up in static/dist . JavaScript for the info.html template resides in static/js and will be included directly by the main html file index.html . Build tool The build tool is webpack . We use our own build.sh to call webpack for various scenarios. You can perform builds, by saying, in the toplevel directory of the GitHub clone: production 1 ./build.sh prod development 1 ./build.sh dev hot development 1 ./build.sh hot Production provides a minified production build. Hot development starts a development server, and produces an incremental development build on every saved change in the source code, with hot-reloading of react modules. building for server and client In order to run the app on a development machine, you need three terminal tabs open: mongo 1 ./build.sh mongo runs the Mongo DB daemon. server production 1 ./build.sh serve development 1 ./build.sh serve hot development 1 ./build.sh servehot client production 1 ./build.sh prod development 1 ./build.sh dev hot development 1 ./build.sh hot Note You can run production builds and development builds on your development machine. Higher level build commands Our build script is much more capable. For example 1 ./build.sh shipcode message builds and publishes the documentation makes a production build of the client code commits the repo with commit message so that after this you can deploy on the server by means of a single call of 1 ./update.sh which pulls the changes from GitHub and restarts Apache. More build.sh commands See the code in build script for an overview of what it can do, or run 1 ./build.sh (without arguments). Cache busting When this app is being developed, and a new version is released, we want browsers to pick up the newer code, instead of serving the older javascript and css from cache. That is why new bundles always have different names. Webpack provides a bit of infrastructure to append hashes after the chunks that make up a bundle. The other thing is to pick those names up in the html template that embodies the Single Page App: index.html . You see that the links to the CSS and the Javascript are variable elements of this template. When the server starts, it may encounter two cases: No dist The /static/dist directory does not exist or is empty. That means that we are in hot development mode running under the webpack dev-server. In this case we do not use hashed names, and the server can use fixed file names for the css and js code. dist non-empty There is a non-empty /static/dist directory. It must contain a webpack generated minimal html file that includes the css and js bundles. The server extracts that info when it starts up and uses it to fill the template variables. See also readBundleNames .","title":"Client code"},{"location":"Maintenance/Deploy/#user-authentication","text":"We make use of the DARIAH infrastructure for user authentication AAI (see in particular Integrating Shibboleth Authentication into your Application .","title":"User authentication"},{"location":"Maintenance/Deploy/#documentation","text":"The app itself gives access to documentation: what where live https://dans-labs.github.io/dariah/ source https://github.com/Dans-labs/dariah/blob/master/docs not only for end users, but also for developers and app-designers. The docs are generated as static GitHub pages by mkdocs with a DANS theme which has been customized from mkdocs-material . To get the DANS theme, follow the instructions in mkdocs-dans .","title":"Documentation"},{"location":"Maintenance/Deploy/#file-structure","text":"By GitHub clone we mean a clone of Dans-labs/dariah . The absolute location is not important. Production server For the production server we assume everything resides in /opt , on the development machine the location does not matter. On production we need in that location: shibboleth Config for the DARIAH identity provider. webapps dariah Root of the GitHub clone. dariah_jwt.secret Secret used for encrypting sessions, can be generated with gen_jwt_secret.sh Development machine On the development machine we need just the GitHub clone and dariah Root of the GitHub clone. /opt/web-apps/dariah_jwt.secret What follows is the structure of the GitHub clone. top level build.sh script for build/development tasks, the options are documented inside, or run it without arguments for help LICENSE license file (MIT) mkdocs.yml documentation config file README.md short description for humans server See server . files compile.py converts yaml model files into python modules gen_jwt_secret.sh Generate a secret for encrypting sessions index.py entry point server.py wsgi entry-point for apache config files default_example.conf example config file for Apache httpd server requirements.txt the list of python packages needed; to be installed with pip3 controllers See controllers . files auth.py handle the login process db.py JSON data from MongoDB file.py JSON data from file system info.py make overviews perm.py permission control user.py handle the user data utils.py low level utilities workflow.py workflow engine models See models . Contains yaml files defining the data model . The yaml files are source files to be compiled to python files in compiled . files model.yaml Generic settings and parameters of the data model and the permission model. compiled See compiled . files (generated) model.py Python datastructure containing the complete data model names.py Python class containing a lot of constant names tables See tables . assessment.yaml contrib.yaml country.yaml criteria.yaml criteriaEntry.yaml decision.yaml discipline.yaml keyword.yaml package.yaml permissionGroup.yaml review.yaml reviewEntry.yaml score.yaml tadirahActivity.yaml tadirahObject.yaml tadirahTechnique.yaml typeContribution.yaml user.yaml vcc.yaml year.yaml templates See templates . files info.html the html template for displaying overviews and stats index.html the html template of the single page app static See static . css See css . files font-awesome.min.css info.css Styling for the info template. leaflet-src.map leaflet.css vars.css Variable settings for the styles for the info template. images See images . For leaflet. dist See dist . JavaScript and css built from client/src . docs See docs . Specific bits of information. files about.md \"about\" text of the contribution tool criteria.docx Specification of criteria (editable in Word). criteria.pdf Specification of criteria (pdf). design.pdf notes on the design of this web app favicons See favicons . Generated set of favicons, based on the logo of the contribution tool, designed in a keynote presentation fonts See fonts . The fonts here come from FontAwesome and Leaflet. images See images . Again favicons and logos. js See js . dariah.js Scripts for the info template. jquery.js Generic toolkit, used by dariah.js tools See tools . These files are not active in the web scenarios, except for documentation. They are helpers to prepare the data for the app. files backoffice.yaml Start package in yaml format. A result from manually transferring the content in criteria.docx to yaml. config.yaml Is used in the conversion that generates initial content. dump.sh copy Filemaker legacy data to production server, as XML export load.sh run Filemaker conversion and import into MongoDB on production server mongoFromFm.py Stand-alone definitive data conversion from FileMaker original to MongoDb removeblank.py Script to remove blank documents from the Mongo Db removeblank.sh Wrapper around removeblank.py to run it on the production server. update.sh script to deploy updates of the web app. Pulls code from the github repo, restarts httpd. country_compose See country_compose . Tool to tweak a map of European countries, result in europe.geo.js files countries.ipynb Jupyter notebook to tweak the European country borders to a lower resolution and export them to json. geojson See geojson . Contains European country borders in files with geojson coordinates. client See client . files mocha-webpack.opts Option file for unit testing with mocha . package-lock.json npm config file used to record the exact javascript module configuration that is in force. package.json npm config file. webpack.common.js Config file for webpack, the build tool. Settings that are common for production and development. webpack.config-test.js Config file for webpack, the build tool. Settings that specific for testing. webpack.dev.js Config file for webpack, the build tool. Settings that specific for development. webpack.prod.js Config file for webpack, the build tool. Settings that specific for production. node_modules See node_modules . JavaScript dependencies, managed by npm . src See src . css See css . files clickables.css custom.css documents.css editing.css filtering.css grid.css main.css nav.css notification.css page.css RelSelect.css stats.css tables.css templates.css tooltip.css vars.css widgets.css workflow.css html See html . files bundle.html Template for the html file that calls the built bundle. That html file will be tweaked for the sake of cache busting of css and js files. js See js . app See app . files main.jsx client-side entry-point for the app components See components . React components in *.jsx files. files App.jsx Bool3.jsx ByValue.jsx CheckboxI.jsx Doc.jsx DocHtml.jsx DocMd.jsx DocPdf.jsx EditControl.jsx EditDelete.jsx EditHelp.jsx EditInsert.jsx EditStatus.jsx ErrorBoundary.jsx EUMap.jsx Expand.jsx Facet.jsx FieldEdit.jsx FieldRead.jsx FieldSet.jsx Filter.jsx Fulltext.jsx Input.jsx InputMulti.jsx Insert.jsx ItemAction.jsx ItemContainer.jsx ItemDetails.jsx ItemEdit.jsx ItemForm.jsx ItemRead.jsx ItemRow.jsx ListContainer.jsx ListFilter.jsx ListGrid.jsx ListPlain.jsx ListStats.jsx Login.jsx MarkdownArea.jsx NotFound.jsx Notification.jsx OpenCloseAll.jsx RelSelect.jsx Root.jsx ScoreBox.jsx Stat.jsx Static.jsx SubApp.jsx Tooltip.jsx TooltipSwitch.jsx Window.jsx WorkflowInfo.jsx dux See dux . Connectors (a.k.a. ducts/dux) between React components and the Redux state. Plain ES6. Every duct handles a specific concern of the app. All are structured with the following sections: actions , reducer , selectors , helpers . files alter.js docs.js filters.js forms.js grid.js me.js notes.js roots.js select.js server.js settings.js tables.js win.js workflow.js tables See tables . Templates (in JSX) for custom formatting some tables . files assessment.jsx contrib.jsx criteriaEntry.jsx review.jsx reviewEntry.jsx lib See lib . files datatypes.js details.js edit.js europe.geo.js fields.js handle.js memo.js templates.js utils.js values.js test See test . Test suites for mocha testing. files Not enumerated.","title":"File structure"},{"location":"Maintenance/Tests/","text":"Tests \u00b6 We use Mocha for testing. Low coverage As we started building tests relatively late (not a good practice!) we do not have too many of them. In fact, I started writing them in order to keep some of the subtler algorithms of the app in check, such as merging new data into objects that should not mutate. fields \u00b6 See fields . Sorting time intervals Contains a test for the sortInterval function, which compares time intervals, including intervals that are open at either side, even at both sides. memo \u00b6 See memo . Correctness and performance of memoization Our memoize function is quite sophisticated, and is used many times in the app. So it should be tested thoroughly. There are extensive tests of the logic of the memoizer and there is a performance test which compares it to an older, unsophisticated version of it. merge \u00b6 See merge . What is the best merge strategy? Several methods for merging new data (read action data ) into an existing object (read state ) are tested. Do they create new objects even if the values have not changed? The most important test is between the two candidates lodash/merge and Immutability-Helper/update . The outcomes shows that the latter achieves a better stability: unchanged parts will not be replaced by new copies of values. genericReducer \u00b6 See genericReducer . Testing the reducers runActionTest Given an action and the description of a few state transitions, and a list of inspection instructions, with expected outcomes, this function will execute those state transitions and carry out the inspections, and check whether the expected outcomes have materialized. The inspection instructions specify a selection of the state. This part will be selected from the state before and after the transition, and then both parts will be checked for object identity. In this way you can test the effect of actions on the state in detail, and especially whether parts that you think should be unaffected, are indeed strictly identical. filtersReducer See filtersReducer . ... There are no tests here yet tablesReducer See tablesReducer . There are a fair amount of tests of the table actions. The tables slice of the state is the biggest and most complex piece of the state. There are also a fair amount of actions that operate on this slice. Together this means that there is a huge number of scenarios to be tested. After each state transition, there are two basic things to assess: Semantics the new state has the right value. If the semantics turns out to be wrong, the app will appear to act stupidly/sloppily. This is the first order error. Pragmatics the unchanged parts of the new state are still the same objects as those parts in the old state. If the pragmatics is wrong, the app will show sluggish behaviour. Long lists on the screen If you have a big list on the screen, and there are many occurrences where a new state is semantically equal, but wrapped in a fresh object, all list items will be rendered twice, or four times, or eight times, depending on the cascades of actions that are being triggered by these spurious state changes.","title":"Tests"},{"location":"Maintenance/Tests/#tests","text":"We use Mocha for testing. Low coverage As we started building tests relatively late (not a good practice!) we do not have too many of them. In fact, I started writing them in order to keep some of the subtler algorithms of the app in check, such as merging new data into objects that should not mutate.","title":"Tests"},{"location":"Maintenance/Tests/#fields","text":"See fields . Sorting time intervals Contains a test for the sortInterval function, which compares time intervals, including intervals that are open at either side, even at both sides.","title":"fields"},{"location":"Maintenance/Tests/#memo","text":"See memo . Correctness and performance of memoization Our memoize function is quite sophisticated, and is used many times in the app. So it should be tested thoroughly. There are extensive tests of the logic of the memoizer and there is a performance test which compares it to an older, unsophisticated version of it.","title":"memo"},{"location":"Maintenance/Tests/#merge","text":"See merge . What is the best merge strategy? Several methods for merging new data (read action data ) into an existing object (read state ) are tested. Do they create new objects even if the values have not changed? The most important test is between the two candidates lodash/merge and Immutability-Helper/update . The outcomes shows that the latter achieves a better stability: unchanged parts will not be replaced by new copies of values.","title":"merge"},{"location":"Maintenance/Tests/#genericreducer","text":"See genericReducer . Testing the reducers runActionTest Given an action and the description of a few state transitions, and a list of inspection instructions, with expected outcomes, this function will execute those state transitions and carry out the inspections, and check whether the expected outcomes have materialized. The inspection instructions specify a selection of the state. This part will be selected from the state before and after the transition, and then both parts will be checked for object identity. In this way you can test the effect of actions on the state in detail, and especially whether parts that you think should be unaffected, are indeed strictly identical. filtersReducer See filtersReducer . ... There are no tests here yet tablesReducer See tablesReducer . There are a fair amount of tests of the table actions. The tables slice of the state is the biggest and most complex piece of the state. There are also a fair amount of actions that operate on this slice. Together this means that there is a huge number of scenarios to be tested. After each state transition, there are two basic things to assess: Semantics the new state has the right value. If the semantics turns out to be wrong, the app will appear to act stupidly/sloppily. This is the first order error. Pragmatics the unchanged parts of the new state are still the same objects as those parts in the old state. If the pragmatics is wrong, the app will show sluggish behaviour. Long lists on the screen If you have a big list on the screen, and there are many occurrences where a new state is semantically equal, but wrapped in a fresh object, all list items will be rendered twice, or four times, or eight times, depending on the cascades of actions that are being triggered by these spurious state changes.","title":"genericReducer"},{"location":"Server/Authentication/","text":"Authentication \u00b6 Authentication on the production system is deferred to the DARIAH Identity Provider. The server performs shibboleth authentication, with credentials coming from the DARIAH Identity provider . /login /logout /slogout The login/logout actions take place at the server after visiting /login , /logout or /slogout . Logout in two stages Currently, /logout performs a logout from this app, but not from the DARIAH Identity Provider. To do the latter, one has to go to /slogout and close the browser. User records \u00b6 When users log in, the details from DARIAH identity provider will be stored in the user table. Auto update User details are stored upon every login. When the DARIAH identity provider has changed attributes of a user, these new attributes will be picked up and stored, replacing older values. So the user table updates itself automatically. These updates reach our user table only for those users that actually log in, at the moment that they do log in. Future users The system may contain records for users that have never logged in. This happens when future users of the system are assigned to field values by their email address. Whenever such a user logs in, the attributes obtained during the authentication will flow into the incomplete user record if it exists, otherwise a new user record will be made. The new user will find him/herself in all places where his/her email address had been entered. Attributes \u00b6 The systems maintains user-associated attributes from two sources: Attributes from the DARIAH identity provider user field in this app attribute provided by DARIAH comments eppn eppn a string by which the user is identified in the DARIAH context email mail the email address according to the DARIAH identity provider firstName givenName lastName sn name cn common name, probably just firstName lastName org o organization to which the user is affiliated membership isMemberOf a semicolon separated string of groups within the DARIAH organization to which the user belongs, e.g. lr_DARIAH-User , humanities-at-scale-contributors , dariah-eu-contributors rel affiliation the type of relation the user has with DARIAH, such as member@dariah.eu Ignored attributes We do not use unscoped-affiliation , which is the affiliation without the @dariah.eu part. Attributes generated by this app user field comments mayLogin whether the user is allowed to login. Default true , but the back office can use this field to prevent a user from logging in. When a user leaves, we advise to set mayLogin to true . It is not an option to delete a user, because (s)he can be the creator/modifier of records that are still in the system. authority the basis on which the identity of the user has been established. See the values below. group the permission level of this user. See the values below. dateLastLogin when the user has logged in most recently statusLastLogin whether the last login attempt was successful And, like almost all records in the system, some standard fields are added. You will not find these fields on the interface in most cases, but it is good to know that they will be recorded in the database. field comments creator the user that created this user record. The legacy user have HaSProject as creator, which is itself a user that cannot login. Other user records do not have a creator. So authenticated users cannot change their user records. dateCreated when the record was created modified a list of modification events, having the date of modification and the user who did it for each event. Display of user attributes When a user is presented on the interface, we choose between the following representations, in order of highest preference first. name , coming from the DARIAH attribute cn (common name) firstName lastName email eppn-autority We append (org) if available. Groups \u00b6 When giving users permissions, the groups they are in play an important role. The attributes authority and group contain the necessary information. authority values authority comments absent the user has never been authenticated. Used for people that occur in the system, but have not yet logged in. DARIAH the user has been logged in by the DARIAH identity provider legacy the user has been imported from the FileMaker legacy data. This kind of user cannot log in. local the user has logged in on the development system. This kind of user should not be present in the production system! group values See the permission model . statusLastLogin values statusLastLogin comments Approved successful login attempt Rejected unsuccessful login attempt","title":"Authentication"},{"location":"Server/Authentication/#authentication","text":"Authentication on the production system is deferred to the DARIAH Identity Provider. The server performs shibboleth authentication, with credentials coming from the DARIAH Identity provider . /login /logout /slogout The login/logout actions take place at the server after visiting /login , /logout or /slogout . Logout in two stages Currently, /logout performs a logout from this app, but not from the DARIAH Identity Provider. To do the latter, one has to go to /slogout and close the browser.","title":"Authentication"},{"location":"Server/Authentication/#user-records","text":"When users log in, the details from DARIAH identity provider will be stored in the user table. Auto update User details are stored upon every login. When the DARIAH identity provider has changed attributes of a user, these new attributes will be picked up and stored, replacing older values. So the user table updates itself automatically. These updates reach our user table only for those users that actually log in, at the moment that they do log in. Future users The system may contain records for users that have never logged in. This happens when future users of the system are assigned to field values by their email address. Whenever such a user logs in, the attributes obtained during the authentication will flow into the incomplete user record if it exists, otherwise a new user record will be made. The new user will find him/herself in all places where his/her email address had been entered.","title":"User records"},{"location":"Server/Authentication/#attributes","text":"The systems maintains user-associated attributes from two sources: Attributes from the DARIAH identity provider user field in this app attribute provided by DARIAH comments eppn eppn a string by which the user is identified in the DARIAH context email mail the email address according to the DARIAH identity provider firstName givenName lastName sn name cn common name, probably just firstName lastName org o organization to which the user is affiliated membership isMemberOf a semicolon separated string of groups within the DARIAH organization to which the user belongs, e.g. lr_DARIAH-User , humanities-at-scale-contributors , dariah-eu-contributors rel affiliation the type of relation the user has with DARIAH, such as member@dariah.eu Ignored attributes We do not use unscoped-affiliation , which is the affiliation without the @dariah.eu part. Attributes generated by this app user field comments mayLogin whether the user is allowed to login. Default true , but the back office can use this field to prevent a user from logging in. When a user leaves, we advise to set mayLogin to true . It is not an option to delete a user, because (s)he can be the creator/modifier of records that are still in the system. authority the basis on which the identity of the user has been established. See the values below. group the permission level of this user. See the values below. dateLastLogin when the user has logged in most recently statusLastLogin whether the last login attempt was successful And, like almost all records in the system, some standard fields are added. You will not find these fields on the interface in most cases, but it is good to know that they will be recorded in the database. field comments creator the user that created this user record. The legacy user have HaSProject as creator, which is itself a user that cannot login. Other user records do not have a creator. So authenticated users cannot change their user records. dateCreated when the record was created modified a list of modification events, having the date of modification and the user who did it for each event. Display of user attributes When a user is presented on the interface, we choose between the following representations, in order of highest preference first. name , coming from the DARIAH attribute cn (common name) firstName lastName email eppn-autority We append (org) if available.","title":"Attributes"},{"location":"Server/Authentication/#groups","text":"When giving users permissions, the groups they are in play an important role. The attributes authority and group contain the necessary information. authority values authority comments absent the user has never been authenticated. Used for people that occur in the system, but have not yet logged in. DARIAH the user has been logged in by the DARIAH identity provider legacy the user has been imported from the FileMaker legacy data. This kind of user cannot log in. local the user has logged in on the development system. This kind of user should not be present in the production system! group values See the permission model . statusLastLogin values statusLastLogin comments Approved successful login attempt Rejected unsuccessful login attempt","title":"Groups"},{"location":"Server/Server/","text":"Server \u00b6 Although this app is a single page application with most of the business logic coded at the client side, there are a bunch of things that are handled at the server side. Data access Almost all data access is handled by server side controllers that implement a data api. These controllers are informed by the data model . When the web server starts, the data model files are read, and converted to python modules with the same base name that encapsulate the information in the YAML files. These modules are then imported by all controllers, so that almost all data access happens in conformance with the data model and its permissions. Other way of data access The module info bypasses the regular data access methods, and peeks straight into the MongoDB data. perm \u00b6 See perm . Contains the methods to compute permissions for controllers, tables and fields. Here are the main methods. allow() 1 2 3 4 5 6 7 8 allow ( table , action , msgs , verbose = True , controller = None , record = None , newValues = None , my = None , ) task Given table and an action (such as read , update ), this method computes whether that action may be performed on behalf of the current web user. No workflow attributes are being used, this is a lower level operation. msgs, verbose If, during the computation of the permission, circumstances occur that must be reported, they will be appended to the list msgs . If the permission is denied, msgs will contain the reason if verbose is True . controller If given, the controller-level permissions will be looked up to see whether the controller may execute for the user at all. If not, no permission will be given and the computation stops. record If given, this is the record in the database for which the permission is computed. If a record is specified, the information in that record will be used to determine whether the record has a special relationship to the user, such as ownership , editorship , or same country and in that case the permissions tend to be more liberal. Without a record , permissions are calculated as if the user does not own any record in the table . newValues If given, this is (part of) the record that results from the action, and it will be used in the calculation of the permission. It is mainly used when one user changes the permission group of another user: we must take care that the principles of who can promote/demote and to what level are not violated. my If given, it is a list of fields. These fields will be looked up in the record , and if the user id of the current user is listed in one of them, the record counts as \"connected\" to the user. Based on the other permission settings, this may lead to permit the action, which might not be permitted if there were no such connection between record and user. returns good a boolean: True : allowed, or False : forbidden. rowFilter specifies, in case of good = True, to which rows the action may be applied. Otherwise, the rowFilter is None . If a record is passed rowFilter will be also be None , because it is not needed. Only if no record is given, a rowFilter will be computed. It has the shape of a MongoDB selection criterion (a dict), but it can also be False (no rows) or True (all rows) or None (irrelevant). If the operation is not permitted on any row, rowFilter becomes False . The reaction to this outcome should be to not perform a database lookup at all. not an error But this is not a permission error, because in this case the list of records for which the operation is allowed is empty. This is different from good is False and rowFilter is None . fieldSet specifies, in case of yes, the set of fields in those rows which may be acted upon. Otherwise, the fieldSet is None . If no fields are permitted, fieldSet is returned as set() . This will still deliver the _id fields, because _id fields are always permitted. If all or part of the fields are permitted, the set of permitted fields is returned. db \u00b6 See db . This is the data access module. It uses the data model to serve any data to any user in such a way that no data is sent from server to client that the current user is not entitled to see. ??? explanation 'Model driven\" The code in db is generic, it does not contain explicit reference to particular tables and fields. All specifics are derived form the model config file and the table specific files in tables . Workflow hooks There are also hooks , where specific behaviour for certain tables can be specified. That behaviour is coded in the workflow module . validate() 1 validate ( table , itemValues , updateFields ) task Server validation of the values of a record. itemValues The dictionary of all field values of the item. updateFields The set of fields to be updated. returns valItemValues A dictionary, keyed by field containing: valid A boolean that states whether all values are valid, diags A dictionary of diagnostic information if there are validation errors. msgs A list of error messages if the validation process itself failed. valValues A list of validated values for this field. newValues A list of new values created in related tables. getList() 1 2 3 4 5 6 7 8 9 getList ( controller , table , data , msgs , verbose = True , titleOnly = False , withValueLists = True , withDetails = True , my = False , ) task A true workhorse, that retrieves the contents of a table, in various circumstances. controller is the name of the top-level method that called this function. table is the name of the table in question. Permissions that are in force may cause a selection on the rows and a restriction on the fields that will be shown for each row. data A dictionary that holds the results. It is keyed by table name, because a single request may need to fetch data from related tables as well. msgs, verbose A list that accumulates messages incurred by fetching data and checking permissions. Will receive more messages if verbose is True . titleOnly tells whether only the titles or the full data of the records should be fetched. Again: access levels may constrain the set of returned fields further. withValueLists If true and if there are fields whose values reside in value lists, these value lists will be fetched as well, if needed. withDetails If true, the detail records as specified by the data model whose masters are in the results, will also be fetched and returned. my if True: only fetches rows that have been created by the current user. If my is a list of fields, these are ourFields . These fields contain user ids, and only records with the current user occurring in one of those fields, will be fetched. Whereas my=True is intended to fetch records that are owned or editable by the current user, my=ourFields is intended to fetch records that are connected to the current user in an other, configurable way. It only works if the data model of table , contains a section ourFields listing a number of fields. getItem() 1 getItem ( controller , table , eId ) task Fetches a single record from a table. controller is the name of the top-level method that called this function. table , eId is the name of the table in question, and eId the identifier of a record in that table. Permissions that are in force may prevent the record to be fetched or cause a restriction on the fields that will be shown. returns ??? explanation \"values\" A dictionary of the values of each field in the record. ??? explanation \"perm\" Whether the record may be updated and or deleted. ??? explanation \"fields\" A set of field names of the fields that the user may update. This is is determined solely on the basis of the permissions, the workflow attributes do not play a role. ??? explanation \"workflow\" A dictionary of all the workflow attributes associated with this record. modItem() 1 modItem ( controller , table , action ) task An other workhorse. This function can insert, update and delete a single item. New items are inserted as rows with blank fields. The information to update items is fetched from the request object. The client has sent this material to the server. workflow These operations are workflow-sensitive: before the operation, workflow attributes will be inspected in order to determine whether the action can be carried out after the operation, workflow attributes will be recomputed to reflect the changes to the data made by the operation. controller Is the name of the top-level method that called this function. table Is the name of the table in question. action A keyword insert , update or delete . request data The request data should contain the data to perform the action : insert : a dictionary of field-values for the new record; delete : a dictionary containing a pair _id: eId which specifies the record to delete; update : a modified record containing a pair _id: eId which specifies the record to delete; insert When inserting records as details of an other record, each inserted record gets the field pointing to the master filled in. The workflow hook detailInsert is called to insert certain detail records after inserting the master record. delete When deleting records, the questions arise: what if the record is used by another record as related record? Deletion would render that other record incomplete. what if the record has releated records? Should they be deleted too? If those are related to other records as well, those records could become incomplete? We deal with these questions as follows: The table model may specify that a certain kind of details should be cascade-deleted by means of the cascade key. Example The assessment model has 1 2 3 4 5 6 7 8 9 10 11 12 13 details : criteriaEntry : table : criteriaEntry linkField : assessment expand : own mode : list border : { read : false , edit : false , } filtered : true cascade : true fixed : true This means that when an assessment is deleted, all its criteria-entries will be deleted as well. Criteria entries form an integral part of an assessment, and no criteria entry record serves multiple assessments. If after cascade-deleting of detail records, there would remain undeleted detail records, then the record will not be deleted, nor any of its details. This check is carried out without deleting anything. update Before an update happens, the new values will be validated on the server. If there are errors, warnings will travel to the client, and the update does not occur. The workflow hook consolidateRecord is called to consolidate the record if some conditions are met. provenance metadata Upon each update, it will be recorded in the updated document who did the update and when. These values will be appended to the field modified in a consolidated way, i.e. the name of the updater is looked up in the related table first. Filtering update times Recording every single update may lead to very long trails in the modified field. For that reason, we filter the trail for each update. Filtering thins updates made before today. For those days, it keeps for each person that modified on that day the last modification time. user \u00b6 See user . Contains the logic needed to maintain the user table. The eppn attribute is key to identify users. It is the name by which they are identified by the DARIAH identity provider. getUser() 1 getUser ( eppn , email = None ) task Return all characteristics of this user that can be found in the system, including to what permission group the user belongs. eppn , email The eppn attribute is used as primary means to identify the user, and only if that does not yield a result, the email address is used. storeUpdate() 1 storeUpdate ( newUserInfo ): task When new users log in through the DARIAH infrastructure, the identifying attributes from the identity provider are collected by authenticate() . From there, this function stores those details in the user table. Or, if there is already an entry for this user, that entry is updated with the new information gathered. auth \u00b6 See auth . Contains the methods to authenticate users. Here all the logic about user sessions and session cookies is written down. It builds on the Flask web framework. It starts working when the server is started. Then it collects information from the environment to set up the cryptography for the sessions. And it (re)computes all workflow attributes of all records in the database from scratch. readBundleNames() 1 readBundleNames ( regime ) task This is an initialization routine which realizes cache busting of javascript and css files. It is called when the AuthApi object is initialized. Cache busting For production, the JS and CSS bundles for the browser have names with a random hash in it, so that an update of the app will trigger all clients to fetch a new version of these bundles instead of relying on their cached versions. Fiddling with the index page The server generates the HTML index page that will load these bundles, to we have to fiddle those hashes into the index template. We have set up the client build script (webpack) in such a way that the hashed file names are written to a file bundle.html in the distribution directory. regime There are several run scenarios, and inspecting the environment variable REGIME enables the server to determine the scenario it works in. Run scenarios There are three scenarios for running the DARIAH app: None production build served by a production webserver The server has not been started with the build script. Hashed file names needed. develop production build served by the local flask webserver The server has been started by the build script with argument serve . Hashed file names needed. hot develop build served by the webpack devserver The server has been started by the build script with argument servehot . Hashed file names not needed. The proper tweaking of bundle.html will take place for all these scenarios. authenticate() 1 authenticate ( login = False ) task Tries to authenticate the current user by looking up a session created by the DARIAH identity provider, and retrieving the attributes of that session. If it finds unsatisfactory attributes in the session, the session will be deleted, and the user is not authenticated. login This is only relevant on the development system. If True , the server asks for a login name on the command line, and if a valid test user is typed in, it logs that user in. On the production system, the login process takes place outside this app. Only after login this app is able to detect whether a user has logged in and if so, which user that is. deauthenticate() 1 deauthenticate () task Clears the info of the current user and if that user has been identified by the DARIAH identity provider, the corresponding session will be deleted. file \u00b6 See file . Contains the methods to get file data from the server. determineOrigin() 1 determineOrigin ( path ) You can configure origin directories for static files depending on the url path. The configuration is in file itself, in the variable origins , which is a dictionary of initial path strings mapped to an origin directory. For each request for a static file, this function is called to locate the file on the server. static() 1 static ( path ) task Reads the file identified by path on the server and sends its contents as a static file over HTTP to the client. json() 1 json ( path ) task Reads the file identified by path on the server and sends its contents, wrapped as JSON data over HTTP to the client. workflow \u00b6 See workflow . Implements the workflow engine which takes care of various aspects of the business logic, just above the level of data fetching and permissions. info \u00b6 See info . This module is reponsible for an overview of the statistics of the contributions. National coordinators and backoffice personnel can (de)select contributions from this page. Permissions It does manage access to data, and takes care that every user can access the data under the proper conditions. It will hide the sensitive fields (cost) from unauthorized users. Care is taken that NCs can only take selection decisions for contributions from their own country. Backoffice users can modify any selection decision. cons \u00b6 See cons . This module is reponsible for showing consolidated records in such a way that they can easily be saved as PDF from the browser. Permissions It does manage access to data, and takes care that every user can access the data under the proper conditions. It will show metadata only to people without update rights to the contribution. Other people are not allowed to see all fields of the contributions, and because a consolidated record contains all information of a contribution and its assessments and reviews, this is only for people that authored/edited the contribution and people in a powerful role, such as office , system , and root . utils \u00b6 See utils . Low level stuff.","title":"Server"},{"location":"Server/Server/#server","text":"Although this app is a single page application with most of the business logic coded at the client side, there are a bunch of things that are handled at the server side. Data access Almost all data access is handled by server side controllers that implement a data api. These controllers are informed by the data model . When the web server starts, the data model files are read, and converted to python modules with the same base name that encapsulate the information in the YAML files. These modules are then imported by all controllers, so that almost all data access happens in conformance with the data model and its permissions. Other way of data access The module info bypasses the regular data access methods, and peeks straight into the MongoDB data.","title":"Server"},{"location":"Server/Server/#perm","text":"See perm . Contains the methods to compute permissions for controllers, tables and fields. Here are the main methods. allow() 1 2 3 4 5 6 7 8 allow ( table , action , msgs , verbose = True , controller = None , record = None , newValues = None , my = None , ) task Given table and an action (such as read , update ), this method computes whether that action may be performed on behalf of the current web user. No workflow attributes are being used, this is a lower level operation. msgs, verbose If, during the computation of the permission, circumstances occur that must be reported, they will be appended to the list msgs . If the permission is denied, msgs will contain the reason if verbose is True . controller If given, the controller-level permissions will be looked up to see whether the controller may execute for the user at all. If not, no permission will be given and the computation stops. record If given, this is the record in the database for which the permission is computed. If a record is specified, the information in that record will be used to determine whether the record has a special relationship to the user, such as ownership , editorship , or same country and in that case the permissions tend to be more liberal. Without a record , permissions are calculated as if the user does not own any record in the table . newValues If given, this is (part of) the record that results from the action, and it will be used in the calculation of the permission. It is mainly used when one user changes the permission group of another user: we must take care that the principles of who can promote/demote and to what level are not violated. my If given, it is a list of fields. These fields will be looked up in the record , and if the user id of the current user is listed in one of them, the record counts as \"connected\" to the user. Based on the other permission settings, this may lead to permit the action, which might not be permitted if there were no such connection between record and user. returns good a boolean: True : allowed, or False : forbidden. rowFilter specifies, in case of good = True, to which rows the action may be applied. Otherwise, the rowFilter is None . If a record is passed rowFilter will be also be None , because it is not needed. Only if no record is given, a rowFilter will be computed. It has the shape of a MongoDB selection criterion (a dict), but it can also be False (no rows) or True (all rows) or None (irrelevant). If the operation is not permitted on any row, rowFilter becomes False . The reaction to this outcome should be to not perform a database lookup at all. not an error But this is not a permission error, because in this case the list of records for which the operation is allowed is empty. This is different from good is False and rowFilter is None . fieldSet specifies, in case of yes, the set of fields in those rows which may be acted upon. Otherwise, the fieldSet is None . If no fields are permitted, fieldSet is returned as set() . This will still deliver the _id fields, because _id fields are always permitted. If all or part of the fields are permitted, the set of permitted fields is returned.","title":"perm"},{"location":"Server/Server/#db","text":"See db . This is the data access module. It uses the data model to serve any data to any user in such a way that no data is sent from server to client that the current user is not entitled to see. ??? explanation 'Model driven\" The code in db is generic, it does not contain explicit reference to particular tables and fields. All specifics are derived form the model config file and the table specific files in tables . Workflow hooks There are also hooks , where specific behaviour for certain tables can be specified. That behaviour is coded in the workflow module . validate() 1 validate ( table , itemValues , updateFields ) task Server validation of the values of a record. itemValues The dictionary of all field values of the item. updateFields The set of fields to be updated. returns valItemValues A dictionary, keyed by field containing: valid A boolean that states whether all values are valid, diags A dictionary of diagnostic information if there are validation errors. msgs A list of error messages if the validation process itself failed. valValues A list of validated values for this field. newValues A list of new values created in related tables. getList() 1 2 3 4 5 6 7 8 9 getList ( controller , table , data , msgs , verbose = True , titleOnly = False , withValueLists = True , withDetails = True , my = False , ) task A true workhorse, that retrieves the contents of a table, in various circumstances. controller is the name of the top-level method that called this function. table is the name of the table in question. Permissions that are in force may cause a selection on the rows and a restriction on the fields that will be shown for each row. data A dictionary that holds the results. It is keyed by table name, because a single request may need to fetch data from related tables as well. msgs, verbose A list that accumulates messages incurred by fetching data and checking permissions. Will receive more messages if verbose is True . titleOnly tells whether only the titles or the full data of the records should be fetched. Again: access levels may constrain the set of returned fields further. withValueLists If true and if there are fields whose values reside in value lists, these value lists will be fetched as well, if needed. withDetails If true, the detail records as specified by the data model whose masters are in the results, will also be fetched and returned. my if True: only fetches rows that have been created by the current user. If my is a list of fields, these are ourFields . These fields contain user ids, and only records with the current user occurring in one of those fields, will be fetched. Whereas my=True is intended to fetch records that are owned or editable by the current user, my=ourFields is intended to fetch records that are connected to the current user in an other, configurable way. It only works if the data model of table , contains a section ourFields listing a number of fields. getItem() 1 getItem ( controller , table , eId ) task Fetches a single record from a table. controller is the name of the top-level method that called this function. table , eId is the name of the table in question, and eId the identifier of a record in that table. Permissions that are in force may prevent the record to be fetched or cause a restriction on the fields that will be shown. returns ??? explanation \"values\" A dictionary of the values of each field in the record. ??? explanation \"perm\" Whether the record may be updated and or deleted. ??? explanation \"fields\" A set of field names of the fields that the user may update. This is is determined solely on the basis of the permissions, the workflow attributes do not play a role. ??? explanation \"workflow\" A dictionary of all the workflow attributes associated with this record. modItem() 1 modItem ( controller , table , action ) task An other workhorse. This function can insert, update and delete a single item. New items are inserted as rows with blank fields. The information to update items is fetched from the request object. The client has sent this material to the server. workflow These operations are workflow-sensitive: before the operation, workflow attributes will be inspected in order to determine whether the action can be carried out after the operation, workflow attributes will be recomputed to reflect the changes to the data made by the operation. controller Is the name of the top-level method that called this function. table Is the name of the table in question. action A keyword insert , update or delete . request data The request data should contain the data to perform the action : insert : a dictionary of field-values for the new record; delete : a dictionary containing a pair _id: eId which specifies the record to delete; update : a modified record containing a pair _id: eId which specifies the record to delete; insert When inserting records as details of an other record, each inserted record gets the field pointing to the master filled in. The workflow hook detailInsert is called to insert certain detail records after inserting the master record. delete When deleting records, the questions arise: what if the record is used by another record as related record? Deletion would render that other record incomplete. what if the record has releated records? Should they be deleted too? If those are related to other records as well, those records could become incomplete? We deal with these questions as follows: The table model may specify that a certain kind of details should be cascade-deleted by means of the cascade key. Example The assessment model has 1 2 3 4 5 6 7 8 9 10 11 12 13 details : criteriaEntry : table : criteriaEntry linkField : assessment expand : own mode : list border : { read : false , edit : false , } filtered : true cascade : true fixed : true This means that when an assessment is deleted, all its criteria-entries will be deleted as well. Criteria entries form an integral part of an assessment, and no criteria entry record serves multiple assessments. If after cascade-deleting of detail records, there would remain undeleted detail records, then the record will not be deleted, nor any of its details. This check is carried out without deleting anything. update Before an update happens, the new values will be validated on the server. If there are errors, warnings will travel to the client, and the update does not occur. The workflow hook consolidateRecord is called to consolidate the record if some conditions are met. provenance metadata Upon each update, it will be recorded in the updated document who did the update and when. These values will be appended to the field modified in a consolidated way, i.e. the name of the updater is looked up in the related table first. Filtering update times Recording every single update may lead to very long trails in the modified field. For that reason, we filter the trail for each update. Filtering thins updates made before today. For those days, it keeps for each person that modified on that day the last modification time.","title":"db"},{"location":"Server/Server/#user","text":"See user . Contains the logic needed to maintain the user table. The eppn attribute is key to identify users. It is the name by which they are identified by the DARIAH identity provider. getUser() 1 getUser ( eppn , email = None ) task Return all characteristics of this user that can be found in the system, including to what permission group the user belongs. eppn , email The eppn attribute is used as primary means to identify the user, and only if that does not yield a result, the email address is used. storeUpdate() 1 storeUpdate ( newUserInfo ): task When new users log in through the DARIAH infrastructure, the identifying attributes from the identity provider are collected by authenticate() . From there, this function stores those details in the user table. Or, if there is already an entry for this user, that entry is updated with the new information gathered.","title":"user"},{"location":"Server/Server/#auth","text":"See auth . Contains the methods to authenticate users. Here all the logic about user sessions and session cookies is written down. It builds on the Flask web framework. It starts working when the server is started. Then it collects information from the environment to set up the cryptography for the sessions. And it (re)computes all workflow attributes of all records in the database from scratch. readBundleNames() 1 readBundleNames ( regime ) task This is an initialization routine which realizes cache busting of javascript and css files. It is called when the AuthApi object is initialized. Cache busting For production, the JS and CSS bundles for the browser have names with a random hash in it, so that an update of the app will trigger all clients to fetch a new version of these bundles instead of relying on their cached versions. Fiddling with the index page The server generates the HTML index page that will load these bundles, to we have to fiddle those hashes into the index template. We have set up the client build script (webpack) in such a way that the hashed file names are written to a file bundle.html in the distribution directory. regime There are several run scenarios, and inspecting the environment variable REGIME enables the server to determine the scenario it works in. Run scenarios There are three scenarios for running the DARIAH app: None production build served by a production webserver The server has not been started with the build script. Hashed file names needed. develop production build served by the local flask webserver The server has been started by the build script with argument serve . Hashed file names needed. hot develop build served by the webpack devserver The server has been started by the build script with argument servehot . Hashed file names not needed. The proper tweaking of bundle.html will take place for all these scenarios. authenticate() 1 authenticate ( login = False ) task Tries to authenticate the current user by looking up a session created by the DARIAH identity provider, and retrieving the attributes of that session. If it finds unsatisfactory attributes in the session, the session will be deleted, and the user is not authenticated. login This is only relevant on the development system. If True , the server asks for a login name on the command line, and if a valid test user is typed in, it logs that user in. On the production system, the login process takes place outside this app. Only after login this app is able to detect whether a user has logged in and if so, which user that is. deauthenticate() 1 deauthenticate () task Clears the info of the current user and if that user has been identified by the DARIAH identity provider, the corresponding session will be deleted.","title":"auth"},{"location":"Server/Server/#file","text":"See file . Contains the methods to get file data from the server. determineOrigin() 1 determineOrigin ( path ) You can configure origin directories for static files depending on the url path. The configuration is in file itself, in the variable origins , which is a dictionary of initial path strings mapped to an origin directory. For each request for a static file, this function is called to locate the file on the server. static() 1 static ( path ) task Reads the file identified by path on the server and sends its contents as a static file over HTTP to the client. json() 1 json ( path ) task Reads the file identified by path on the server and sends its contents, wrapped as JSON data over HTTP to the client.","title":"file"},{"location":"Server/Server/#workflow","text":"See workflow . Implements the workflow engine which takes care of various aspects of the business logic, just above the level of data fetching and permissions.","title":"workflow"},{"location":"Server/Server/#info","text":"See info . This module is reponsible for an overview of the statistics of the contributions. National coordinators and backoffice personnel can (de)select contributions from this page. Permissions It does manage access to data, and takes care that every user can access the data under the proper conditions. It will hide the sensitive fields (cost) from unauthorized users. Care is taken that NCs can only take selection decisions for contributions from their own country. Backoffice users can modify any selection decision.","title":"info"},{"location":"Server/Server/#cons","text":"See cons . This module is reponsible for showing consolidated records in such a way that they can easily be saved as PDF from the browser. Permissions It does manage access to data, and takes care that every user can access the data under the proper conditions. It will show metadata only to people without update rights to the contribution. Other people are not allowed to see all fields of the contributions, and because a consolidated record contains all information of a contribution and its assessments and reviews, this is only for people that authored/edited the contribution and people in a powerful role, such as office , system , and root .","title":"cons"},{"location":"Server/Server/#utils","text":"See utils . Low level stuff.","title":"utils"},{"location":"Technology/ES6/","text":"ES6 \u00b6 We use ECMAScript 6, also known as ES6, also known as ES2015, also known as JavaScript for the client side of the app. The evolution of JavaScript to ES6 and beyond has transformed JavaScript from a \"horrible language\" into a performant language with a beautiful syntax on one of the most widely supported platforms: the browser. Instead of pushing JavaScript out of sight, we fully embrace it as our principal programming formalism at the client side. Full stack? Others (see for example Meteor ) go even further and use it on the server as well, but we have not taken that step. From ES6 to browser JS The code is transpiled through Babel into a version of JavaScript that all major browsers understand. The compilation from source code to what the browser eventually gets is way more complicated. It is taken care of by the build tool of our choice: Webpack Code style Our source code conforms to a number of style guides, which are checked by eslint . There are many options and choices, ours are here . Not all of these are relevant, because we also enforce style by means of prettier . We highlight a few, not all, concepts in ES6 that we make use of. Class notation \u00b6 Classes are not the main paradigm here See Class notation . In our code, we do not do that much with classes and object-oriented programming. Wherever possible, we prefer writing functions that can be used irrespective of classes. In the React/Redux world, function composition is the preferred way of building up complex functionality out of simpler functionality. Still, there are cases where object orientation definitely has advantages. Syntax The new syntax for classes is like this: 1 2 3 4 5 6 7 8 9 10 11 class Foo extends Bar { constructor () { super () } method1 ( x , y , z ) { this . prop = x } method2 = ( e , f , g ) => { this . event = e } } This is nice, terse, clean syntax. this There is difference between method1 and method2 . method1 is an ordinary method, and the this in the body points to the caller. So if you want to send method1 around as a callback, you have to manually bind the this : 1 callback = this . method1 . bind ( this ) binding deprecated in React In several react contexts, it is undesirable to do this binding, because behind the screens it creates a new object. In a React component, it is much more efficient to pass a statically defined callback around. method2 comes to the rescue. It is a class property , and the this is now lexical . So, whoever calls it, this is the this of class Foo . So you can just say: 1 callback = this . method2 This syntax is ES7 Note that this syntax of class properties is in ES7, beyond ES6. Yet we can use it without issue because of Babel . Arrow functions \u00b6 arrow notation See Arrow Functions . There is now a very handy notation to write functions: arrow notation. Instead of 1 2 3 function myFunc ( x , y ) { return x + y } you can write: 1 const myFunc = ( x , y ) => x + y even shorter If there is only 1 argument, it is even shorter: 1 const myFunc = x => x + 1 functions returning functions If you have functions that return functions, everything goes smoother now: 1 const handleEvent = id => event => dispatch ({ id , value : event . target . value }) this For arrow functions the this is lexical. Object notations \u00b6 Objects are central to JavaScript. ES6 contains new syntax, that makes working with objects very pleasant indeed. to get a taste In our app we have activated linters that insist on using that syntax to the maximum amount possible. It will dramatically change the general outlook of a piece of JavaScript code. Just to have a taste, look at this bit of source code . Destructuring See destructuring . An object contains key-value pairs like this: 1 const props = { foo : 1 , bar : { x : 2 , y : 3 } } If we want to extract the foo and y part, we could say: 1 2 const foo = props . foo const y = props . bar . y But there is a more elegant way, using destructuring : 1 const { foo : foo , bar : { y : y } } = props This does in one statement exactly the same as in the previous statement. Shorthand See shorthand . On top of destructuring, there is another trick: shorthand . If you have a pattern like 1 name: name inside an object, you may also say 1 { name } And if you are in a scope where name is bound to a value v , you may define an object like this: 1 const props = { name } which is equivalent to 1 const props = { name : v } Returning to our foo bar example: 1 const { foo : foo , bar : { y : y } } = props we can write it even more compactly: 1 const { foo , bar : { y } } = props Rest spread See rest spread . Plain usage If props has a lot of keys, and we are interested in doing something with its keys foo and bar , and want to pass the remaining keys on, we can do so using object rest spread , as follows: 1 2 3 const { foo , bar , ... rest } = props doSomething ( foo , bar ) passOn ( rest ) In function definitions 1 2 3 4 const process = ({ foo , bar , ... rest }) => { doSomething ( foo , bar ) passOn ( rest ) } Missing keys If you use object destructuring and the key you destructure is not present in the object, you get undefined. But you can also specify defaults: 1 2 3 const { foo , bar : { y } = { y : 3 , z : 4 }, ... rest } = props doSomething ( foo , bar ) passOn ( rest ) 1 2 3 4 const process = ({ foo = 3 , bar = { x : 0 , y : 0 }, ... rest }) => { doSomething ( foo , bar ) passOn ( rest ) } Use case: shallow copying Object rest spread is also handy to make a shallow copy of an object with some keys changed. Suppose we have a state object, with many keys. Suppose one of them is filter , pointing to an object like this: 1 { 35 : false , 36 : false , 37 : false } Level 1 We want a new state, as a shallow copy of the old state, with the filter updated to 1 { 36 : true } This is how you do that: 1 const newState = { ... state , filter : { 36 : true } } Then newState is a new object. All its members except filter are the same objects as in state . filter in newState is a completely new object. Level 2 Suppose that you do not want to replace the filter object with the one given above, but only its key 36, leaving all other keys intact. You can use object spread twice to achieve this: 1 2 3 4 5 6 7 const newState = { ... state , filter : { ... state . filter , 36 : true , } } Then newState is a new object. All its members except filter are the same objects as in state . filter in newState is a new object. All keys in the new filter except 36 are the same objects as in the filter in state . Merging in reducers This kind of code is often needed in reducers , functions that compute a new state from an old state in such a way that everything that is changed, is copied shallowly to a new object, and every thing that is the same, remains the same object. However, if what has changed is really deeply nested, there are better methods to achieve is, e.g. lodash merge or Immutability-Helper . See also our test suite for reducers . Promises \u00b6 Asynchrone See Promise . Promise is an ES6 data structure to contain the result of asynchronous functions. It has as state that is either pending , failed or resolved . Once the state is failed or resolved , it will not change any more. If the state is resolved , the return value is available. Typical usage The typical way to use a promise is 1 2 3 4 5 6 7 8 9 10 11 const retrievedData = {} const getData = url => fetch ( url ) // assuming that fetch returns a Promise, we can then say getData ( '/api/blob/23' ). then ( blob => { retrievedData . url = blob }, error => console . error ( error ), ) Our usage See server.js . This is virtually the only occurrence in our code where we use Promise syntax.","title":"ES6"},{"location":"Technology/ES6/#es6","text":"We use ECMAScript 6, also known as ES6, also known as ES2015, also known as JavaScript for the client side of the app. The evolution of JavaScript to ES6 and beyond has transformed JavaScript from a \"horrible language\" into a performant language with a beautiful syntax on one of the most widely supported platforms: the browser. Instead of pushing JavaScript out of sight, we fully embrace it as our principal programming formalism at the client side. Full stack? Others (see for example Meteor ) go even further and use it on the server as well, but we have not taken that step. From ES6 to browser JS The code is transpiled through Babel into a version of JavaScript that all major browsers understand. The compilation from source code to what the browser eventually gets is way more complicated. It is taken care of by the build tool of our choice: Webpack Code style Our source code conforms to a number of style guides, which are checked by eslint . There are many options and choices, ours are here . Not all of these are relevant, because we also enforce style by means of prettier . We highlight a few, not all, concepts in ES6 that we make use of.","title":"ES6"},{"location":"Technology/ES6/#class-notation","text":"Classes are not the main paradigm here See Class notation . In our code, we do not do that much with classes and object-oriented programming. Wherever possible, we prefer writing functions that can be used irrespective of classes. In the React/Redux world, function composition is the preferred way of building up complex functionality out of simpler functionality. Still, there are cases where object orientation definitely has advantages. Syntax The new syntax for classes is like this: 1 2 3 4 5 6 7 8 9 10 11 class Foo extends Bar { constructor () { super () } method1 ( x , y , z ) { this . prop = x } method2 = ( e , f , g ) => { this . event = e } } This is nice, terse, clean syntax. this There is difference between method1 and method2 . method1 is an ordinary method, and the this in the body points to the caller. So if you want to send method1 around as a callback, you have to manually bind the this : 1 callback = this . method1 . bind ( this ) binding deprecated in React In several react contexts, it is undesirable to do this binding, because behind the screens it creates a new object. In a React component, it is much more efficient to pass a statically defined callback around. method2 comes to the rescue. It is a class property , and the this is now lexical . So, whoever calls it, this is the this of class Foo . So you can just say: 1 callback = this . method2 This syntax is ES7 Note that this syntax of class properties is in ES7, beyond ES6. Yet we can use it without issue because of Babel .","title":"Class notation"},{"location":"Technology/ES6/#arrow-functions","text":"arrow notation See Arrow Functions . There is now a very handy notation to write functions: arrow notation. Instead of 1 2 3 function myFunc ( x , y ) { return x + y } you can write: 1 const myFunc = ( x , y ) => x + y even shorter If there is only 1 argument, it is even shorter: 1 const myFunc = x => x + 1 functions returning functions If you have functions that return functions, everything goes smoother now: 1 const handleEvent = id => event => dispatch ({ id , value : event . target . value }) this For arrow functions the this is lexical.","title":"Arrow functions"},{"location":"Technology/ES6/#object-notations","text":"Objects are central to JavaScript. ES6 contains new syntax, that makes working with objects very pleasant indeed. to get a taste In our app we have activated linters that insist on using that syntax to the maximum amount possible. It will dramatically change the general outlook of a piece of JavaScript code. Just to have a taste, look at this bit of source code . Destructuring See destructuring . An object contains key-value pairs like this: 1 const props = { foo : 1 , bar : { x : 2 , y : 3 } } If we want to extract the foo and y part, we could say: 1 2 const foo = props . foo const y = props . bar . y But there is a more elegant way, using destructuring : 1 const { foo : foo , bar : { y : y } } = props This does in one statement exactly the same as in the previous statement. Shorthand See shorthand . On top of destructuring, there is another trick: shorthand . If you have a pattern like 1 name: name inside an object, you may also say 1 { name } And if you are in a scope where name is bound to a value v , you may define an object like this: 1 const props = { name } which is equivalent to 1 const props = { name : v } Returning to our foo bar example: 1 const { foo : foo , bar : { y : y } } = props we can write it even more compactly: 1 const { foo , bar : { y } } = props Rest spread See rest spread . Plain usage If props has a lot of keys, and we are interested in doing something with its keys foo and bar , and want to pass the remaining keys on, we can do so using object rest spread , as follows: 1 2 3 const { foo , bar , ... rest } = props doSomething ( foo , bar ) passOn ( rest ) In function definitions 1 2 3 4 const process = ({ foo , bar , ... rest }) => { doSomething ( foo , bar ) passOn ( rest ) } Missing keys If you use object destructuring and the key you destructure is not present in the object, you get undefined. But you can also specify defaults: 1 2 3 const { foo , bar : { y } = { y : 3 , z : 4 }, ... rest } = props doSomething ( foo , bar ) passOn ( rest ) 1 2 3 4 const process = ({ foo = 3 , bar = { x : 0 , y : 0 }, ... rest }) => { doSomething ( foo , bar ) passOn ( rest ) } Use case: shallow copying Object rest spread is also handy to make a shallow copy of an object with some keys changed. Suppose we have a state object, with many keys. Suppose one of them is filter , pointing to an object like this: 1 { 35 : false , 36 : false , 37 : false } Level 1 We want a new state, as a shallow copy of the old state, with the filter updated to 1 { 36 : true } This is how you do that: 1 const newState = { ... state , filter : { 36 : true } } Then newState is a new object. All its members except filter are the same objects as in state . filter in newState is a completely new object. Level 2 Suppose that you do not want to replace the filter object with the one given above, but only its key 36, leaving all other keys intact. You can use object spread twice to achieve this: 1 2 3 4 5 6 7 const newState = { ... state , filter : { ... state . filter , 36 : true , } } Then newState is a new object. All its members except filter are the same objects as in state . filter in newState is a new object. All keys in the new filter except 36 are the same objects as in the filter in state . Merging in reducers This kind of code is often needed in reducers , functions that compute a new state from an old state in such a way that everything that is changed, is copied shallowly to a new object, and every thing that is the same, remains the same object. However, if what has changed is really deeply nested, there are better methods to achieve is, e.g. lodash merge or Immutability-Helper . See also our test suite for reducers .","title":"Object notations"},{"location":"Technology/ES6/#promises","text":"Asynchrone See Promise . Promise is an ES6 data structure to contain the result of asynchronous functions. It has as state that is either pending , failed or resolved . Once the state is failed or resolved , it will not change any more. If the state is resolved , the return value is available. Typical usage The typical way to use a promise is 1 2 3 4 5 6 7 8 9 10 11 const retrievedData = {} const getData = url => fetch ( url ) // assuming that fetch returns a Promise, we can then say getData ( '/api/blob/23' ). then ( blob => { retrievedData . url = blob }, error => console . error ( error ), ) Our usage See server.js . This is virtually the only occurrence in our code where we use Promise syntax.","title":"Promises"},{"location":"Technology/React/","text":"React \u00b6 Components \u00b6 React Components represent pieces of the web page and their functionality. Building blocks Components are organized hierarchically. Components can be parametrized by properties , which parents pass to children. A component acts as a template instruction to build a piece of DOM. Components can be programmed as classes or as functions. In this app we distinguish between three capability levels of components. Pure components If a component knows how to build the DOM, purely on the basis of its properties and a static template, it can be (and will be) coded as a pure function. Example: Stat . Simple stateful components If a component needs to store the effects of the outside world (incoming server data or user interaction), it is stateful. If the component does not need life cycle methods, it can be programmed as a pure function that will be connected to the Redux state by means of a simple binding: connect . Example: Facet . Complex components If a component has to handle the DOM after it has been constructed, e.g. apply some hiding and showing, fill a DIV with a third party component, or get data from the state in a sophisticated way, then we need to program the component as a class with so-called life cycle methods . Example: Bool3 Example: ListContainer . Processing concepts \u00b6 React renders updates to components very efficiently. The render() function is a template for a element fragment , not the real DOM . So, after an update, it is not costly to recompute the fragment for that component completely, because the DOM is not touched. Reconciliation Once the new fragment has been constructed, a clever, React-internal process called reconciliation is carried out. This computes the minimum number of update actions that have to be applied to the previous, real DOM incarnation of the component, to change it to match the new fragment. MiniDOM A compact internal representation of the DOM , made from React elements . A React element is an instance of the React Element class. In jsx you can refer to a React element just by saying 1 < p > foo < /p> React elements reflect HTML elements, but you can mingle them with React components, which look nearly the same in jsx : 1 2 3 < p > < NavLink to = \"/data\" > bar < /NavLink> < /p> DOM DOM is an abbreviation for Document Object Model . The DOM is what the browser gets in memory once it has loaded an HTML document. One of the principal tasks of JavaScript in the browser is to manipulate this DOM. The DOM and its API are exceedingly bloated, hence DOM operations are slow, no matter how fast JavaScript currently is. This is one of the reasons that a niche for React exists, with its MiniDOM . Fragment A fragment is a mixture of properly nested React elements and components. It is part of the React's toolkit to manage DOM manipulations efficiently. See Reconciliation . Property management \u00b6 PropTypes PropTypes are a means to do type checking for React Components is done by PropTypes . Only in development mode PropType checking in react only happens in development mode. React checks whether the named props that are passed to a component correspond to the props declared. In addition, it performs a basic type check on the values inside those props. We don't use them I find the PropType verbose, and no match for the otherwise clean and pleasant syntax of JSX. Additionally, most of the mistakes I make, do not reveal themselves as value type mistakes. On top it this all: declaring PropTypes forces you to repeat all the names of your properties, so is against the principle of don't repeat yourself . In this application, the property names are always clear in the code, either as 1 const MyComponent = ({ foo , bar )} => ... or as 1 const { props : { foo , bar } } = this Context Context is a React mechanism to pass data directly from ancestors to deep descendants. The React documentation considers context as a brittle part of itself, and warns against over-use. At the same time, Redux depends critically on it, so I consider it safe to use. But our code will not use it explicitly, only through Redux. Life cycle \u00b6 The main function of a component is to act as a template to be render() ed. But if there is additional work to be done, this can be hooked up at various stages in the component's life cycle . Stages Most stages occur during (re)rendering, and there is a stage of construction and unmounting. Constructor When a component is being rendered the constructor is the method to construct the corresponding React class. It will set up the state . componentDidMount When a component has been added to the DOM its method componentDidMount will be called just after. This is the recommended time to fetch data for this component, if needed. componentDidUpdate When a component has been updated due to receiving new properties, its method componentDidUpdate will be called just after. If DOM manipulations are needed to complete the rendering, this is the place to do it. Not initially This will not called upon initial rendering. So if the DOM manipulation is also needed initially, it is handy to write a function for it and call it in this method and in componentDidMount() . componentWillMount When a component will be added to the DOM, its method componentWillMount will be called just before. This is the first thing that happens after constructor() . componentWillReceiveProps When a component is about to receive new props (as part of the update process), its method componentWillReceiveProps will be called just before. The new props are passed with it, so that it is possible to execute actions dependent on whether pros have changed. componentWillUnMount When a component will be removed from the DOM, its method componentWillUnmount will be called just before. If we want to save state, we can hook it up here. render The main function of a component is to act as a template to be rendered. Its method render constructs the template to be rendered. During rendering the template will be used as a set of instructions to build a real DOM somewhere on the actual web page. Controlled Component \u00b6 For elements that can receive user input (forms, inputs, etc.) there is the option to handle input in a way controlled by React, and not by the default HTML behaviour. We say that those elements are used as controlled Components . Mechanism So when a user clicks a checkbox, the check is not managed by the browser, but: a callback is called a parent component executes it the state gets updated the state change trickles down as property updates to child elements the checkbox in question is told by properties to be checked (or unchecked). State \u00b6 There are two main reasons for a component to maintain state : getting external data, reacting to user events. In both cases, something happens in the outside world that must be remembered. Local State Components remember events in their state , which only they can update. Trickle down through properties Components can compute derived data from their state and pass that as properties to their children. State updates trigger these computations automatically, and children whose properties are dependent on this state, are re-rendered automatically (and economically). Vanilla React The vanilla React way is that components have their own state, which only they can modify through setState . Local state is very intuitive and leads to nice separation of concerns. Lift state up But even in React, state is not completely local, because in many cases several components need to have access to the state. The preferred way of dealing with that is to lift state up to the nearest common ancestor of all components that need the state. Descendants that must modify ancestral state are passed a callback to do so. Drawback of local state There comes a moment that components want to be informed of each other's state. Especially when components start modifying data from the server and saving it, other components that rely on the same data, want to be notified. Setting up ad-hoc communication between such components leads to an asynchronous dependency hell, which can be avoided by a central state as a single source of truth. Central State In this app, we have left the path of local state, and embraced central state . A widely used approach to central state is Redux . Redux \u00b6 Redux is a popular implementation of the idea that state is centralized and all components have to subscribe to a state Provider , the store. Mechanism Components read slices of the state by means of selectors . If a component needs to update the state: it dispatches an action to the store; so-called reducers translate the action into state updates; then the component is triggered to re-render. Code organization Using Redux requires a lot of extra code in actions and reducers, which get separated from the components for which it is used. Idiomatic Redux However, there is a way to do it nicely. There is a way of writing idiomatic redux, beautifully advocated by its creator, Dan Abramov, in 30 videos . Dux A next level of organization is ducts (we call them dux) . We divide the state into segments that are responsible for well-described tasks, such as tables of data from the server notification faceted browsing alternative presentations to the user window resizing For every such task, we make a duct and put it into the dux directory. Every duct manages a slice of the state has four sections: Actions Functions that create the actions whose dispatch will trigger a state update. Reducer A single function that translates all relevant actions into updates of its slice of the state. Selectors Functions that grab data from the state in order to offer it to connected components. Helpers Functions that contain additional logic, especially for selectors. See for an example filters . Merge \u00b6 When a reducer transforms a state, it must happen in such a way that unaffected parts of the state do not change, all intermediate objects between the top-level state and a changed leaf are fresh objects. Merge tools lodash merge/mergeWith A candidate to achieve this is to use lodash merge and lodash mergeWith . The hint to use Lodash functions for this is given here . But tests have shown that not in all cases equal parts remained identical objects. immutability helper We ended up using Immutability-Helper in all cases. Its function update() takes an object, and transforms it on the basis of an other object, precisely as needed for our purposes. See the code in the notes duct . Select \u00b6 The opposite of merging data into the state is selecting data from the state. Selectors Our components need bits and pieces of the state in order to know what they should render. To this end, we write selector functions, that return suitable slices of the state. computations In some cases, selecting the data requires quite a bit of computation. Normalized data When the data in the state is normalized and the component needs denormalized data. Faceted browsing The items to show must be computed from the list of items in the table slice of the state, combined with the current filter settings from the filter slice of the state. Performance problem Here we encounter a potential performance problem. Sometimes components will be re-rendered even if their piece of the state has not changed. Or, if it has changed, it is often the case that the derived data that the component needs, has not changed. In general, if we do nothing about it, the computations in selectors will be executed more often than necessary. Solution: memoization The method to deal with this is memoization. Reselect The redux documentation suggests the reselect library here . Reselect facilitates the fabrication of selectors that remember their last output in combination with the parameters passed to it. If such a selector is called repeatedly with the same arguments, it will fetch the computed result from its cache the second time it is called and then onwards. We use this library only to implement a function that combines selectors . Homegrown memoization However, we will also encounter cases where we need more complete memoization, so that functions have a cache for their results given multiple sets of parameters. See memo . Connect \u00b6 Redux and the dux streamline very much how components deal with the centralized store. The central function is Redux connect . Connecting components to the state If a component X needs state, we can create a connected component Xc from X . Connected means: connected to the state. 1 Xc = connect ( selectors , dispatchers )( X ) The new component Xc has extra props: selectors Data provided by the function selectors , which is a function that reads the global state and returns information of it as a props object. dispatchers Callback provided by the function dispatchers . This returns a props object of action creator functions. Xc can use these where a callback is needed. When such a function is called, the action will be created and dispatched, which in turn will lead to a state change. See also Architecture . Routing \u00b6 React-router is a convenient library to manage the connection between the URL and the part of your app that should be active in response to it. Routers as components The router and its routes are basically React components . But they come loaded with some extra behaviour. Basically, when a route is rendered, it checks its path attribute with the current URL. If it matches, it renders itself. Otherwise, it does not mount, or if it was mounted, it will unmount. API and State Several tricks are employed to make this a really useful library. See the API docs . However, precisely because of this repeated mounting and unmounting caused by routing events, the need arises for components to save their states, especially the ones with a costly state. Here is another reason why local state becomes cumbersome. With Redux, this is not a problem, because state is severed from the components.","title":"React"},{"location":"Technology/React/#react","text":"","title":"React"},{"location":"Technology/React/#components","text":"React Components represent pieces of the web page and their functionality. Building blocks Components are organized hierarchically. Components can be parametrized by properties , which parents pass to children. A component acts as a template instruction to build a piece of DOM. Components can be programmed as classes or as functions. In this app we distinguish between three capability levels of components. Pure components If a component knows how to build the DOM, purely on the basis of its properties and a static template, it can be (and will be) coded as a pure function. Example: Stat . Simple stateful components If a component needs to store the effects of the outside world (incoming server data or user interaction), it is stateful. If the component does not need life cycle methods, it can be programmed as a pure function that will be connected to the Redux state by means of a simple binding: connect . Example: Facet . Complex components If a component has to handle the DOM after it has been constructed, e.g. apply some hiding and showing, fill a DIV with a third party component, or get data from the state in a sophisticated way, then we need to program the component as a class with so-called life cycle methods . Example: Bool3 Example: ListContainer .","title":"Components"},{"location":"Technology/React/#processing-concepts","text":"React renders updates to components very efficiently. The render() function is a template for a element fragment , not the real DOM . So, after an update, it is not costly to recompute the fragment for that component completely, because the DOM is not touched. Reconciliation Once the new fragment has been constructed, a clever, React-internal process called reconciliation is carried out. This computes the minimum number of update actions that have to be applied to the previous, real DOM incarnation of the component, to change it to match the new fragment. MiniDOM A compact internal representation of the DOM , made from React elements . A React element is an instance of the React Element class. In jsx you can refer to a React element just by saying 1 < p > foo < /p> React elements reflect HTML elements, but you can mingle them with React components, which look nearly the same in jsx : 1 2 3 < p > < NavLink to = \"/data\" > bar < /NavLink> < /p> DOM DOM is an abbreviation for Document Object Model . The DOM is what the browser gets in memory once it has loaded an HTML document. One of the principal tasks of JavaScript in the browser is to manipulate this DOM. The DOM and its API are exceedingly bloated, hence DOM operations are slow, no matter how fast JavaScript currently is. This is one of the reasons that a niche for React exists, with its MiniDOM . Fragment A fragment is a mixture of properly nested React elements and components. It is part of the React's toolkit to manage DOM manipulations efficiently. See Reconciliation .","title":"Processing concepts"},{"location":"Technology/React/#property-management","text":"PropTypes PropTypes are a means to do type checking for React Components is done by PropTypes . Only in development mode PropType checking in react only happens in development mode. React checks whether the named props that are passed to a component correspond to the props declared. In addition, it performs a basic type check on the values inside those props. We don't use them I find the PropType verbose, and no match for the otherwise clean and pleasant syntax of JSX. Additionally, most of the mistakes I make, do not reveal themselves as value type mistakes. On top it this all: declaring PropTypes forces you to repeat all the names of your properties, so is against the principle of don't repeat yourself . In this application, the property names are always clear in the code, either as 1 const MyComponent = ({ foo , bar )} => ... or as 1 const { props : { foo , bar } } = this Context Context is a React mechanism to pass data directly from ancestors to deep descendants. The React documentation considers context as a brittle part of itself, and warns against over-use. At the same time, Redux depends critically on it, so I consider it safe to use. But our code will not use it explicitly, only through Redux.","title":"Property management"},{"location":"Technology/React/#life-cycle","text":"The main function of a component is to act as a template to be render() ed. But if there is additional work to be done, this can be hooked up at various stages in the component's life cycle . Stages Most stages occur during (re)rendering, and there is a stage of construction and unmounting. Constructor When a component is being rendered the constructor is the method to construct the corresponding React class. It will set up the state . componentDidMount When a component has been added to the DOM its method componentDidMount will be called just after. This is the recommended time to fetch data for this component, if needed. componentDidUpdate When a component has been updated due to receiving new properties, its method componentDidUpdate will be called just after. If DOM manipulations are needed to complete the rendering, this is the place to do it. Not initially This will not called upon initial rendering. So if the DOM manipulation is also needed initially, it is handy to write a function for it and call it in this method and in componentDidMount() . componentWillMount When a component will be added to the DOM, its method componentWillMount will be called just before. This is the first thing that happens after constructor() . componentWillReceiveProps When a component is about to receive new props (as part of the update process), its method componentWillReceiveProps will be called just before. The new props are passed with it, so that it is possible to execute actions dependent on whether pros have changed. componentWillUnMount When a component will be removed from the DOM, its method componentWillUnmount will be called just before. If we want to save state, we can hook it up here. render The main function of a component is to act as a template to be rendered. Its method render constructs the template to be rendered. During rendering the template will be used as a set of instructions to build a real DOM somewhere on the actual web page.","title":"Life cycle"},{"location":"Technology/React/#controlled-component","text":"For elements that can receive user input (forms, inputs, etc.) there is the option to handle input in a way controlled by React, and not by the default HTML behaviour. We say that those elements are used as controlled Components . Mechanism So when a user clicks a checkbox, the check is not managed by the browser, but: a callback is called a parent component executes it the state gets updated the state change trickles down as property updates to child elements the checkbox in question is told by properties to be checked (or unchecked).","title":"Controlled Component"},{"location":"Technology/React/#state","text":"There are two main reasons for a component to maintain state : getting external data, reacting to user events. In both cases, something happens in the outside world that must be remembered. Local State Components remember events in their state , which only they can update. Trickle down through properties Components can compute derived data from their state and pass that as properties to their children. State updates trigger these computations automatically, and children whose properties are dependent on this state, are re-rendered automatically (and economically). Vanilla React The vanilla React way is that components have their own state, which only they can modify through setState . Local state is very intuitive and leads to nice separation of concerns. Lift state up But even in React, state is not completely local, because in many cases several components need to have access to the state. The preferred way of dealing with that is to lift state up to the nearest common ancestor of all components that need the state. Descendants that must modify ancestral state are passed a callback to do so. Drawback of local state There comes a moment that components want to be informed of each other's state. Especially when components start modifying data from the server and saving it, other components that rely on the same data, want to be notified. Setting up ad-hoc communication between such components leads to an asynchronous dependency hell, which can be avoided by a central state as a single source of truth. Central State In this app, we have left the path of local state, and embraced central state . A widely used approach to central state is Redux .","title":"State"},{"location":"Technology/React/#redux","text":"Redux is a popular implementation of the idea that state is centralized and all components have to subscribe to a state Provider , the store. Mechanism Components read slices of the state by means of selectors . If a component needs to update the state: it dispatches an action to the store; so-called reducers translate the action into state updates; then the component is triggered to re-render. Code organization Using Redux requires a lot of extra code in actions and reducers, which get separated from the components for which it is used. Idiomatic Redux However, there is a way to do it nicely. There is a way of writing idiomatic redux, beautifully advocated by its creator, Dan Abramov, in 30 videos . Dux A next level of organization is ducts (we call them dux) . We divide the state into segments that are responsible for well-described tasks, such as tables of data from the server notification faceted browsing alternative presentations to the user window resizing For every such task, we make a duct and put it into the dux directory. Every duct manages a slice of the state has four sections: Actions Functions that create the actions whose dispatch will trigger a state update. Reducer A single function that translates all relevant actions into updates of its slice of the state. Selectors Functions that grab data from the state in order to offer it to connected components. Helpers Functions that contain additional logic, especially for selectors. See for an example filters .","title":"Redux"},{"location":"Technology/React/#merge","text":"When a reducer transforms a state, it must happen in such a way that unaffected parts of the state do not change, all intermediate objects between the top-level state and a changed leaf are fresh objects. Merge tools lodash merge/mergeWith A candidate to achieve this is to use lodash merge and lodash mergeWith . The hint to use Lodash functions for this is given here . But tests have shown that not in all cases equal parts remained identical objects. immutability helper We ended up using Immutability-Helper in all cases. Its function update() takes an object, and transforms it on the basis of an other object, precisely as needed for our purposes. See the code in the notes duct .","title":"Merge"},{"location":"Technology/React/#select","text":"The opposite of merging data into the state is selecting data from the state. Selectors Our components need bits and pieces of the state in order to know what they should render. To this end, we write selector functions, that return suitable slices of the state. computations In some cases, selecting the data requires quite a bit of computation. Normalized data When the data in the state is normalized and the component needs denormalized data. Faceted browsing The items to show must be computed from the list of items in the table slice of the state, combined with the current filter settings from the filter slice of the state. Performance problem Here we encounter a potential performance problem. Sometimes components will be re-rendered even if their piece of the state has not changed. Or, if it has changed, it is often the case that the derived data that the component needs, has not changed. In general, if we do nothing about it, the computations in selectors will be executed more often than necessary. Solution: memoization The method to deal with this is memoization. Reselect The redux documentation suggests the reselect library here . Reselect facilitates the fabrication of selectors that remember their last output in combination with the parameters passed to it. If such a selector is called repeatedly with the same arguments, it will fetch the computed result from its cache the second time it is called and then onwards. We use this library only to implement a function that combines selectors . Homegrown memoization However, we will also encounter cases where we need more complete memoization, so that functions have a cache for their results given multiple sets of parameters. See memo .","title":"Select"},{"location":"Technology/React/#connect","text":"Redux and the dux streamline very much how components deal with the centralized store. The central function is Redux connect . Connecting components to the state If a component X needs state, we can create a connected component Xc from X . Connected means: connected to the state. 1 Xc = connect ( selectors , dispatchers )( X ) The new component Xc has extra props: selectors Data provided by the function selectors , which is a function that reads the global state and returns information of it as a props object. dispatchers Callback provided by the function dispatchers . This returns a props object of action creator functions. Xc can use these where a callback is needed. When such a function is called, the action will be created and dispatched, which in turn will lead to a state change. See also Architecture .","title":"Connect"},{"location":"Technology/React/#routing","text":"React-router is a convenient library to manage the connection between the URL and the part of your app that should be active in response to it. Routers as components The router and its routes are basically React components . But they come loaded with some extra behaviour. Basically, when a route is rendered, it checks its path attribute with the current URL. If it matches, it renders itself. Otherwise, it does not mount, or if it was mounted, it will unmount. API and State Several tricks are employed to make this a really useful library. See the API docs . However, precisely because of this repeated mounting and unmounting caused by routing events, the need arises for components to save their states, especially the ones with a costly state. Here is another reason why local state becomes cumbersome. With Redux, this is not a problem, because state is severed from the components.","title":"Routing"},{"location":"Technology/Tech/","text":"Technical references \u00b6 This is an alphabetical list of tech references. Sometimes we refer to a technology without making use of it in the app, we have marked those entries with an \u2717. References \u00b6 Generic bash shell scripting cloc counting lines of code geojson geographical data in json format leaflet geo-mapping library iso8601 date and time format Web design spa single page application: webApi interacting with the loaded document in a browser Styling css cascading stylesheets: flexbox laying out boxes in flexible ways \u2717 grid laying out boxes in a grid hsl color space \u2717 sass css preprocessor html markup language for the web Shorthands markdown rich text from plain text yaml configuration language, as simple as markdown. Editing \u2717 IDE Integrated Developer's Environment \u2717 Atom IDE by GitHub \u2717 SublimeText commercial text editor vim old-hands text editor, still competes with IDEs ALE runs linters and formatters within vim \u2717 Visual Studio Code IDE by Microsoft \u2717 Webstorm commercial IDE ???+ abstract \"Linters and formatters * remark linter and formatter for markdown * flake8 code linter for Python * yapf code formatter for Python Client side language javascript scripting language for the web babel compiles ES6 (modern Javascript) to older Javascript (understood by browsers) es7cp static methods for classes eslint checks ES6 code against style requirements prettier code formatter for javascript libraries lodash handy functions for dealing with collections mocha test framework tools node run javascript outside browsers npm package manager for javascript webpack build tool for javascript frameworks \u2717 mern mongo-express-react-node stack for web development \u2717 meteor full-stack javascript web framework react web framework for rendering in the browser immutability immutable data structures autovivification creating sub-objects when needed \u2717 select select boxes in React reselect selecting data from the state router routing in React tutorial redux global state management in React and other frameworks ducks source code organization for redux apps videos redux-form user entry forms, processable in redux react-redux bindings for redux in react Server side python data-oriented scripting language flask micro web framework wsgi bridge between the python language and webservers \u2717 socket push messages from server to all connected clients \u2717 python-socket python wrapper for socket.io Database mongodb NO-SQL database, JSON/Javascript based Other \u2717 shebanq web interface for Hebrew text and linguistic annotations","title":"Tech"},{"location":"Technology/Tech/#technical-references","text":"This is an alphabetical list of tech references. Sometimes we refer to a technology without making use of it in the app, we have marked those entries with an \u2717.","title":"Technical references"},{"location":"Technology/Tech/#references","text":"Generic bash shell scripting cloc counting lines of code geojson geographical data in json format leaflet geo-mapping library iso8601 date and time format Web design spa single page application: webApi interacting with the loaded document in a browser Styling css cascading stylesheets: flexbox laying out boxes in flexible ways \u2717 grid laying out boxes in a grid hsl color space \u2717 sass css preprocessor html markup language for the web Shorthands markdown rich text from plain text yaml configuration language, as simple as markdown. Editing \u2717 IDE Integrated Developer's Environment \u2717 Atom IDE by GitHub \u2717 SublimeText commercial text editor vim old-hands text editor, still competes with IDEs ALE runs linters and formatters within vim \u2717 Visual Studio Code IDE by Microsoft \u2717 Webstorm commercial IDE ???+ abstract \"Linters and formatters * remark linter and formatter for markdown * flake8 code linter for Python * yapf code formatter for Python Client side language javascript scripting language for the web babel compiles ES6 (modern Javascript) to older Javascript (understood by browsers) es7cp static methods for classes eslint checks ES6 code against style requirements prettier code formatter for javascript libraries lodash handy functions for dealing with collections mocha test framework tools node run javascript outside browsers npm package manager for javascript webpack build tool for javascript frameworks \u2717 mern mongo-express-react-node stack for web development \u2717 meteor full-stack javascript web framework react web framework for rendering in the browser immutability immutable data structures autovivification creating sub-objects when needed \u2717 select select boxes in React reselect selecting data from the state router routing in React tutorial redux global state management in React and other frameworks ducks source code organization for redux apps videos redux-form user entry forms, processable in redux react-redux bindings for redux in react Server side python data-oriented scripting language flask micro web framework wsgi bridge between the python language and webservers \u2717 socket push messages from server to all connected clients \u2717 python-socket python wrapper for socket.io Database mongodb NO-SQL database, JSON/Javascript based Other \u2717 shebanq web interface for Hebrew text and linguistic annotations","title":"References"}]}