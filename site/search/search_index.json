{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 DARIAH contribution tool This is the documentation for the DARIAH contribution tool, an instrument to register and assess community contributions to the DARIAH . The documentation contains parts that range from functional , conceptual , technical to mundane . About Code base To get an impression of the kind of work behind this app, we reveal how many lines of code have been written in which languages. See also how we managed to keep the code in all those languages tidy. Lessons learned It has taken a lot of time to develop this app. Lots more than I expected from the start. News Every now and then I resume what has happened during development. It is not regular and not comprehensive! Functionality For a vivid impression of the intended functions of this app, see these slides which I made near the end of the project (2017-12-14). Business logic The actual handling of contributions, assessments and reviews is the business logic of this app. Workflow At the highest level of abstraction a workflow engine implements the business logic. Tables Several tables work together with the workflow engine. Templates Those tables receive custom formatting through a very dynamic templating system. Legacy Content This app inherits 800 contributions that have been entered in 2015-2017 into a FileMaker database. We have migrated those to a MongoDB model. Concepts Model The whole app is centered around data: contributions, assessments, reviews and more. We have to organize and specify that data. Architecture This is a complex app. We need a lot of structure to get every bit of data there where it is needed. On time. Routing This is a web app. We need to divide labour between client and server, and define a routing scheme that steers the app by URLs. Server Server The part of the app that guards the data sits at the server. From there it sends it to the web browsers (clients) of the users. Authentication Users are authenticated at the server, and every bit of data that they subsequently receive, has passed a customs control. Client Components The client (web browser) is where the app speaks to the user. The user interface is built up from dozens of components, that mediate between the user and the server. Dux The client collects the actions of the user and the data from the server into an internal state, from which it flows back to the components. Lib We have developed quite a bit of library functions to assist our components. Technology ES6 We have implemented the client application in ES6, i.e. modern Javascript. That is our glue language. React Our components are written in React, a framework that defines a syntactic sugar right within ES6. Tech index We have listed most of the technology that we have made use of. Integration API The data of the tool is accessible through an API. In fact, this app itself uses that API, whenever the client needs data from the server. Maintenance Deploy Here are the bits and pieces you have to do in order to get a working system out of this. Tests Testing becomes a life saver when your app is growing in complexity. When you add new behaviours you run the risk that existing behaviours break. The remedy is to write tests for all aspects of the behaviours, and run them rigorously after each change and refactoring. That way, you proactively discover your bugs before your users do. Author Dirk Roorda DANS dirk.roorda@dans.knaw.nl 2019-03-04 2017-12-14","title":"Home"},{"location":"#home","text":"DARIAH contribution tool This is the documentation for the DARIAH contribution tool, an instrument to register and assess community contributions to the DARIAH . The documentation contains parts that range from functional , conceptual , technical to mundane . About Code base To get an impression of the kind of work behind this app, we reveal how many lines of code have been written in which languages. See also how we managed to keep the code in all those languages tidy. Lessons learned It has taken a lot of time to develop this app. Lots more than I expected from the start. News Every now and then I resume what has happened during development. It is not regular and not comprehensive! Functionality For a vivid impression of the intended functions of this app, see these slides which I made near the end of the project (2017-12-14). Business logic The actual handling of contributions, assessments and reviews is the business logic of this app. Workflow At the highest level of abstraction a workflow engine implements the business logic. Tables Several tables work together with the workflow engine. Templates Those tables receive custom formatting through a very dynamic templating system. Legacy Content This app inherits 800 contributions that have been entered in 2015-2017 into a FileMaker database. We have migrated those to a MongoDB model. Concepts Model The whole app is centered around data: contributions, assessments, reviews and more. We have to organize and specify that data. Architecture This is a complex app. We need a lot of structure to get every bit of data there where it is needed. On time. Routing This is a web app. We need to divide labour between client and server, and define a routing scheme that steers the app by URLs. Server Server The part of the app that guards the data sits at the server. From there it sends it to the web browsers (clients) of the users. Authentication Users are authenticated at the server, and every bit of data that they subsequently receive, has passed a customs control. Client Components The client (web browser) is where the app speaks to the user. The user interface is built up from dozens of components, that mediate between the user and the server. Dux The client collects the actions of the user and the data from the server into an internal state, from which it flows back to the components. Lib We have developed quite a bit of library functions to assist our components. Technology ES6 We have implemented the client application in ES6, i.e. modern Javascript. That is our glue language. React Our components are written in React, a framework that defines a syntactic sugar right within ES6. Tech index We have listed most of the technology that we have made use of. Integration API The data of the tool is accessible through an API. In fact, this app itself uses that API, whenever the client needs data from the server. Maintenance Deploy Here are the bits and pieces you have to do in order to get a working system out of this. Tests Testing becomes a life saver when your app is growing in complexity. When you add new behaviours you run the risk that existing behaviours break. The remedy is to write tests for all aspects of the behaviours, and run them rigorously after each change and refactoring. That way, you proactively discover your bugs before your users do. Author Dirk Roorda DANS dirk.roorda@dans.knaw.nl 2019-03-04 2017-12-14","title":"Home"},{"location":"About/Codebase/","text":"Codebase \u00b6 Statistics \u00b6 cloc tool Statistics Legend \u00b6 The numbers stand for lines of code. 1000 lines is ~ 20 typed A4 pages of text. YAML \u00b6 A simple plain-text way to convey structured data. What Markdown is to text, YAML is to XML-JSON. In this app we use YAML for configuration details. the conversion of legacy contribution data into MongoDB is steered by a config.yaml . the data model lists all the tables and fields, including how they hang together and how we want to represent them on screen. It also defines access control. If you, as developer, need to add new tables and fields, you can do so by modifying these files: model per table . No extra coding is needed. Markdown \u00b6 A simple plain-text way to write formatted text. See it as a shortcut to writing HTML. It is handy for writing documentation without being distracted by too many formatting options and issues, as you experience when writing in Word or plain HTML. Markdown is usually converted to HTML, but even when it is not converted, it is still very readable. If you use GitHub, one of the first things is to write a README file for your project. This must be a markdown file. If you use other documentation options on GitHub, such as Wiki or Pages, you will also write markdown. Markdown has a sister: YAML , which is used for structured data. In this app we use markdown in the following ways: all documentation here is written in markdown the app can present markdown documents all big text fields in this app support markdown. JavaScript \u00b6 The principal scripting language for web applications. It has evolved into a performant language with a beautiful syntax, capable of running on the server and in websites. This app uses JavaScript in the client only. We use it as a work horse which takes care of a copy of data from the database. It reacts to changes by integrating new bits of data into the existing state, a process that is called reducing . JSX \u00b6 This is also JavaScript, but with a thin layer of syntactic sugar, by which you can present your code as a collection of React components . In this app we have dozens of JSX files, each containing exactly one component (with a few exceptions). Components are pieces of code that realize parts of the website that you can actually see, and often interact with. They are supported by sophisticated plumbing (dux, ducts) , which connects them to the global state of the app. The state is divided in sections, where individual duct connects such a section with several components. See Architecture for how this hangs together. The plumbing needs some specialized, technical functions, which are collected in the lib section of the app. One of the most crucial is memoization . Python \u00b6 A general purpose scripting language with excellent data processing facilities. This app uses python (version 3.6.1+) for the web server. The web server itself is Flask , a light-weight framework for handling http(s) requests. We have added a set of controllers . The actual code there is quite lean, but when it comes to database access, the module db does the heavy lifting and tends to become uglier and uglier. CSS \u00b6 Styling the app has nightmarish overtones, because the concerns of style often cut right across the concerns of the components. There are several ways to control the resulting mess, and one of the best is to use the modern features of CSS. Cascading style sheets are the ultimate way to paint the final look and feel of the website. By using flex boxes instead of tables we can make the app respond gracefully to changes in the size of the display without resorting to the bureaucracy of overdefining style properties. Note that our app does not use the HTML <table> element any more for aligning pieces of content. We use a lot of the CSS-3 features, including variables , and calc() . This lessens our need for a style sheet preprocessor such as SASS to 0%. Note especially how colour management has become easy: all colour definitions are in variables all colour definitions are in HSLA , which allows a very consistent definition of families of colours. Quote from Mozilla : One advantage of HSLA over RGB is that it is more intuitive: you can guess 1 2 3 at the color you want, and tweak it from there. It is also easier to create a set of matching colors (e.g., by keeping the hue the same, while varying the lightness/darkness and saturation). This is exactly what we do. See vars.css . Shell \u00b6 The shell is the interpreter of system level commands. Our app does not use it, but we use it to develop the app. All the development tasks, such as transpiling code, pushing code to GitHub, transporting databases to the production server are done by specialized frameworks. These frameworks must be steered by intricate commands with many options which are easily forgotten. That's why we have a build script. You have to pass it just the name of a task, and the script executes that task with all the sophistication needed. HTML \u00b6 The core language of the web. Surprisingly, our code does not contain HTML any more. In JSX there are fragments that look like HTML, but that is exactly what it is, and real HTML it is not. When the browser encounters HTML material, it parses it and stores it in its memory in a certain standard representation: the DOM . But our server does not send HTML any more to the browser, except for a very first short page , that serves to load a bulk of style sheets and JavaScript into the browser. This JavaScript code builds and manipulates the DOM directly, without generating any formal HTML. JSON \u00b6 A format to serialize JavaScript objects. In web applications, the program logic happens at two separate places (at least): the server and the client. It is important that data can flow seamlessly from one programming context to the other. JSON achieves that. In our app, we use JSON: to send data from server to client configure the main development tools, such as Webpack for building and Mocha for testing. Keeping the code tidy \u00b6 There are three progressive levels of caring for your code. Level 1 is adopting a style guide and meticulously keeping to it. It is hard, especially if you work in two syntactically and culturally diverse languages such as JavaScript and Python. Add CSS, Markdown and YAML to the mix, and you can feel the need for a next step. Yet this is the fundamental step, it cannot be skipped. Level 2 is using linters . They are little programs that observe your code and check it for correctness and style, as far as that is possible without actually running the code. Usually, your editing environment runs them sneakily while you type or when you save, and give you unobtrusive but conspicuous feedback. It saves you a lot of round trips of compiling/building/running/staring at errors. Moreover, it gives you the feedback right where you are typing, so you do not have to lookup files and line numbers. Sometimes linters give you so much feedback that your heart sinks at the thought of going through all those cases and fix them all, even if you have a splendid IDE. That is where the next step comes in. Level 3 is using formatters . They have a lot in common with linters, but they fix the problems. Sometimes they parse your program with the parser of the language and then format the abstract syntax three they've got. That is the end of all style inconsistencies. Tools \u00b6 For JavaScript we use eslint as linter, and prettier as formatter. For Python we use flake8 as linter, and yapf as formatter. For Markdown we use remark as linter. As formatter we use a combo: first prettier (which can wrap long lines, and then remark . Formatters are not perfect, sometimes they produce code at which the linter balks, especially yapf is doing that. Luckily, you can selectively suppress certain kinds of transformations. Editor or IDE? \u00b6 For projects like these, you need a good editing environment. IDEs can give you that, but the good old ones like Eclipse are not really suited to the JavaScript and Python environments. There are interesting modern ones such as GitHub's Atom modernized ones such as Microsoft's Visual Studio Code and commercial ones such as Webstorm . You can also choose to work with a text editor, such as the free Vim or the commercial Sublime Text . My choice has been Vim, since I use it from its start in 1991. These are the key reasons for which Vim stands out: it has a compositional command set, like Unix itself. By this you get all your (massive) editing chores done. it has a rich ecosystem of plugins. By this you can turn Vim into an IDE. It is rock solid. You can edit many small files and then some big ones, at the same time. You do not loose data. Just for the record, here is a piece of my .vimrc file (the configuration file, which draws in plugins, and customises the interface). You can find out more about the plugins by visiting GitHub and append the full plugin reference to the URL, since they are all GitHub repos. 1 2 3 4 5 6 7 8 9 10 11 call plug#begin () Plug 'jelera/vim-javascript-syntax' Plug 'pangloss/vim-javascript' Plug 'mxw/vim-jsx' Plug 'hail2u/vim-css3-syntax' Plug 'nathanaelkane/vim-indent-guides' Plug 'othree/yajs.vim' Plug 'othree/javascript-libraries-syntax.vim' Plug 'scrooloose/nerdtree' Plug 'w0rp/ale' call plug# end () An honourable mention for the ALE plugin. This is an arch plugin that invokes linters for your files while you edit. The beauty is, that if you have installed the linters first outside Vim, ALE is smart enough to detect them and run them for you, asynchronously, and with zero configuration.","title":"Codebase"},{"location":"About/Codebase/#codebase","text":"","title":"Codebase"},{"location":"About/Codebase/#statistics","text":"cloc tool Statistics","title":"Statistics"},{"location":"About/Codebase/#legend","text":"The numbers stand for lines of code. 1000 lines is ~ 20 typed A4 pages of text.","title":"Legend"},{"location":"About/Codebase/#yaml","text":"A simple plain-text way to convey structured data. What Markdown is to text, YAML is to XML-JSON. In this app we use YAML for configuration details. the conversion of legacy contribution data into MongoDB is steered by a config.yaml . the data model lists all the tables and fields, including how they hang together and how we want to represent them on screen. It also defines access control. If you, as developer, need to add new tables and fields, you can do so by modifying these files: model per table . No extra coding is needed.","title":"YAML"},{"location":"About/Codebase/#markdown","text":"A simple plain-text way to write formatted text. See it as a shortcut to writing HTML. It is handy for writing documentation without being distracted by too many formatting options and issues, as you experience when writing in Word or plain HTML. Markdown is usually converted to HTML, but even when it is not converted, it is still very readable. If you use GitHub, one of the first things is to write a README file for your project. This must be a markdown file. If you use other documentation options on GitHub, such as Wiki or Pages, you will also write markdown. Markdown has a sister: YAML , which is used for structured data. In this app we use markdown in the following ways: all documentation here is written in markdown the app can present markdown documents all big text fields in this app support markdown.","title":"Markdown"},{"location":"About/Codebase/#javascript","text":"The principal scripting language for web applications. It has evolved into a performant language with a beautiful syntax, capable of running on the server and in websites. This app uses JavaScript in the client only. We use it as a work horse which takes care of a copy of data from the database. It reacts to changes by integrating new bits of data into the existing state, a process that is called reducing .","title":"JavaScript"},{"location":"About/Codebase/#jsx","text":"This is also JavaScript, but with a thin layer of syntactic sugar, by which you can present your code as a collection of React components . In this app we have dozens of JSX files, each containing exactly one component (with a few exceptions). Components are pieces of code that realize parts of the website that you can actually see, and often interact with. They are supported by sophisticated plumbing (dux, ducts) , which connects them to the global state of the app. The state is divided in sections, where individual duct connects such a section with several components. See Architecture for how this hangs together. The plumbing needs some specialized, technical functions, which are collected in the lib section of the app. One of the most crucial is memoization .","title":"JSX"},{"location":"About/Codebase/#python","text":"A general purpose scripting language with excellent data processing facilities. This app uses python (version 3.6.1+) for the web server. The web server itself is Flask , a light-weight framework for handling http(s) requests. We have added a set of controllers . The actual code there is quite lean, but when it comes to database access, the module db does the heavy lifting and tends to become uglier and uglier.","title":"Python"},{"location":"About/Codebase/#css","text":"Styling the app has nightmarish overtones, because the concerns of style often cut right across the concerns of the components. There are several ways to control the resulting mess, and one of the best is to use the modern features of CSS. Cascading style sheets are the ultimate way to paint the final look and feel of the website. By using flex boxes instead of tables we can make the app respond gracefully to changes in the size of the display without resorting to the bureaucracy of overdefining style properties. Note that our app does not use the HTML <table> element any more for aligning pieces of content. We use a lot of the CSS-3 features, including variables , and calc() . This lessens our need for a style sheet preprocessor such as SASS to 0%. Note especially how colour management has become easy: all colour definitions are in variables all colour definitions are in HSLA , which allows a very consistent definition of families of colours. Quote from Mozilla : One advantage of HSLA over RGB is that it is more intuitive: you can guess 1 2 3 at the color you want, and tweak it from there. It is also easier to create a set of matching colors (e.g., by keeping the hue the same, while varying the lightness/darkness and saturation). This is exactly what we do. See vars.css .","title":"CSS"},{"location":"About/Codebase/#shell","text":"The shell is the interpreter of system level commands. Our app does not use it, but we use it to develop the app. All the development tasks, such as transpiling code, pushing code to GitHub, transporting databases to the production server are done by specialized frameworks. These frameworks must be steered by intricate commands with many options which are easily forgotten. That's why we have a build script. You have to pass it just the name of a task, and the script executes that task with all the sophistication needed.","title":"Shell"},{"location":"About/Codebase/#html","text":"The core language of the web. Surprisingly, our code does not contain HTML any more. In JSX there are fragments that look like HTML, but that is exactly what it is, and real HTML it is not. When the browser encounters HTML material, it parses it and stores it in its memory in a certain standard representation: the DOM . But our server does not send HTML any more to the browser, except for a very first short page , that serves to load a bulk of style sheets and JavaScript into the browser. This JavaScript code builds and manipulates the DOM directly, without generating any formal HTML.","title":"HTML"},{"location":"About/Codebase/#json","text":"A format to serialize JavaScript objects. In web applications, the program logic happens at two separate places (at least): the server and the client. It is important that data can flow seamlessly from one programming context to the other. JSON achieves that. In our app, we use JSON: to send data from server to client configure the main development tools, such as Webpack for building and Mocha for testing.","title":"JSON"},{"location":"About/Codebase/#keeping-the-code-tidy","text":"There are three progressive levels of caring for your code. Level 1 is adopting a style guide and meticulously keeping to it. It is hard, especially if you work in two syntactically and culturally diverse languages such as JavaScript and Python. Add CSS, Markdown and YAML to the mix, and you can feel the need for a next step. Yet this is the fundamental step, it cannot be skipped. Level 2 is using linters . They are little programs that observe your code and check it for correctness and style, as far as that is possible without actually running the code. Usually, your editing environment runs them sneakily while you type or when you save, and give you unobtrusive but conspicuous feedback. It saves you a lot of round trips of compiling/building/running/staring at errors. Moreover, it gives you the feedback right where you are typing, so you do not have to lookup files and line numbers. Sometimes linters give you so much feedback that your heart sinks at the thought of going through all those cases and fix them all, even if you have a splendid IDE. That is where the next step comes in. Level 3 is using formatters . They have a lot in common with linters, but they fix the problems. Sometimes they parse your program with the parser of the language and then format the abstract syntax three they've got. That is the end of all style inconsistencies.","title":"Keeping the code tidy"},{"location":"About/Codebase/#tools","text":"For JavaScript we use eslint as linter, and prettier as formatter. For Python we use flake8 as linter, and yapf as formatter. For Markdown we use remark as linter. As formatter we use a combo: first prettier (which can wrap long lines, and then remark . Formatters are not perfect, sometimes they produce code at which the linter balks, especially yapf is doing that. Luckily, you can selectively suppress certain kinds of transformations.","title":"Tools"},{"location":"About/Codebase/#editor-or-ide","text":"For projects like these, you need a good editing environment. IDEs can give you that, but the good old ones like Eclipse are not really suited to the JavaScript and Python environments. There are interesting modern ones such as GitHub's Atom modernized ones such as Microsoft's Visual Studio Code and commercial ones such as Webstorm . You can also choose to work with a text editor, such as the free Vim or the commercial Sublime Text . My choice has been Vim, since I use it from its start in 1991. These are the key reasons for which Vim stands out: it has a compositional command set, like Unix itself. By this you get all your (massive) editing chores done. it has a rich ecosystem of plugins. By this you can turn Vim into an IDE. It is rock solid. You can edit many small files and then some big ones, at the same time. You do not loose data. Just for the record, here is a piece of my .vimrc file (the configuration file, which draws in plugins, and customises the interface). You can find out more about the plugins by visiting GitHub and append the full plugin reference to the URL, since they are all GitHub repos. 1 2 3 4 5 6 7 8 9 10 11 call plug#begin () Plug 'jelera/vim-javascript-syntax' Plug 'pangloss/vim-javascript' Plug 'mxw/vim-jsx' Plug 'hail2u/vim-css3-syntax' Plug 'nathanaelkane/vim-indent-guides' Plug 'othree/yajs.vim' Plug 'othree/javascript-libraries-syntax.vim' Plug 'scrooloose/nerdtree' Plug 'w0rp/ale' call plug# end () An honourable mention for the ALE plugin. This is an arch plugin that invokes linters for your files while you edit. The beauty is, that if you have installed the linters first outside Vim, ALE is smart enough to detect them and run them for you, asynchronously, and with zero configuration.","title":"Editor or IDE?"},{"location":"About/Diagrams/","text":"Diagrams \u00b6 Architecture \u00b6 Authentication \u00b6 Business \u00b6 Components \u00b6 Dux \u00b6 Routing \u00b6 Workflow \u00b6","title":"Diagrams"},{"location":"About/Diagrams/#diagrams","text":"","title":"Diagrams"},{"location":"About/Diagrams/#architecture","text":"","title":"Architecture"},{"location":"About/Diagrams/#authentication","text":"","title":"Authentication"},{"location":"About/Diagrams/#business","text":"","title":"Business"},{"location":"About/Diagrams/#components","text":"","title":"Components"},{"location":"About/Diagrams/#dux","text":"","title":"Dux"},{"location":"About/Diagrams/#routing","text":"","title":"Routing"},{"location":"About/Diagrams/#workflow","text":"","title":"Workflow"},{"location":"About/Lessons/","text":"Lessons \u00b6 Because it took so long to develop this tool, and because it has grown so big, I started reflecting on the choices I've made, and the things I've learned. What follows can be read as a self-assessment of the development process. \"Best\" practices \u00b6 The tool has been built using modern, top-notch, popular frameworks and tools, such as React, MongoDb, Python, modern Javascript (ES6), and its documentation is in Markdown on Github. But it is a complex beast, and it will be hard for other developers to dive in. Developers that want to upgrade this tool, should be seasoned React developers, or they should be willing and have time to enter a steep learning curve. This approach - alternative approaches \u00b6 A quick glance at the statistics of the code base makes clear the amount of thought that has gone into the tool. I have asked myself the question: why do we need so much programming for such a mundane task? Is it really necessary to build something this big for it? The answer: to my best knowledge, yes, but I'm open to be contradicted. What could we have done differently? More classical framework: Django \u00b6 We could have used Django, but then we would have missed the opportunity to engage in real modern web application programming. The Javascript world is brewing with dynamics and innovation, and we would have skipped all that. Besides, also a Django application would contain a considerable amount of custom programming. Generic app/framework \u00b6 We could have used an app like Trello or Basecamp, or a content management system that has not been designed to support a specific workflow like this. We would have had several disadvantages: an extra dependency on a Silicon-Valley service the struggle to customize the service the need to instruct the users to use the system according to the intended workflow. This approach: from the ground up \u00b6 What we have now, is something that has been built from the ground up. We have total control over all aspects of the app, its data, and the servers at which it runs. We can connect it to other apps, define new microservices around it quite easily. So, the price has been high, much higher than I expected (and promised), but I think we've got something to build on. The learning curve (for what it is worth) \u00b6 When I started writing, I had the experience of developing SHEBANQ . At first, the tools I used for SHEBANQ were a model for developing this contrib tool. From the start it was clear that the contrib tool needed more profound underpinnings. I started out to write those underpinnings myself, programmed in pure, modern Javascript. That worked to a certain extent, but I doubted whether it was strong enough to carry the weight of the full app. After a while I started a big search, trying Google's Angular, Facebook's React, and various solutions that combined these frameworks in so-called full-stack setups, such as Meteor and MERN . Here is a selection of 10 lessons I learned during what followed. Lesson 1: exit full-stack \u00b6 Without any experience in React or Angular, it was simply too hard to get started with any of the combined solutions. They were cutting edge, evolving in a rapid sequence of versions, and examples on the internet almost never worked because of being outdated already. Without having an understanding already of the intention, I found it impossible to overcome the discrepancies between theory and practice. Lesson 2: Angular versus react \u00b6 I had to choose between Angular and React, and I choose React because: it had more limited goals, combined better with the other parts of the app, was more popular among developers, and was a natural continuation of the work I had already done in my self-made framework. Angular had just moved to version 2, the learning curve had steepened, and I heard developers say that at first it worked like a charm, but that it was very hard to move beyond tutorial level. Lesson 3: Beyond vanilla React \u00b6 React was not enough. After achieving a lot of functionality, I reached a stage where I encountered bugs that I could not solve. My app became too big for vanilla React, and I needed Redux , an add-on that provides an app-wide data structure (central state). Lesson 4: Grokking Redux \u00b6 To get started with Redux I needed a course. Without it, I could not get to grips with it. I watched 30 online video's by the maker of it, Dan Abramov, also developer at Facebook for React. After the videos I could not remember how I could NOT understand it. Lesson 5: Idiomatic Redux and code organization \u00b6 After using Redux throughout the app, the code started to look much better, and I got much better control over the workings of the app. On the internet, this is called: \"idiomatic Redux\". It is a kind of Javascript that old fashioned web programmers hardly recognise as Javascript! It is very important to follow up all the best practices that are advised here, because the performance and correctness of the app depend crucially on them all. What also helped is a hint by Erik Ras, creator of redux-form , to organize your redux code in files: the concept of ducks . Lesson 6: CRUD layer \u00b6 Some operations are so ubiquitous, that you have to program them once and for all: create/update/delete/read of database items (CRUD), all subject to user permissions. All things that are particular to specific tables and fields must be specified as configuration, all actions must read the configs and carry out generic code. Lesson 7: Custom Workflow layer \u00b6 You cannot do all the business logic this way, without overloading your nice generic system. So the app has two layers of abstraction: level 1 for CRUD, level 2 for additional workflow. It is level 2 that your users will interact with most. Lesson 8: Hooks and config for workflow \u00b6 instead of applying workflow functions in an add-hoc manner, you should add hooks at key points of the CRUD code. Only at those hooks the workflow functions are given a say in the matter. These workflow functions should again be programmed in a generic way, with the particulars moved to an other level of configuration. Lesson 9: Build tools: Webpack \u00b6 To be able to run the app and to ship it to the outside world, your build-system should be top-of-the bill. I started with just a little script of my own to massage the code into a web-app bundle. Then I moved to Gulp and used it for a long time. I saw that the React people were using Webpack all the time, but I could barely understand Webpack, let alone get it working. In the end, I decided that I wanted Webpack no matter what, and got it working, including all the niceties it had to offer. The result: for production I can ship very compact code, in such a way that the client web browsers load it very fast; for development, I have a very easy and short feedback loop: when I save my code, it is automatically rebuilt, and in a fraction of a second the updated modules reload in the browser, and when there are errors, I get pointed to the exact line in the code where it went wrong. Lesson 10: Trust React \u00b6 React is really well-designed, it does not let you down, you do not have to look under the hood, and it gives very helpful debug messages. The contrib app is growing and contains dozens of components, but the performance remains excellent. Before I used idiomatic Redux, the performance was worrying at times.","title":"Lessons"},{"location":"About/Lessons/#lessons","text":"Because it took so long to develop this tool, and because it has grown so big, I started reflecting on the choices I've made, and the things I've learned. What follows can be read as a self-assessment of the development process.","title":"Lessons"},{"location":"About/Lessons/#best-practices","text":"The tool has been built using modern, top-notch, popular frameworks and tools, such as React, MongoDb, Python, modern Javascript (ES6), and its documentation is in Markdown on Github. But it is a complex beast, and it will be hard for other developers to dive in. Developers that want to upgrade this tool, should be seasoned React developers, or they should be willing and have time to enter a steep learning curve.","title":"\"Best\" practices"},{"location":"About/Lessons/#this-approach-alternative-approaches","text":"A quick glance at the statistics of the code base makes clear the amount of thought that has gone into the tool. I have asked myself the question: why do we need so much programming for such a mundane task? Is it really necessary to build something this big for it? The answer: to my best knowledge, yes, but I'm open to be contradicted. What could we have done differently?","title":"This approach - alternative approaches"},{"location":"About/Lessons/#more-classical-framework-django","text":"We could have used Django, but then we would have missed the opportunity to engage in real modern web application programming. The Javascript world is brewing with dynamics and innovation, and we would have skipped all that. Besides, also a Django application would contain a considerable amount of custom programming.","title":"More classical framework: Django"},{"location":"About/Lessons/#generic-appframework","text":"We could have used an app like Trello or Basecamp, or a content management system that has not been designed to support a specific workflow like this. We would have had several disadvantages: an extra dependency on a Silicon-Valley service the struggle to customize the service the need to instruct the users to use the system according to the intended workflow.","title":"Generic app/framework"},{"location":"About/Lessons/#this-approach-from-the-ground-up","text":"What we have now, is something that has been built from the ground up. We have total control over all aspects of the app, its data, and the servers at which it runs. We can connect it to other apps, define new microservices around it quite easily. So, the price has been high, much higher than I expected (and promised), but I think we've got something to build on.","title":"This approach: from the ground up"},{"location":"About/Lessons/#the-learning-curve-for-what-it-is-worth","text":"When I started writing, I had the experience of developing SHEBANQ . At first, the tools I used for SHEBANQ were a model for developing this contrib tool. From the start it was clear that the contrib tool needed more profound underpinnings. I started out to write those underpinnings myself, programmed in pure, modern Javascript. That worked to a certain extent, but I doubted whether it was strong enough to carry the weight of the full app. After a while I started a big search, trying Google's Angular, Facebook's React, and various solutions that combined these frameworks in so-called full-stack setups, such as Meteor and MERN . Here is a selection of 10 lessons I learned during what followed.","title":"The learning curve (for what it is worth)"},{"location":"About/Lessons/#lesson-1-exit-full-stack","text":"Without any experience in React or Angular, it was simply too hard to get started with any of the combined solutions. They were cutting edge, evolving in a rapid sequence of versions, and examples on the internet almost never worked because of being outdated already. Without having an understanding already of the intention, I found it impossible to overcome the discrepancies between theory and practice.","title":"Lesson 1: exit full-stack"},{"location":"About/Lessons/#lesson-2-angular-versus-react","text":"I had to choose between Angular and React, and I choose React because: it had more limited goals, combined better with the other parts of the app, was more popular among developers, and was a natural continuation of the work I had already done in my self-made framework. Angular had just moved to version 2, the learning curve had steepened, and I heard developers say that at first it worked like a charm, but that it was very hard to move beyond tutorial level.","title":"Lesson 2: Angular versus react"},{"location":"About/Lessons/#lesson-3-beyond-vanilla-react","text":"React was not enough. After achieving a lot of functionality, I reached a stage where I encountered bugs that I could not solve. My app became too big for vanilla React, and I needed Redux , an add-on that provides an app-wide data structure (central state).","title":"Lesson 3: Beyond vanilla React"},{"location":"About/Lessons/#lesson-4-grokking-redux","text":"To get started with Redux I needed a course. Without it, I could not get to grips with it. I watched 30 online video's by the maker of it, Dan Abramov, also developer at Facebook for React. After the videos I could not remember how I could NOT understand it.","title":"Lesson 4: Grokking Redux"},{"location":"About/Lessons/#lesson-5-idiomatic-redux-and-code-organization","text":"After using Redux throughout the app, the code started to look much better, and I got much better control over the workings of the app. On the internet, this is called: \"idiomatic Redux\". It is a kind of Javascript that old fashioned web programmers hardly recognise as Javascript! It is very important to follow up all the best practices that are advised here, because the performance and correctness of the app depend crucially on them all. What also helped is a hint by Erik Ras, creator of redux-form , to organize your redux code in files: the concept of ducks .","title":"Lesson 5: Idiomatic Redux and code organization"},{"location":"About/Lessons/#lesson-6-crud-layer","text":"Some operations are so ubiquitous, that you have to program them once and for all: create/update/delete/read of database items (CRUD), all subject to user permissions. All things that are particular to specific tables and fields must be specified as configuration, all actions must read the configs and carry out generic code.","title":"Lesson 6: CRUD layer"},{"location":"About/Lessons/#lesson-7-custom-workflow-layer","text":"You cannot do all the business logic this way, without overloading your nice generic system. So the app has two layers of abstraction: level 1 for CRUD, level 2 for additional workflow. It is level 2 that your users will interact with most.","title":"Lesson 7: Custom Workflow layer"},{"location":"About/Lessons/#lesson-8-hooks-and-config-for-workflow","text":"instead of applying workflow functions in an add-hoc manner, you should add hooks at key points of the CRUD code. Only at those hooks the workflow functions are given a say in the matter. These workflow functions should again be programmed in a generic way, with the particulars moved to an other level of configuration.","title":"Lesson 8: Hooks and config for workflow"},{"location":"About/Lessons/#lesson-9-build-tools-webpack","text":"To be able to run the app and to ship it to the outside world, your build-system should be top-of-the bill. I started with just a little script of my own to massage the code into a web-app bundle. Then I moved to Gulp and used it for a long time. I saw that the React people were using Webpack all the time, but I could barely understand Webpack, let alone get it working. In the end, I decided that I wanted Webpack no matter what, and got it working, including all the niceties it had to offer. The result: for production I can ship very compact code, in such a way that the client web browsers load it very fast; for development, I have a very easy and short feedback loop: when I save my code, it is automatically rebuilt, and in a fraction of a second the updated modules reload in the browser, and when there are errors, I get pointed to the exact line in the code where it went wrong.","title":"Lesson 9: Build tools: Webpack"},{"location":"About/Lessons/#lesson-10-trust-react","text":"React is really well-designed, it does not let you down, you do not have to look under the hood, and it gives very helpful debug messages. The contrib app is growing and contains dozens of components, but the performance remains excellent. Before I used idiomatic Redux, the performance was worrying at times.","title":"Lesson 10: Trust React"},{"location":"About/News/","text":"News \u00b6 2019-05-03 \u00b6 The overview page lead to a server error in some circumstances. The critical error is fixed, maybe there is an other root cause to discover. 2019-04-24 \u00b6 The info page with tables that give an overview of the DARIAH contributions now have a button to download the overview to Excel. The Excel data is based on the same data as the overview. The format is csv (technically: in utf-16-le with BOM mark). This format can be opened without questions by Excel and Numbers. 2019-03-04 \u00b6 Bottle has been replaced by Flask also online 2018-12-11 \u00b6 Bottle has been replaced by Flask (not yet online) 2017-12-14 \u00b6 The workflow functions have developed into a serious engine, that can be configured from within the data model. Templates are the prime consumers of this information. The review workflow is implemented. Not yet in all fullness, but the basics such as advice by the first reviewer, decision by the second reviewer work, as well as marking a successfully reviewed contribution as DARIAH approved. For Python, Javascript and Markdown I have started using code formatters. So the exact formatting of all these sources are not my doing, but the work of carefully configured software tools. That brings a bit more consistency in the sources. I have done a lot of documentation updates. 2017-09-22 \u00b6 There is now a templating mechanism in place by which I can design the display of detail records and related records within the display of another record. I use this to customise the criteriaEntry records within an assessment, as well as the contribution record within an assessment. Specific workflow code has factored out of the generic code, both in the client app as well as in the server modules. The server documentation has been updated. Bugs have been fixed, and probably more have been introduced. 2017-09-21 \u00b6 The presentation of assessment is developing to much more useful layouts. Lots of issues of an information-logistic nature had to be solved. Talking of which: the conversion of legacy content has now improved. The import is repeatable, and will not disturb data that has been added later, using the contribution tool itself. Read more . 2017-07-01 \u00b6 Functionally \u00b6 The app can now create assessments and populate an assessment with the relevant criteria based on the type of the contribution being assessed and the current package. A version of a few dozen real world criteria and their scoring has been added to the database. Technically \u00b6 We count the lines of code in all formats used. See the codebase page. Many changes in the table area: lists and items and filters. It has become more generic. Master-detail relations can be defined and utilized. New custom business logic is being introduced. The reducers work better, and leave more parts of the state untouched if they have not changed. The replacement of lodash/merge by Immutability-Helper plays a big part in this. Merging and reducing are now being unit-tested. We have put the Mocha test framework to use and built hundreds of tests. The documentation has been reworked extensively. 2017-05-19 \u00b6 Fixed subtle issues in form entry: FieldEdit and InputMulti .","title":"News"},{"location":"About/News/#news","text":"","title":"News"},{"location":"About/News/#2019-05-03","text":"The overview page lead to a server error in some circumstances. The critical error is fixed, maybe there is an other root cause to discover.","title":"2019-05-03"},{"location":"About/News/#2019-04-24","text":"The info page with tables that give an overview of the DARIAH contributions now have a button to download the overview to Excel. The Excel data is based on the same data as the overview. The format is csv (technically: in utf-16-le with BOM mark). This format can be opened without questions by Excel and Numbers.","title":"2019-04-24"},{"location":"About/News/#2019-03-04","text":"Bottle has been replaced by Flask also online","title":"2019-03-04"},{"location":"About/News/#2018-12-11","text":"Bottle has been replaced by Flask (not yet online)","title":"2018-12-11"},{"location":"About/News/#2017-12-14","text":"The workflow functions have developed into a serious engine, that can be configured from within the data model. Templates are the prime consumers of this information. The review workflow is implemented. Not yet in all fullness, but the basics such as advice by the first reviewer, decision by the second reviewer work, as well as marking a successfully reviewed contribution as DARIAH approved. For Python, Javascript and Markdown I have started using code formatters. So the exact formatting of all these sources are not my doing, but the work of carefully configured software tools. That brings a bit more consistency in the sources. I have done a lot of documentation updates.","title":"2017-12-14"},{"location":"About/News/#2017-09-22","text":"There is now a templating mechanism in place by which I can design the display of detail records and related records within the display of another record. I use this to customise the criteriaEntry records within an assessment, as well as the contribution record within an assessment. Specific workflow code has factored out of the generic code, both in the client app as well as in the server modules. The server documentation has been updated. Bugs have been fixed, and probably more have been introduced.","title":"2017-09-22"},{"location":"About/News/#2017-09-21","text":"The presentation of assessment is developing to much more useful layouts. Lots of issues of an information-logistic nature had to be solved. Talking of which: the conversion of legacy content has now improved. The import is repeatable, and will not disturb data that has been added later, using the contribution tool itself. Read more .","title":"2017-09-21"},{"location":"About/News/#2017-07-01","text":"","title":"2017-07-01"},{"location":"About/News/#functionally","text":"The app can now create assessments and populate an assessment with the relevant criteria based on the type of the contribution being assessed and the current package. A version of a few dozen real world criteria and their scoring has been added to the database.","title":"Functionally"},{"location":"About/News/#technically","text":"We count the lines of code in all formats used. See the codebase page. Many changes in the table area: lists and items and filters. It has become more generic. Master-detail relations can be defined and utilized. New custom business logic is being introduced. The reducers work better, and leave more parts of the state untouched if they have not changed. The replacement of lodash/merge by Immutability-Helper plays a big part in this. Merging and reducing are now being unit-tested. We have put the Mocha test framework to use and built hundreds of tests. The documentation has been reworked extensively.","title":"Technically"},{"location":"About/News/#2017-05-19","text":"Fixed subtle issues in form entry: FieldEdit and InputMulti .","title":"2017-05-19"},{"location":"About/Stats/","text":"cloc github.com/AlDanial/cloc v 1.82 T=2.31 s (108.4 files/s, 16156.5 lines/s) Language files blank comment code JavaScript 59 476 451 9759 Markdown 38 2253 0 5387 JSX 58 313 77 5128 Python 14 565 304 4048 YAML 20 197 12 3824 CSS 19 40 19 1448 HTML 29 483 0 965 Jupyter Notebook 2 0 636 249 Bourne Shell 6 45 63 201 JSON 4 0 0 177 XML 1 0 0 128 -------- -------- -------- -------- -------- SUM: 250 4372 1562 31314","title":"Stats"},{"location":"Client/Components/","text":"Components (React) \u00b6 These are the React components, that make up the part of the app that is visible in the browser. They lean on the dux that work for them in the background. Click on the names in the titles to view their source code on GitHub. Standard props \u00b6 Components get properties as input (we call them props ). For each component we mention the props they expect and what type of data they represent. However, some props occur over and over again, and we name them consistently. Here is a list of those props and their types. When we mention these props later on, we omit the types. alter object ; a slice of the state from getAltSection ; Group of settings for components with alternative renderings: these settings tell which alternative has been chosen for each of those components; alterSection string ; name of a section of the alter state; such a section contains the choice of alternative for a bunch of components that are relevant to the present component; each component that requests data from alter only gets data for a single section; in this way components will not be dependent on too big a part of the state; those dependencies may cause spurious re-renderings; alterTag string ; name that lives within a section of the alter state; this functions as the address of a component that needs to expand or collapse; the triggering event will change the alter state, keyed by alterSection and then by alterTag ; amounts object ; for a faceted filter: contains the amount of items that match each facet; see computeFiltering ; children components ; a special prop defined by React itself; it contains the material that has been put in the component; you find it in the render function of the component; it is everything between <Component> and </Component> ; className string ; a class name to be put in the top level element of the rendered component; compact bool ; whether the component should minimize the real estate on the screen that it uses; detailFragments array of object ; the information on the basis of which the detail records of an item can be rendered; every entry in the array corresponds to a detail table that may contain detail records of the master record that is being dealt with; ultimately computed by makeDetails and then passed to child components; dispatch function ; this function belongs to the store that holds the state; it is generally injected into the props of a component by connect ing a component to the store; this only happens if connect() is called with zero or one argument (the MapDispatchToProps argument should be undefined); the dispatch function enables the component to trigger an action that changes the state; where you would call setState() in vanilla-React you put dispatch(action) if your app uses Redux; eId string ; the MongoDB id of an entity that is being dealt with; field string ; the name of a field that is being dealt with; fieldFragments array an array with instructions per field how to render it; ultimately computed by makeFields and then passed to child components; filtered bool ; whether the list should be accompanied by filters; the specification of the filters themselves is in the data model ; fields objects ; defines a subset of all fields: these are the fields that the component has to deal with; filteredAmount number ; the number of items that pass all filters; see computeFiltering ; filteredAmountOthers object ; for each filter, the amount of items that passes all filters except that one filter; see computeFiltering ; filterField string ; the name of the field that the current filter is acting upon; (as in the data model ; filterRelField string ; the name of the related field that the current filter is acting upon; this is relevant for fields that point to a related table: you can filter on the values of a specific field in the related table; (as in the data model ; filterId number ; the sequence number of a specific filter which identifies it among all filters for the same table; filterLabel string ; the user-facing name of the filter; filters object ; a slice of the state from getFilters ; contains the actual filter settings, i.e. what the user has entered in search boxes and which facets the user has clicked; organized by table and then by filterTag and then by filterId ; filterSettings object ; a slice of the state, sub-slice of filters , corresponding to the filters of a single filterTag of a single table ; filterSetting object or string ; a slice of the state, sub-slice of filterSetting , corresponding to a single filter, identified by filterId ; whether this is an object or a string, depends on the nature of the filter: for a Fulltext filter it is a string (the search text), for a ByValue filter it is an object, containing the status (boolean) of all its facet checkboxes; filterTag string ; identifies a group of filters for a single table; tables may have multiple incarnations; a table can be a main table, but also a detail table for a specific record; the filters for a table when it displays details may be distinct from the filters of the same table when it is displayed as the main table; we separate those cases by means of a filterTag prop; linkField string ; when rendering a list of records that are details of some master record, this is the field of the detail records that holds the masterId ; in this way the detail record links to its master record; when the component creates a new detail record, it will pre-fill this field with the current masterId ; listIds array of string ; a sequence of strings which are essentially MongoDB identifiers of entities in a table; components that display lists use this prop to determine which entities must be actually appear on the screen and in what order; see also the prop filteredIds ; masterId string ; when rendering a list of records that are details of some master record, this holds the MongoDB id of the master record; me object ; a slice of the state from getMe ; the information about the currently logged-in user, fetched from the server; mode string ; either list or grid ; whether the list of items should render as a list of expandable headings, or as a grid with full field information; perm object ; Holds permissions for a record: whether deleting is allowed, and per field whether updating is allowed; myValues object ; ultimately extracted from the tables slice of the state; it contains the values of the fields of the entity that is being dealt with; select string ; sometimes a list is fetched as a whole, sometimes only my own records are displayed and yet other times only records that are the details of some master record must be shown; this property indicates which is which; settings object ; a slice of the state from getSettings ; settings are pieces of custom information that are relevant to many components of the app; table string ; name of the table that the component must deal with; submitValues function ; a callback that is used to save form values to the database; used for components that supply edit controls for form values: they can call submitValues after a change or upon loss of focus; it is basically the handleSubmit from Redux-From, with a specific first argument passed ( toDb ) that saves values to the database; tables object ; a slice of the state from getTables ; all data that comes from database tables; organized by table name; for each table there is spec information and actual entity data; win { width number , height number } ; a slice of the state from getWinDim ; contains the physical dimensions of the window at any time. roots \u00b6 main \u00b6 connected via roots Task \u00b6 Entry point of the client side app. Contains the routing , wrapped in a Root component, that sets up the store in which the central state lives. Root \u00b6 presents roots Props \u00b6 children \u00b6 Task \u00b6 Top-level wrapping component to set up the central store. It does so by configuring the store, calling configureStore , and passing it to the special Provider component of Redux. Then it wraps the whole remaining app in a Window component for detecting some global UI events. settings \u00b6 Tooltip \u00b6 (life cycle) connected via settings Task \u00b6 A dynamic tooltip, based on CSS3 techniques. The tooltip is initially put as content with an absolute position and with opcaity 0. A lot can happen on the page: scrolling, re-rendering of components, and they may all cause changes in the positions of elements. So the position of the invisible tooltip is not where it should be, most of the time. That does not matter, as long as we adjust it just in time, before it becomes visible. When that happens, the positioning of the tooltip will be adjusted to the current position of the element. The trigger to make a tooltip visible is a focus event or a mouse-over event. It is possible to switch all tooltips off. This is governed by showTooltips , a boolean setting in settings . Apart from this, the tooltip machinery does not use special React/Redux mechanisms. All is done at DOM level and with CSS3. Props \u00b6 Props \u00b6 settings \u00b6 tip string or fragment \u00b6 The content of the tooltip. Any content will do. at string \u00b6 The position of the tooltip relative to its target. Should be one of top bottom left right . The positioning algorithm looks whether there is sufficient room for the tooltip. If not, it will change top to bottom and vice versa, and left to right` and vice versa. It will also shift the tooltip so that it does not extends beyond the page. focusOnly boolean \u00b6 Whether the tooltip should be triggered by focus actions only, or hovering as well. Handy for text input elements ( <input type=\"text\"> or <textarea> ) if you want to show editing help, but only if the user is actually typing in the field. className string \u00b6 An additional CSS class to pass on to the <Tooltip> outermost element. classTip string \u00b6 An additional CSS class to pass on to the element that holds the tooltip. classArrow string \u00b6 An additional CSS class to pass on to the element that holds the little arrow of the tooltip. TooltipSwitch \u00b6 connected via settings Props \u00b6 settings dispatch \u00b6 Task \u00b6 Switches tooltips on or off, globally. workflow \u00b6 ScoreBox \u00b6 presents workflow Props \u00b6 score \u00b6 This is an object, containing several score quantities, relevant to the scoring of assessments. Task \u00b6 The server computes the scores, and delivers it as workflow attributes with contribution and assessment records. Displays the score of an assessment, and can be expanded to show a derivation of that score. It should be used in templates that have access to workflow attributes. See the mainAction templates of contrib and assessment . WorkflowInfo \u00b6 presents workflow Props \u00b6 resets \u00b6 Information about the (manual) workflow resets after the last startup of the webserver. stats \u00b6 This is an object, containing several statistical quantities about the workflow attributes. total \u00b6 The number of records that have workflow information associated with them. Task \u00b6 Present overview information about the workflow information that is currently in use. Offer a control to reset the workflow information (i.e. recompute it). See Workflow . me \u00b6 Login \u00b6 (life cycle) connected via me Props \u00b6 me dispatch \u00b6 Task \u00b6 The main task of Login is to fetch the current authentication status: is there an authenticated user, and if so, what is his/her name? SubApp \u00b6 presents win Props \u00b6 me table children \u00b6 routes components \u00b6 These are object passed by React-Router . From this the navigation route that the user has followed to arrive here, can be read. Task \u00b6 This is one of the components just below App . It contains a set of panes and navigation links to main subcomponents to display in those panes. Most of those subcomponents are linked to a main table, which is passed in the table prop. win \u00b6 App \u00b6 connected via win Props \u00b6 win children \u00b6 Task \u00b6 As far as the logic of the web page is concerned, this is the top level component. App is always in view and consists of the top navigation bar with logo, Login ; Notification ); static links to documentation. It is only used to display the height and the width somewhere on the screen. Window \u00b6 (life cycle) connected via win Props \u00b6 Task \u00b6 Detects window resize events and passes the resulting height and width of the main window to the state. On mounting an event listener is installed, and on unmounting the event handler is removed. During resizing, the frequency of emitted events is throttled to one per second, in order to prevent screen flicker. docs \u00b6 Doc \u00b6 presents docs Props \u00b6 location object \u00b6 From this object the property pathname will be read, which will be split into directory, file and extension parts. The extension is used to switch to the component for that type of documents. Task \u00b6 Handles the display of documents. Depending on the type of document (markdown, html, pdf) it delegates work to specialized document components: DocMd , DocHtml and DocPdf . DocHtml \u00b6 presents docs Props \u00b6 docDir , docName , docExt string \u00b6 The directory, filename and extension of the document container. Task \u00b6 Displays an HTML document by linking to it in an IFRAME. DocMd \u00b6 (life cycle) connected via docs Props \u00b6 alter alterSection dispatch \u00b6 docName string \u00b6 The name of the document. text string from getDoc \u00b6 The raw content of the document. Task \u00b6 Show Markdown text, coming from files on the server. The conversion to HTML is done client side, and the user gets a control to switch between Markdown source and formatted HTML. A function RouterLink is defined to wrap local links into Link components when transforming the markdown to html. It makes it possible to write Markdown documents with internal links to this application. A full link (with protocol http ( s ) is translated to a plain HTML a element, so clicking it will leave this application. DocPdf \u00b6 presents docs docDir , docName , docExt string \u00b6 The directory, filename and extension of the document container. Task \u00b6 Displays a PDF document by linking to it in an OBJECT. NB: On iOS this does not work well, only the first page of the PDF gets shown, we work around it by just displaying a link to open the PDF in a new tab. We only do that when we detect an iOS browser. notes \u00b6 Notification \u00b6 (life cycle) connected via notes Props \u00b6 dispatch \u00b6 The following properties are injected from the state by getNotes : messages array of objects \u00b6 The list of notifications that have been issued since the beginning of the session or since the last time that the user has cleared the messages. busy \u00b6 The amount of asynchronous actions that are still pending. show \u00b6 Whether the panel should be hidden. lastMsg , lastNote , lastKind \u00b6 The indexes of the last message and the last notable message, and the kind of the last notable message, which is one of error , warning , special . Only the kind info is non-special. When the notifications are displayed, the panel will be scrolled to the last notable message if there is one, otherwise to the last message. Task \u00b6 Component that receives notifications and displays them in a little panel with fixed position on the screen. The panel is hidden by default and pops up if there is an important notification. The user can click it away and also clear the notifications. There is also a progress indicator, a little circle fixed at the top right corner of the screen. It hints at the current status of asynchronous operations. A click on it will show the notifications panel. tables \u00b6 EditControl \u00b6 A component that shows the current edit status of a record. It is presented as a button that can be clicked to submit and save a form. It can only be used as descendant of a redux-form -enabled <form> -carrying component. See also EditStatus . Uses the library function editControl . EditDelete \u00b6 Button to delete the record that is displayed with it. The component is rather dumb, it needs to be passed an onClick handler that will perform the delete action. EditHelp \u00b6 Information panel below input fields and markdown fields, telling how to save and cancel, and showing the markdown constructs. EditInsert \u00b6 Button to insert a blank record into the currently displayed table. The component is rather dumb, it needs to be passed an onClick handler that will perform the insert action. EditStatus \u00b6 A component that shows the current edit status of a record. It is presented as a <span> that looks exactly as an EditControl , but it cannot be clicked to submit and save values. It can be used everywhere, and it is itself enhanced by redux-form . Because it is outside a <form> context, submitting will not work. Uses the library function editControl . FieldEdit \u00b6 connected via tables Props \u00b6 alter tables table eId field dispatch submitValues \u00b6 allowed object \u00b6 An array of entity ids that are the allowed elements when the field is a multiple choice field. ...props any \u00b6 There are many more props that get passed to FieldEdit . They have been injected by the wrapper redux-form() into ItemForm , the parent of this component, and they will be passed on to Field and FieldArray , so that they can do their magic. Task \u00b6 Edit control for an editable field. Depending on the type of the field and the multiplicity, it presents the right control. Basically, this component produces one or more Field or FieldArray components (which are provided by redux-form . Note that we do not pass the actual values to these components. They know how to get the current values from the state, and what actions must be dispatched to change them. However, both <Field /> and <FieldArray /> still do not actually present the edit control. They only do the plumbing. For the actual presentation, you can plug in a component of choice. We will use <input type=\"...\" /> , <textarea>...</textarea> elements and our own custom component RelSelect for multi-select controls. We enhance textareas by offering markdown previews of their content. See MarkdownArea . We wrap multiple *input*s in InputMulti and single inputs in Input . The extra level of wrapping of these presentational components is needed for showing validation errors. Note on the prop allowed \u00b6 In most cases a multiple choice is between members of a value list or related table, but sometimes we want to restrict the set of choices further, especially when we are offering a choice in a detail record. Then the master record might contain information that constrains the option for some fields in the detail records. For example, the criteriaEntry record contains a multiple choice field to choose between a bunch of scores. However, not all scores of the score table are valid choices, only those scores that belong to the criteria record referred by the criteriaEntry record. Caution \u00b6 In order to get everything working correctly, two problems had to be solved. Both turned out to be related to Redux-Form. The component that you pass to the component prop of Field and FieldArray must not be dynamically composed in the render() function that produces Field(Array) . Because in that case, the Field(Array) is re-rendered too often, and effect for the user is that he loses focus after entering the first character, which is very annoying. So, the value for component must be a static function. But what if this function needs dynamically determined arguments? How can they be passed to it? The solution is simple: pass them as props to Field(Array) , and they will be passed on to the component function by redux-form. This is actually documented in the redux-form docs. You need this , section 2. A stateless function You must define the stateless function outside of your render() method, or else it will be recreated on every render and will force the Field to re-render because its component prop will be different. If you are defining your stateless function inside of render(), it will not only be slower, but your input will lose focus whenever the entire form component re-renders. and this : Any custom props passed to Field will be merged into the props object on the same level as the input and meta objects. When navigating between forms for several records, the onChange callback, that should be bound to the proper form, becomes bound to the wrong form. As far as I can see, all other things work as expected, so it was difficult to see why this occurred. The explanation is in a GitHub issue . Summarized: the construction of the onChange function is effectively memoized. It is determined upon mounting of the component, but not on updating it. The workaround is easy: add an extra key property to the form. Another cause for the same problem I encountered in InputMulti , where I had memoized the callbacks for adding and removing values to/from a sequence. FieldRead \u00b6 connected via tables Props \u00b6 settings tables table myValues field \u00b6 Task \u00b6 Presents the value(s) of a read-only field, based on initial values . Note that value of type textarea will be rendered as formatted markdown. FieldSet \u00b6 presents tables Props \u00b6 submitValues \u00b6 input object \u00b6 Contains the attribute onChange by which the form value of this field can be changed. widget function \u00b6 A function that when passed a handler, will return a React fragment. When this fragment receives a click, the event handler will be called. setValue any value \u00b6 The value that will be passed to the handler of widget , when it receives a click. Task \u00b6 This is a form input component meant to be passed to a Field component, like Input . But unlike an Input , it only handles a click event, upon which it will change the value in the field to setValue , and save the form to the database. Input \u00b6 presents tables Props \u00b6 submitValues \u00b6 meta object \u00b6 Contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? input object \u00b6 Contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> . type string \u00b6 The type of <input type=\"...\" /> . It will go to the place of the dots. Task \u00b6 Shows an <input type=\"...\" /> control, and shows validation errors if the value entered by the user does not validate. It is a controlled component . InputMulti \u00b6 presents tables Props \u00b6 submitValues \u00b6 table eId fields \u00b6 componentSingle function \u00b6 The edit component that has to be rendered multiple times. validateSingle function \u00b6 Validation function. Takes a value and return undefined if all is well, and otherwise a reason why not. normalizeSingle function \u00b6 Transforms the entered value into a normalized value for saving. fields array \u00b6 The names of the individual fields. If the collective name of this field is foo , than this array contains foo[0] , foo[1] , etc., as many as their are values. These names are just strings. meta object \u00b6 Contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? ...props any \u00b6 There are many more props that must be passed to Field . They have been injected by the wrapper reduxForm() into ItemForm , the uncle ( InputMulti is passed as attribute to Field which is a child of FieldEdit ) of this component, and they are just passed on to Field and FieldArray , so that they can do their magic. Task \u00b6 Renders a sequence of Field components on behalf of a FieldArray component. There are controls to remove values, and to add fresh, empty values. Validation and normalization are done per individual Field . It is a controlled component . Insert \u00b6 Button to insert a blank record into a table. Unlike EditInsert , this does not have to be a currently displayed table. After insertion the app will navigate to the table in which the item has been inserted, and it will open the freshly created item. ItemAction \u00b6 connected via tables Props \u00b6 settings tables table eId linkField fieldFragments dispatch \u00b6 These are all the properties that ItemForm gets from its parent and from its connection with the state. But we wrap ItemForm in reduxForm() and this will inject a number of other properties into it. We list the few that we visibly use. There are more injected properties, and these we pass carefully on to other components. handleSubmit function \u00b6 A function that is invoked when the form is submitted. This function is passed from redux-form and handles all the form submission machinery. See ItemEdit . Task \u00b6 Manages the display of a single record, but only as far as an ActionTemplate has been provided for that table. The action template may contain controls that modify fields and save them to the database, exactly as ItemEdit . The component does not show save and reset buttons. It is meant for controls that save changed values on their own. This component is meant for stuff that needs to be present both in read-only view and in edit-view. Using templates \u00b6 This component uses applyEditTemplate to see whether there is an action template defined in Templates . If yes, that template will be applied, if no, nothing will be rendered. ItemContainer \u00b6 (life cycle) connected via tables Props \u00b6 settings tables table eId filters dispatch \u00b6 Task \u00b6 Container for a single record in a table. This component is responsible for fetching the item data from the database (if needed), but not form input. ItemDetails \u00b6 connected via tables Props \u00b6 alter alterSection tables table eId filters detailFragments dispatch \u00b6 Task \u00b6 Presents a list of detail items of a master record. ItemEdit \u00b6 connected via tables Props \u00b6 tables table eId fieldFragments dispatch \u00b6 nextAlt function \u00b6 This function can be used to switch this component from read-only view to edit view and back. It will be passed on to the widget that also has the edit controls for submitting and resetting the form. These are all the properties that ItemForm gets from its parent and from its connection with the state. But we wrap ItemForm in reduxForm() and this will inject a number of other properties into it. We list the few that we visibly use. There are more injected properties, and these we pass carefully on to other components. dirty boolean \u00b6 Whether the form contains changed, unsaved values in any of its fields. invalid boolean \u00b6 Whether the form contains invalid, values in any of its fields. The form uses two kinds of validation: synchronous: on every keystroke, the current value will be subjected to a validation function on submit: the submitted values will be validated on the server, and if that fails, the reasons for failure will be reported in exactly the same way as for synchronous validation. error object \u00b6 Object that contains the reasons for validation errors. submitting boolean \u00b6 Whether a submit action of the form is pending. reset boolean \u00b6 A function that can reset the form. Resetting means: changing all edited values back to the initialValues. handleSubmit function \u00b6 A function that is invoked when the form is submitted. This function is passed from redux-form and handles all the form submission machinery. It also calls a function that you can pass to it as first argument. We pass it our toDb(table, eId, mod) function. This is a function that takes a values object, and calls mod(table, eId, values) , where mod is the function that dispatches a server action: the values are sent to the server, where they are used to update the record eId in table . Task \u00b6 Manages the display and editing of a single record. It is only used if there are editable field. If that is not the case, ItemRead is being used. We do this to avoid to invoke the costly machinery of editable forms when it is not needed. The component also shows save and reset buttons (if appropriate). The component has two render modes: read-only view and edit-view. When a user has edited the form, he can switch to the read only view to see the result. In read-only view, markdown fields are rendered as formatted text, and tags in select controls do not open the choice when you click on it. Instead such a click takes to an item view of that value in its own table. We use redux-form for displaying forms, filling them out, submitting them, sending the values to the database, validating and normalizing values. Although redux-form has an awesome functionality, it is far from trivial to get it integrated. The work horses are the Field and FieldArray components. These elements can be put in an arbitrary component, under a <form/> element. The resulting component is enhanced by the reduxForm() function. The basic flow is this: we read the values of a record from the state and pass them to the redux-form component as initial values ; redux-form manages its own slice of the state ( form ) and has its own set of actions to respond to user interactions; when the user interacts with the form, the work ends up in the form slice of the state; when the form is submitted : the current values are sent to the database, and the updated record is read back from the database; the updated values are passed to the form as new initial values the form re-initializes itself, and the user can start again; when the user interrupts editing the form, and switches to another component, nothing is lost: the edits are saved in the state; when the form is mounted again, not only the initial values are fetched back, but also the edit state is restored; submitting happens with auto save : whenever an input field looses focus, the form is submitted; submitting happens also for those fields in which you can not have a cursor: whenever a field value is changed by a click, the form is submitted. Hence it is easy to edit two forms at the same time, which can be handy if (s)he edits two contributions that need to have a consistent wording. It is also possible to edit the same records in multiple components on the interface. Both refer to the same underlying state. Implementation \u00b6 The construction of the actual fields is done by a function makeFields() , that generates an array of fragments, one for each field. An editable field will be handled by a ` component, and a read-only field by a `\\ component. Using templates \u00b6 Before setting up the fields of an item, applyEditTemplate is called. If it finds a suitable template in Templates it will be applied. If not, all fields will be displayed in a generic presentation. ItemForm \u00b6 connected via tables Props \u00b6 alter alterSection tables table eId filters fields perm fieldFragments detailFragments dispatch \u00b6 initialValues object \u00b6 An object with the initial values of all fields that are being managed by the form as a whole. isactive string \u00b6 A CSS class name to add extra formatting if the record in question is deemed inactive . The notion of active items is defined in the duct workflow . Task \u00b6 This is the component that can open an item and show its fields, either for reading or for editing. Every list rendering component that want to display an individual item full view, will use this component. Full view means: as a vertical table of field labels and field values. ItemRead \u00b6 connected via tables Props \u00b6 tables eId fieldFragments \u00b6 Task \u00b6 Manages the display (read-only) of a single record. It is used if no fields need to be edited. For editing records, ItemEdit is being used. You might wonder why table is missing in the props. The fieldFragment s prop contains that information. Before setting up the fields of an item, applyTemplate is called. If it finds a suitable template in Templates it will be applied. If not, all fields will be displayed in a generic presentation. ItemRow \u00b6 connected via tables Props \u00b6 tables table eId fields perm filters widthStyles \u00b6 initialValues object \u00b6 An object with the initial values of all fields that are being managed by the form as a whole. widthStyles object \u00b6 Since this component has to render records in a grid view, it must know something about the widths of the columns. That information is contained in this prop, as a CSS style per column. alt bool \u00b6 The component must know whether it is an ordinary grid row, or whether the fields should be expanded into a vertical form. nextAlt function \u00b6 This function can be used by a control by which the user can switch between row view and vertical view of the record. isactive string \u00b6 A CSS class name to add extra formatting if the record in question is deemed inactive . The notion of active items is defined in the duct workflow . Task \u00b6 This component displays a record in row form, so that it fits in a grid view of the whole table. See ListGrid . ListContainer \u00b6 (life cycle) connected via tables Props \u00b6 tables table eId select mode filtered dispatch \u00b6 Task \u00b6 Manages a table. Responsible for fetching data from the server. The display of the (filtered) table is left to other components, such as ListFilter . It can be instructed to navigate to a specific item. This is used when the id of the item to navigate to is contained in the URL. The eId prop is the one that contains the item to navigate to. ListFilter \u00b6 (life cycle) connected via tables and filters Props \u00b6 filteredAmount object, filteredAmountOthers object, amounts object from getFiltersApplied \u00b6 The results of applying the filters. initialized bool \u00b6 Whether the filters have been initialized. init function is setupFiltering \u00b6 Callback to initialize filtering. Task \u00b6 Parent component of a table and all its filters. The table must be present. Fetching tables is done by other components, such as ListContainer . This component is for processing user interaction on the filters. The filters and the list of filtered items are shown in separate Pane s. ListGrid \u00b6 connected via tables Props \u00b6 alter alterSection settings tables table listIds select filters perm masterId linkField dispatch \u00b6 grid object \u00b6 Slice of the state, obtained with getGrid , which holds sorting information of table grids. gridTag string \u00b6 Key under which the component finds its information about which columns are sorted in what order and direction. Task \u00b6 This component shows a table as a grid. It uses CSS flex-box for the grid layout. There is also CSS grid but at the time of writing this app, browser support for grid was substantially inferior to browser support for flex. The grid can be sorted by column, in ascending and descending order. You can sort on one column first and then on another and so on. Every grid remembers its sorting state in the grid slice of the state, where it is available under a key. ListPlain \u00b6 (life cycle) connected via tables Props \u00b6 alter alterSection tables table listIds select filters perm masterId linkField dispatch \u00b6 navItem string \u00b6 The item to navigate to, by its MongoDB id. It will be opened and scrolled into view. Task \u00b6 Displays a list of items from a table. Every items is represented as a heading, usually consisting of the title field of the item. If the user has permission to see more, there is a control on each item to expand the heading into the fields and values of the item. If the user has edit permissions, he can edit the item from here. If the user inserts a new item, the component will navigate to that item. ListStats \u00b6 (life cycle) connected via tables Props \u00b6 settings tables table \u00b6 Task \u00b6 Displays aggregated management information about contributions, assessments and reviews. MarkdownArea \u00b6 connected via tables Props \u00b6 alter alterSection table eId dispatch submitValues \u00b6 meta object \u00b6 Contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason? input object \u00b6 Contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> . Task \u00b6 An edit control for bigger chunks of text. It is basically a <textarea>...</textarea> but it is enhanced to convert to the text to markdown and to display a formatted preview of the text. What is saved to the database is the raw markdown. The formatted text is ephemeral, its only function is for the pleasure of the user. Note that in read-only view these values will be also rendered as formatted text. OpenCloseAll \u00b6 A control by which you can close all currently open records in a list. If the list is a detail records list, there is also a control to open all items in the list. But in general, a complete list cannot massively be opened in this way. The real work is done by the functions handleOpenAll , handleCloseAll in tables . filters \u00b6 CheckboxI \u00b6 (life cycle) connected via filters Props \u00b6 table filterTag filterId filterSetting dispatch \u00b6 Task \u00b6 Displays a collective checkbox for a facet filter with many facets. Clicking on this box will collectively check and uncheck all associate checkboxes. The component invokes the method handleCheck upon clicking the checkbox. This checkbox can have an indeterminate state, if some but not all of the associate checkboxes are checked. We have to resort to a DOM manipulation after rendering to get the indeterminate state across. EUMap \u00b6 (life cycle) connected via filters Props \u00b6 alter alterSection tables table filterTag filterSetting filterId filterField filterLabel listIds dispatch \u00b6 (These are the same props as ByValue ) Task \u00b6 A complex component! It is a facet filter for the field country , using ByValue for that. It also contains a map of Europe, visualizing by means of markers, how the filter result is distributed over the DARIAH countries. Both ingredients of this component are brought together not by class extension but by including a <ByValue/> component in the rendering of the <EUMap/> component. The map is a Leaflet module on a blank pane, with a geojson file of country boundaries laid out on it. The map is not React-aware, it will be rendered in its own <div/> . The life cycle methods of this component set up the map and update when new filter settings have been applied. Compute Marker Radius \u00b6 When we know the filter results per country, we can put markers on them with a radius in proportion to their scores. However, if the scores are very far apart, either the small markers get invisible, or the big markers get too big. We mitigate this effect, by using proportional radii only for values below a certain threshold ( LEVEL_OFF ). For higher values we essentially take the square root. ByValue \u00b6 connected via filters Props \u00b6 alter alterSection tables table filterTag filterSetting filterId filterField filterRelField filterLabel filteredAmount filteredAmountOthers listIds compact dispatch \u00b6 maxCols number \u00b6 The maximum number of columns in which the facets have to be stacked. expanded bool \u00b6 Whether the facets should be initially expanded or collapsed (hidden). Task \u00b6 A widget by which the user can click the facet s associated with one field. There is also a collective checkbox , by which the user can check or uncheck all facets in one go. All values that occur are displayed, with statistics in the form subtotal of total . Facet \u00b6 connected via filters Props \u00b6 table filterTag filterId filterSetting className dispatch \u00b6 valueId string \u00b6 The id of the value that is associated to this facet. valueRep string \u00b6 The string representation of the value that is associated to this facet. Task \u00b6 Displays a single facet. Just a checkbox and a value representation. Note that we use the strategy of controlled components here. Filter \u00b6 connected via filters Props \u00b6 tables table listIds filters filterTag filteredAmount filteredAmountOthers amounts compact \u00b6 Task \u00b6 A control to filter a list of items. The following types of filters are implemented. Fulltext : Search in a textual field for a pattern. The pattern is entered by the user, the search is incremental, after each keystroke the results are updated. ByValue : Faceted search for values of a specific field. EUMap : Faceted search on country, together with a map visualization The list of the available filter types and their characteristics are not configured on the client, but come from the server. This generic component merely calls the specialized filter components with the right props for each filter associated with a table. Whereas the incoming props contain information for all filters, each individual specialized filter is passed only the slice that is relevant to that one filter. Fulltext \u00b6 connected via filters Props \u00b6 table filterTag filterId filterLabel filterSetting filteredAmount filteredAmountOthers compact dispatch \u00b6 Task \u00b6 Displays a full text search input field. The characters entered in this field are passed upwards by means of a callback. This is incremental search. Not only the full text search, but also all other filters are computed upon each character entered. Note that we use the strategy of controlled components here. Stat \u00b6 presents filters Props \u00b6 className \u00b6 subtotal , total number \u00b6 Task \u00b6 Displays a string of the form subTotal of total . If one of the two is missing, the of will not display. select \u00b6 RelSelect \u00b6 presents select Props \u00b6 settings tables table select field dispatch submitValues \u00b6 multiple bool \u00b6 Whether to display a select widget where the user can make multi-selections or only single selections. allowNew bool \u00b6 Whether to allow the user to add new options. selectTag string \u00b6 A key under which this component stores its data on the select slice of the global state. This is about whether the options have popped up and what search text the user has entered in the filter box. activeItems array \u00b6 The notion of active items is defined in the duct workflow . isactive string \u00b6 A CSS class name to add extra formatting if the record in question is deemed inactive . allowed object \u00b6 An array of entity ids that are the allowed elements when the field is a multiple choice field. input object \u00b6 Contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> . Task \u00b6 An implementation of multi-select widgets. There is a fairly complete react-select component on GitHub. However, it has some flaws that prevents a successful usage of it in our app. That is why I have written this component. The capabilities of this widget are: single select or multi-select, depending on the property multiple ; fixed list of values or the possibility to create new values on the fly, depending on the prop allowNew ; options can be filtered by a full text filter; only one copy of an option can be chosen; selected options are removed from the list of selectable options; plays well with Redux-Form ; facilitates disabling some options and presenting options in custom ways alter \u00b6 Expand \u00b6 presents alter Props \u00b6 alter alterSection alterTag className \u00b6 initAlt number \u00b6 Initial expand/collapse state. headActive string \u00b6 Clickable part of the component. headLine string \u00b6 Part of the component that is visible in both states. full component \u00b6 Part of the component that is visible in the expanded state only. iconOpen component \u00b6 Icon, clickable, to trigger expansion. iconClose component \u00b6 Icon, clickable, to trigger collapse. titleOpen string \u00b6 Tooltip for the expansion trigger. titleClose string \u00b6 Tooltip for the collapse trigger. Task \u00b6 Shows a expandable / collapsable component, together with controls to trigger these actions. In expanded form, only the headActive and headLine are visible. The headActive is the part that the user can click on to trigger expansion and collapse. The headActive is combined with iconOpen and iconClose , which are indicators for the state of the component. All this is wrapped in a Tooltip components, that display the titleOpen and titleClose texts. In the full form, also the full is visible. Sometimes you need more distance between the control and the material of the component. So we export related components as well: ExpandHead \u00b6 Works with the same args as Expand , minus full . This component presents the headline part, including the clickable part to trigger the actions. ExpandBody \u00b6 Works with the same args as Expand , minus alter , alterSection , alterTag , initAlt , className . This component presents the fully expanded part if the states indicate so, or else nothing. miscellaneous \u00b6 ErrorBoundary \u00b6 Generic component, using new error handling functionality of React 16. We use it to wrap components inside which errors may occur. Those errors are then propagated to an enclosing ErrorBoundary , where they will be catched. The console will log the error, and at the ErrorBoundary will be rendered in place of its normal contents. Currently we render the error boundary as a red block with a single diagnostic message. NavLink \u00b6 presents none Props \u00b6 activeClassName \u00b6 The CSS class to be used when the navigation link has been clicked. ...props any \u00b6 All other props are passed to the wrapped <Link/> component. Task \u00b6 Displays a navigation link that is sensitive to routing. That means: it is a link that can activate a component, and, when clicked, it will become highlighted. NotFound \u00b6 presents none Props \u00b6 splat string \u00b6 The text to display on the 404 page. Task \u00b6 Displays a 404 if no route in main matches. Overview \u00b6 Under construction. Meant to become a customized dashboard for the back office functions. Static \u00b6 presents none Props \u00b6 None. Task \u00b6 Displays navigation links to some static resources.","title":"Components"},{"location":"Client/Components/#components-react","text":"These are the React components, that make up the part of the app that is visible in the browser. They lean on the dux that work for them in the background. Click on the names in the titles to view their source code on GitHub.","title":"Components (React)"},{"location":"Client/Components/#standard-props","text":"Components get properties as input (we call them props ). For each component we mention the props they expect and what type of data they represent. However, some props occur over and over again, and we name them consistently. Here is a list of those props and their types. When we mention these props later on, we omit the types. alter object ; a slice of the state from getAltSection ; Group of settings for components with alternative renderings: these settings tell which alternative has been chosen for each of those components; alterSection string ; name of a section of the alter state; such a section contains the choice of alternative for a bunch of components that are relevant to the present component; each component that requests data from alter only gets data for a single section; in this way components will not be dependent on too big a part of the state; those dependencies may cause spurious re-renderings; alterTag string ; name that lives within a section of the alter state; this functions as the address of a component that needs to expand or collapse; the triggering event will change the alter state, keyed by alterSection and then by alterTag ; amounts object ; for a faceted filter: contains the amount of items that match each facet; see computeFiltering ; children components ; a special prop defined by React itself; it contains the material that has been put in the component; you find it in the render function of the component; it is everything between <Component> and </Component> ; className string ; a class name to be put in the top level element of the rendered component; compact bool ; whether the component should minimize the real estate on the screen that it uses; detailFragments array of object ; the information on the basis of which the detail records of an item can be rendered; every entry in the array corresponds to a detail table that may contain detail records of the master record that is being dealt with; ultimately computed by makeDetails and then passed to child components; dispatch function ; this function belongs to the store that holds the state; it is generally injected into the props of a component by connect ing a component to the store; this only happens if connect() is called with zero or one argument (the MapDispatchToProps argument should be undefined); the dispatch function enables the component to trigger an action that changes the state; where you would call setState() in vanilla-React you put dispatch(action) if your app uses Redux; eId string ; the MongoDB id of an entity that is being dealt with; field string ; the name of a field that is being dealt with; fieldFragments array an array with instructions per field how to render it; ultimately computed by makeFields and then passed to child components; filtered bool ; whether the list should be accompanied by filters; the specification of the filters themselves is in the data model ; fields objects ; defines a subset of all fields: these are the fields that the component has to deal with; filteredAmount number ; the number of items that pass all filters; see computeFiltering ; filteredAmountOthers object ; for each filter, the amount of items that passes all filters except that one filter; see computeFiltering ; filterField string ; the name of the field that the current filter is acting upon; (as in the data model ; filterRelField string ; the name of the related field that the current filter is acting upon; this is relevant for fields that point to a related table: you can filter on the values of a specific field in the related table; (as in the data model ; filterId number ; the sequence number of a specific filter which identifies it among all filters for the same table; filterLabel string ; the user-facing name of the filter; filters object ; a slice of the state from getFilters ; contains the actual filter settings, i.e. what the user has entered in search boxes and which facets the user has clicked; organized by table and then by filterTag and then by filterId ; filterSettings object ; a slice of the state, sub-slice of filters , corresponding to the filters of a single filterTag of a single table ; filterSetting object or string ; a slice of the state, sub-slice of filterSetting , corresponding to a single filter, identified by filterId ; whether this is an object or a string, depends on the nature of the filter: for a Fulltext filter it is a string (the search text), for a ByValue filter it is an object, containing the status (boolean) of all its facet checkboxes; filterTag string ; identifies a group of filters for a single table; tables may have multiple incarnations; a table can be a main table, but also a detail table for a specific record; the filters for a table when it displays details may be distinct from the filters of the same table when it is displayed as the main table; we separate those cases by means of a filterTag prop; linkField string ; when rendering a list of records that are details of some master record, this is the field of the detail records that holds the masterId ; in this way the detail record links to its master record; when the component creates a new detail record, it will pre-fill this field with the current masterId ; listIds array of string ; a sequence of strings which are essentially MongoDB identifiers of entities in a table; components that display lists use this prop to determine which entities must be actually appear on the screen and in what order; see also the prop filteredIds ; masterId string ; when rendering a list of records that are details of some master record, this holds the MongoDB id of the master record; me object ; a slice of the state from getMe ; the information about the currently logged-in user, fetched from the server; mode string ; either list or grid ; whether the list of items should render as a list of expandable headings, or as a grid with full field information; perm object ; Holds permissions for a record: whether deleting is allowed, and per field whether updating is allowed; myValues object ; ultimately extracted from the tables slice of the state; it contains the values of the fields of the entity that is being dealt with; select string ; sometimes a list is fetched as a whole, sometimes only my own records are displayed and yet other times only records that are the details of some master record must be shown; this property indicates which is which; settings object ; a slice of the state from getSettings ; settings are pieces of custom information that are relevant to many components of the app; table string ; name of the table that the component must deal with; submitValues function ; a callback that is used to save form values to the database; used for components that supply edit controls for form values: they can call submitValues after a change or upon loss of focus; it is basically the handleSubmit from Redux-From, with a specific first argument passed ( toDb ) that saves values to the database; tables object ; a slice of the state from getTables ; all data that comes from database tables; organized by table name; for each table there is spec information and actual entity data; win { width number , height number } ; a slice of the state from getWinDim ; contains the physical dimensions of the window at any time.","title":"Standard props"},{"location":"Client/Components/#roots","text":"","title":"roots"},{"location":"Client/Components/#main","text":"connected via roots","title":"main"},{"location":"Client/Components/#task","text":"Entry point of the client side app. Contains the routing , wrapped in a Root component, that sets up the store in which the central state lives.","title":"Task"},{"location":"Client/Components/#root","text":"presents roots","title":"Root"},{"location":"Client/Components/#props","text":"","title":"Props"},{"location":"Client/Components/#children","text":"","title":"children"},{"location":"Client/Components/#task_1","text":"Top-level wrapping component to set up the central store. It does so by configuring the store, calling configureStore , and passing it to the special Provider component of Redux. Then it wraps the whole remaining app in a Window component for detecting some global UI events.","title":"Task"},{"location":"Client/Components/#settings","text":"","title":"settings"},{"location":"Client/Components/#tooltip","text":"(life cycle) connected via settings","title":"Tooltip"},{"location":"Client/Components/#task_2","text":"A dynamic tooltip, based on CSS3 techniques. The tooltip is initially put as content with an absolute position and with opcaity 0. A lot can happen on the page: scrolling, re-rendering of components, and they may all cause changes in the positions of elements. So the position of the invisible tooltip is not where it should be, most of the time. That does not matter, as long as we adjust it just in time, before it becomes visible. When that happens, the positioning of the tooltip will be adjusted to the current position of the element. The trigger to make a tooltip visible is a focus event or a mouse-over event. It is possible to switch all tooltips off. This is governed by showTooltips , a boolean setting in settings . Apart from this, the tooltip machinery does not use special React/Redux mechanisms. All is done at DOM level and with CSS3.","title":"Task"},{"location":"Client/Components/#props_1","text":"","title":"Props"},{"location":"Client/Components/#props_2","text":"","title":"Props"},{"location":"Client/Components/#settings_1","text":"","title":"settings"},{"location":"Client/Components/#tip-string-or-fragment","text":"The content of the tooltip. Any content will do.","title":"tip string or fragment"},{"location":"Client/Components/#at-string","text":"The position of the tooltip relative to its target. Should be one of top bottom left right . The positioning algorithm looks whether there is sufficient room for the tooltip. If not, it will change top to bottom and vice versa, and left to right` and vice versa. It will also shift the tooltip so that it does not extends beyond the page.","title":"at string"},{"location":"Client/Components/#focusonly-boolean","text":"Whether the tooltip should be triggered by focus actions only, or hovering as well. Handy for text input elements ( <input type=\"text\"> or <textarea> ) if you want to show editing help, but only if the user is actually typing in the field.","title":"focusOnly boolean"},{"location":"Client/Components/#classname-string","text":"An additional CSS class to pass on to the <Tooltip> outermost element.","title":"className string"},{"location":"Client/Components/#classtip-string","text":"An additional CSS class to pass on to the element that holds the tooltip.","title":"classTip string"},{"location":"Client/Components/#classarrow-string","text":"An additional CSS class to pass on to the element that holds the little arrow of the tooltip.","title":"classArrow string"},{"location":"Client/Components/#tooltipswitch","text":"connected via settings","title":"TooltipSwitch"},{"location":"Client/Components/#props_3","text":"","title":"Props"},{"location":"Client/Components/#settings-dispatch","text":"","title":"settings dispatch"},{"location":"Client/Components/#task_3","text":"Switches tooltips on or off, globally.","title":"Task"},{"location":"Client/Components/#workflow","text":"","title":"workflow"},{"location":"Client/Components/#scorebox","text":"presents workflow","title":"ScoreBox"},{"location":"Client/Components/#props_4","text":"","title":"Props"},{"location":"Client/Components/#score","text":"This is an object, containing several score quantities, relevant to the scoring of assessments.","title":"score"},{"location":"Client/Components/#task_4","text":"The server computes the scores, and delivers it as workflow attributes with contribution and assessment records. Displays the score of an assessment, and can be expanded to show a derivation of that score. It should be used in templates that have access to workflow attributes. See the mainAction templates of contrib and assessment .","title":"Task"},{"location":"Client/Components/#workflowinfo","text":"presents workflow","title":"WorkflowInfo"},{"location":"Client/Components/#props_5","text":"","title":"Props"},{"location":"Client/Components/#resets","text":"Information about the (manual) workflow resets after the last startup of the webserver.","title":"resets"},{"location":"Client/Components/#stats","text":"This is an object, containing several statistical quantities about the workflow attributes.","title":"stats"},{"location":"Client/Components/#total","text":"The number of records that have workflow information associated with them.","title":"total"},{"location":"Client/Components/#task_5","text":"Present overview information about the workflow information that is currently in use. Offer a control to reset the workflow information (i.e. recompute it). See Workflow .","title":"Task"},{"location":"Client/Components/#me","text":"","title":"me"},{"location":"Client/Components/#login","text":"(life cycle) connected via me","title":"Login"},{"location":"Client/Components/#props_6","text":"","title":"Props"},{"location":"Client/Components/#me-dispatch","text":"","title":"me dispatch"},{"location":"Client/Components/#task_6","text":"The main task of Login is to fetch the current authentication status: is there an authenticated user, and if so, what is his/her name?","title":"Task"},{"location":"Client/Components/#subapp","text":"presents win","title":"SubApp"},{"location":"Client/Components/#props_7","text":"","title":"Props"},{"location":"Client/Components/#me-table-children","text":"","title":"me table children"},{"location":"Client/Components/#routes-components","text":"These are object passed by React-Router . From this the navigation route that the user has followed to arrive here, can be read.","title":"routes components"},{"location":"Client/Components/#task_7","text":"This is one of the components just below App . It contains a set of panes and navigation links to main subcomponents to display in those panes. Most of those subcomponents are linked to a main table, which is passed in the table prop.","title":"Task"},{"location":"Client/Components/#win","text":"","title":"win"},{"location":"Client/Components/#app","text":"connected via win","title":"App"},{"location":"Client/Components/#props_8","text":"","title":"Props"},{"location":"Client/Components/#win-children","text":"","title":"win children"},{"location":"Client/Components/#task_8","text":"As far as the logic of the web page is concerned, this is the top level component. App is always in view and consists of the top navigation bar with logo, Login ; Notification ); static links to documentation. It is only used to display the height and the width somewhere on the screen.","title":"Task"},{"location":"Client/Components/#window","text":"(life cycle) connected via win","title":"Window"},{"location":"Client/Components/#props_9","text":"","title":"Props"},{"location":"Client/Components/#task_9","text":"Detects window resize events and passes the resulting height and width of the main window to the state. On mounting an event listener is installed, and on unmounting the event handler is removed. During resizing, the frequency of emitted events is throttled to one per second, in order to prevent screen flicker.","title":"Task"},{"location":"Client/Components/#docs","text":"","title":"docs"},{"location":"Client/Components/#doc","text":"presents docs","title":"Doc"},{"location":"Client/Components/#props_10","text":"","title":"Props"},{"location":"Client/Components/#location-object","text":"From this object the property pathname will be read, which will be split into directory, file and extension parts. The extension is used to switch to the component for that type of documents.","title":"location object"},{"location":"Client/Components/#task_10","text":"Handles the display of documents. Depending on the type of document (markdown, html, pdf) it delegates work to specialized document components: DocMd , DocHtml and DocPdf .","title":"Task"},{"location":"Client/Components/#dochtml","text":"presents docs","title":"DocHtml"},{"location":"Client/Components/#props_11","text":"","title":"Props"},{"location":"Client/Components/#docdir-docname-docext-string","text":"The directory, filename and extension of the document container.","title":"docDir, docName, docExt string"},{"location":"Client/Components/#task_11","text":"Displays an HTML document by linking to it in an IFRAME.","title":"Task"},{"location":"Client/Components/#docmd","text":"(life cycle) connected via docs","title":"DocMd"},{"location":"Client/Components/#props_12","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-dispatch","text":"","title":"alter alterSection dispatch"},{"location":"Client/Components/#docname-string","text":"The name of the document.","title":"docName string"},{"location":"Client/Components/#text-string-from-getdoc","text":"The raw content of the document.","title":"text string from getDoc"},{"location":"Client/Components/#task_12","text":"Show Markdown text, coming from files on the server. The conversion to HTML is done client side, and the user gets a control to switch between Markdown source and formatted HTML. A function RouterLink is defined to wrap local links into Link components when transforming the markdown to html. It makes it possible to write Markdown documents with internal links to this application. A full link (with protocol http ( s ) is translated to a plain HTML a element, so clicking it will leave this application.","title":"Task"},{"location":"Client/Components/#docpdf","text":"presents docs","title":"DocPdf"},{"location":"Client/Components/#docdir-docname-docext-string_1","text":"The directory, filename and extension of the document container.","title":"docDir, docName, docExt string"},{"location":"Client/Components/#task_13","text":"Displays a PDF document by linking to it in an OBJECT. NB: On iOS this does not work well, only the first page of the PDF gets shown, we work around it by just displaying a link to open the PDF in a new tab. We only do that when we detect an iOS browser.","title":"Task"},{"location":"Client/Components/#notes","text":"","title":"notes"},{"location":"Client/Components/#notification","text":"(life cycle) connected via notes","title":"Notification"},{"location":"Client/Components/#props_13","text":"","title":"Props"},{"location":"Client/Components/#dispatch","text":"The following properties are injected from the state by getNotes :","title":"dispatch"},{"location":"Client/Components/#messages-array-of-objects","text":"The list of notifications that have been issued since the beginning of the session or since the last time that the user has cleared the messages.","title":"messages array of objects"},{"location":"Client/Components/#busy","text":"The amount of asynchronous actions that are still pending.","title":"busy"},{"location":"Client/Components/#show","text":"Whether the panel should be hidden.","title":"show"},{"location":"Client/Components/#lastmsg-lastnote-lastkind","text":"The indexes of the last message and the last notable message, and the kind of the last notable message, which is one of error , warning , special . Only the kind info is non-special. When the notifications are displayed, the panel will be scrolled to the last notable message if there is one, otherwise to the last message.","title":"lastMsg, lastNote, lastKind"},{"location":"Client/Components/#task_14","text":"Component that receives notifications and displays them in a little panel with fixed position on the screen. The panel is hidden by default and pops up if there is an important notification. The user can click it away and also clear the notifications. There is also a progress indicator, a little circle fixed at the top right corner of the screen. It hints at the current status of asynchronous operations. A click on it will show the notifications panel.","title":"Task"},{"location":"Client/Components/#tables","text":"","title":"tables"},{"location":"Client/Components/#editcontrol","text":"A component that shows the current edit status of a record. It is presented as a button that can be clicked to submit and save a form. It can only be used as descendant of a redux-form -enabled <form> -carrying component. See also EditStatus . Uses the library function editControl .","title":"EditControl"},{"location":"Client/Components/#editdelete","text":"Button to delete the record that is displayed with it. The component is rather dumb, it needs to be passed an onClick handler that will perform the delete action.","title":"EditDelete"},{"location":"Client/Components/#edithelp","text":"Information panel below input fields and markdown fields, telling how to save and cancel, and showing the markdown constructs.","title":"EditHelp"},{"location":"Client/Components/#editinsert","text":"Button to insert a blank record into the currently displayed table. The component is rather dumb, it needs to be passed an onClick handler that will perform the insert action.","title":"EditInsert"},{"location":"Client/Components/#editstatus","text":"A component that shows the current edit status of a record. It is presented as a <span> that looks exactly as an EditControl , but it cannot be clicked to submit and save values. It can be used everywhere, and it is itself enhanced by redux-form . Because it is outside a <form> context, submitting will not work. Uses the library function editControl .","title":"EditStatus"},{"location":"Client/Components/#fieldedit","text":"connected via tables","title":"FieldEdit"},{"location":"Client/Components/#props_14","text":"","title":"Props"},{"location":"Client/Components/#alter-tables-table-eid-field-dispatch-submitvalues","text":"","title":"alter tables table eId field dispatch submitValues"},{"location":"Client/Components/#allowed-object","text":"An array of entity ids that are the allowed elements when the field is a multiple choice field.","title":"allowed object"},{"location":"Client/Components/#props-any","text":"There are many more props that get passed to FieldEdit . They have been injected by the wrapper redux-form() into ItemForm , the parent of this component, and they will be passed on to Field and FieldArray , so that they can do their magic.","title":"...props any"},{"location":"Client/Components/#task_15","text":"Edit control for an editable field. Depending on the type of the field and the multiplicity, it presents the right control. Basically, this component produces one or more Field or FieldArray components (which are provided by redux-form . Note that we do not pass the actual values to these components. They know how to get the current values from the state, and what actions must be dispatched to change them. However, both <Field /> and <FieldArray /> still do not actually present the edit control. They only do the plumbing. For the actual presentation, you can plug in a component of choice. We will use <input type=\"...\" /> , <textarea>...</textarea> elements and our own custom component RelSelect for multi-select controls. We enhance textareas by offering markdown previews of their content. See MarkdownArea . We wrap multiple *input*s in InputMulti and single inputs in Input . The extra level of wrapping of these presentational components is needed for showing validation errors.","title":"Task"},{"location":"Client/Components/#note-on-the-prop-allowed","text":"In most cases a multiple choice is between members of a value list or related table, but sometimes we want to restrict the set of choices further, especially when we are offering a choice in a detail record. Then the master record might contain information that constrains the option for some fields in the detail records. For example, the criteriaEntry record contains a multiple choice field to choose between a bunch of scores. However, not all scores of the score table are valid choices, only those scores that belong to the criteria record referred by the criteriaEntry record.","title":"Note on the prop allowed"},{"location":"Client/Components/#caution","text":"In order to get everything working correctly, two problems had to be solved. Both turned out to be related to Redux-Form. The component that you pass to the component prop of Field and FieldArray must not be dynamically composed in the render() function that produces Field(Array) . Because in that case, the Field(Array) is re-rendered too often, and effect for the user is that he loses focus after entering the first character, which is very annoying. So, the value for component must be a static function. But what if this function needs dynamically determined arguments? How can they be passed to it? The solution is simple: pass them as props to Field(Array) , and they will be passed on to the component function by redux-form. This is actually documented in the redux-form docs. You need this , section 2. A stateless function You must define the stateless function outside of your render() method, or else it will be recreated on every render and will force the Field to re-render because its component prop will be different. If you are defining your stateless function inside of render(), it will not only be slower, but your input will lose focus whenever the entire form component re-renders. and this : Any custom props passed to Field will be merged into the props object on the same level as the input and meta objects. When navigating between forms for several records, the onChange callback, that should be bound to the proper form, becomes bound to the wrong form. As far as I can see, all other things work as expected, so it was difficult to see why this occurred. The explanation is in a GitHub issue . Summarized: the construction of the onChange function is effectively memoized. It is determined upon mounting of the component, but not on updating it. The workaround is easy: add an extra key property to the form. Another cause for the same problem I encountered in InputMulti , where I had memoized the callbacks for adding and removing values to/from a sequence.","title":"Caution"},{"location":"Client/Components/#fieldread","text":"connected via tables","title":"FieldRead"},{"location":"Client/Components/#props_15","text":"","title":"Props"},{"location":"Client/Components/#settings-tables-table-myvalues-field","text":"","title":"settings tables table myValues field"},{"location":"Client/Components/#task_16","text":"Presents the value(s) of a read-only field, based on initial values . Note that value of type textarea will be rendered as formatted markdown.","title":"Task"},{"location":"Client/Components/#fieldset","text":"presents tables","title":"FieldSet"},{"location":"Client/Components/#props_16","text":"","title":"Props"},{"location":"Client/Components/#submitvalues","text":"","title":"submitValues"},{"location":"Client/Components/#input-object","text":"Contains the attribute onChange by which the form value of this field can be changed.","title":"input object"},{"location":"Client/Components/#widget-function","text":"A function that when passed a handler, will return a React fragment. When this fragment receives a click, the event handler will be called.","title":"widget function"},{"location":"Client/Components/#setvalue-any-value","text":"The value that will be passed to the handler of widget , when it receives a click.","title":"setValue any value"},{"location":"Client/Components/#task_17","text":"This is a form input component meant to be passed to a Field component, like Input . But unlike an Input , it only handles a click event, upon which it will change the value in the field to setValue , and save the form to the database.","title":"Task"},{"location":"Client/Components/#input","text":"presents tables","title":"Input"},{"location":"Client/Components/#props_17","text":"","title":"Props"},{"location":"Client/Components/#submitvalues_1","text":"","title":"submitValues"},{"location":"Client/Components/#meta-object","text":"Contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason?","title":"meta object"},{"location":"Client/Components/#input-object_1","text":"Contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> .","title":"input object"},{"location":"Client/Components/#type-string","text":"The type of <input type=\"...\" /> . It will go to the place of the dots.","title":"type string"},{"location":"Client/Components/#task_18","text":"Shows an <input type=\"...\" /> control, and shows validation errors if the value entered by the user does not validate. It is a controlled component .","title":"Task"},{"location":"Client/Components/#inputmulti","text":"presents tables","title":"InputMulti"},{"location":"Client/Components/#props_18","text":"","title":"Props"},{"location":"Client/Components/#submitvalues_2","text":"","title":"submitValues"},{"location":"Client/Components/#table-eid-fields","text":"","title":"table eId fields"},{"location":"Client/Components/#componentsingle-function","text":"The edit component that has to be rendered multiple times.","title":"componentSingle function"},{"location":"Client/Components/#validatesingle-function","text":"Validation function. Takes a value and return undefined if all is well, and otherwise a reason why not.","title":"validateSingle function"},{"location":"Client/Components/#normalizesingle-function","text":"Transforms the entered value into a normalized value for saving.","title":"normalizeSingle function"},{"location":"Client/Components/#fields-array","text":"The names of the individual fields. If the collective name of this field is foo , than this array contains foo[0] , foo[1] , etc., as many as their are values. These names are just strings.","title":"fields array"},{"location":"Client/Components/#meta-object_1","text":"Contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason?","title":"meta object"},{"location":"Client/Components/#props-any_1","text":"There are many more props that must be passed to Field . They have been injected by the wrapper reduxForm() into ItemForm , the uncle ( InputMulti is passed as attribute to Field which is a child of FieldEdit ) of this component, and they are just passed on to Field and FieldArray , so that they can do their magic.","title":"...props any"},{"location":"Client/Components/#task_19","text":"Renders a sequence of Field components on behalf of a FieldArray component. There are controls to remove values, and to add fresh, empty values. Validation and normalization are done per individual Field . It is a controlled component .","title":"Task"},{"location":"Client/Components/#insert","text":"Button to insert a blank record into a table. Unlike EditInsert , this does not have to be a currently displayed table. After insertion the app will navigate to the table in which the item has been inserted, and it will open the freshly created item.","title":"Insert"},{"location":"Client/Components/#itemaction","text":"connected via tables","title":"ItemAction"},{"location":"Client/Components/#props_19","text":"","title":"Props"},{"location":"Client/Components/#settings-tables-table-eid-linkfield-fieldfragments-dispatch","text":"These are all the properties that ItemForm gets from its parent and from its connection with the state. But we wrap ItemForm in reduxForm() and this will inject a number of other properties into it. We list the few that we visibly use. There are more injected properties, and these we pass carefully on to other components.","title":"settings tables table eId linkField fieldFragments dispatch"},{"location":"Client/Components/#handlesubmit-function","text":"A function that is invoked when the form is submitted. This function is passed from redux-form and handles all the form submission machinery. See ItemEdit .","title":"handleSubmit function"},{"location":"Client/Components/#task_20","text":"Manages the display of a single record, but only as far as an ActionTemplate has been provided for that table. The action template may contain controls that modify fields and save them to the database, exactly as ItemEdit . The component does not show save and reset buttons. It is meant for controls that save changed values on their own. This component is meant for stuff that needs to be present both in read-only view and in edit-view.","title":"Task"},{"location":"Client/Components/#using-templates","text":"This component uses applyEditTemplate to see whether there is an action template defined in Templates . If yes, that template will be applied, if no, nothing will be rendered.","title":"Using templates"},{"location":"Client/Components/#itemcontainer","text":"(life cycle) connected via tables","title":"ItemContainer"},{"location":"Client/Components/#props_20","text":"","title":"Props"},{"location":"Client/Components/#settings-tables-table-eid-filters-dispatch","text":"","title":"settings tables table eId filters dispatch"},{"location":"Client/Components/#task_21","text":"Container for a single record in a table. This component is responsible for fetching the item data from the database (if needed), but not form input.","title":"Task"},{"location":"Client/Components/#itemdetails","text":"connected via tables","title":"ItemDetails"},{"location":"Client/Components/#props_21","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-tables-table-eid-filters-detailfragments-dispatch","text":"","title":"alter alterSection tables table eId filters detailFragments dispatch"},{"location":"Client/Components/#task_22","text":"Presents a list of detail items of a master record.","title":"Task"},{"location":"Client/Components/#itemedit","text":"connected via tables","title":"ItemEdit"},{"location":"Client/Components/#props_22","text":"","title":"Props"},{"location":"Client/Components/#tables-table-eid-fieldfragments-dispatch","text":"","title":"tables table eId fieldFragments dispatch"},{"location":"Client/Components/#nextalt-function","text":"This function can be used to switch this component from read-only view to edit view and back. It will be passed on to the widget that also has the edit controls for submitting and resetting the form. These are all the properties that ItemForm gets from its parent and from its connection with the state. But we wrap ItemForm in reduxForm() and this will inject a number of other properties into it. We list the few that we visibly use. There are more injected properties, and these we pass carefully on to other components.","title":"nextAlt function"},{"location":"Client/Components/#dirty-boolean","text":"Whether the form contains changed, unsaved values in any of its fields.","title":"dirty boolean"},{"location":"Client/Components/#invalid-boolean","text":"Whether the form contains invalid, values in any of its fields. The form uses two kinds of validation: synchronous: on every keystroke, the current value will be subjected to a validation function on submit: the submitted values will be validated on the server, and if that fails, the reasons for failure will be reported in exactly the same way as for synchronous validation.","title":"invalid boolean"},{"location":"Client/Components/#error-object","text":"Object that contains the reasons for validation errors.","title":"error object"},{"location":"Client/Components/#submitting-boolean","text":"Whether a submit action of the form is pending.","title":"submitting boolean"},{"location":"Client/Components/#reset-boolean","text":"A function that can reset the form. Resetting means: changing all edited values back to the initialValues.","title":"reset boolean"},{"location":"Client/Components/#handlesubmit-function_1","text":"A function that is invoked when the form is submitted. This function is passed from redux-form and handles all the form submission machinery. It also calls a function that you can pass to it as first argument. We pass it our toDb(table, eId, mod) function. This is a function that takes a values object, and calls mod(table, eId, values) , where mod is the function that dispatches a server action: the values are sent to the server, where they are used to update the record eId in table .","title":"handleSubmit function"},{"location":"Client/Components/#task_23","text":"Manages the display and editing of a single record. It is only used if there are editable field. If that is not the case, ItemRead is being used. We do this to avoid to invoke the costly machinery of editable forms when it is not needed. The component also shows save and reset buttons (if appropriate). The component has two render modes: read-only view and edit-view. When a user has edited the form, he can switch to the read only view to see the result. In read-only view, markdown fields are rendered as formatted text, and tags in select controls do not open the choice when you click on it. Instead such a click takes to an item view of that value in its own table. We use redux-form for displaying forms, filling them out, submitting them, sending the values to the database, validating and normalizing values. Although redux-form has an awesome functionality, it is far from trivial to get it integrated. The work horses are the Field and FieldArray components. These elements can be put in an arbitrary component, under a <form/> element. The resulting component is enhanced by the reduxForm() function. The basic flow is this: we read the values of a record from the state and pass them to the redux-form component as initial values ; redux-form manages its own slice of the state ( form ) and has its own set of actions to respond to user interactions; when the user interacts with the form, the work ends up in the form slice of the state; when the form is submitted : the current values are sent to the database, and the updated record is read back from the database; the updated values are passed to the form as new initial values the form re-initializes itself, and the user can start again; when the user interrupts editing the form, and switches to another component, nothing is lost: the edits are saved in the state; when the form is mounted again, not only the initial values are fetched back, but also the edit state is restored; submitting happens with auto save : whenever an input field looses focus, the form is submitted; submitting happens also for those fields in which you can not have a cursor: whenever a field value is changed by a click, the form is submitted. Hence it is easy to edit two forms at the same time, which can be handy if (s)he edits two contributions that need to have a consistent wording. It is also possible to edit the same records in multiple components on the interface. Both refer to the same underlying state.","title":"Task"},{"location":"Client/Components/#implementation","text":"The construction of the actual fields is done by a function makeFields() , that generates an array of fragments, one for each field. An editable field will be handled by a ` component, and a read-only field by a `\\ component.","title":"Implementation"},{"location":"Client/Components/#using-templates_1","text":"Before setting up the fields of an item, applyEditTemplate is called. If it finds a suitable template in Templates it will be applied. If not, all fields will be displayed in a generic presentation.","title":"Using templates"},{"location":"Client/Components/#itemform","text":"connected via tables","title":"ItemForm"},{"location":"Client/Components/#props_23","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-tables-table-eid-filters-fields-perm-fieldfragments-detailfragments-dispatch","text":"","title":"alter alterSection tables table eId filters fields perm fieldFragments detailFragments dispatch"},{"location":"Client/Components/#initialvalues-object","text":"An object with the initial values of all fields that are being managed by the form as a whole.","title":"initialValues object"},{"location":"Client/Components/#isactive-string","text":"A CSS class name to add extra formatting if the record in question is deemed inactive . The notion of active items is defined in the duct workflow .","title":"isactive string"},{"location":"Client/Components/#task_24","text":"This is the component that can open an item and show its fields, either for reading or for editing. Every list rendering component that want to display an individual item full view, will use this component. Full view means: as a vertical table of field labels and field values.","title":"Task"},{"location":"Client/Components/#itemread","text":"connected via tables","title":"ItemRead"},{"location":"Client/Components/#props_24","text":"","title":"Props"},{"location":"Client/Components/#tables-eid-fieldfragments","text":"","title":"tables eId fieldFragments"},{"location":"Client/Components/#task_25","text":"Manages the display (read-only) of a single record. It is used if no fields need to be edited. For editing records, ItemEdit is being used. You might wonder why table is missing in the props. The fieldFragment s prop contains that information. Before setting up the fields of an item, applyTemplate is called. If it finds a suitable template in Templates it will be applied. If not, all fields will be displayed in a generic presentation.","title":"Task"},{"location":"Client/Components/#itemrow","text":"connected via tables","title":"ItemRow"},{"location":"Client/Components/#props_25","text":"","title":"Props"},{"location":"Client/Components/#tables-table-eid-fields-perm-filters-widthstyles","text":"","title":"tables table eId fields perm filters widthStyles"},{"location":"Client/Components/#initialvalues-object_1","text":"An object with the initial values of all fields that are being managed by the form as a whole.","title":"initialValues object"},{"location":"Client/Components/#widthstyles-object","text":"Since this component has to render records in a grid view, it must know something about the widths of the columns. That information is contained in this prop, as a CSS style per column.","title":"widthStyles object"},{"location":"Client/Components/#alt-bool","text":"The component must know whether it is an ordinary grid row, or whether the fields should be expanded into a vertical form.","title":"alt bool"},{"location":"Client/Components/#nextalt-function_1","text":"This function can be used by a control by which the user can switch between row view and vertical view of the record.","title":"nextAlt function"},{"location":"Client/Components/#isactive-string_1","text":"A CSS class name to add extra formatting if the record in question is deemed inactive . The notion of active items is defined in the duct workflow .","title":"isactive string"},{"location":"Client/Components/#task_26","text":"This component displays a record in row form, so that it fits in a grid view of the whole table. See ListGrid .","title":"Task"},{"location":"Client/Components/#listcontainer","text":"(life cycle) connected via tables","title":"ListContainer"},{"location":"Client/Components/#props_26","text":"","title":"Props"},{"location":"Client/Components/#tables-table-eid-select-mode-filtered-dispatch","text":"","title":"tables table eId select mode filtered dispatch"},{"location":"Client/Components/#task_27","text":"Manages a table. Responsible for fetching data from the server. The display of the (filtered) table is left to other components, such as ListFilter . It can be instructed to navigate to a specific item. This is used when the id of the item to navigate to is contained in the URL. The eId prop is the one that contains the item to navigate to.","title":"Task"},{"location":"Client/Components/#listfilter","text":"(life cycle) connected via tables and filters","title":"ListFilter"},{"location":"Client/Components/#props_27","text":"","title":"Props"},{"location":"Client/Components/#filteredamount-object-filteredamountothers-object-amounts-object-from-getfiltersapplied","text":"The results of applying the filters.","title":"filteredAmount object, filteredAmountOthers object, amounts object from getFiltersApplied"},{"location":"Client/Components/#initialized-bool","text":"Whether the filters have been initialized.","title":"initialized bool"},{"location":"Client/Components/#init-function-is-setupfiltering","text":"Callback to initialize filtering.","title":"init function is setupFiltering"},{"location":"Client/Components/#task_28","text":"Parent component of a table and all its filters. The table must be present. Fetching tables is done by other components, such as ListContainer . This component is for processing user interaction on the filters. The filters and the list of filtered items are shown in separate Pane s.","title":"Task"},{"location":"Client/Components/#listgrid","text":"connected via tables","title":"ListGrid"},{"location":"Client/Components/#props_28","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-settings-tables-table-listids-select-filters-perm-masterid-linkfield-dispatch","text":"","title":"alter alterSection settings tables table listIds select filters perm masterId linkField dispatch"},{"location":"Client/Components/#grid-object","text":"Slice of the state, obtained with getGrid , which holds sorting information of table grids.","title":"grid object"},{"location":"Client/Components/#gridtag-string","text":"Key under which the component finds its information about which columns are sorted in what order and direction.","title":"gridTag string"},{"location":"Client/Components/#task_29","text":"This component shows a table as a grid. It uses CSS flex-box for the grid layout. There is also CSS grid but at the time of writing this app, browser support for grid was substantially inferior to browser support for flex. The grid can be sorted by column, in ascending and descending order. You can sort on one column first and then on another and so on. Every grid remembers its sorting state in the grid slice of the state, where it is available under a key.","title":"Task"},{"location":"Client/Components/#listplain","text":"(life cycle) connected via tables","title":"ListPlain"},{"location":"Client/Components/#props_29","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-tables-table-listids-select-filters-perm-masterid-linkfield-dispatch","text":"","title":"alter alterSection tables table listIds select filters perm masterId linkField dispatch"},{"location":"Client/Components/#navitem-string","text":"The item to navigate to, by its MongoDB id. It will be opened and scrolled into view.","title":"navItem string"},{"location":"Client/Components/#task_30","text":"Displays a list of items from a table. Every items is represented as a heading, usually consisting of the title field of the item. If the user has permission to see more, there is a control on each item to expand the heading into the fields and values of the item. If the user has edit permissions, he can edit the item from here. If the user inserts a new item, the component will navigate to that item.","title":"Task"},{"location":"Client/Components/#liststats","text":"(life cycle) connected via tables","title":"ListStats"},{"location":"Client/Components/#props_30","text":"","title":"Props"},{"location":"Client/Components/#settings-tables-table","text":"","title":"settings tables table"},{"location":"Client/Components/#task_31","text":"Displays aggregated management information about contributions, assessments and reviews.","title":"Task"},{"location":"Client/Components/#markdownarea","text":"connected via tables","title":"MarkdownArea"},{"location":"Client/Components/#props_31","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-table-eid-dispatch-submitvalues","text":"","title":"alter alterSection table eId dispatch submitValues"},{"location":"Client/Components/#meta-object_2","text":"Contains attributes related to validation and edit state; is the value changed and unsaved, invalid, and of so, for what reason?","title":"meta object"},{"location":"Client/Components/#input-object_2","text":"Contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> .","title":"input object"},{"location":"Client/Components/#task_32","text":"An edit control for bigger chunks of text. It is basically a <textarea>...</textarea> but it is enhanced to convert to the text to markdown and to display a formatted preview of the text. What is saved to the database is the raw markdown. The formatted text is ephemeral, its only function is for the pleasure of the user. Note that in read-only view these values will be also rendered as formatted text.","title":"Task"},{"location":"Client/Components/#opencloseall","text":"A control by which you can close all currently open records in a list. If the list is a detail records list, there is also a control to open all items in the list. But in general, a complete list cannot massively be opened in this way. The real work is done by the functions handleOpenAll , handleCloseAll in tables .","title":"OpenCloseAll"},{"location":"Client/Components/#filters","text":"","title":"filters"},{"location":"Client/Components/#checkboxi","text":"(life cycle) connected via filters","title":"CheckboxI"},{"location":"Client/Components/#props_32","text":"","title":"Props"},{"location":"Client/Components/#table-filtertag-filterid-filtersetting-dispatch","text":"","title":"table filterTag filterId filterSetting dispatch"},{"location":"Client/Components/#task_33","text":"Displays a collective checkbox for a facet filter with many facets. Clicking on this box will collectively check and uncheck all associate checkboxes. The component invokes the method handleCheck upon clicking the checkbox. This checkbox can have an indeterminate state, if some but not all of the associate checkboxes are checked. We have to resort to a DOM manipulation after rendering to get the indeterminate state across.","title":"Task"},{"location":"Client/Components/#eumap","text":"(life cycle) connected via filters","title":"EUMap"},{"location":"Client/Components/#props_33","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-tables-table-filtertag-filtersetting-filterid-filterfield-filterlabel-listids-dispatch","text":"(These are the same props as ByValue )","title":"alter alterSection tables table filterTag filterSetting filterId filterField filterLabel listIds dispatch"},{"location":"Client/Components/#task_34","text":"A complex component! It is a facet filter for the field country , using ByValue for that. It also contains a map of Europe, visualizing by means of markers, how the filter result is distributed over the DARIAH countries. Both ingredients of this component are brought together not by class extension but by including a <ByValue/> component in the rendering of the <EUMap/> component. The map is a Leaflet module on a blank pane, with a geojson file of country boundaries laid out on it. The map is not React-aware, it will be rendered in its own <div/> . The life cycle methods of this component set up the map and update when new filter settings have been applied.","title":"Task"},{"location":"Client/Components/#compute-marker-radius","text":"When we know the filter results per country, we can put markers on them with a radius in proportion to their scores. However, if the scores are very far apart, either the small markers get invisible, or the big markers get too big. We mitigate this effect, by using proportional radii only for values below a certain threshold ( LEVEL_OFF ). For higher values we essentially take the square root.","title":"Compute Marker Radius"},{"location":"Client/Components/#byvalue","text":"connected via filters","title":"ByValue"},{"location":"Client/Components/#props_34","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-tables-table-filtertag-filtersetting-filterid-filterfield-filterrelfield-filterlabel-filteredamount-filteredamountothers-listids-compact-dispatch","text":"","title":"alter alterSection tables table filterTag filterSetting filterId filterField filterRelField filterLabel filteredAmount filteredAmountOthers listIds compact dispatch"},{"location":"Client/Components/#maxcols-number","text":"The maximum number of columns in which the facets have to be stacked.","title":"maxCols number"},{"location":"Client/Components/#expanded-bool","text":"Whether the facets should be initially expanded or collapsed (hidden).","title":"expanded bool"},{"location":"Client/Components/#task_35","text":"A widget by which the user can click the facet s associated with one field. There is also a collective checkbox , by which the user can check or uncheck all facets in one go. All values that occur are displayed, with statistics in the form subtotal of total .","title":"Task"},{"location":"Client/Components/#facet","text":"connected via filters","title":"Facet"},{"location":"Client/Components/#props_35","text":"","title":"Props"},{"location":"Client/Components/#table-filtertag-filterid-filtersetting-classname-dispatch","text":"","title":"table filterTag filterId filterSetting className dispatch"},{"location":"Client/Components/#valueid-string","text":"The id of the value that is associated to this facet.","title":"valueId string"},{"location":"Client/Components/#valuerep-string","text":"The string representation of the value that is associated to this facet.","title":"valueRep string"},{"location":"Client/Components/#task_36","text":"Displays a single facet. Just a checkbox and a value representation. Note that we use the strategy of controlled components here.","title":"Task"},{"location":"Client/Components/#filter","text":"connected via filters","title":"Filter"},{"location":"Client/Components/#props_36","text":"","title":"Props"},{"location":"Client/Components/#tables-table-listids-filters-filtertag-filteredamount-filteredamountothers-amounts-compact","text":"","title":"tables table listIds filters filterTag filteredAmount filteredAmountOthers amounts compact"},{"location":"Client/Components/#task_37","text":"A control to filter a list of items. The following types of filters are implemented. Fulltext : Search in a textual field for a pattern. The pattern is entered by the user, the search is incremental, after each keystroke the results are updated. ByValue : Faceted search for values of a specific field. EUMap : Faceted search on country, together with a map visualization The list of the available filter types and their characteristics are not configured on the client, but come from the server. This generic component merely calls the specialized filter components with the right props for each filter associated with a table. Whereas the incoming props contain information for all filters, each individual specialized filter is passed only the slice that is relevant to that one filter.","title":"Task"},{"location":"Client/Components/#fulltext","text":"connected via filters","title":"Fulltext"},{"location":"Client/Components/#props_37","text":"","title":"Props"},{"location":"Client/Components/#table-filtertag-filterid-filterlabel-filtersetting-filteredamount-filteredamountothers-compact-dispatch","text":"","title":"table filterTag filterId filterLabel filterSetting filteredAmount filteredAmountOthers compact dispatch"},{"location":"Client/Components/#task_38","text":"Displays a full text search input field. The characters entered in this field are passed upwards by means of a callback. This is incremental search. Not only the full text search, but also all other filters are computed upon each character entered. Note that we use the strategy of controlled components here.","title":"Task"},{"location":"Client/Components/#stat","text":"presents filters","title":"Stat"},{"location":"Client/Components/#props_38","text":"","title":"Props"},{"location":"Client/Components/#classname","text":"","title":"className"},{"location":"Client/Components/#subtotal-total-number","text":"","title":"subtotal, total number"},{"location":"Client/Components/#task_39","text":"Displays a string of the form subTotal of total . If one of the two is missing, the of will not display.","title":"Task"},{"location":"Client/Components/#select","text":"","title":"select"},{"location":"Client/Components/#relselect","text":"presents select","title":"RelSelect"},{"location":"Client/Components/#props_39","text":"","title":"Props"},{"location":"Client/Components/#settings-tables-table-select-field-dispatch-submitvalues","text":"","title":"settings tables table select field dispatch submitValues"},{"location":"Client/Components/#multiple-bool","text":"Whether to display a select widget where the user can make multi-selections or only single selections.","title":"multiple bool"},{"location":"Client/Components/#allownew-bool","text":"Whether to allow the user to add new options.","title":"allowNew bool"},{"location":"Client/Components/#selecttag-string","text":"A key under which this component stores its data on the select slice of the global state. This is about whether the options have popped up and what search text the user has entered in the filter box.","title":"selectTag string"},{"location":"Client/Components/#activeitems-array","text":"The notion of active items is defined in the duct workflow .","title":"activeItems array"},{"location":"Client/Components/#isactive-string_2","text":"A CSS class name to add extra formatting if the record in question is deemed inactive .","title":"isactive string"},{"location":"Client/Components/#allowed-object_1","text":"An array of entity ids that are the allowed elements when the field is a multiple choice field.","title":"allowed object"},{"location":"Client/Components/#input-object_3","text":"Contains attributes related to the actual value that is being held. These attributes are passed verbatim to the underlying <input /> .","title":"input object"},{"location":"Client/Components/#task_40","text":"An implementation of multi-select widgets. There is a fairly complete react-select component on GitHub. However, it has some flaws that prevents a successful usage of it in our app. That is why I have written this component. The capabilities of this widget are: single select or multi-select, depending on the property multiple ; fixed list of values or the possibility to create new values on the fly, depending on the prop allowNew ; options can be filtered by a full text filter; only one copy of an option can be chosen; selected options are removed from the list of selectable options; plays well with Redux-Form ; facilitates disabling some options and presenting options in custom ways","title":"Task"},{"location":"Client/Components/#alter","text":"","title":"alter"},{"location":"Client/Components/#expand","text":"presents alter","title":"Expand"},{"location":"Client/Components/#props_40","text":"","title":"Props"},{"location":"Client/Components/#alter-altersection-altertag-classname","text":"","title":"alter alterSection alterTag className"},{"location":"Client/Components/#initalt-number","text":"Initial expand/collapse state.","title":"initAlt number"},{"location":"Client/Components/#headactive-string","text":"Clickable part of the component.","title":"headActive string"},{"location":"Client/Components/#headline-string","text":"Part of the component that is visible in both states.","title":"headLine string"},{"location":"Client/Components/#full-component","text":"Part of the component that is visible in the expanded state only.","title":"full component"},{"location":"Client/Components/#iconopen-component","text":"Icon, clickable, to trigger expansion.","title":"iconOpen component"},{"location":"Client/Components/#iconclose-component","text":"Icon, clickable, to trigger collapse.","title":"iconClose component"},{"location":"Client/Components/#titleopen-string","text":"Tooltip for the expansion trigger.","title":"titleOpen string"},{"location":"Client/Components/#titleclose-string","text":"Tooltip for the collapse trigger.","title":"titleClose string"},{"location":"Client/Components/#task_41","text":"Shows a expandable / collapsable component, together with controls to trigger these actions. In expanded form, only the headActive and headLine are visible. The headActive is the part that the user can click on to trigger expansion and collapse. The headActive is combined with iconOpen and iconClose , which are indicators for the state of the component. All this is wrapped in a Tooltip components, that display the titleOpen and titleClose texts. In the full form, also the full is visible. Sometimes you need more distance between the control and the material of the component. So we export related components as well:","title":"Task"},{"location":"Client/Components/#expandhead","text":"Works with the same args as Expand , minus full . This component presents the headline part, including the clickable part to trigger the actions.","title":"ExpandHead"},{"location":"Client/Components/#expandbody","text":"Works with the same args as Expand , minus alter , alterSection , alterTag , initAlt , className . This component presents the fully expanded part if the states indicate so, or else nothing.","title":"ExpandBody"},{"location":"Client/Components/#miscellaneous","text":"","title":"miscellaneous"},{"location":"Client/Components/#errorboundary","text":"Generic component, using new error handling functionality of React 16. We use it to wrap components inside which errors may occur. Those errors are then propagated to an enclosing ErrorBoundary , where they will be catched. The console will log the error, and at the ErrorBoundary will be rendered in place of its normal contents. Currently we render the error boundary as a red block with a single diagnostic message.","title":"ErrorBoundary"},{"location":"Client/Components/#navlink","text":"presents none","title":"NavLink"},{"location":"Client/Components/#props_41","text":"","title":"Props"},{"location":"Client/Components/#activeclassname","text":"The CSS class to be used when the navigation link has been clicked.","title":"activeClassName"},{"location":"Client/Components/#props-any_2","text":"All other props are passed to the wrapped <Link/> component.","title":"...props any"},{"location":"Client/Components/#task_42","text":"Displays a navigation link that is sensitive to routing. That means: it is a link that can activate a component, and, when clicked, it will become highlighted.","title":"Task"},{"location":"Client/Components/#notfound","text":"presents none","title":"NotFound"},{"location":"Client/Components/#props_42","text":"","title":"Props"},{"location":"Client/Components/#splat-string","text":"The text to display on the 404 page.","title":"splat string"},{"location":"Client/Components/#task_43","text":"Displays a 404 if no route in main matches.","title":"Task"},{"location":"Client/Components/#overview","text":"Under construction. Meant to become a customized dashboard for the back office functions.","title":"Overview"},{"location":"Client/Components/#static","text":"presents none","title":"Static"},{"location":"Client/Components/#props_43","text":"None.","title":"Props"},{"location":"Client/Components/#task_44","text":"Displays navigation links to some static resources.","title":"Task"},{"location":"Client/Dux/","text":"Dux (Appliances) \u00b6 Dux (ducts) are appliances within the app, i.e. sets of components that all work with the same slice of the state A duct is a connector between a slice of the state and the components that work with that slice. As such, it is a piece of plumbing, hidden behind the walls and under the floors. We have organized dux as follows: one file that contains its actions , reducer , selectors and helpers . the reducer is programmed as an object of flows . For each action, there is a flow with the same name, which is a function that produces a new state on the basis of that action. a number of React components that make use of these by importing them. This app contains the following dux: alter docs filters forms grid me notes roots select server settings tables win workflow However, life is complicated, and the interplay between dux and components is no exception. Sometimes actions will be fired that affect more than one slice of the state. For example, in order to set up filters for a table, both the tables slice and the filters slice are needed. And when the user expands a table row into a record form, the alter state is changed to cater for the expand action, and the tables slice is changed by receiving additional data for that record. In Redux, the slices of the state are not sealed off from each other. In the end, there is one and only one reducer, that examines every dispatched action for its type property, and hands it over to a sub-reducer that has \"subscribed\" to handle actions for that type. It is perfectly possible that multiple sub-reducers will deal with a single action. A good example is when a record is displayed with multiple detail records, displayed as a list of titles. There is a button \"Open All\" on the interface. When it is pressed, data for all detail records is fetched, and the titles expand into full record views for those details. The way it is implemented, is that pressing \"Open All\" leads to the dispatch of an action with type fetchItems , and with payload the list of ids of the entities that must be fetched. To this action, the tables sub-reducer reacts by fetching the corresponding entity data from the server, and the alter sub-reducer reacts by expanding the corresponding entity titles into full records. Whenever you are tempted to write complicated, time-sensitive logic to orchestrate what happens at multiple slices of the state, all that is needed is in fact just an extra response of an other sub reducer. alter \u00b6 A mechanism for switching between alternative representations of a component, such as: expanded / collapsed, editable / read-only. It is a bit more general than that: you can supply n alternatives and n controls, and let the user cycle through the alternatives by clicking the controls. Components that work with alternatives must collect them in a group. The name of that group is passed as a prop called alterSection . Component that are passed this prop, have access to the state of the alternatives in this group. To get the state information for a single alternative, another key must be supplied, usually called alterTag . The component that displays the alternatives need not be the same component that presents the controls to switch alternatives. Actions \u00b6 Both actions below work relative an alterSection and alterTag . nextAlt \u00b6 Switch to the next alternative. This action must specify the total number of alternatives and an optional initial value. If there is not yet a state for this instantiation, the initial value will be used to start from. setAlt \u00b6 Switch to specified alternative. setItems \u00b6 This function is used to switch a bunch of records from an open to a closed state or vice versa. Reducer \u00b6 Increases the index of the alternative by one, cyclically, and puts it under the right keys in the state.. Selectors \u00b6 getAltSection \u00b6 Delivers the numbers of the current alternatives as far as they are registered under the alterSection key in the alter slice of the state. Helpers \u00b6 compileAlternatives \u00b6 A component that wants to work with the alternatives, of a group of components, must call compileAlternatives() with the right parameters. Think of a List component that wants to provide child items with a control to expand themselves. It is more efficient that the List connects to the alter state, than that each item connects to that state individually. This function is a factory function that, given an alterTag , delivers an object with functions for getting and setting the alternatives of that particular instance. Caution \u00b6 It is tempting to make one alterSection for all components in the app that need alternatives. The flip side of doing so is that all those components will be triggered for re-render whenever any single one of them switches alternatives. That is why offer the possibility of grouping related components under the same alterSection and be shielded from updates in the components that belong to other alterSections . docs \u00b6 Manages Markdown documents. Fetches raw source from the server and stores it into the state, under a key, which is the path information of the document. The DocMd provides a widget for such documents. Actions \u00b6 fetchDoc \u00b6 Fetches a document from the server asynchronously. Reducer \u00b6 Stores the fetched raw document source into the state. Selectors \u00b6 getDoc \u00b6 Retrieves the stored data for the specified document. Helpers \u00b6 needDoc \u00b6 Check whether a component contains the data for its document. changedDoc \u00b6 Check whether a component has new props in such a way that a new document should be fetched. filters \u00b6 Supports the display of filtered lists, where there is a bunch of filters and a list with items filtered by those. Lists and filters form a complex system of components, involving fetching list data from the server, fetching filter specifications fetching the metadata that is used by the filtering handling the user interactions with the filters supporting special effects such as a map of European countries with markers having a radius indicative of the number of filtered items by that country. This duct not only needs data from the filters slice, but also from the tables slice! Actions \u00b6 changeFulltext \u00b6 Responds to a change in the search text in a Fulltext search widget. changeFacet \u00b6 Responds to a click in the checkbox of a facet Facet . changeFacetAll \u00b6 Responds to a click to (de)select all facets of a field. initFiltering \u00b6 Initializes filtering for a table. This action also looks at the tables slice of the state, which is managed by tables . The actual work is done by a memoized helper function: compileFieldIds . On the basis of this, initial settings of facet filters can be made. This is done by the helper function initFilterSettings and these settings are to be added to the filters slice of the state under the key table and then under a key filterTag . In this way you can set up various kinds of filtering for the same table. Reducer \u00b6 Transforms the state in response to dispatched actions, notably the filters slice and within that a sliced keyed by table . Selectors \u00b6 Filter information is being translated from the state to props that can be consumed by components. getFilters \u00b6 Reads the current settings of a filter and injects it as filters into the props of the receiving components, which are typically the filter widgets that receive user interaction: Fulltext Facet , and also CheckboxI , EUMap . Helpers \u00b6 compileValues \u00b6 For every field that is chosen for faceted browsing, the list of values will be compiled. The result is used by ByValue . This component is responsible for all the facets of a field. It is useful to store the results of this compilation, but where? We do not store it in the state, because it is derived data, and we adhere to the principle that the state is a normalized single source of truth . Selectors are invoked upon each rendering, but in this case we do not want to redo the compilation all the time. The solution is to use a memoized function . I have created my own memoizer . computeFiltering \u00b6 Applies the filters, according to the current filter settings. Applying means: determine the subset of filtered items ( filteredData ), and provide statistics for the facets. Every faceted field displays as total the amount of items filtered by all other filters ( filteredAmountOthers ). For each of its facets, it displays how many items of this relative total correspond to that facet ( amounts ). So this function delivers exactly that: filteredData , filteredAmountOthers , amounts . It is also a costly function, but it does need to be invoked upon each rendering caused by a click or a key press. makeTag \u00b6 Makes a filterTag , depending on the situation of the List of items that needs the filtering. The most fundamental issue is: is the list showing all items in the table, or my items only, or is it a list of detail records of some master record in an other table? testAllChecks \u00b6 Looks if all facets are checked, or all unchecked, of none of both. Used to steer the collective checkbox that governs all facets. forms \u00b6 The forms slice of the state is under control of the Redux-Form module. It contains all current form data of components where the user is interacting with forms. Some other components might want to know whether a component is engaged in data entry or not, without fully connecting to all form state properties of redux-form. This duct gives that information and that information only. Actions \u00b6 Reducer \u00b6 Selectors \u00b6 getForms \u00b6 Returns the set of keys of the forms slice of the state. It calls a memoized function to turn the keys into a set. So, if the set of keys is asked repeatedly without having been changed, exactly the same set object is being returned. Helpers \u00b6 No helpers. grid \u00b6 This duct support grid views of tables, by managing sorting information of the grid columns. Every grid table must identify itself with a gridTag and its data resides on the grid slice of the state under that tag. Actions \u00b6 resetSort \u00b6 Removes all sorting information under a gridTag . addColumn \u00b6 Adds a sorting column. Grids can be sorted by multiple columns. delColumn \u00b6 Deletes a sorting column. turnColumn \u00b6 Toggles the sort method between ascending and descending for a specified column. Reducer \u00b6 Applies the state changes, defined by the actions, to the grid slice, under the key gridTag . Selectors \u00b6 getGrid \u00b6 Returns the grid slice of the state. Helpers \u00b6 compileSortedData \u00b6 This function actually applies a given sort order to a list of ids of items from a table. me \u00b6 Powers the login widget, top right on the screen, realized by the component Login . The login procedure caters for shibboleth logins. Upon successful login, the server sends information about the currently logged in user to the client. The main task of Login is to fetch the current authentication status: is there an authenticated user, and if so, what is his/her name? NB: Because of the federated login, the username and password are not entered in any form in this app. So the client does not know who the user is, except by asking the server. The current user can be retrieved by /api/db/who/ami . Actions \u00b6 fetchMe \u00b6 Fetches data about me , the logged in user. It is actually handled by the helper server . Reducer \u00b6 Transforms the state in response to dispatched ticket, notably the me slice. It just contains the known attributes of a single user, the one that is logged in. Selectors \u00b6 getMe \u00b6 Plainly hand over the attributes of the currently logged in user. At the moment only the Login component is interested in it. Helpers \u00b6 No helpers. notes \u00b6 Powers the notification widget, top right on the screen, realized by the component Notification . A notification has a kind and a text . The kind is one of error , warning , special , info . All non-info messages are considered important. Normally, the notification panel is hidden, but it can be called up by clicking on the progress circle in the top-right of the screen. The panel also shows up if there is a new important message, and it will scroll to the last important one. The user can click away the panel and hide the messages. Actions \u00b6 notify \u00b6 Issues its payload, which consists of an array of messages, as notifications. clear \u00b6 Clears the existing list of notifications. display \u00b6 Turns the visibility of notification panel on or off. Other components can issue notifications easily, either by importing these actions, or by dispatching the right actions themselves. The helper function accessData can issue notifications. These notifications are given the type async and convey a status pending , success , or error . Reducer \u00b6 Transforms the state in response to dispatched ticket, notably the notes slice. The state maintains a counter busy , which is the number of currently asynchronously pending operations. A notification widget can show a progress spinner if busy > 0 . Selectors \u00b6 getNotes \u00b6 The notification widget gets the notifications from the state, including busy and show , the latter indicating whether the notification panel should be hidden or not. For the convenience of the Notification component, the index of the last important notification message is also computed, and its kind. Helpers \u00b6 No helpers. roots \u00b6 Top level management of the state: initialization and combination of all the other dux. Actions \u00b6 configureStore \u00b6 Root does not have proper actions of its own. But it does set up the store, and passes it on to the main component. Reducer \u00b6 Combines all slices of the state and combines all reducers that work their own slice of the state into the root reducer , that operates on the whole state. Selectors \u00b6 Helpers \u00b6 No helpers. select \u00b6 Manages the UI-state of the RelSelect component. Every RelSelect instance must be identified by a tag, so that the states of the select controls do not get confused. The most obvious choice for a tag value is a composition of the table name, the entity id, and the field name. Actions \u00b6 setSearch \u00b6 When a user types something in the search input field associated with the select control, the search string is sent to the state. setPopUp \u00b6 Parts of the interface of the select widget will pop up after a user action, or disappear after an other user action. This action sets the popped up state categorically to true or false , depending on a parameter. togglePopUp \u00b6 Toggles the popped up state of the relevant part of the widget. Reducer \u00b6 Straightforward merge of the payload of pop up actions and search string updates into the state. Selectors \u00b6 getSelect \u00b6 Retrieves all state information of a specific select control, i.e. an instance identified by a tag. Helpers \u00b6 compileOptions \u00b6 Initializes the state for a specific select control. This is an initialization per tag . server \u00b6 Here all interaction with the server is managed. All activity that involves waiting for a server, will eventually reach out to actions here. The actions below only are concerned with requesting a server response, waiting for it, and reporting success or failure. Before a request is made, it is checked whether that request has been submitted before and is still pending. In that case, the request counter will be increased, and no new request will be made. request counters that are non-zero correspond to requests that are either pending, or have ended in failure; pending requests have positive request counters, the number represents the number of requests the app has tried to make so far (only 1 request will be issued effectively); successful request have their request counter set to 0 again. Actions \u00b6 accessData \u00b6 Asynchronous action to fetch data from the server, and also to send data to it. A task object specifies what to fetch, and can contain data to send to the server. It can be used for database queries or file content. During the stages of a request, notify actions will be dispatched. progress \u00b6 This action represents the situation that a request is offered multiple times before the first one has been completed. The request will not be made, but the request counter will be increased. ask \u00b6 Just before a request is made, this action sets the request counter to 1. err \u00b6 When a request returns failure, the request counter is set to -1. succeed \u00b6 When a request returns success, the request counter is set to 0. Reducer \u00b6 Manages the request counter and puts it under a key under the server slice of the state. The key is identical to the path of the request (the URL that is fired to the server). Note \u00b6 But all actions except accessData are also picked up by the notes reducer, where they result in notifications. Selectors \u00b6 There are no selectors. So far, no component needs this slice of the state. Helpers \u00b6 No helpers. settings \u00b6 Cross cutting settings for the app are defined here. The settings slice of the state is just a store of keys and values. Actions \u00b6 set \u00b6 Adds a key value pair. Reducer \u00b6 Straightforward reducer. Selectors \u00b6 getSettings \u00b6 Returns the settings slice of the state. Helpers \u00b6 No helpers. tables \u00b6 Manages database data from the server. It keeps a normalized copy of the data. When different components fetch the bits and pieces they need, it all lands here, properly organized. This reduces the amount of fetching that is needed, and it improves consistency, because all data consuming components look at the same data. Principal data consuming components are ListContainer and Items . In order to do the job properly, a fair amount of metadata about tables and fields is also fetched and stored. In particular, tables specify which filters can be used on which fields. This filter setup is not hard-wired into the client app, but comes from the server, where it is configured in the data model . Actions \u00b6 fetchTable \u00b6 Fetches a complete table, but only the title fields and the fields needed for filtering. fetchTables \u00b6 Fetches a list of tables by successively calling fetchTable . fetchItem \u00b6 Fetches a single rows from a table, all fields. The server decides which fields I am allowed to retrieve. If fields refer to other tables for their values, the above actions will fetch these tables as well. fetchItems \u00b6 Fetches a selection of rows from a table, all fields. The selection is given by a list of _id s to fetch. The server decides which fields may be retrieved. modItem \u00b6 Sends a request to update an item to the server, and merges the answer (the updated values) into the state. insertItem \u00b6 Sends a request to insert an item to the server, and merges the answer (the inserted item) into the state. delItem \u00b6 Sends a request to delete an item to the server, and updates the state to reflect the deletion of that item. Reducer \u00b6 The actions above potentially receive overlapping data. The reducer takes care that all gets sorted out, and that every bit ends up in its proper place. A table is stored under its name as key. The table information is an object of entities (rows), keyed by their database id. Next to the entities their is an array, called order , of ids that specifies the order. If only my rows are being retrieved, there is an alternative array, called my , that contains the ids of the retrieved entities in the right order. Next to the entity and order information there is field type information. There is also information about permissions (read, insert, delete, update). The entities themselves have a values object, with all the field values, keyed by field name. Next to the values there is an attribute complete that tells whether all fields for this entity have been fetched, or only the core fields. As an example, consider the scenario that first the complete list of items is fetched, then the my items. The question is: after fetching the my items, will the full table that has been fetched before, be disturbed? The answer is of course no. Because the reducer merges the my entities with the existing entities. So the non- my entities are untouched. But what about order ? Well, when reducing a my-fetch action, there is no incoming order array but a my array instead, and the order that already exists on the state is not touched. As a second example, consider the scenario where a single item is fetched first, with all its fields, and then the full list of items, but with only title fields. The question is: will the previously fetched item loose its extra fields? The answer is of course no. Because the reducer merges the new entities' values with existing entities' values. Of all dux, this is the best example of what proper reducing is and what it achieves. It might look hard to take care of this merging, under the constraint that only those branches of the state should be touched that are actually updated. But the lodash mergeWith makes this a breeze. Unfortunately, this library does not always leave unchanged values untouched, which results in unnecessary re-renderings of components. The best solution turned out to be Immutability-Helper . If you want to dive deeper into this issue, see the tests about merging , which includes tests that makes this issue crystal clear. The methods of the Immutability-Helper have a syntax inspired by the MongoDB commands, which is a nice reduction of cognitive load, since we use MongoDB at the server side. Have a look again at the reducer source code and see how straightforward it is to code one of the most tricky reducers in this app. This reducer actively covered by tests . Have a look at them to get more feeling of how table actions cause state transitions. Selectors \u00b6 getTables \u00b6 Return the whole tables slice of the state. Helpers \u00b6 entityHead \u00b6 Computes the title for an item, based on the data model or on specialized functions, defined here. See also repr . needTable \u00b6 Checks if sufficient table data is available in the state. needTables \u00b6 Checks a list of table names to see if sufficient data is available in the state. needValues \u00b6 Checks a single entity in a single table to see if it contains values for all fields. listValues \u00b6 Gives the list of all values of a specified field in a table. presentUser \u00b6 Presents a user, by means of name, email address, and/or eppn , depending on what information is available, which also depends on what information may be shared with the currently logged in user. changedItem \u00b6 Checks if properties have changed in such a few that new data should be fetched. headEntity \u00b6 The head line of a record, based on its title field and/or other data. For some specific tables custom logic is used. repr \u00b6 Makes a streamlined string representation out of a field value. It looks up ids in related value list tables. For some tables, special representation functions will be invoked. (users, countries, etc.). toDb \u00b6 Dispatches an item modification action to the store. handleOpenAll \u00b6 When a user clicks on an Open All button, this function is invoked to fetch the corresponding records (if needed). handleCloseAll \u00b6 When a user clicks on an Close All button, this function is invoked to collapse the corresponding records and remove the _id s of the previously open records from the URL, using browserHistory . win \u00b6 Reacts to window resizing by the user. It will deliver the new window size after resizing. Useful for components that care about the window size, such as App . Actions \u00b6 changeWinDim \u00b6 Responds to window resizing, as set up in Window . It is just a matter of storing the height and the width of the window into the state. Note that the event emitter in Window is being throttled, so that it does not run too frequently during the actual resizing. Reducer \u00b6 Transforms the win slice of the state in response to resize events. Selectors \u00b6 getWinDim \u00b6 Returns the win slice of the state, which is just the current width and height of the browser window. Helpers \u00b6 No helpers. workflow \u00b6 A lot of the logic of showing lists, items, related items and fields is purely generic and driven by the data model . But there is considerably more to an app than this kind of generic logic. The workflow duct is the entry point for additional, non-trivial business logic. It is still in development. Active items \u00b6 The package table determines a lot about the assessment process. It has records with a specified startDate end endDate. The packages that have started and are not yet passed there endDate are the active packages. Normally there will be exactly one package. From the active package derive a number of other active concepts: the contribution types listed in the typeContribution field of the active package are the active types the criteria that are details of the active package are active criteria . The generic List and Item components can be made sensitive to this notion of activity. Active items can be formatted specially, and likewise the non-active items, which can also be disabled in some contexts. The way (in)active items are displayed is controlled by the data model . See for example the field typeContribution in the tables package and criteria . Actions \u00b6 fetchWorkflow \u00b6 Fetch the info about the workflow information from the server, in particular the reset history since the last startup of the web server. resetWorkflow \u00b6 Fetch the same information as fetchWorkflow does, but add ?reset=true to the URL that is used to query this information from the server. This will instruct the server to perform a workflow reset. Reducer \u00b6 The reducer is simple, it only has to perform one action: put incoming workflow data unto the state. No sophisticated merging is needed, because this workflow meta information is only needed for one component, WorkflowInfo , which is meant for sysadmins only. Note that the factual workflow data moves from server to client on the shoulders of the tables reducer. Selectors \u00b6 getWorkflow \u00b6 Returns the workflow slice of the state. odebase: 'About/Codebase.md' compileActive \u00b6 Computes the active packages, types and criteria and deliver them in an object, keyed by kind of item and containing an array of active item MongoDB ids for that kind. decisions \u00b6 Most of the contents of the decision table, in the form of objects by which you can find various user-facing strings associated with the three possible review decisions: accept , revise , and reject . finalDecision \u00b6 From workflow attributes that contain reviewers and reviews respectively, find out whether there has been a final decision by reviewer 2, and if so, what it was. getItem \u00b6 Peels out items of data from a workflow attribute that has fetched arrays of data from other records. isReviewerType \u00b6 Computes whether a given author is the first or second reviewer. loadExtra \u00b6 This is a configuration object that specifies which extra tables should be fetched from the server along with particular other tables. For example, the app can only perform its business logic on contributions, if the tables package , criteria , typeContribution , and decision are all present on the state. processStatus \u00b6 Produce a string that contains the current assessment status and review status of an assessment. This function can be called from a contribution, an assessment and a review. So for all these kinds of document we can produce a short overview of the state they have reached in the assessment / review process. The outcome has a bit that reveals the assessment status and a bit about the review status. When it is run on behalf of a user with marginal rights, it delivers either the empty string, or the outcome of the final review, but only if there has been a positive outcome. For users with more rights: assessment status: \u25b6 if the assessment has been (re)submitted; \u270d otherwise; the assessment score review status: empty string if there review has not reached a final decision; \u2714 on accept ; \u270b on revise ; \u2718 on reject . reviewerRole \u00b6 Object that maps the acronyms E and F to appropriate labels designating first and second reviewer.","title":"Dux"},{"location":"Client/Dux/#dux-appliances","text":"Dux (ducts) are appliances within the app, i.e. sets of components that all work with the same slice of the state A duct is a connector between a slice of the state and the components that work with that slice. As such, it is a piece of plumbing, hidden behind the walls and under the floors. We have organized dux as follows: one file that contains its actions , reducer , selectors and helpers . the reducer is programmed as an object of flows . For each action, there is a flow with the same name, which is a function that produces a new state on the basis of that action. a number of React components that make use of these by importing them. This app contains the following dux: alter docs filters forms grid me notes roots select server settings tables win workflow However, life is complicated, and the interplay between dux and components is no exception. Sometimes actions will be fired that affect more than one slice of the state. For example, in order to set up filters for a table, both the tables slice and the filters slice are needed. And when the user expands a table row into a record form, the alter state is changed to cater for the expand action, and the tables slice is changed by receiving additional data for that record. In Redux, the slices of the state are not sealed off from each other. In the end, there is one and only one reducer, that examines every dispatched action for its type property, and hands it over to a sub-reducer that has \"subscribed\" to handle actions for that type. It is perfectly possible that multiple sub-reducers will deal with a single action. A good example is when a record is displayed with multiple detail records, displayed as a list of titles. There is a button \"Open All\" on the interface. When it is pressed, data for all detail records is fetched, and the titles expand into full record views for those details. The way it is implemented, is that pressing \"Open All\" leads to the dispatch of an action with type fetchItems , and with payload the list of ids of the entities that must be fetched. To this action, the tables sub-reducer reacts by fetching the corresponding entity data from the server, and the alter sub-reducer reacts by expanding the corresponding entity titles into full records. Whenever you are tempted to write complicated, time-sensitive logic to orchestrate what happens at multiple slices of the state, all that is needed is in fact just an extra response of an other sub reducer.","title":"Dux (Appliances)"},{"location":"Client/Dux/#alter","text":"A mechanism for switching between alternative representations of a component, such as: expanded / collapsed, editable / read-only. It is a bit more general than that: you can supply n alternatives and n controls, and let the user cycle through the alternatives by clicking the controls. Components that work with alternatives must collect them in a group. The name of that group is passed as a prop called alterSection . Component that are passed this prop, have access to the state of the alternatives in this group. To get the state information for a single alternative, another key must be supplied, usually called alterTag . The component that displays the alternatives need not be the same component that presents the controls to switch alternatives.","title":"alter"},{"location":"Client/Dux/#actions","text":"Both actions below work relative an alterSection and alterTag .","title":"Actions"},{"location":"Client/Dux/#nextalt","text":"Switch to the next alternative. This action must specify the total number of alternatives and an optional initial value. If there is not yet a state for this instantiation, the initial value will be used to start from.","title":"nextAlt"},{"location":"Client/Dux/#setalt","text":"Switch to specified alternative.","title":"setAlt"},{"location":"Client/Dux/#setitems","text":"This function is used to switch a bunch of records from an open to a closed state or vice versa.","title":"setItems"},{"location":"Client/Dux/#reducer","text":"Increases the index of the alternative by one, cyclically, and puts it under the right keys in the state..","title":"Reducer"},{"location":"Client/Dux/#selectors","text":"","title":"Selectors"},{"location":"Client/Dux/#getaltsection","text":"Delivers the numbers of the current alternatives as far as they are registered under the alterSection key in the alter slice of the state.","title":"getAltSection"},{"location":"Client/Dux/#helpers","text":"","title":"Helpers"},{"location":"Client/Dux/#compilealternatives","text":"A component that wants to work with the alternatives, of a group of components, must call compileAlternatives() with the right parameters. Think of a List component that wants to provide child items with a control to expand themselves. It is more efficient that the List connects to the alter state, than that each item connects to that state individually. This function is a factory function that, given an alterTag , delivers an object with functions for getting and setting the alternatives of that particular instance.","title":"compileAlternatives"},{"location":"Client/Dux/#caution","text":"It is tempting to make one alterSection for all components in the app that need alternatives. The flip side of doing so is that all those components will be triggered for re-render whenever any single one of them switches alternatives. That is why offer the possibility of grouping related components under the same alterSection and be shielded from updates in the components that belong to other alterSections .","title":"Caution"},{"location":"Client/Dux/#docs","text":"Manages Markdown documents. Fetches raw source from the server and stores it into the state, under a key, which is the path information of the document. The DocMd provides a widget for such documents.","title":"docs"},{"location":"Client/Dux/#actions_1","text":"","title":"Actions"},{"location":"Client/Dux/#fetchdoc","text":"Fetches a document from the server asynchronously.","title":"fetchDoc"},{"location":"Client/Dux/#reducer_1","text":"Stores the fetched raw document source into the state.","title":"Reducer"},{"location":"Client/Dux/#selectors_1","text":"","title":"Selectors"},{"location":"Client/Dux/#getdoc","text":"Retrieves the stored data for the specified document.","title":"getDoc"},{"location":"Client/Dux/#helpers_1","text":"","title":"Helpers"},{"location":"Client/Dux/#needdoc","text":"Check whether a component contains the data for its document.","title":"needDoc"},{"location":"Client/Dux/#changeddoc","text":"Check whether a component has new props in such a way that a new document should be fetched.","title":"changedDoc"},{"location":"Client/Dux/#filters","text":"Supports the display of filtered lists, where there is a bunch of filters and a list with items filtered by those. Lists and filters form a complex system of components, involving fetching list data from the server, fetching filter specifications fetching the metadata that is used by the filtering handling the user interactions with the filters supporting special effects such as a map of European countries with markers having a radius indicative of the number of filtered items by that country. This duct not only needs data from the filters slice, but also from the tables slice!","title":"filters"},{"location":"Client/Dux/#actions_2","text":"","title":"Actions"},{"location":"Client/Dux/#changefulltext","text":"Responds to a change in the search text in a Fulltext search widget.","title":"changeFulltext"},{"location":"Client/Dux/#changefacet","text":"Responds to a click in the checkbox of a facet Facet .","title":"changeFacet"},{"location":"Client/Dux/#changefacetall","text":"Responds to a click to (de)select all facets of a field.","title":"changeFacetAll"},{"location":"Client/Dux/#initfiltering","text":"Initializes filtering for a table. This action also looks at the tables slice of the state, which is managed by tables . The actual work is done by a memoized helper function: compileFieldIds . On the basis of this, initial settings of facet filters can be made. This is done by the helper function initFilterSettings and these settings are to be added to the filters slice of the state under the key table and then under a key filterTag . In this way you can set up various kinds of filtering for the same table.","title":"initFiltering"},{"location":"Client/Dux/#reducer_2","text":"Transforms the state in response to dispatched actions, notably the filters slice and within that a sliced keyed by table .","title":"Reducer"},{"location":"Client/Dux/#selectors_2","text":"Filter information is being translated from the state to props that can be consumed by components.","title":"Selectors"},{"location":"Client/Dux/#getfilters","text":"Reads the current settings of a filter and injects it as filters into the props of the receiving components, which are typically the filter widgets that receive user interaction: Fulltext Facet , and also CheckboxI , EUMap .","title":"getFilters"},{"location":"Client/Dux/#helpers_2","text":"","title":"Helpers"},{"location":"Client/Dux/#compilevalues","text":"For every field that is chosen for faceted browsing, the list of values will be compiled. The result is used by ByValue . This component is responsible for all the facets of a field. It is useful to store the results of this compilation, but where? We do not store it in the state, because it is derived data, and we adhere to the principle that the state is a normalized single source of truth . Selectors are invoked upon each rendering, but in this case we do not want to redo the compilation all the time. The solution is to use a memoized function . I have created my own memoizer .","title":"compileValues"},{"location":"Client/Dux/#computefiltering","text":"Applies the filters, according to the current filter settings. Applying means: determine the subset of filtered items ( filteredData ), and provide statistics for the facets. Every faceted field displays as total the amount of items filtered by all other filters ( filteredAmountOthers ). For each of its facets, it displays how many items of this relative total correspond to that facet ( amounts ). So this function delivers exactly that: filteredData , filteredAmountOthers , amounts . It is also a costly function, but it does need to be invoked upon each rendering caused by a click or a key press.","title":"computeFiltering"},{"location":"Client/Dux/#maketag","text":"Makes a filterTag , depending on the situation of the List of items that needs the filtering. The most fundamental issue is: is the list showing all items in the table, or my items only, or is it a list of detail records of some master record in an other table?","title":"makeTag"},{"location":"Client/Dux/#testallchecks","text":"Looks if all facets are checked, or all unchecked, of none of both. Used to steer the collective checkbox that governs all facets.","title":"testAllChecks"},{"location":"Client/Dux/#forms","text":"The forms slice of the state is under control of the Redux-Form module. It contains all current form data of components where the user is interacting with forms. Some other components might want to know whether a component is engaged in data entry or not, without fully connecting to all form state properties of redux-form. This duct gives that information and that information only.","title":"forms"},{"location":"Client/Dux/#actions_3","text":"","title":"Actions"},{"location":"Client/Dux/#reducer_3","text":"","title":"Reducer"},{"location":"Client/Dux/#selectors_3","text":"","title":"Selectors"},{"location":"Client/Dux/#getforms","text":"Returns the set of keys of the forms slice of the state. It calls a memoized function to turn the keys into a set. So, if the set of keys is asked repeatedly without having been changed, exactly the same set object is being returned.","title":"getForms"},{"location":"Client/Dux/#helpers_3","text":"No helpers.","title":"Helpers"},{"location":"Client/Dux/#grid","text":"This duct support grid views of tables, by managing sorting information of the grid columns. Every grid table must identify itself with a gridTag and its data resides on the grid slice of the state under that tag.","title":"grid"},{"location":"Client/Dux/#actions_4","text":"","title":"Actions"},{"location":"Client/Dux/#resetsort","text":"Removes all sorting information under a gridTag .","title":"resetSort"},{"location":"Client/Dux/#addcolumn","text":"Adds a sorting column. Grids can be sorted by multiple columns.","title":"addColumn"},{"location":"Client/Dux/#delcolumn","text":"Deletes a sorting column.","title":"delColumn"},{"location":"Client/Dux/#turncolumn","text":"Toggles the sort method between ascending and descending for a specified column.","title":"turnColumn"},{"location":"Client/Dux/#reducer_4","text":"Applies the state changes, defined by the actions, to the grid slice, under the key gridTag .","title":"Reducer"},{"location":"Client/Dux/#selectors_4","text":"","title":"Selectors"},{"location":"Client/Dux/#getgrid","text":"Returns the grid slice of the state.","title":"getGrid"},{"location":"Client/Dux/#helpers_4","text":"","title":"Helpers"},{"location":"Client/Dux/#compilesorteddata","text":"This function actually applies a given sort order to a list of ids of items from a table.","title":"compileSortedData"},{"location":"Client/Dux/#me","text":"Powers the login widget, top right on the screen, realized by the component Login . The login procedure caters for shibboleth logins. Upon successful login, the server sends information about the currently logged in user to the client. The main task of Login is to fetch the current authentication status: is there an authenticated user, and if so, what is his/her name? NB: Because of the federated login, the username and password are not entered in any form in this app. So the client does not know who the user is, except by asking the server. The current user can be retrieved by /api/db/who/ami .","title":"me"},{"location":"Client/Dux/#actions_5","text":"","title":"Actions"},{"location":"Client/Dux/#fetchme","text":"Fetches data about me , the logged in user. It is actually handled by the helper server .","title":"fetchMe"},{"location":"Client/Dux/#reducer_5","text":"Transforms the state in response to dispatched ticket, notably the me slice. It just contains the known attributes of a single user, the one that is logged in.","title":"Reducer"},{"location":"Client/Dux/#selectors_5","text":"","title":"Selectors"},{"location":"Client/Dux/#getme","text":"Plainly hand over the attributes of the currently logged in user. At the moment only the Login component is interested in it.","title":"getMe"},{"location":"Client/Dux/#helpers_5","text":"No helpers.","title":"Helpers"},{"location":"Client/Dux/#notes","text":"Powers the notification widget, top right on the screen, realized by the component Notification . A notification has a kind and a text . The kind is one of error , warning , special , info . All non-info messages are considered important. Normally, the notification panel is hidden, but it can be called up by clicking on the progress circle in the top-right of the screen. The panel also shows up if there is a new important message, and it will scroll to the last important one. The user can click away the panel and hide the messages.","title":"notes"},{"location":"Client/Dux/#actions_6","text":"","title":"Actions"},{"location":"Client/Dux/#notify","text":"Issues its payload, which consists of an array of messages, as notifications.","title":"notify"},{"location":"Client/Dux/#clear","text":"Clears the existing list of notifications.","title":"clear"},{"location":"Client/Dux/#display","text":"Turns the visibility of notification panel on or off. Other components can issue notifications easily, either by importing these actions, or by dispatching the right actions themselves. The helper function accessData can issue notifications. These notifications are given the type async and convey a status pending , success , or error .","title":"display"},{"location":"Client/Dux/#reducer_6","text":"Transforms the state in response to dispatched ticket, notably the notes slice. The state maintains a counter busy , which is the number of currently asynchronously pending operations. A notification widget can show a progress spinner if busy > 0 .","title":"Reducer"},{"location":"Client/Dux/#selectors_6","text":"","title":"Selectors"},{"location":"Client/Dux/#getnotes","text":"The notification widget gets the notifications from the state, including busy and show , the latter indicating whether the notification panel should be hidden or not. For the convenience of the Notification component, the index of the last important notification message is also computed, and its kind.","title":"getNotes"},{"location":"Client/Dux/#helpers_6","text":"No helpers.","title":"Helpers"},{"location":"Client/Dux/#roots","text":"Top level management of the state: initialization and combination of all the other dux.","title":"roots"},{"location":"Client/Dux/#actions_7","text":"","title":"Actions"},{"location":"Client/Dux/#configurestore","text":"Root does not have proper actions of its own. But it does set up the store, and passes it on to the main component.","title":"configureStore"},{"location":"Client/Dux/#reducer_7","text":"Combines all slices of the state and combines all reducers that work their own slice of the state into the root reducer , that operates on the whole state.","title":"Reducer"},{"location":"Client/Dux/#selectors_7","text":"","title":"Selectors"},{"location":"Client/Dux/#helpers_7","text":"No helpers.","title":"Helpers"},{"location":"Client/Dux/#select","text":"Manages the UI-state of the RelSelect component. Every RelSelect instance must be identified by a tag, so that the states of the select controls do not get confused. The most obvious choice for a tag value is a composition of the table name, the entity id, and the field name.","title":"select"},{"location":"Client/Dux/#actions_8","text":"","title":"Actions"},{"location":"Client/Dux/#setsearch","text":"When a user types something in the search input field associated with the select control, the search string is sent to the state.","title":"setSearch"},{"location":"Client/Dux/#setpopup","text":"Parts of the interface of the select widget will pop up after a user action, or disappear after an other user action. This action sets the popped up state categorically to true or false , depending on a parameter.","title":"setPopUp"},{"location":"Client/Dux/#togglepopup","text":"Toggles the popped up state of the relevant part of the widget.","title":"togglePopUp"},{"location":"Client/Dux/#reducer_8","text":"Straightforward merge of the payload of pop up actions and search string updates into the state.","title":"Reducer"},{"location":"Client/Dux/#selectors_8","text":"","title":"Selectors"},{"location":"Client/Dux/#getselect","text":"Retrieves all state information of a specific select control, i.e. an instance identified by a tag.","title":"getSelect"},{"location":"Client/Dux/#helpers_8","text":"","title":"Helpers"},{"location":"Client/Dux/#compileoptions","text":"Initializes the state for a specific select control. This is an initialization per tag .","title":"compileOptions"},{"location":"Client/Dux/#server","text":"Here all interaction with the server is managed. All activity that involves waiting for a server, will eventually reach out to actions here. The actions below only are concerned with requesting a server response, waiting for it, and reporting success or failure. Before a request is made, it is checked whether that request has been submitted before and is still pending. In that case, the request counter will be increased, and no new request will be made. request counters that are non-zero correspond to requests that are either pending, or have ended in failure; pending requests have positive request counters, the number represents the number of requests the app has tried to make so far (only 1 request will be issued effectively); successful request have their request counter set to 0 again.","title":"server"},{"location":"Client/Dux/#actions_9","text":"","title":"Actions"},{"location":"Client/Dux/#accessdata","text":"Asynchronous action to fetch data from the server, and also to send data to it. A task object specifies what to fetch, and can contain data to send to the server. It can be used for database queries or file content. During the stages of a request, notify actions will be dispatched.","title":"accessData"},{"location":"Client/Dux/#progress","text":"This action represents the situation that a request is offered multiple times before the first one has been completed. The request will not be made, but the request counter will be increased.","title":"progress"},{"location":"Client/Dux/#ask","text":"Just before a request is made, this action sets the request counter to 1.","title":"ask"},{"location":"Client/Dux/#err","text":"When a request returns failure, the request counter is set to -1.","title":"err"},{"location":"Client/Dux/#succeed","text":"When a request returns success, the request counter is set to 0.","title":"succeed"},{"location":"Client/Dux/#reducer_9","text":"Manages the request counter and puts it under a key under the server slice of the state. The key is identical to the path of the request (the URL that is fired to the server).","title":"Reducer"},{"location":"Client/Dux/#note","text":"But all actions except accessData are also picked up by the notes reducer, where they result in notifications.","title":"Note"},{"location":"Client/Dux/#selectors_9","text":"There are no selectors. So far, no component needs this slice of the state.","title":"Selectors"},{"location":"Client/Dux/#helpers_9","text":"No helpers.","title":"Helpers"},{"location":"Client/Dux/#settings","text":"Cross cutting settings for the app are defined here. The settings slice of the state is just a store of keys and values.","title":"settings"},{"location":"Client/Dux/#actions_10","text":"","title":"Actions"},{"location":"Client/Dux/#set","text":"Adds a key value pair.","title":"set"},{"location":"Client/Dux/#reducer_10","text":"Straightforward reducer.","title":"Reducer"},{"location":"Client/Dux/#selectors_10","text":"","title":"Selectors"},{"location":"Client/Dux/#getsettings","text":"Returns the settings slice of the state.","title":"getSettings"},{"location":"Client/Dux/#helpers_10","text":"No helpers.","title":"Helpers"},{"location":"Client/Dux/#tables","text":"Manages database data from the server. It keeps a normalized copy of the data. When different components fetch the bits and pieces they need, it all lands here, properly organized. This reduces the amount of fetching that is needed, and it improves consistency, because all data consuming components look at the same data. Principal data consuming components are ListContainer and Items . In order to do the job properly, a fair amount of metadata about tables and fields is also fetched and stored. In particular, tables specify which filters can be used on which fields. This filter setup is not hard-wired into the client app, but comes from the server, where it is configured in the data model .","title":"tables"},{"location":"Client/Dux/#actions_11","text":"","title":"Actions"},{"location":"Client/Dux/#fetchtable","text":"Fetches a complete table, but only the title fields and the fields needed for filtering.","title":"fetchTable"},{"location":"Client/Dux/#fetchtables","text":"Fetches a list of tables by successively calling fetchTable .","title":"fetchTables"},{"location":"Client/Dux/#fetchitem","text":"Fetches a single rows from a table, all fields. The server decides which fields I am allowed to retrieve. If fields refer to other tables for their values, the above actions will fetch these tables as well.","title":"fetchItem"},{"location":"Client/Dux/#fetchitems","text":"Fetches a selection of rows from a table, all fields. The selection is given by a list of _id s to fetch. The server decides which fields may be retrieved.","title":"fetchItems"},{"location":"Client/Dux/#moditem","text":"Sends a request to update an item to the server, and merges the answer (the updated values) into the state.","title":"modItem"},{"location":"Client/Dux/#insertitem","text":"Sends a request to insert an item to the server, and merges the answer (the inserted item) into the state.","title":"insertItem"},{"location":"Client/Dux/#delitem","text":"Sends a request to delete an item to the server, and updates the state to reflect the deletion of that item.","title":"delItem"},{"location":"Client/Dux/#reducer_11","text":"The actions above potentially receive overlapping data. The reducer takes care that all gets sorted out, and that every bit ends up in its proper place. A table is stored under its name as key. The table information is an object of entities (rows), keyed by their database id. Next to the entities their is an array, called order , of ids that specifies the order. If only my rows are being retrieved, there is an alternative array, called my , that contains the ids of the retrieved entities in the right order. Next to the entity and order information there is field type information. There is also information about permissions (read, insert, delete, update). The entities themselves have a values object, with all the field values, keyed by field name. Next to the values there is an attribute complete that tells whether all fields for this entity have been fetched, or only the core fields. As an example, consider the scenario that first the complete list of items is fetched, then the my items. The question is: after fetching the my items, will the full table that has been fetched before, be disturbed? The answer is of course no. Because the reducer merges the my entities with the existing entities. So the non- my entities are untouched. But what about order ? Well, when reducing a my-fetch action, there is no incoming order array but a my array instead, and the order that already exists on the state is not touched. As a second example, consider the scenario where a single item is fetched first, with all its fields, and then the full list of items, but with only title fields. The question is: will the previously fetched item loose its extra fields? The answer is of course no. Because the reducer merges the new entities' values with existing entities' values. Of all dux, this is the best example of what proper reducing is and what it achieves. It might look hard to take care of this merging, under the constraint that only those branches of the state should be touched that are actually updated. But the lodash mergeWith makes this a breeze. Unfortunately, this library does not always leave unchanged values untouched, which results in unnecessary re-renderings of components. The best solution turned out to be Immutability-Helper . If you want to dive deeper into this issue, see the tests about merging , which includes tests that makes this issue crystal clear. The methods of the Immutability-Helper have a syntax inspired by the MongoDB commands, which is a nice reduction of cognitive load, since we use MongoDB at the server side. Have a look again at the reducer source code and see how straightforward it is to code one of the most tricky reducers in this app. This reducer actively covered by tests . Have a look at them to get more feeling of how table actions cause state transitions.","title":"Reducer"},{"location":"Client/Dux/#selectors_11","text":"","title":"Selectors"},{"location":"Client/Dux/#gettables","text":"Return the whole tables slice of the state.","title":"getTables"},{"location":"Client/Dux/#helpers_11","text":"","title":"Helpers"},{"location":"Client/Dux/#entityhead","text":"Computes the title for an item, based on the data model or on specialized functions, defined here. See also repr .","title":"entityHead"},{"location":"Client/Dux/#needtable","text":"Checks if sufficient table data is available in the state.","title":"needTable"},{"location":"Client/Dux/#needtables","text":"Checks a list of table names to see if sufficient data is available in the state.","title":"needTables"},{"location":"Client/Dux/#needvalues","text":"Checks a single entity in a single table to see if it contains values for all fields.","title":"needValues"},{"location":"Client/Dux/#listvalues","text":"Gives the list of all values of a specified field in a table.","title":"listValues"},{"location":"Client/Dux/#presentuser","text":"Presents a user, by means of name, email address, and/or eppn , depending on what information is available, which also depends on what information may be shared with the currently logged in user.","title":"presentUser"},{"location":"Client/Dux/#changeditem","text":"Checks if properties have changed in such a few that new data should be fetched.","title":"changedItem"},{"location":"Client/Dux/#headentity","text":"The head line of a record, based on its title field and/or other data. For some specific tables custom logic is used.","title":"headEntity"},{"location":"Client/Dux/#repr","text":"Makes a streamlined string representation out of a field value. It looks up ids in related value list tables. For some tables, special representation functions will be invoked. (users, countries, etc.).","title":"repr"},{"location":"Client/Dux/#todb","text":"Dispatches an item modification action to the store.","title":"toDb"},{"location":"Client/Dux/#handleopenall","text":"When a user clicks on an Open All button, this function is invoked to fetch the corresponding records (if needed).","title":"handleOpenAll"},{"location":"Client/Dux/#handlecloseall","text":"When a user clicks on an Close All button, this function is invoked to collapse the corresponding records and remove the _id s of the previously open records from the URL, using browserHistory .","title":"handleCloseAll"},{"location":"Client/Dux/#win","text":"Reacts to window resizing by the user. It will deliver the new window size after resizing. Useful for components that care about the window size, such as App .","title":"win"},{"location":"Client/Dux/#actions_12","text":"","title":"Actions"},{"location":"Client/Dux/#changewindim","text":"Responds to window resizing, as set up in Window . It is just a matter of storing the height and the width of the window into the state. Note that the event emitter in Window is being throttled, so that it does not run too frequently during the actual resizing.","title":"changeWinDim"},{"location":"Client/Dux/#reducer_12","text":"Transforms the win slice of the state in response to resize events.","title":"Reducer"},{"location":"Client/Dux/#selectors_12","text":"","title":"Selectors"},{"location":"Client/Dux/#getwindim","text":"Returns the win slice of the state, which is just the current width and height of the browser window.","title":"getWinDim"},{"location":"Client/Dux/#helpers_12","text":"No helpers.","title":"Helpers"},{"location":"Client/Dux/#workflow","text":"A lot of the logic of showing lists, items, related items and fields is purely generic and driven by the data model . But there is considerably more to an app than this kind of generic logic. The workflow duct is the entry point for additional, non-trivial business logic. It is still in development.","title":"workflow"},{"location":"Client/Dux/#active-items","text":"The package table determines a lot about the assessment process. It has records with a specified startDate end endDate. The packages that have started and are not yet passed there endDate are the active packages. Normally there will be exactly one package. From the active package derive a number of other active concepts: the contribution types listed in the typeContribution field of the active package are the active types the criteria that are details of the active package are active criteria . The generic List and Item components can be made sensitive to this notion of activity. Active items can be formatted specially, and likewise the non-active items, which can also be disabled in some contexts. The way (in)active items are displayed is controlled by the data model . See for example the field typeContribution in the tables package and criteria .","title":"Active items"},{"location":"Client/Dux/#actions_13","text":"","title":"Actions"},{"location":"Client/Dux/#fetchworkflow","text":"Fetch the info about the workflow information from the server, in particular the reset history since the last startup of the web server.","title":"fetchWorkflow"},{"location":"Client/Dux/#resetworkflow","text":"Fetch the same information as fetchWorkflow does, but add ?reset=true to the URL that is used to query this information from the server. This will instruct the server to perform a workflow reset.","title":"resetWorkflow"},{"location":"Client/Dux/#reducer_13","text":"The reducer is simple, it only has to perform one action: put incoming workflow data unto the state. No sophisticated merging is needed, because this workflow meta information is only needed for one component, WorkflowInfo , which is meant for sysadmins only. Note that the factual workflow data moves from server to client on the shoulders of the tables reducer.","title":"Reducer"},{"location":"Client/Dux/#selectors_13","text":"","title":"Selectors"},{"location":"Client/Dux/#getworkflow","text":"Returns the workflow slice of the state. odebase: 'About/Codebase.md'","title":"getWorkflow"},{"location":"Client/Dux/#compileactive","text":"Computes the active packages, types and criteria and deliver them in an object, keyed by kind of item and containing an array of active item MongoDB ids for that kind.","title":"compileActive"},{"location":"Client/Dux/#decisions","text":"Most of the contents of the decision table, in the form of objects by which you can find various user-facing strings associated with the three possible review decisions: accept , revise , and reject .","title":"decisions"},{"location":"Client/Dux/#finaldecision","text":"From workflow attributes that contain reviewers and reviews respectively, find out whether there has been a final decision by reviewer 2, and if so, what it was.","title":"finalDecision"},{"location":"Client/Dux/#getitem","text":"Peels out items of data from a workflow attribute that has fetched arrays of data from other records.","title":"getItem"},{"location":"Client/Dux/#isreviewertype","text":"Computes whether a given author is the first or second reviewer.","title":"isReviewerType"},{"location":"Client/Dux/#loadextra","text":"This is a configuration object that specifies which extra tables should be fetched from the server along with particular other tables. For example, the app can only perform its business logic on contributions, if the tables package , criteria , typeContribution , and decision are all present on the state.","title":"loadExtra"},{"location":"Client/Dux/#processstatus","text":"Produce a string that contains the current assessment status and review status of an assessment. This function can be called from a contribution, an assessment and a review. So for all these kinds of document we can produce a short overview of the state they have reached in the assessment / review process. The outcome has a bit that reveals the assessment status and a bit about the review status. When it is run on behalf of a user with marginal rights, it delivers either the empty string, or the outcome of the final review, but only if there has been a positive outcome. For users with more rights: assessment status: \u25b6 if the assessment has been (re)submitted; \u270d otherwise; the assessment score review status: empty string if there review has not reached a final decision; \u2714 on accept ; \u270b on revise ; \u2718 on reject .","title":"processStatus"},{"location":"Client/Dux/#reviewerrole","text":"Object that maps the acronyms E and F to appropriate labels designating first and second reviewer.","title":"reviewerRole"},{"location":"Client/Lib/","text":"Library \u00b6 datatypes \u00b6 Elementary operations on data that comes in basic types, such as strings, numbers and dates. This file contains also the functions that normalize and validate values. getDateTime \u00b6 Convert a datetime object or string into a numerical value, so you can make comparisons. If absent, yield negative infinity for start dates and positive infinity for end dates. Used in workflow . normalization \u00b6 An object with normalization functions, named after the types of the values they normalize. All functions take a value, and return a normalized value. sortStringTemplate \u00b6 Compare function for sorting. Wraps the values to be compared in a template before actually comparing them. Used in workflow . sortTimeInterval \u00b6 Sort by time interval. Sorting by time intervals should works as follows: if both intervals are fully specified, the interval with the earlier start date comes first; if the start dates are equal, the one with the LATER end date comes first, in this way, containing intervals come before contained intervals; if the start date is missing, the start date is assumed to be in the infinite past; if the end date is missing, the end date is assumed to be in the infinite future. Used in workflow . trimDate \u00b6 Removes the milliseconds from an ISO string representing a datetime. Can also remove the whole time part from a datetime. This essentially presents a datetime as a date. validation \u00b6 An object with validation functions, named after the types of the values they validate. All functions take a value, and return undefined if the value passes validation or is itself undefined. If a value does not pass validation, a simple string expressing the reason is returned. details \u00b6 These functions help by setting up lists of detail records for master records. The carry out what has been specified in the data model config files under the keys detail and detailOrder . getMasterTable \u00b6 Given a table and the name of a field that links to an other, related, table, if finds the name of that related table. If that other table list this table as a details table, and marks this field as the link field, then the related table is indeed the master table. But this function is indifferent to that. It merely consults the fieldSpec of field in table . makeDetails \u00b6 Prepare lists of details for an item of a table. Collect the specs and put all information in an array of objects, each corresponding to a details list, from which components can easily construct a widget for handling lists of details makeKeepInfo \u00b6 Collects information on the basis of which it can be decided whether a record may be deleted or not. A record may be deleted if it has no detail records, except those that will be deleted as well. Those are the details which are marked as cascade in the data model . This function returns a list of all non-cascade detail tables that have records linking to the record in question. Example : ItemForm edit \u00b6 Helpers for presenting edit controls, such as a save button. editClass \u00b6 Returns the proper CSS class for styling content that is being edited, depending on the state it may be in: dirty : a changed value that has not been saved to the database yet, and/or invalid : a value that does not pass validation. editControl \u00b6 This is nearly a React component, except it needs a boolean parameter canSubmit , to direct it into one behaviour or another. The basic function of this component is to give an indication of the edit status of a record. Whether values have changed ( dirty ), values are invalid , or values are being submitted . If this component is put inside a <form> element under the control of redux-form , it is also capable to trigger a submit and save action. canSubmit = true \u00b6 The component EditControl calls this function with submit capacity. It also has to provide the resulting component with typical form properties, such as dirty , valid , handleSubmit . Because in this case the component lives inside a component that is already enhanced with reduxForm , namely ItemEdit , these properties have been injected higher up in the component tree and can be passed down as props. canSubmit = false \u00b6 The the component EditStatus calls this function without submit capacity. The typical form properties are now obtained by enhancing this very component with reduxForm . However, because this component is not assumed to be within a <form> context, it cannot perform a submit. makeChangeSave \u00b6 Produces a function, that when triggered by a value, will submit that value (after a short delay). See makeSubmitTime . This is used when an input field fires an event with a value entered by the user. makeChangeSaveVal \u00b6 Produces a function, with a value baked in. When called, this function will submit that value (after a short delay). This is used when the user clicks a button, like submit review in which case a specific field has to be set to a specific value, in this example: submitted = true . makeReset \u00b6 Composes an attribute that sets up an onKeyUp handler for an input field. It will react to the Esc key, and reset the input field to its pristine value, i.e. the value it had before the user started interacting with it. makeSubmit \u00b6 Produces a submit action or a null-returning function, depending on parameters. The parameters tell whether some record is dirty, valid and not currently submitting. In that case, the result is a submit function (which is also passed as parameter). This function is used in those cases where an input field looses focus. It then generates a submit action if all is well. makeSubmitTime \u00b6 Given a (submit)-function, transforms it into the same function that will be invoked with a small delay. This can be used after events that change a form, without a blur event. The event should trigger a submit and save, but first the triggering action should have done its work. Example : Input onSubmitSuccess \u00b6 Needed in a workaround for an issue in redux-form . See ItemEdit europe.geo \u00b6 countryBorders \u00b6 Object that contains the borders of the European countries plus a bit of additional information in geojson format. See this Jupyter notebook to see where this data comes from and how it has been tweaked for this website. fields \u00b6 checkDisabled \u00b6 Checks whether a certain value is inactive and should be disabled. See workflow logic . Used in component RelSelect . dealWithProvenance \u00b6 Remove provenance fields if current settings require that. See settings . Used in component ItemContainer and others. itemEditField \u00b6 Render an edit field in standard presentation, like ItemEdit does it. In fact, ItemEdit uses this very function to render its editable fields. This function can be conveniently used in custom templates to render some fields in the standard way. Example : Templates itemReadField \u00b6 Render an read-only field in standard presentation, like ItemRead does it. In fact, ItemRead uses this very function to render its read-only fields. This function can be conveniently used in custom templates to render some fields in the standard way. Example : Templates makeFields \u00b6 Prepare field components for an item of a table. Collect the specs from the fieldOrder and fieldSpecs fields of the data model and put all information in an array objects, each corresponding to a field, from which components can easily construct a widget for showing or editing that field. Example : ItemForm someEditable \u00b6 Checks whether a list of fields contains at least one that the current user may edit. Example : ItemForm toFieldInfo \u00b6 Reduces the information in the fragments produced by makeFields to a simple object with only the value(s) of that field. Used in ItemRead to pass an argument to applyTemplate . handle \u00b6 It is tempting to pass callbacks to React components as arrow functions, like this: 1 2 3 <MyComp onClick={event => handle(event)} /> The problem with this is that the event => handle(event) creates a brand new function object every time <MyComp/> is being rendered. This is not incorrect, but it is a burden for the garbage collector, especially when your component is part of a list item in a big list. It is much better to defined a fixed function elsewhere, and pass it to <MyComp> . But what if the callback is dependent on some parameters, that depend on its instances? For example, if the callback has to be passed to the items of a list, and cause the showing of hiding of individual list items? You could do it like this: 1 2 3 4 5 6 7 const handleItem = item => event => handle(event, item) items.map(item => <MyComp onClick={handleItem(item)} /> ) As it stands, this suffers from the same problem, because for every item a fresh bound function object is allocated. And if the list is rendered twice, the second time results in completely new function objects. The solution is to use a memoized version of handleItem . The following functions are conveniences for doing exactly that. handle-1 \u00b6 Arguments: (dispatch, actionCreator, actionArgs) This is a memoized action creator wrapper. It return a function, that can be called with an event. After receiving the event, the passed actionCreator will be called with the given arguments to produce an action. Subsequently, this action will be dispatched to the store that holds the state, which will result in the intended state change. This particular function handle will not use the information in the event. It takes trouble to neutralize the event instead. If there is relevant information in the event, use one of the following functions. handlE-2 \u00b6 Like handle , and the information in the event is not used, but the default behaviour of the event and its propagation are not suppressed. handlEV \u00b6 Like handle , but now the event.target.value is passed the actionCreator as final argument. memo \u00b6 makeSet \u00b6 We use plain objects, including Array s for all things on the state. But what if your component prefers the data as a Set ? Well, it is easy to turn an object into a Set . But if you do it twice, based on an identical state, you get two copies of the same set, which is a waste. Here memoization is a solution. makeSet is a memoized function that takes an array and returns its values as a Set . memoize \u00b6 Turns the function f into a memoized function memF that yields the same results for the same parameters. It stores computed results under a key dependent on the parameters for which the result is computed. When the function is called with the same parameters again, it delivers its result from cache, rather than to recompute it. In development mode, if you call the memoized function without arguments, it sends usage information to the console: the number of times it has computed a result and the number of times it has retrieved a result from cache. In many cases, the reselect library is all we need for the memoization of selector functions . However, if you want to bind a callback function to concrete arguments, e.g. in InputMulti , you need more powerful memoization, such as memoize here. However, a naive implementation of memoize has a big drawback. In order to store a function result obtained when computing the function on the basis of a list of arguments, you need to come up with key under which to store those result. This key must be computed from the list of arguments, and the computation of the key should not take more time than bluntly computing the function in question. The most common way of computing a key from arguments is to JSON.stringify them. However, many of the functions we need to memoize, take a slice of the state as argument. That can be a big object, e.g. tables , which hold all data that the app has downloaded from the server in the current section. In those cases it will not do to stringify the argument. Rather we fall back on object identity: we use a WeakMap , which seems to have been designed exactly for this purpose. However, it is not immediately obvious how to use this solution if you have more than one argument, and if you mix non-object values and functions with real objects. These problems can be solved, and memoize() has evolved into a flexible memoizer for all kinds of situations. \\ What you can do with it is to stringify a shallow to-level structure of an object, to a given depth, and from then on work with object identity and WeakMaps. You can also forego object identity altogether and use solely stringify, which is often the most efficient solution. We have built quite a few tests to verify the logic and the performance of this memoizer. The flip-side of a memoizer is that you end-up with a lot of obsolete function results, that will never be used again. Especially when one of the arguments is a slice of the state, the corresponding result will be outdated as soon as that slice of the state has undergone an update. Even if it will revert to the same state later on, it will be a different object. To prevent a needless clutter of obsolete computation results, the cache will be emptied periodically. By default, every result will live at most 30 minutes after having been created, but this is configurable. This brings us to the reason why we use WeakMap and not the more versatile Map data structure. For Map does not suffer the constraint that keys must be objects, so if your arguments are a mixture of objects and non-objects, Map seems the obvious choice. However, if your Map key is a big object, the object can not be garbage collected as long as it is part of the map. That is a pity, because the only information we need of this object is its identity as an object, not its complete value. Think again of the tables slice of the state. It keeps changing when users fetch or change data, so memoized functions that use tables will cling to many successive copies of this state. Despite the fact that these copies share most of their data, this hampers a smooth garbage collection process. WeakMaps do not cling to the objects that act as their keys. They somehow store the identity of their key objects, without claiming the continued existence of them. Usage \u00b6 1 2 3 4 5 6 const baseFunction = ( x , y , z ) => expensiveResult const memBaseFunction = memoize ( baseFunction , levels , config ) memBaseFunction ( a , b , c ) // computes baseFunction(a, b, c) memBaseFunction ( a , b , c ) // retrieves baseFunction(a, b, c) from cache instead of computing it Level \u00b6 If the level paramter is null or undefined , all arguments will be stringified in one go. If levels is an empty object, all object arguments will be treated by object identity. Otherwise, levels should be an object, keyed by argument position and valued by level. If you specify a level for argument n , it means that argument n contributes to the memo key in the following way: level -1 : JSON stringify it level 0 : use the object identity of it as key in a WeakMap level i+i : JSON stringify the top i levels of it; everything from level i+1 onwards is treated by object identity. N.B: Function arguments can not be stringified, they always go by way of object identitiy. For examples, see the test suite . Config \u00b6 The config parameter takes the following keys: clearCache : time in seconds that a key is being retained in the memCache debug : string : when the memoized function computes a result, retrieves it from cache, or cleares it from cache, the debug string will be output through console.warn . Only in development mode! It is also possible to add extra bits of debugging information, by adapting the debugStyle object in the source code . Caution \u00b6 If you memoize a function that takes big objects as parameters, and you forget to specify that those arguments must be treated by object identity, you may hit a murderous performance penalty. I did forget it and the function involved computed related values for given identifiers, and in order to find those values it needed to receive the tables slice of the state. As a consequence, opening a contribution record within the list of all contributions, took a full 3 seconds. It took me long to pinpoint the memoizer as the root cause of this particular slowness. templates \u00b6 This library contains templates that customize the presentation of records and fields. See Templates for how the template system is structured. This library contains the functions to apply templates. applyInsertTemplate \u00b6 Applies a template for the insert record button for a list. This template cannot have field values, because it is for a whole list of records. However, it is invoked by lists that are detail lists, and hence there is a master record. This template has access to the fields of that master record. It is invoked in EditInsert components. applyTemplate \u00b6 Applies a read only template. You can merge a template with FieldRead components. applyEditTemplate \u00b6 Applies an edit template. There is a bit of extra data here compared to read-only templates, namely whether fields are editable or not. You can merge a template with FieldRead components, as well as with FieldEdit components. Examples : ItemRead ItemEdit See also Templates . editMode \u00b6 This function computes a test function for a record, and the test function is customized per table, in the same way as templates are customized per table. Per table you can define any function, and in doing so you are given the information which fields are empty. In practice we use this function to determine whether we start the presentation of a record in read-only mode or in edit mode. Example In ListPlain we invoke this function to determine the startMode function, which computes for each record a choice between alternatives (edit mode or read-only mode), called thisStartMode . When ListPlain is called to display the criteriaEntry detail records of an assessment record, a test function is invoked, defined in criteriaEntry telling to return 1 if the score is empty or if the evidence is empty. Alternative 1 corresponds to edit mode. So, whenever a criteriaEntry record is certainly incomplete, it will be opened in edit mode. If it is possibly complete, it will be opened in read-only mode. utils \u00b6 combineSelectors \u00b6 Arguments: (...selectors) Given a list of selector functions, creates a combined selector that returns an object containing the results of the individual selectors. This function uses the reselect's createSelector . We use it quite often when components need multiple sections of the state. emptyX (S A O F) \u00b6 emptyA \u00b6 Array. emptyF \u00b6 Function. emptyO \u00b6 Object. emptyS \u00b6 String. emptySet \u00b6 Set. Explanation \u00b6 Many objects get created during rendering and re-rendering. If we render a list of thousand entries, and we pass each item component a property with a value like 1 details={details || {}} then thousand instances of an empty object will be created and need to be garbage collected soon after that. But if we are interested in the value of the empty object, without an intention to modify it, this is an utter waste. Therefore we declare a few empty concepts: We also freeze them, so that we cannot inadvertently mutate them. The contract with ourselves is: do not ever use one of 1 '' [] {} x =&gt; x if you need an empty value, but use an empty X ( X in S , A , O , F ) instead. getUrlParts \u00b6 Analyse URLs in order to extract a part /item/ itemID from it (if present). This is needed if we open and close items in a list and want the URL to reflect that. See ListPlain for an example. jString \u00b6 When we need the value of an object as a key, for example when we memoize functions, the most straightforward way is to JSON.stringify that object (if it is not forbiddingly large). But this has one defect: the order in which the keys of objects are serialized is not fixed. So two results of a stringify of objects with the same value can be different, due to different orders of keys. Our function jString fixes that. It is a bit more expensive to run than the plain JSON.stringify , but the penalty of not using it has the consequence that we fail to detect the equality of objects, which results in spurious re-rendering of components. If that happens too often, the cost adds up or even multiplies quickly. makeReducer \u00b6 Arguments: (flows, init) Given an object of flows and an initial state, returns a reducer function. The flows is an object with functions, named after actions . These functions define how a new state must be produced when an action has been dispatched . This function helps to write down complex reducer function as small components with a clean syntax. max \u00b6 Returns the maximum of an array of numbers. If the array is empty, return negative infinity. min \u00b6 Returns the minimum of an array of numbers. If the array is empty, return positive infinity. propsChanged \u00b6 Arguments: (newProps, need, oldProps, keyPropNames) Determines whether newProps differ significantly from oldProps , based on the props with keyPropNames only. If the props are sufficiently changed, it uses the need function to finally determine whether the change should result in an action. sum \u00b6 Returns the sum of an array of numbers. If the array is empty, return 0 . updateAuto \u00b6 The update() function of the Immutability-Helper module is great. But one thing is a bit clumsy: it does not have auto-vivification . The documentation points to a way out , but the code for that becomes tedious quickly. The idea, however, is right, and this function is a variant of the update() function with auto vivification. withParams \u00b6 Arguments: (Component) Higher order function that turns a Component (which is a function) into another component. The outgoing component is identical to the incoming one, except that you can offer the outgoing component its properties in a slightly different form. Instead of offering properties foo , bar , it is also possible to offer it property { params: { foo, bar } } . Put otherwise: the resulting component spreads its params alongside the rest of its properties. We also do this for route , like params . This function is useful for components that occur as component on a route in main on the one hand, but are also used as ordinary children that receive props from parents. In the first case, it receives some properties as params . When we write our components, we do not want to care about this, hence we wrap them as withParams(Component) . values \u00b6 This is a library of functions that produce formatted representations of values from the database. composeAttributes \u00b6 When composing a Field component for an item, compute attributes telling whether the item is active or not, and merge them into the other attributes. Used in component RelSelect . getValType \u00b6 Arguments: (valType) For a given value type, such as text , URL , number , return a component and subtype for handling the input of such values, e.g. <input type=\"URL\" /> . Example : FieldEdit wrappedRepr \u00b6 Produces a representation for a field value, complete with surrounding elements and attributes. Values of link fields will be wrapped in <a href=\"...\"> elements, Used in FieldRead .","title":"Lib"},{"location":"Client/Lib/#library","text":"","title":"Library"},{"location":"Client/Lib/#datatypes","text":"Elementary operations on data that comes in basic types, such as strings, numbers and dates. This file contains also the functions that normalize and validate values.","title":"datatypes"},{"location":"Client/Lib/#getdatetime","text":"Convert a datetime object or string into a numerical value, so you can make comparisons. If absent, yield negative infinity for start dates and positive infinity for end dates. Used in workflow .","title":"getDateTime"},{"location":"Client/Lib/#normalization","text":"An object with normalization functions, named after the types of the values they normalize. All functions take a value, and return a normalized value.","title":"normalization"},{"location":"Client/Lib/#sortstringtemplate","text":"Compare function for sorting. Wraps the values to be compared in a template before actually comparing them. Used in workflow .","title":"sortStringTemplate"},{"location":"Client/Lib/#sorttimeinterval","text":"Sort by time interval. Sorting by time intervals should works as follows: if both intervals are fully specified, the interval with the earlier start date comes first; if the start dates are equal, the one with the LATER end date comes first, in this way, containing intervals come before contained intervals; if the start date is missing, the start date is assumed to be in the infinite past; if the end date is missing, the end date is assumed to be in the infinite future. Used in workflow .","title":"sortTimeInterval"},{"location":"Client/Lib/#trimdate","text":"Removes the milliseconds from an ISO string representing a datetime. Can also remove the whole time part from a datetime. This essentially presents a datetime as a date.","title":"trimDate"},{"location":"Client/Lib/#validation","text":"An object with validation functions, named after the types of the values they validate. All functions take a value, and return undefined if the value passes validation or is itself undefined. If a value does not pass validation, a simple string expressing the reason is returned.","title":"validation"},{"location":"Client/Lib/#details","text":"These functions help by setting up lists of detail records for master records. The carry out what has been specified in the data model config files under the keys detail and detailOrder .","title":"details"},{"location":"Client/Lib/#getmastertable","text":"Given a table and the name of a field that links to an other, related, table, if finds the name of that related table. If that other table list this table as a details table, and marks this field as the link field, then the related table is indeed the master table. But this function is indifferent to that. It merely consults the fieldSpec of field in table .","title":"getMasterTable"},{"location":"Client/Lib/#makedetails","text":"Prepare lists of details for an item of a table. Collect the specs and put all information in an array of objects, each corresponding to a details list, from which components can easily construct a widget for handling lists of details","title":"makeDetails"},{"location":"Client/Lib/#makekeepinfo","text":"Collects information on the basis of which it can be decided whether a record may be deleted or not. A record may be deleted if it has no detail records, except those that will be deleted as well. Those are the details which are marked as cascade in the data model . This function returns a list of all non-cascade detail tables that have records linking to the record in question. Example : ItemForm","title":"makeKeepInfo"},{"location":"Client/Lib/#edit","text":"Helpers for presenting edit controls, such as a save button.","title":"edit"},{"location":"Client/Lib/#editclass","text":"Returns the proper CSS class for styling content that is being edited, depending on the state it may be in: dirty : a changed value that has not been saved to the database yet, and/or invalid : a value that does not pass validation.","title":"editClass"},{"location":"Client/Lib/#editcontrol","text":"This is nearly a React component, except it needs a boolean parameter canSubmit , to direct it into one behaviour or another. The basic function of this component is to give an indication of the edit status of a record. Whether values have changed ( dirty ), values are invalid , or values are being submitted . If this component is put inside a <form> element under the control of redux-form , it is also capable to trigger a submit and save action.","title":"editControl"},{"location":"Client/Lib/#cansubmit-true","text":"The component EditControl calls this function with submit capacity. It also has to provide the resulting component with typical form properties, such as dirty , valid , handleSubmit . Because in this case the component lives inside a component that is already enhanced with reduxForm , namely ItemEdit , these properties have been injected higher up in the component tree and can be passed down as props.","title":"canSubmit = true"},{"location":"Client/Lib/#cansubmit-false","text":"The the component EditStatus calls this function without submit capacity. The typical form properties are now obtained by enhancing this very component with reduxForm . However, because this component is not assumed to be within a <form> context, it cannot perform a submit.","title":"canSubmit = false"},{"location":"Client/Lib/#makechangesave","text":"Produces a function, that when triggered by a value, will submit that value (after a short delay). See makeSubmitTime . This is used when an input field fires an event with a value entered by the user.","title":"makeChangeSave"},{"location":"Client/Lib/#makechangesaveval","text":"Produces a function, with a value baked in. When called, this function will submit that value (after a short delay). This is used when the user clicks a button, like submit review in which case a specific field has to be set to a specific value, in this example: submitted = true .","title":"makeChangeSaveVal"},{"location":"Client/Lib/#makereset","text":"Composes an attribute that sets up an onKeyUp handler for an input field. It will react to the Esc key, and reset the input field to its pristine value, i.e. the value it had before the user started interacting with it.","title":"makeReset"},{"location":"Client/Lib/#makesubmit","text":"Produces a submit action or a null-returning function, depending on parameters. The parameters tell whether some record is dirty, valid and not currently submitting. In that case, the result is a submit function (which is also passed as parameter). This function is used in those cases where an input field looses focus. It then generates a submit action if all is well.","title":"makeSubmit"},{"location":"Client/Lib/#makesubmittime","text":"Given a (submit)-function, transforms it into the same function that will be invoked with a small delay. This can be used after events that change a form, without a blur event. The event should trigger a submit and save, but first the triggering action should have done its work. Example : Input","title":"makeSubmitTime"},{"location":"Client/Lib/#onsubmitsuccess","text":"Needed in a workaround for an issue in redux-form . See ItemEdit","title":"onSubmitSuccess"},{"location":"Client/Lib/#europegeo","text":"","title":"europe.geo"},{"location":"Client/Lib/#countryborders","text":"Object that contains the borders of the European countries plus a bit of additional information in geojson format. See this Jupyter notebook to see where this data comes from and how it has been tweaked for this website.","title":"countryBorders"},{"location":"Client/Lib/#fields","text":"","title":"fields"},{"location":"Client/Lib/#checkdisabled","text":"Checks whether a certain value is inactive and should be disabled. See workflow logic . Used in component RelSelect .","title":"checkDisabled"},{"location":"Client/Lib/#dealwithprovenance","text":"Remove provenance fields if current settings require that. See settings . Used in component ItemContainer and others.","title":"dealWithProvenance"},{"location":"Client/Lib/#itemeditfield","text":"Render an edit field in standard presentation, like ItemEdit does it. In fact, ItemEdit uses this very function to render its editable fields. This function can be conveniently used in custom templates to render some fields in the standard way. Example : Templates","title":"itemEditField"},{"location":"Client/Lib/#itemreadfield","text":"Render an read-only field in standard presentation, like ItemRead does it. In fact, ItemRead uses this very function to render its read-only fields. This function can be conveniently used in custom templates to render some fields in the standard way. Example : Templates","title":"itemReadField"},{"location":"Client/Lib/#makefields","text":"Prepare field components for an item of a table. Collect the specs from the fieldOrder and fieldSpecs fields of the data model and put all information in an array objects, each corresponding to a field, from which components can easily construct a widget for showing or editing that field. Example : ItemForm","title":"makeFields"},{"location":"Client/Lib/#someeditable","text":"Checks whether a list of fields contains at least one that the current user may edit. Example : ItemForm","title":"someEditable"},{"location":"Client/Lib/#tofieldinfo","text":"Reduces the information in the fragments produced by makeFields to a simple object with only the value(s) of that field. Used in ItemRead to pass an argument to applyTemplate .","title":"toFieldInfo"},{"location":"Client/Lib/#handle","text":"It is tempting to pass callbacks to React components as arrow functions, like this: 1 2 3 <MyComp onClick={event => handle(event)} /> The problem with this is that the event => handle(event) creates a brand new function object every time <MyComp/> is being rendered. This is not incorrect, but it is a burden for the garbage collector, especially when your component is part of a list item in a big list. It is much better to defined a fixed function elsewhere, and pass it to <MyComp> . But what if the callback is dependent on some parameters, that depend on its instances? For example, if the callback has to be passed to the items of a list, and cause the showing of hiding of individual list items? You could do it like this: 1 2 3 4 5 6 7 const handleItem = item => event => handle(event, item) items.map(item => <MyComp onClick={handleItem(item)} /> ) As it stands, this suffers from the same problem, because for every item a fresh bound function object is allocated. And if the list is rendered twice, the second time results in completely new function objects. The solution is to use a memoized version of handleItem . The following functions are conveniences for doing exactly that.","title":"handle"},{"location":"Client/Lib/#handle-1","text":"Arguments: (dispatch, actionCreator, actionArgs) This is a memoized action creator wrapper. It return a function, that can be called with an event. After receiving the event, the passed actionCreator will be called with the given arguments to produce an action. Subsequently, this action will be dispatched to the store that holds the state, which will result in the intended state change. This particular function handle will not use the information in the event. It takes trouble to neutralize the event instead. If there is relevant information in the event, use one of the following functions.","title":"handle-1"},{"location":"Client/Lib/#handle-2","text":"Like handle , and the information in the event is not used, but the default behaviour of the event and its propagation are not suppressed.","title":"handlE-2"},{"location":"Client/Lib/#handlev","text":"Like handle , but now the event.target.value is passed the actionCreator as final argument.","title":"handlEV"},{"location":"Client/Lib/#memo","text":"","title":"memo"},{"location":"Client/Lib/#makeset","text":"We use plain objects, including Array s for all things on the state. But what if your component prefers the data as a Set ? Well, it is easy to turn an object into a Set . But if you do it twice, based on an identical state, you get two copies of the same set, which is a waste. Here memoization is a solution. makeSet is a memoized function that takes an array and returns its values as a Set .","title":"makeSet"},{"location":"Client/Lib/#memoize","text":"Turns the function f into a memoized function memF that yields the same results for the same parameters. It stores computed results under a key dependent on the parameters for which the result is computed. When the function is called with the same parameters again, it delivers its result from cache, rather than to recompute it. In development mode, if you call the memoized function without arguments, it sends usage information to the console: the number of times it has computed a result and the number of times it has retrieved a result from cache. In many cases, the reselect library is all we need for the memoization of selector functions . However, if you want to bind a callback function to concrete arguments, e.g. in InputMulti , you need more powerful memoization, such as memoize here. However, a naive implementation of memoize has a big drawback. In order to store a function result obtained when computing the function on the basis of a list of arguments, you need to come up with key under which to store those result. This key must be computed from the list of arguments, and the computation of the key should not take more time than bluntly computing the function in question. The most common way of computing a key from arguments is to JSON.stringify them. However, many of the functions we need to memoize, take a slice of the state as argument. That can be a big object, e.g. tables , which hold all data that the app has downloaded from the server in the current section. In those cases it will not do to stringify the argument. Rather we fall back on object identity: we use a WeakMap , which seems to have been designed exactly for this purpose. However, it is not immediately obvious how to use this solution if you have more than one argument, and if you mix non-object values and functions with real objects. These problems can be solved, and memoize() has evolved into a flexible memoizer for all kinds of situations. \\ What you can do with it is to stringify a shallow to-level structure of an object, to a given depth, and from then on work with object identity and WeakMaps. You can also forego object identity altogether and use solely stringify, which is often the most efficient solution. We have built quite a few tests to verify the logic and the performance of this memoizer. The flip-side of a memoizer is that you end-up with a lot of obsolete function results, that will never be used again. Especially when one of the arguments is a slice of the state, the corresponding result will be outdated as soon as that slice of the state has undergone an update. Even if it will revert to the same state later on, it will be a different object. To prevent a needless clutter of obsolete computation results, the cache will be emptied periodically. By default, every result will live at most 30 minutes after having been created, but this is configurable. This brings us to the reason why we use WeakMap and not the more versatile Map data structure. For Map does not suffer the constraint that keys must be objects, so if your arguments are a mixture of objects and non-objects, Map seems the obvious choice. However, if your Map key is a big object, the object can not be garbage collected as long as it is part of the map. That is a pity, because the only information we need of this object is its identity as an object, not its complete value. Think again of the tables slice of the state. It keeps changing when users fetch or change data, so memoized functions that use tables will cling to many successive copies of this state. Despite the fact that these copies share most of their data, this hampers a smooth garbage collection process. WeakMaps do not cling to the objects that act as their keys. They somehow store the identity of their key objects, without claiming the continued existence of them.","title":"memoize"},{"location":"Client/Lib/#usage","text":"1 2 3 4 5 6 const baseFunction = ( x , y , z ) => expensiveResult const memBaseFunction = memoize ( baseFunction , levels , config ) memBaseFunction ( a , b , c ) // computes baseFunction(a, b, c) memBaseFunction ( a , b , c ) // retrieves baseFunction(a, b, c) from cache instead of computing it","title":"Usage"},{"location":"Client/Lib/#level","text":"If the level paramter is null or undefined , all arguments will be stringified in one go. If levels is an empty object, all object arguments will be treated by object identity. Otherwise, levels should be an object, keyed by argument position and valued by level. If you specify a level for argument n , it means that argument n contributes to the memo key in the following way: level -1 : JSON stringify it level 0 : use the object identity of it as key in a WeakMap level i+i : JSON stringify the top i levels of it; everything from level i+1 onwards is treated by object identity. N.B: Function arguments can not be stringified, they always go by way of object identitiy. For examples, see the test suite .","title":"Level"},{"location":"Client/Lib/#config","text":"The config parameter takes the following keys: clearCache : time in seconds that a key is being retained in the memCache debug : string : when the memoized function computes a result, retrieves it from cache, or cleares it from cache, the debug string will be output through console.warn . Only in development mode! It is also possible to add extra bits of debugging information, by adapting the debugStyle object in the source code .","title":"Config"},{"location":"Client/Lib/#caution","text":"If you memoize a function that takes big objects as parameters, and you forget to specify that those arguments must be treated by object identity, you may hit a murderous performance penalty. I did forget it and the function involved computed related values for given identifiers, and in order to find those values it needed to receive the tables slice of the state. As a consequence, opening a contribution record within the list of all contributions, took a full 3 seconds. It took me long to pinpoint the memoizer as the root cause of this particular slowness.","title":"Caution"},{"location":"Client/Lib/#templates","text":"This library contains templates that customize the presentation of records and fields. See Templates for how the template system is structured. This library contains the functions to apply templates.","title":"templates"},{"location":"Client/Lib/#applyinserttemplate","text":"Applies a template for the insert record button for a list. This template cannot have field values, because it is for a whole list of records. However, it is invoked by lists that are detail lists, and hence there is a master record. This template has access to the fields of that master record. It is invoked in EditInsert components.","title":"applyInsertTemplate"},{"location":"Client/Lib/#applytemplate","text":"Applies a read only template. You can merge a template with FieldRead components.","title":"applyTemplate"},{"location":"Client/Lib/#applyedittemplate","text":"Applies an edit template. There is a bit of extra data here compared to read-only templates, namely whether fields are editable or not. You can merge a template with FieldRead components, as well as with FieldEdit components. Examples : ItemRead ItemEdit See also Templates .","title":"applyEditTemplate"},{"location":"Client/Lib/#editmode","text":"This function computes a test function for a record, and the test function is customized per table, in the same way as templates are customized per table. Per table you can define any function, and in doing so you are given the information which fields are empty. In practice we use this function to determine whether we start the presentation of a record in read-only mode or in edit mode. Example In ListPlain we invoke this function to determine the startMode function, which computes for each record a choice between alternatives (edit mode or read-only mode), called thisStartMode . When ListPlain is called to display the criteriaEntry detail records of an assessment record, a test function is invoked, defined in criteriaEntry telling to return 1 if the score is empty or if the evidence is empty. Alternative 1 corresponds to edit mode. So, whenever a criteriaEntry record is certainly incomplete, it will be opened in edit mode. If it is possibly complete, it will be opened in read-only mode.","title":"editMode"},{"location":"Client/Lib/#utils","text":"","title":"utils"},{"location":"Client/Lib/#combineselectors","text":"Arguments: (...selectors) Given a list of selector functions, creates a combined selector that returns an object containing the results of the individual selectors. This function uses the reselect's createSelector . We use it quite often when components need multiple sections of the state.","title":"combineSelectors"},{"location":"Client/Lib/#emptyx-s-a-o-f","text":"","title":"emptyX (S A O F)"},{"location":"Client/Lib/#emptya","text":"Array.","title":"emptyA"},{"location":"Client/Lib/#emptyf","text":"Function.","title":"emptyF"},{"location":"Client/Lib/#emptyo","text":"Object.","title":"emptyO"},{"location":"Client/Lib/#emptys","text":"String.","title":"emptyS"},{"location":"Client/Lib/#emptyset","text":"Set.","title":"emptySet"},{"location":"Client/Lib/#explanation","text":"Many objects get created during rendering and re-rendering. If we render a list of thousand entries, and we pass each item component a property with a value like 1 details={details || {}} then thousand instances of an empty object will be created and need to be garbage collected soon after that. But if we are interested in the value of the empty object, without an intention to modify it, this is an utter waste. Therefore we declare a few empty concepts: We also freeze them, so that we cannot inadvertently mutate them. The contract with ourselves is: do not ever use one of 1 '' [] {} x =&gt; x if you need an empty value, but use an empty X ( X in S , A , O , F ) instead.","title":"Explanation"},{"location":"Client/Lib/#geturlparts","text":"Analyse URLs in order to extract a part /item/ itemID from it (if present). This is needed if we open and close items in a list and want the URL to reflect that. See ListPlain for an example.","title":"getUrlParts"},{"location":"Client/Lib/#jstring","text":"When we need the value of an object as a key, for example when we memoize functions, the most straightforward way is to JSON.stringify that object (if it is not forbiddingly large). But this has one defect: the order in which the keys of objects are serialized is not fixed. So two results of a stringify of objects with the same value can be different, due to different orders of keys. Our function jString fixes that. It is a bit more expensive to run than the plain JSON.stringify , but the penalty of not using it has the consequence that we fail to detect the equality of objects, which results in spurious re-rendering of components. If that happens too often, the cost adds up or even multiplies quickly.","title":"jString"},{"location":"Client/Lib/#makereducer","text":"Arguments: (flows, init) Given an object of flows and an initial state, returns a reducer function. The flows is an object with functions, named after actions . These functions define how a new state must be produced when an action has been dispatched . This function helps to write down complex reducer function as small components with a clean syntax.","title":"makeReducer"},{"location":"Client/Lib/#max","text":"Returns the maximum of an array of numbers. If the array is empty, return negative infinity.","title":"max"},{"location":"Client/Lib/#min","text":"Returns the minimum of an array of numbers. If the array is empty, return positive infinity.","title":"min"},{"location":"Client/Lib/#propschanged","text":"Arguments: (newProps, need, oldProps, keyPropNames) Determines whether newProps differ significantly from oldProps , based on the props with keyPropNames only. If the props are sufficiently changed, it uses the need function to finally determine whether the change should result in an action.","title":"propsChanged"},{"location":"Client/Lib/#sum","text":"Returns the sum of an array of numbers. If the array is empty, return 0 .","title":"sum"},{"location":"Client/Lib/#updateauto","text":"The update() function of the Immutability-Helper module is great. But one thing is a bit clumsy: it does not have auto-vivification . The documentation points to a way out , but the code for that becomes tedious quickly. The idea, however, is right, and this function is a variant of the update() function with auto vivification.","title":"updateAuto"},{"location":"Client/Lib/#withparams","text":"Arguments: (Component) Higher order function that turns a Component (which is a function) into another component. The outgoing component is identical to the incoming one, except that you can offer the outgoing component its properties in a slightly different form. Instead of offering properties foo , bar , it is also possible to offer it property { params: { foo, bar } } . Put otherwise: the resulting component spreads its params alongside the rest of its properties. We also do this for route , like params . This function is useful for components that occur as component on a route in main on the one hand, but are also used as ordinary children that receive props from parents. In the first case, it receives some properties as params . When we write our components, we do not want to care about this, hence we wrap them as withParams(Component) .","title":"withParams"},{"location":"Client/Lib/#values","text":"This is a library of functions that produce formatted representations of values from the database.","title":"values"},{"location":"Client/Lib/#composeattributes","text":"When composing a Field component for an item, compute attributes telling whether the item is active or not, and merge them into the other attributes. Used in component RelSelect .","title":"composeAttributes"},{"location":"Client/Lib/#getvaltype","text":"Arguments: (valType) For a given value type, such as text , URL , number , return a component and subtype for handling the input of such values, e.g. <input type=\"URL\" /> . Example : FieldEdit","title":"getValType"},{"location":"Client/Lib/#wrappedrepr","text":"Produces a representation for a field value, complete with surrounding elements and attributes. Values of link fields will be wrapped in <a href=\"...\"> elements, Used in FieldRead .","title":"wrappedRepr"},{"location":"Concepts/Architecture/","text":"Architecture \u00b6 Introduction \u00b6 This app consists of many React components. By default React components have a private state where they can store everything that changes in their life courses. That is: user interaction and server data. If many components handle overlapping data, problems arise, and they manifest themselves first as subtle bugs. Hard to reproduce, hard to fix, because they have to do with unpredictable timing of changing entities. That is where Redux comes to the rescue. Redux provides a central state as a single source of truth . Redux itself is a very small library, under 600 lines of code, but using it will have a dramatic effect on all your React components, especially if you use Redux in an idiomatic way. Overview \u00b6 Components and Dux \u00b6 In Redux, every component may obtain read access to the state, and has indirect write access to it by dispatching actions . The state is held in a store and the store manages all access to the state. When actions are dispatched to the store, the store calls a reducer , which is a function written by the application developer. The reducer is given the action, which has a type and a payload, and on that basis, and that basis alone, it produces a new state from the old state. An app has many concerns, some of which are pretty well separable from others. Such a concern tends to be centred around a specific slice of the state, involving a specific set of actions, and a dedicated partial reducer of that slice. The components involved do not need the whole state, but only this specific slice of the state. Some of the actions may become really specialized, involved, and complex, and for those one writes dedicated helpers . We have organized these concerns into dux (plural of duct or more affectionately: duck ), where a duct is one file of ES6 code that exports action creator functions (one or more as named exports); their names typically start with handle , change , fetch ; fetch as in \"asynchronously fetch data from the server\". a single reducer function (as the default export); selector functions (one or more as named exports); their names always start with get ; get as in: \"get a fragment of the whole state\". helper functions (some of which do not have to be exported); quite often their names start with compile as in \"compile the state data into something that may component can readily consume\". Such a duct ties in very well with the way that React components can be connected to the state. The idiomatic approach is to write your component as a pure, stateless function, even if it needs state. When it does need to read the state, assume that your component will receive that information as properties . And when it needs to modify the state, assume that it will receive callbacks, also as properties , to dispatch actions. See also connect . Dux \u00b6 We employ a glue between components and the state : dux . If you have written your component, say MyComp , and you need a piece of the state mySlice that is provided by a selector getMySlice , and you need to dispatch an action handle in response of a user click, and the action creator changeSlice provides that, then you can wrap your component by means of the Redux higher order function connect like this: 1 export connect(getMySlice, { handle: changeSlice })(MyComp) In this way, most components that deal with change can still be written as pure functions, relatively easy to understand, while the response to change is expressed in a very simple pattern. This will reduce the potential bugs considerably. Note that all code to make the connection between components and a (slice of the) state are located in a duct. We are talking about the selectors , the actions , and possibly the helpers . The reducer is something that is hidden from the component code. It is only used by the store, via a kind of subscription. The structure of the reducer follows the types of the actions very closely so it really makes sense to have all four things in one file. The dux of this app \u00b6 Currently, these are the dux of this app: alter : show/hide, cycle through n alternative representations of a piece of user interface; example: widgets that can be expanded and collapsed by the user; workflow : specialized logic for the assessment and review workflow e.g. to determine what are the active contribution types and assessment criteria at a given point in time; docs : fetch documents, especially markdown ones, and show them in two representations: source and formatted; filters : the machinery of faceted and full text filtering of entities from tables; forms : the state of all data entry forms in the app; managed by redux-form ; but other parts of the app need to inspect the form slice of the state as well; grid : the display state of all lists in grid layout: the sort columns and the directions of sorting; me : data about the currently logged-in user; notes : the notification system; this is what displays progress and error messages; it can be accessed by the user by clicking the unobtrusive open circle in the upper right corner of the browser window; roots : combining all the other dux; select : the state of all multi-select widgets in the app; server : handling asynchronous actions and reporting about success, failure and pending requests; it also prevents subsequent requests of data between the first request and the arrival of the data; settings : cross-cutting operational parameters, such as whether to show or hide the provenance fields (creator, created data, sequence of modified-by records); tables : manage all database data that has been fetched from the server; in fact, we construct a normalized copy of all tables that contain information that is application needs; when more data is needed, the application fetches it from the server and merges it in tables slice of the state; this slice not only holds the data of the tables, but also the specs of them, such as the fields, their types, the relations between tables, the master-detail structure, etc.; win : react to the resizing of the browser window; earlier stages of the application used this to resize certain areas in the application window; however, by using new CSS features such as flexbox we do not have any real need to make the window size known to the app; this might change when the app acquires new functionality, so for the moment we retain this mechanism.","title":"Architecture"},{"location":"Concepts/Architecture/#architecture","text":"","title":"Architecture"},{"location":"Concepts/Architecture/#introduction","text":"This app consists of many React components. By default React components have a private state where they can store everything that changes in their life courses. That is: user interaction and server data. If many components handle overlapping data, problems arise, and they manifest themselves first as subtle bugs. Hard to reproduce, hard to fix, because they have to do with unpredictable timing of changing entities. That is where Redux comes to the rescue. Redux provides a central state as a single source of truth . Redux itself is a very small library, under 600 lines of code, but using it will have a dramatic effect on all your React components, especially if you use Redux in an idiomatic way.","title":"Introduction"},{"location":"Concepts/Architecture/#overview","text":"","title":"Overview"},{"location":"Concepts/Architecture/#components-and-dux","text":"In Redux, every component may obtain read access to the state, and has indirect write access to it by dispatching actions . The state is held in a store and the store manages all access to the state. When actions are dispatched to the store, the store calls a reducer , which is a function written by the application developer. The reducer is given the action, which has a type and a payload, and on that basis, and that basis alone, it produces a new state from the old state. An app has many concerns, some of which are pretty well separable from others. Such a concern tends to be centred around a specific slice of the state, involving a specific set of actions, and a dedicated partial reducer of that slice. The components involved do not need the whole state, but only this specific slice of the state. Some of the actions may become really specialized, involved, and complex, and for those one writes dedicated helpers . We have organized these concerns into dux (plural of duct or more affectionately: duck ), where a duct is one file of ES6 code that exports action creator functions (one or more as named exports); their names typically start with handle , change , fetch ; fetch as in \"asynchronously fetch data from the server\". a single reducer function (as the default export); selector functions (one or more as named exports); their names always start with get ; get as in: \"get a fragment of the whole state\". helper functions (some of which do not have to be exported); quite often their names start with compile as in \"compile the state data into something that may component can readily consume\". Such a duct ties in very well with the way that React components can be connected to the state. The idiomatic approach is to write your component as a pure, stateless function, even if it needs state. When it does need to read the state, assume that your component will receive that information as properties . And when it needs to modify the state, assume that it will receive callbacks, also as properties , to dispatch actions. See also connect .","title":"Components and Dux"},{"location":"Concepts/Architecture/#dux","text":"We employ a glue between components and the state : dux . If you have written your component, say MyComp , and you need a piece of the state mySlice that is provided by a selector getMySlice , and you need to dispatch an action handle in response of a user click, and the action creator changeSlice provides that, then you can wrap your component by means of the Redux higher order function connect like this: 1 export connect(getMySlice, { handle: changeSlice })(MyComp) In this way, most components that deal with change can still be written as pure functions, relatively easy to understand, while the response to change is expressed in a very simple pattern. This will reduce the potential bugs considerably. Note that all code to make the connection between components and a (slice of the) state are located in a duct. We are talking about the selectors , the actions , and possibly the helpers . The reducer is something that is hidden from the component code. It is only used by the store, via a kind of subscription. The structure of the reducer follows the types of the actions very closely so it really makes sense to have all four things in one file.","title":"Dux"},{"location":"Concepts/Architecture/#the-dux-of-this-app","text":"Currently, these are the dux of this app: alter : show/hide, cycle through n alternative representations of a piece of user interface; example: widgets that can be expanded and collapsed by the user; workflow : specialized logic for the assessment and review workflow e.g. to determine what are the active contribution types and assessment criteria at a given point in time; docs : fetch documents, especially markdown ones, and show them in two representations: source and formatted; filters : the machinery of faceted and full text filtering of entities from tables; forms : the state of all data entry forms in the app; managed by redux-form ; but other parts of the app need to inspect the form slice of the state as well; grid : the display state of all lists in grid layout: the sort columns and the directions of sorting; me : data about the currently logged-in user; notes : the notification system; this is what displays progress and error messages; it can be accessed by the user by clicking the unobtrusive open circle in the upper right corner of the browser window; roots : combining all the other dux; select : the state of all multi-select widgets in the app; server : handling asynchronous actions and reporting about success, failure and pending requests; it also prevents subsequent requests of data between the first request and the arrival of the data; settings : cross-cutting operational parameters, such as whether to show or hide the provenance fields (creator, created data, sequence of modified-by records); tables : manage all database data that has been fetched from the server; in fact, we construct a normalized copy of all tables that contain information that is application needs; when more data is needed, the application fetches it from the server and merges it in tables slice of the state; this slice not only holds the data of the tables, but also the specs of them, such as the fields, their types, the relations between tables, the master-detail structure, etc.; win : react to the resizing of the browser window; earlier stages of the application used this to resize certain areas in the application window; however, by using new CSS features such as flexbox we do not have any real need to make the window size known to the app; this might change when the app acquires new functionality, so for the moment we retain this mechanism.","title":"The dux of this app"},{"location":"Concepts/Model/","text":"Model \u00b6 This application contains a generic engine to display MongoDB data according to any specified data model, respecting access privileges. MongoDB \u00b6 We store the data in a MongoDB . A MongoDB does not work with a fixed schema. A MongoDB collection consists of documents , which are essentially JSON-like structures, arbitrarily large and arbitrarily nested. That makes it easy to add new kinds of data to documents and collections when the need arises to do so. This will not break the existing code. MongoDB is optimized to read quickly, at the cost of more expensive data manipulation operations. Its documentation favours storing related data inside the main document. This increases the redundancy of the data and may lead to consistency problems, unless the application tries to enforce consistency somehow. In this app, with a limited amount of data, we use MongoDB primarily for its flexibility. We still adhere largely to SQL-like practices when we deal with related tables. So instead of storing the information of related records directly inside the main record, we only store references to related records inside the main records. Configuration \u00b6 The model and the files in table are YAML configuration files, and by tweaking them you can achieve a lot of customization. Name handling \u00b6 There are a lot of names in these yaml files. The most obvious way to use them in our programs (Python on the server, JavaScript on the client) is by just mentioning them as strings, e.g.: 1 title = DM [ 'tables' ][ 'permissionGroup' ][ 'title' ] and 1 title = DM . tables . permissionGroup . title or 1 const { tables : { permissionGroup : { title } } } = DM But then the question arises: how can we use these names in our programs in such a way that we are protected agains typos? Well, we convert the .yaml model files to Python modules that expose the same model, but now as Python data structure. This is done by means of the compile.py script, just before starting the server. That enables us to collect the names and generate some code. Every part of the .yaml files that may act as a name, is collected. We generate a module names.py that contains a line N_ name = ' name ' This module of names will be imported whenever the models are imported. So whenever we want to refer to a name in one of the models, we have a Python variable in our name space that is equal to that name prepended with N_ . By consequently using N_ names instead of plain strings, we guard ourselves against typos, because the Python parser will complain about undefined variables. Moreover, the same compile.py module also checks all the code in the controllers directory for names: whether every N_ name is defined in the names.py and if there are occurrences of plain strings for which an N_ name is defined. This solves the case for the Python server code. For the client JavaScript code we do not have such measures. We could do the same approach, but that would severely uglify the code: 1 title = DM [ N_tables ][ N_permissionGroup ][ N_title ] or 1 const { [ N_tables ] : { [ N_permissionGroup ] : { [ N_title ] : title } } } = DM Especially the replacement of 1 2 3 { name } by 1 { [ N_name ] : name } really hurts. So we do not do anything here, and rely on debugging away the typos the hard way. Data model \u00b6 The data model consists of the dictionaries generic , custom and tables . The generic dictionary contains field names that are used in many tables, such as dateCreated . The custom dictionary is a list of names used in custom workflows, such as defined in workflow (see also Workflow . The tables dictionary has a key for each table, and contains all model information that the application needs to work with that table. Here is a description of the table model information. generic \u00b6 Most branches of the generic dictionary are lists of names with the purpose of triggering the creation of a N_ name , so that we can refer to those names in a consistent way. A few branches will actually be used as such by the app. systemFields \u00b6 A list of field names that occur in most records. The fields themselves must still be specified in the tables where they occur, including their types. Table defaults \u00b6 Here are the branches under generic that contain defaults for the table specifications. title \u00b6 The name of the field that will be used as title when a records are listed. item \u00b6 A display name by which we call individual entities, with a value for singular and plural. E.g. for the table country we have as item: country and countries . sort \u00b6 A list of sort keys. A sort key is a pair consisting of a field, and a direction (-1: descending, 1: ascending). fieldOrder \u00b6 A list of the fields, in the order by which will we displayed when the interface presents a record. fieldSpecs \u00b6 A dictionary of the fields and their characteristics, needed to accommodate the display and manipulation of its values. A field spec is a dictionary, keyed by field name. A field spec value may contain the following bits of information: label : a user-friendly display name of the field. multiple : whether there is only one value allowed for this field, or a list of values. valType : the type of the field and its other behavioural characteristics: see the section valType below. grid : this is a branch of settings relevant for laying out the table in a grid. They are the CSS flex attributes. width : the intended width of the column in which this field is presented; grow ( optional: default: 0 ) the degree by which the column width is allowed to increase shrink ( optional: default: 0 ) the degree by which the column width is allowed to decrease. valid : the name of a client-side validation function by which new and modified values for this field are validated. The validators are exposed in fields.js as member functions of a validation object. N.B: the server carries out extensive, non-customizable validation as well, in order to protect the integrity of the database. valType \u00b6 If a field contains an explicit value or list of values, i.e. a value that stands on its own and does not refer to other records, valType is just a string that specifies the type of the field. If the field may contain a list of values, valType specifies the type of a single value. Possible types are: bool : true or false . datetime : a date time, mostly represented in its ISO 8601 format. number : an integer or real number. text : a string of characters, usually just a one-liner. url : a syntactically valid URL: i.e. a string of text that can be interpreted as a URL. A validation routine will check this. email : a syntactically valid email address. A validation routine will check this. textarea : a string of characters, which may extend to several pages. It is assumed that this is Markdown text, and its formatted version will be shown on the interface, see MarkdownArea . When a field refers to other records, there is much more to specify. In this case valType is a branch with the following information. relTable : the table that contains the related records; allowNew : whether the user is allowed to enter new records in the related table; popUpIfEmpty : ( optional: default: false ) if an edit view on a record having an empty value for this field is shown, a widget to choose a value will pop up immediately. Otherwise there will be just a control button, inviting you to enter a value. select : a criterion on records in the related table, see section select below; fixed ( optional, default: false ) whether the value of this field is fixed after it has been assigned initially; see section fixed below. inactive : ( optional ) this field relates to custom presentations, defined in Workflow ; see section inactive below. select \u00b6 Only the records that satisfy the criterion specified in select , are allowed values. The criterion may be an arbitrary MongoDb selction constraint. Example 1: the country field in the contrib table has isMember: true . So when we choose a country for a contribution, we will be presented with a choice between those countries that are a member of DARIAH. Example 2: the reviewerE field in the assessment table points to the user table, but it has a select condition: 1 2 authority : - $ne : legacy That means, only users for which the authority field is not legacy can be chosen as reviewer. fixed \u00b6 A fixed field can be assigned a value, and after that it is frozen. If a field is fixed, the user interface will be informed to not provide edit controls for it, and the server will be instructed not to modify this field. Example: When an assessment record is created for a contribution, its field assessmentType is copied from the typeContribution field of the master contribution record. Based on that, a fixed set of criteriaEntry records are assembled as details to the assessment record. If the contribution type is changed in a later stage, the assessmentType still shows the type on which the assembly of criteriaEntry records is based. We cannot change these records, because the user may have entered data in it. If the contribution really needs an other type, the best way to proceed is to create a new blank assessment, copy the relevant information over from the old assessment, and then remove the old assessment. inactive \u00b6 By some definition, certain records can be marked as inactive . inactive is a branch with settings how to present inactive items: disabled : if true, do not present inactive items in choice widgets: so if you modify the value, you cannot choose inactive values. attributes : e.g. a CSS className and a title attribute (tooltip) that will be put on the element that renders the item. Any set of valid attributes will do, there are no additional constraints. Example: The typeContribution field of a contrib record may be obsolete, because it is not specified in the current package (see Workflow . In the valType for this field we see the following specification: 1 2 3 4 inactive : attributes : className : inactive disabled : true This is the rendered HTML for this value: 1 2 3 4 < a href = \"/data/typeContribution/list/item/00000000cca4bbd9fe00000b\" class = \"tag disabled inactive\" > Tools and Software </ a > Listing related records \u00b6 When we need to show a related record as a single value, we use its title field, as specified by its title entry in the table info, if present, otherwise we look it up from the generic branch. However, the client code may have implemented special code for certain tables, such as user , and country . See repCountry and repUser . Note, that in many cases, the related table is a value list : every record consists of an _id field (the standard MongoDB identifier field) and a field called rep , which contains the representation of the value. Value lists may or may not have table information specified. The default table information in generic is such that the value lists are covered by it. N.B. In all cases, the permissions model is also consulted, because the permissions model has a say in which fields are allowed to reach the client. For example, if a non-authenticated user is shown the creator of a record, (s)he sees information from the user table. But the permissions are such that (s)he may not see the email address of that user. So the email address does not even reach the client. tables \u00b6 For every table we specify its fields, filters, details and a few other attributes. We have already seen branches under generic for the default specification. The specific tables may have these branches too, with table-specific values. There are some more. filters \u00b6 A list of filters by which to constrain the set of records to be displayed. There are fulltext filters and faceted filters. Each filter is a dictionary with the following information. field The name of the field to be filtered. relField ( optional ) If field is an identifier pointing to a related table, the relField specifies which field in the related table should be filtered. For example, if you want to filter criteriaEntry records on there score , you are faced with the fact that scores live in a separate table, and the actual score is contained in the field score of that table. The criteriaEntry records contain just an _id into the table score . Hence, if we want to filter on actual scores, we say field: score and relField: score . label A user friendly name for the filter, usually the label of the field to be filtered. type The type of filter: ByValue : faceted, EUMap : faceted, plus a visualisation on the map of Europe, Fulltext : full text search in the field. maxCols : ( not needed for Fulltext filters ) facets are displayed in a table with at most this amount of columns. expanded : ( not needed for Fulltext filters ) whether the table of facets is initially expanded or collapsed. details and detailOrder \u00b6 A record may have detail records associated with it. We call such a record a master record with respect to its details. Details are records, usually in another table, having a field that points to their master record by means of an _id value. A master record may have multiple kinds of detail records, i.e. detail records from several distinct tables. It is also possible to specify multiple kinds from one and the same originating table. The kind is specified by just a tag, which often is the name of the originating table. When a master record is presented in full view, all of its fields are expanded with their values. Below that there are lists of head lines of detail records, sorted by table where they are from. The order of these kinds is specified in detailOrder . The specification of each kind of detail is specified in the branch details . For each originating kind there is the following information: table The name of the originating table; linkField The name of the field in the originating table that links to the master record; mode The display mode of the detal records: as grid or list; filtered whether the detais of this kind should have filter controls. If yes, the filters are taken from the specification of the originating table. expand ( optional, default: false ) If this is true, the all detail records of this kind will be immediately expanded. Normally, detail records are presented as head lines initially. border ( optional, default: read: true, edit: true ) whether to put a border around each individual detail record of this kind. This feature must be specified for the read-only presentation and the editable presentation separately, by means of the keys read and edit . cascade ( optional, default: false ) when the master record is deleted, its details have a dangling reference to a non-existing master record. In some cases it is desirable to delete the detail records as well. If cascade: true , the detail records of this kind will be deleted together with the master record. Example 1: the criteriaEntry detail records are deleted with their master assessment record. Example 2: the criteria detail records are not deleted with their master package record. fixed ( optional, default: false ) whether the list of details of this kind is fixed. Details of a kind are fixed, if, after having been created, no details may be added or removed. Individual details may still be modified. Example: once an assessment record for a contribution has been created, a special workflow takes care to lookup the list of criteria that apply to this contribution, based on its typeContribution field. (This mapping is read from the criteria detail records of the currently active package records). For each criterion a criteriaEntry detail record is added to the master assessment record. After that, the list of criteriaEntries for this assessment record may not change anymore. But the user is still be able to fill out the criteriaEntry records. needMaster \u00b6 optional: default: false . Some tables act as containers for detail records exclusively, and it makes no sense to create a detail record if there is no master record to point to. If that is the case, specify needMaster: true , otherwise, leave it out. If needMaster: true , there will be no plus button (insert item) when the records are displayed as a main list. Only when they are displayed as a list of details to some master record, the plus button will appear. Example 1: assessment s can only be created as detail of a contribution . Example 2: package s can be seen as details of typeContribution , in the sense that for each contribution type, there is a list of packages to tell when that contribution type was valid and which criteria were associated with it. Yet a package record makes sense on its own. When you create it, you do not have to select a contribution type first. Rather, you create a package, and in its typeContribution field you select a number of contribution types. Permission model \u00b6 The authorization system is built on the basis of permission levels. Users are assigned to groups, which determine their permission level. In practice, we identify the concepts of groups and permission levels . Users may call methods which undertake actions on tables and fields. These actions are authorized to happen on behalf of a certain user if the permission level of the user, is at least the permission level that the thing requires for that action. In some cases, the identity of the user is relevant, namely when users want to modify things they themselves have created. For those things, users are in a pseudo group called own . In yet other cases, when users change the permission levels of users, the permission levels of both users need to be taken into account. Here are the details. Groups \u00b6 The following groups are distinguished, from least powerful to most powerful: public : unauthenticated user auth : authenticated user office : management user system : system administrator root : root access Levels \u00b6 Things may require the following access levels, from least powerful to most powerful: public auth own : authenticated user and creator of records in question OWN : idem, cannot be overridden by higher levels ownLT : only if owner's power is less than editor's power office system root nobody : omnipotent access (however: nobody can be member of this group, so this effectively means: nobody is allowed to do this) The difference between own and OWN is subtle and only relevant for groups more powerful than own . If a thing requires level own , but the user is in a more powerful group, such as system , that user has access to the thing, even if it is not his own thing. In some circumstances this is undesirable. For example if you want to show a user a list of My items , we want to show the items this user owns, not the items he is allowed to change. In such a case, we specify level OWN for My items . The level ownLT is only relevant when one user modifies the group of another user. The level ownLT means that this operation is only permitted if the user that undergoes modification is currently less powerful than the user that performs the modification. Authorize \u00b6 A table which specify the power of each group over each level that a thing may require. It is a dictionary of dictionaries: the first key is the user group, the second key is the level of the thing. If the dictionary of a user group does not contain a key for a certain level, then the users in that group have no power to do that things that require that level. Otherwise the value is either 1, -1, or -2, meaning: 1 : access is to be granted. -1 : access is only to be granted if the thing has been created by the user. -2 : access is only to be granted if the relative group levels work out: like ownLT above: users cannot modify the power of more powerful users and users cannot assign more power (to themselves or others) than they themselves have. Methods \u00b6 If a user needs to do something, (s)he interacts with the user interface at the client. That will lead to an API call to the server, which will translate into the invocation of a method . At that point, the first check will be made: is this user allowed to invoke this method? The check is performed on the basis of the methods table, which is a dictionary of method names. For each method name a description is given, and the level required to invoke that method. Currently we have the following methods: mylist get my items from a list list get all items from a list view get the details of a record mod modify the details of a record, or insert/delete a record Actions \u00b6 Methods give rise to actions . We distinguish: insert : create an item list : read item titles read : read items update : update an item delete : delete an item. Note the difference between read and list . An item may allow list to public but not read . In that case, unauthenticated user may see the list of items, usually their titles, but they cannot drill down to see the full details of records. Tables and Fields \u00b6 For every table and every field in it, we specify an access level. That means: for every action on that field we state the required access level. The authorization logic on tables then works like this: the access level for invoking the method is checked; if allowed, the actions and tables that the method is going to perform are considered; for every (table-action) combination a row filter and a field filter is constructed, restricting the action to only those rows and fields that are permitted to the user; this might be an empty set; if the set is not empty, the action is executed on those rows and those fields that pass the filters. The permissions model has a configuration section for tables as a whole, which will be checked first. This will give rise to the row filter. Then there is also a configuration section for all fields in all tables, which will give rise to the field filter.","title":"Model"},{"location":"Concepts/Model/#model","text":"This application contains a generic engine to display MongoDB data according to any specified data model, respecting access privileges.","title":"Model"},{"location":"Concepts/Model/#mongodb","text":"We store the data in a MongoDB . A MongoDB does not work with a fixed schema. A MongoDB collection consists of documents , which are essentially JSON-like structures, arbitrarily large and arbitrarily nested. That makes it easy to add new kinds of data to documents and collections when the need arises to do so. This will not break the existing code. MongoDB is optimized to read quickly, at the cost of more expensive data manipulation operations. Its documentation favours storing related data inside the main document. This increases the redundancy of the data and may lead to consistency problems, unless the application tries to enforce consistency somehow. In this app, with a limited amount of data, we use MongoDB primarily for its flexibility. We still adhere largely to SQL-like practices when we deal with related tables. So instead of storing the information of related records directly inside the main record, we only store references to related records inside the main records.","title":"MongoDB"},{"location":"Concepts/Model/#configuration","text":"The model and the files in table are YAML configuration files, and by tweaking them you can achieve a lot of customization.","title":"Configuration"},{"location":"Concepts/Model/#name-handling","text":"There are a lot of names in these yaml files. The most obvious way to use them in our programs (Python on the server, JavaScript on the client) is by just mentioning them as strings, e.g.: 1 title = DM [ 'tables' ][ 'permissionGroup' ][ 'title' ] and 1 title = DM . tables . permissionGroup . title or 1 const { tables : { permissionGroup : { title } } } = DM But then the question arises: how can we use these names in our programs in such a way that we are protected agains typos? Well, we convert the .yaml model files to Python modules that expose the same model, but now as Python data structure. This is done by means of the compile.py script, just before starting the server. That enables us to collect the names and generate some code. Every part of the .yaml files that may act as a name, is collected. We generate a module names.py that contains a line N_ name = ' name ' This module of names will be imported whenever the models are imported. So whenever we want to refer to a name in one of the models, we have a Python variable in our name space that is equal to that name prepended with N_ . By consequently using N_ names instead of plain strings, we guard ourselves against typos, because the Python parser will complain about undefined variables. Moreover, the same compile.py module also checks all the code in the controllers directory for names: whether every N_ name is defined in the names.py and if there are occurrences of plain strings for which an N_ name is defined. This solves the case for the Python server code. For the client JavaScript code we do not have such measures. We could do the same approach, but that would severely uglify the code: 1 title = DM [ N_tables ][ N_permissionGroup ][ N_title ] or 1 const { [ N_tables ] : { [ N_permissionGroup ] : { [ N_title ] : title } } } = DM Especially the replacement of 1 2 3 { name } by 1 { [ N_name ] : name } really hurts. So we do not do anything here, and rely on debugging away the typos the hard way.","title":"Name handling"},{"location":"Concepts/Model/#data-model","text":"The data model consists of the dictionaries generic , custom and tables . The generic dictionary contains field names that are used in many tables, such as dateCreated . The custom dictionary is a list of names used in custom workflows, such as defined in workflow (see also Workflow . The tables dictionary has a key for each table, and contains all model information that the application needs to work with that table. Here is a description of the table model information.","title":"Data model"},{"location":"Concepts/Model/#generic","text":"Most branches of the generic dictionary are lists of names with the purpose of triggering the creation of a N_ name , so that we can refer to those names in a consistent way. A few branches will actually be used as such by the app.","title":"generic"},{"location":"Concepts/Model/#systemfields","text":"A list of field names that occur in most records. The fields themselves must still be specified in the tables where they occur, including their types.","title":"systemFields"},{"location":"Concepts/Model/#table-defaults","text":"Here are the branches under generic that contain defaults for the table specifications.","title":"Table defaults"},{"location":"Concepts/Model/#title","text":"The name of the field that will be used as title when a records are listed.","title":"title"},{"location":"Concepts/Model/#item","text":"A display name by which we call individual entities, with a value for singular and plural. E.g. for the table country we have as item: country and countries .","title":"item"},{"location":"Concepts/Model/#sort","text":"A list of sort keys. A sort key is a pair consisting of a field, and a direction (-1: descending, 1: ascending).","title":"sort"},{"location":"Concepts/Model/#fieldorder","text":"A list of the fields, in the order by which will we displayed when the interface presents a record.","title":"fieldOrder"},{"location":"Concepts/Model/#fieldspecs","text":"A dictionary of the fields and their characteristics, needed to accommodate the display and manipulation of its values. A field spec is a dictionary, keyed by field name. A field spec value may contain the following bits of information: label : a user-friendly display name of the field. multiple : whether there is only one value allowed for this field, or a list of values. valType : the type of the field and its other behavioural characteristics: see the section valType below. grid : this is a branch of settings relevant for laying out the table in a grid. They are the CSS flex attributes. width : the intended width of the column in which this field is presented; grow ( optional: default: 0 ) the degree by which the column width is allowed to increase shrink ( optional: default: 0 ) the degree by which the column width is allowed to decrease. valid : the name of a client-side validation function by which new and modified values for this field are validated. The validators are exposed in fields.js as member functions of a validation object. N.B: the server carries out extensive, non-customizable validation as well, in order to protect the integrity of the database.","title":"fieldSpecs"},{"location":"Concepts/Model/#valtype","text":"If a field contains an explicit value or list of values, i.e. a value that stands on its own and does not refer to other records, valType is just a string that specifies the type of the field. If the field may contain a list of values, valType specifies the type of a single value. Possible types are: bool : true or false . datetime : a date time, mostly represented in its ISO 8601 format. number : an integer or real number. text : a string of characters, usually just a one-liner. url : a syntactically valid URL: i.e. a string of text that can be interpreted as a URL. A validation routine will check this. email : a syntactically valid email address. A validation routine will check this. textarea : a string of characters, which may extend to several pages. It is assumed that this is Markdown text, and its formatted version will be shown on the interface, see MarkdownArea . When a field refers to other records, there is much more to specify. In this case valType is a branch with the following information. relTable : the table that contains the related records; allowNew : whether the user is allowed to enter new records in the related table; popUpIfEmpty : ( optional: default: false ) if an edit view on a record having an empty value for this field is shown, a widget to choose a value will pop up immediately. Otherwise there will be just a control button, inviting you to enter a value. select : a criterion on records in the related table, see section select below; fixed ( optional, default: false ) whether the value of this field is fixed after it has been assigned initially; see section fixed below. inactive : ( optional ) this field relates to custom presentations, defined in Workflow ; see section inactive below.","title":"valType"},{"location":"Concepts/Model/#select","text":"Only the records that satisfy the criterion specified in select , are allowed values. The criterion may be an arbitrary MongoDb selction constraint. Example 1: the country field in the contrib table has isMember: true . So when we choose a country for a contribution, we will be presented with a choice between those countries that are a member of DARIAH. Example 2: the reviewerE field in the assessment table points to the user table, but it has a select condition: 1 2 authority : - $ne : legacy That means, only users for which the authority field is not legacy can be chosen as reviewer.","title":"select"},{"location":"Concepts/Model/#fixed","text":"A fixed field can be assigned a value, and after that it is frozen. If a field is fixed, the user interface will be informed to not provide edit controls for it, and the server will be instructed not to modify this field. Example: When an assessment record is created for a contribution, its field assessmentType is copied from the typeContribution field of the master contribution record. Based on that, a fixed set of criteriaEntry records are assembled as details to the assessment record. If the contribution type is changed in a later stage, the assessmentType still shows the type on which the assembly of criteriaEntry records is based. We cannot change these records, because the user may have entered data in it. If the contribution really needs an other type, the best way to proceed is to create a new blank assessment, copy the relevant information over from the old assessment, and then remove the old assessment.","title":"fixed"},{"location":"Concepts/Model/#inactive","text":"By some definition, certain records can be marked as inactive . inactive is a branch with settings how to present inactive items: disabled : if true, do not present inactive items in choice widgets: so if you modify the value, you cannot choose inactive values. attributes : e.g. a CSS className and a title attribute (tooltip) that will be put on the element that renders the item. Any set of valid attributes will do, there are no additional constraints. Example: The typeContribution field of a contrib record may be obsolete, because it is not specified in the current package (see Workflow . In the valType for this field we see the following specification: 1 2 3 4 inactive : attributes : className : inactive disabled : true This is the rendered HTML for this value: 1 2 3 4 < a href = \"/data/typeContribution/list/item/00000000cca4bbd9fe00000b\" class = \"tag disabled inactive\" > Tools and Software </ a >","title":"inactive"},{"location":"Concepts/Model/#listing-related-records","text":"When we need to show a related record as a single value, we use its title field, as specified by its title entry in the table info, if present, otherwise we look it up from the generic branch. However, the client code may have implemented special code for certain tables, such as user , and country . See repCountry and repUser . Note, that in many cases, the related table is a value list : every record consists of an _id field (the standard MongoDB identifier field) and a field called rep , which contains the representation of the value. Value lists may or may not have table information specified. The default table information in generic is such that the value lists are covered by it. N.B. In all cases, the permissions model is also consulted, because the permissions model has a say in which fields are allowed to reach the client. For example, if a non-authenticated user is shown the creator of a record, (s)he sees information from the user table. But the permissions are such that (s)he may not see the email address of that user. So the email address does not even reach the client.","title":"Listing related records"},{"location":"Concepts/Model/#tables","text":"For every table we specify its fields, filters, details and a few other attributes. We have already seen branches under generic for the default specification. The specific tables may have these branches too, with table-specific values. There are some more.","title":"tables"},{"location":"Concepts/Model/#filters","text":"A list of filters by which to constrain the set of records to be displayed. There are fulltext filters and faceted filters. Each filter is a dictionary with the following information. field The name of the field to be filtered. relField ( optional ) If field is an identifier pointing to a related table, the relField specifies which field in the related table should be filtered. For example, if you want to filter criteriaEntry records on there score , you are faced with the fact that scores live in a separate table, and the actual score is contained in the field score of that table. The criteriaEntry records contain just an _id into the table score . Hence, if we want to filter on actual scores, we say field: score and relField: score . label A user friendly name for the filter, usually the label of the field to be filtered. type The type of filter: ByValue : faceted, EUMap : faceted, plus a visualisation on the map of Europe, Fulltext : full text search in the field. maxCols : ( not needed for Fulltext filters ) facets are displayed in a table with at most this amount of columns. expanded : ( not needed for Fulltext filters ) whether the table of facets is initially expanded or collapsed.","title":"filters"},{"location":"Concepts/Model/#details-and-detailorder","text":"A record may have detail records associated with it. We call such a record a master record with respect to its details. Details are records, usually in another table, having a field that points to their master record by means of an _id value. A master record may have multiple kinds of detail records, i.e. detail records from several distinct tables. It is also possible to specify multiple kinds from one and the same originating table. The kind is specified by just a tag, which often is the name of the originating table. When a master record is presented in full view, all of its fields are expanded with their values. Below that there are lists of head lines of detail records, sorted by table where they are from. The order of these kinds is specified in detailOrder . The specification of each kind of detail is specified in the branch details . For each originating kind there is the following information: table The name of the originating table; linkField The name of the field in the originating table that links to the master record; mode The display mode of the detal records: as grid or list; filtered whether the detais of this kind should have filter controls. If yes, the filters are taken from the specification of the originating table. expand ( optional, default: false ) If this is true, the all detail records of this kind will be immediately expanded. Normally, detail records are presented as head lines initially. border ( optional, default: read: true, edit: true ) whether to put a border around each individual detail record of this kind. This feature must be specified for the read-only presentation and the editable presentation separately, by means of the keys read and edit . cascade ( optional, default: false ) when the master record is deleted, its details have a dangling reference to a non-existing master record. In some cases it is desirable to delete the detail records as well. If cascade: true , the detail records of this kind will be deleted together with the master record. Example 1: the criteriaEntry detail records are deleted with their master assessment record. Example 2: the criteria detail records are not deleted with their master package record. fixed ( optional, default: false ) whether the list of details of this kind is fixed. Details of a kind are fixed, if, after having been created, no details may be added or removed. Individual details may still be modified. Example: once an assessment record for a contribution has been created, a special workflow takes care to lookup the list of criteria that apply to this contribution, based on its typeContribution field. (This mapping is read from the criteria detail records of the currently active package records). For each criterion a criteriaEntry detail record is added to the master assessment record. After that, the list of criteriaEntries for this assessment record may not change anymore. But the user is still be able to fill out the criteriaEntry records.","title":"details and detailOrder"},{"location":"Concepts/Model/#needmaster","text":"optional: default: false . Some tables act as containers for detail records exclusively, and it makes no sense to create a detail record if there is no master record to point to. If that is the case, specify needMaster: true , otherwise, leave it out. If needMaster: true , there will be no plus button (insert item) when the records are displayed as a main list. Only when they are displayed as a list of details to some master record, the plus button will appear. Example 1: assessment s can only be created as detail of a contribution . Example 2: package s can be seen as details of typeContribution , in the sense that for each contribution type, there is a list of packages to tell when that contribution type was valid and which criteria were associated with it. Yet a package record makes sense on its own. When you create it, you do not have to select a contribution type first. Rather, you create a package, and in its typeContribution field you select a number of contribution types.","title":"needMaster"},{"location":"Concepts/Model/#permission-model","text":"The authorization system is built on the basis of permission levels. Users are assigned to groups, which determine their permission level. In practice, we identify the concepts of groups and permission levels . Users may call methods which undertake actions on tables and fields. These actions are authorized to happen on behalf of a certain user if the permission level of the user, is at least the permission level that the thing requires for that action. In some cases, the identity of the user is relevant, namely when users want to modify things they themselves have created. For those things, users are in a pseudo group called own . In yet other cases, when users change the permission levels of users, the permission levels of both users need to be taken into account. Here are the details.","title":"Permission model"},{"location":"Concepts/Model/#groups","text":"The following groups are distinguished, from least powerful to most powerful: public : unauthenticated user auth : authenticated user office : management user system : system administrator root : root access","title":"Groups"},{"location":"Concepts/Model/#levels","text":"Things may require the following access levels, from least powerful to most powerful: public auth own : authenticated user and creator of records in question OWN : idem, cannot be overridden by higher levels ownLT : only if owner's power is less than editor's power office system root nobody : omnipotent access (however: nobody can be member of this group, so this effectively means: nobody is allowed to do this) The difference between own and OWN is subtle and only relevant for groups more powerful than own . If a thing requires level own , but the user is in a more powerful group, such as system , that user has access to the thing, even if it is not his own thing. In some circumstances this is undesirable. For example if you want to show a user a list of My items , we want to show the items this user owns, not the items he is allowed to change. In such a case, we specify level OWN for My items . The level ownLT is only relevant when one user modifies the group of another user. The level ownLT means that this operation is only permitted if the user that undergoes modification is currently less powerful than the user that performs the modification.","title":"Levels"},{"location":"Concepts/Model/#authorize","text":"A table which specify the power of each group over each level that a thing may require. It is a dictionary of dictionaries: the first key is the user group, the second key is the level of the thing. If the dictionary of a user group does not contain a key for a certain level, then the users in that group have no power to do that things that require that level. Otherwise the value is either 1, -1, or -2, meaning: 1 : access is to be granted. -1 : access is only to be granted if the thing has been created by the user. -2 : access is only to be granted if the relative group levels work out: like ownLT above: users cannot modify the power of more powerful users and users cannot assign more power (to themselves or others) than they themselves have.","title":"Authorize"},{"location":"Concepts/Model/#methods","text":"If a user needs to do something, (s)he interacts with the user interface at the client. That will lead to an API call to the server, which will translate into the invocation of a method . At that point, the first check will be made: is this user allowed to invoke this method? The check is performed on the basis of the methods table, which is a dictionary of method names. For each method name a description is given, and the level required to invoke that method. Currently we have the following methods: mylist get my items from a list list get all items from a list view get the details of a record mod modify the details of a record, or insert/delete a record","title":"Methods"},{"location":"Concepts/Model/#actions","text":"Methods give rise to actions . We distinguish: insert : create an item list : read item titles read : read items update : update an item delete : delete an item. Note the difference between read and list . An item may allow list to public but not read . In that case, unauthenticated user may see the list of items, usually their titles, but they cannot drill down to see the full details of records.","title":"Actions"},{"location":"Concepts/Model/#tables-and-fields","text":"For every table and every field in it, we specify an access level. That means: for every action on that field we state the required access level. The authorization logic on tables then works like this: the access level for invoking the method is checked; if allowed, the actions and tables that the method is going to perform are considered; for every (table-action) combination a row filter and a field filter is constructed, restricting the action to only those rows and fields that are permitted to the user; this might be an empty set; if the set is not empty, the action is executed on those rows and those fields that pass the filters. The permissions model has a configuration section for tables as a whole, which will be checked first. This will give rise to the row filter. Then there is also a configuration section for all fields in all tables, which will give rise to the field filter.","title":"Tables and Fields"},{"location":"Concepts/Routing/","text":"Routing \u00b6 Client \u00b6 Entry point \u00b6 At the client side, the app starts in main . The first priority is to create a Redux Provider component, which will be ancestor to all other components. Routing \u00b6 The second priority is to set up the routes configuration, i.e. the way URLs give rise to activating certain components. We are still talking about client side routing. Server \u00b6 At the server there are other rules that link URLs to behaviour. Here are a few rules that capture how routing works in a Single Page App (SPA) like this, and the diagram visualizes the same logic. Fall-back behaviour \u00b6 The server responds to any URL with sending the index page, which also causes the bundled app in dist to load. The server's rules are very simple: no matter what the URL, respond with the whole app. The response is static, it is always the same. The client has to figure out what component(s) of the app to show and where, based on the details of the URL. This behaviour is needed to cater for the case that the user hits the browser's refresh button. At that moment, the current URL might be a deep path, and we cannot expect the server to know those paths. The best the server can do is to send the whole app again. Special behaviour \u00b6 There are a few exceptions, though: Static \u00b6 If the URL points to a static file, i.e. a file under /static/ , the server will respond with the file contents. Otherwise there was no way to serve the static JavaScript app in the first place. Api \u00b6 If the URL points to /api/ , the server will respond in a variety of ways, depending on the rest of the URL. By means of these /api/ URLs the client can ask for additional data services, from file system or database. The server side routing in index.py maps these URLs to specific controllers that fetch and assemble the requested data. Not only the client app can access this api , you can too.","title":"Routing"},{"location":"Concepts/Routing/#routing","text":"","title":"Routing"},{"location":"Concepts/Routing/#client","text":"","title":"Client"},{"location":"Concepts/Routing/#entry-point","text":"At the client side, the app starts in main . The first priority is to create a Redux Provider component, which will be ancestor to all other components.","title":"Entry point"},{"location":"Concepts/Routing/#routing_1","text":"The second priority is to set up the routes configuration, i.e. the way URLs give rise to activating certain components. We are still talking about client side routing.","title":"Routing"},{"location":"Concepts/Routing/#server","text":"At the server there are other rules that link URLs to behaviour. Here are a few rules that capture how routing works in a Single Page App (SPA) like this, and the diagram visualizes the same logic.","title":"Server"},{"location":"Concepts/Routing/#fall-back-behaviour","text":"The server responds to any URL with sending the index page, which also causes the bundled app in dist to load. The server's rules are very simple: no matter what the URL, respond with the whole app. The response is static, it is always the same. The client has to figure out what component(s) of the app to show and where, based on the details of the URL. This behaviour is needed to cater for the case that the user hits the browser's refresh button. At that moment, the current URL might be a deep path, and we cannot expect the server to know those paths. The best the server can do is to send the whole app again.","title":"Fall-back behaviour"},{"location":"Concepts/Routing/#special-behaviour","text":"There are a few exceptions, though:","title":"Special behaviour"},{"location":"Concepts/Routing/#static","text":"If the URL points to a static file, i.e. a file under /static/ , the server will respond with the file contents. Otherwise there was no way to serve the static JavaScript app in the first place.","title":"Static"},{"location":"Concepts/Routing/#api","text":"If the URL points to /api/ , the server will respond in a variety of ways, depending on the rest of the URL. By means of these /api/ URLs the client can ask for additional data services, from file system or database. The server side routing in index.py maps these URLs to specific controllers that fetch and assemble the requested data. Not only the client app can access this api , you can too.","title":"Api"},{"location":"Functionality/Business/","text":"Business Logic \u00b6 Here we document the functionality of the app from the perspective of the users and stakeholders. We focus on the scenarios that are supported. N.B.: (\u2717) Items marked with a single \u2717, are not implemented yet, but are expected to make to the delivery on 2017-12-31. (\u2717\u2717) Items marked with a double \u2717, are not expected to be implemented before the delivery on 2017-12-31. They may or may not be implemented in 2018. Contributions \u00b6 A contribution is a piece of work in Digital Humanities, delivered by a person or institute, and potentially relevant to the European DARIAH research infrastructure. The national members of DARIAH may add such a contribution to their agreed budget of in-kind contributions to DARIAH as a whole. This makes it necessary to assess contributions against a set of well-defined criteria. Assessment scenario \u00b6 Contributions may represent diverse efforts such as consultancy, workshops, software development, and hosting services. This asks for a diversification of contribution types and associated criteria. Moreover, types and criteria may change over time, but during an assessment and review cycle they should be fixed. The assessor of a contribution (from now on called applicant ) needs to state how that contribution scores for each relevant criterion, and for each score, evidence must be given. typeContribution is the table with the set of contribution types. criteria is the table with the individual criteria, where each criteria can be associated with one or more types. package is the table of fixed constellations of types and criteria. At any point in time there are one or more active packages, usually just one. A package defines a set of contribution types, and a set of criteria. Every criterion is linked to a number of contribution types, meaning that the criterion is relevant to contributions of those types and no others. Every criterion is associated with exactly one package, hence the package ultimately determines the mapping between types and criteria. A package has a validity interval, i.e. a start date and an end date. A package is active at a point in time, if that point in time is inside the validity interval. The types of an active package are the active types, and its criteria are the active criteria. Technically, more than one package can be valid at the same time. In that case, the sets of active types and criteria are the union of the sets of types and criteria for each active package. But the intention is that there is always exactly one active package. Other components may call workflow functions in order to determine what the active packages, types and criteria are, so they can render inactive and active ones in different ways. Assessing \u00b6 Applicants with write-access to a contribution can add a self-assessment to a contribution. A self assessment is a record in the assessment table, and consists of a few metadata fields. When an assessment record is created, additional detail records will be created as well. These are criteriaEntry records. For each assessment, there is a fixed set of criteriaEntry records. This set is determined by the currently active set of criteria: one criteriaEntry record will be created per active criterion. A criteriaEntry record has a field for choosing a score and a text field for entering the evidence. Scores are defined in yet another type of record. Scoring \u00b6 The scores for a criterion are entered in with the help of score records, which are detail records of criteria. Scores have a number, typically 0 , 2 , 4 , and a short description, typically None , Partial , Full , but the number and nature of scores may vary freely between criteria. The score of an assessment as a whole is the sum of the individual scores expressed as percentage of the total amount of points that can be assigned. A temporary overall score is obtained by treating unfilled scores as having value 0 . However, some criteria may allow scores with a value -1 (non-applicable). If an assessment assigns that score to a criterion, 0 points are added, but points missed from this criterion will be subtracted from the total score, so that this criterion will not be counted in the average. Example : Suppose there are four criteria, A, B, C, D. A, B, and C have scores 0 , 2 , and 4 . D has scores -1 , 0 , 2 , 4 . Now there are two contributions U and V, with scores as follows: Criterion contrib U contrib V A 4 4 B 4 4 C 4 4 D -1 0 sum 12 12 total 12 16 score 100% 75% See how U does better than V although they have an equal number of points. But for U criterion D does not count, while for V it counts, but the score is 0. N.B. Not all criteria will allow -1 values! Review scenario \u00b6 After a contributor has filled out an assessment, (s)he can submit it for review. The office will select two reviewers, and they will get access to the self assessment. Upon asking for review, the assessment and the contribution will be locked temporarily. The two reviewers have distinct roles: reviewer 1 (expert) inspects the assessment closely and advises a decision; reviewer 2(final say) makes the decision. (\u2717\u2717) Both reviewers can enter comments in a comment stream, which are detail records of the assessment. The advice/decision that can be made by the reviewers is approve reject revise Consolidation \u00b6 In all cases, a consolidated version of the reviews will be made. This records contains the information of both of the reviews, the assessment and the contribution. Consolidated means that all links to related records have been replaced by the concrete values found in those records at that time. Consolidated records do not contain fields that point to other records, only concrete text/number/datetime values. Currently, the consolidated version is stored in the database as a tree of documents. All these documents are consolidated versions of documents that the final review document refers to, directly or indirectly. Because the final review refers to the self-assessment, and the self-assessment to both reviews, the other review is also included in the tree. The output below shows how this tree ends up in the client, on the application state. It is shown by the console of the web page, in development mode. You can see how this tree is a mini database of records and related records, hanging together with simple identifiers of the form \"ddd\" where d is a digit. It is not completely trivial to distil a nice, well-readable document out of this. What we need is a consolidation template , that grabs the relevant data from this mini-database. From that template, we can produce first HTML and then PDF. Rather than a single template, we should make templates for each of the tables involved. (\u2717\u2717) Consolidated records will be stored as PDF and viewable from within the app. What needs to be done here, is to write templates that select the desired information from the tree of consolidated documents. Approve \u00b6 A consolidated review-set will be stored in a collection called reviewConsolidated . Apart from the consolidated materials of the reviews, the assessment and the contribution, it contains the _id of the live contribution, and a time stamp of the moment of consolidating. The live assessment will remain immutable, but the live contribution becomes mutable again. So the consolidated review-set contains all information upon which the outcome of the assessment is based, even if the live contribution undergoes subsequent development. The reason why contributions will not be permanently immutable is this: contributions are likely to continue to evolve after assessment; their metadata (among which URLs and email addresses) may change, and the contributor may wish to keep the data for his/her contribution up to date, especially in view of data exchange between the contribution tool and the Market Place. Reject \u00b6 A consolidated version of the review will be stored. The live assessment will remain immutable, but the live contribution becomes mutable again. (\u2717\u2717) The applicant may enter an objection. In that case the back office will ask a second opinion and take appropriate action, which might lead to a change of decision, e.g. towards revise , or to a new review by other reviewers. Revise \u00b6 The live assessment and live contribution will become mutable again, and the applicant can modify both in response to comments by the reviewers. When (s)he is finished, the applicant can submit the modified version. Trails \u00b6 After an assessment and review process, the system contains a trail of all that has gone on in the following form: live contribution The contribution record is still in place, mutable, and contains only the actual situation live assessment The assessment record is still in place, but immutable. (\u2717\u2717) live comments trail (\u2717\u2717) by reviewers: comments and suggestions for modification (\u2717\u2717) by the applicant: to state an objection (\u2717) consolidated versions of assessments There are snapshots of the assessment at pivotal points in time: (\u2717\u2717) when the assessment has been offered for review (\u2717\u2717) when reviewers have made decisions (\u2717\u2717) when second opinions have been asked and given Management information \u00b6 The app compiles management information of a statistical nature, both to the public and authenticated users. The quantity of information given is dependent on user rights. The public can see contributions, but not assessments and reviews, except the ones that are finalized with outcome \"accept\". (\u2717) In those cases, the assessment score is also visible. Left-overs \u00b6 Email notification \u00b6 It might be handy to send emails to users involved in assessing and reviewing to notify them that a key event has occurred, such as the submission of an assessment, the appointment of reviewers, the decisions by reviewers. Push notification \u00b6 When an assessor calls up his/her assessment, and at the same time a reviewer takes a decision, this fact is not pushed to the assessor's browsing session. Only when the assessor feels like refreshing the page, (s)he will see the effects of that decision. We need some mechanism of hinting the user that important changes have been made and a refresh is needed. I know it can be done ( socket , python-socket ) but it requires a bit of research to find the best way to do it.","title":"Business"},{"location":"Functionality/Business/#business-logic","text":"Here we document the functionality of the app from the perspective of the users and stakeholders. We focus on the scenarios that are supported. N.B.: (\u2717) Items marked with a single \u2717, are not implemented yet, but are expected to make to the delivery on 2017-12-31. (\u2717\u2717) Items marked with a double \u2717, are not expected to be implemented before the delivery on 2017-12-31. They may or may not be implemented in 2018.","title":"Business Logic"},{"location":"Functionality/Business/#contributions","text":"A contribution is a piece of work in Digital Humanities, delivered by a person or institute, and potentially relevant to the European DARIAH research infrastructure. The national members of DARIAH may add such a contribution to their agreed budget of in-kind contributions to DARIAH as a whole. This makes it necessary to assess contributions against a set of well-defined criteria.","title":"Contributions"},{"location":"Functionality/Business/#assessment-scenario","text":"Contributions may represent diverse efforts such as consultancy, workshops, software development, and hosting services. This asks for a diversification of contribution types and associated criteria. Moreover, types and criteria may change over time, but during an assessment and review cycle they should be fixed. The assessor of a contribution (from now on called applicant ) needs to state how that contribution scores for each relevant criterion, and for each score, evidence must be given. typeContribution is the table with the set of contribution types. criteria is the table with the individual criteria, where each criteria can be associated with one or more types. package is the table of fixed constellations of types and criteria. At any point in time there are one or more active packages, usually just one. A package defines a set of contribution types, and a set of criteria. Every criterion is linked to a number of contribution types, meaning that the criterion is relevant to contributions of those types and no others. Every criterion is associated with exactly one package, hence the package ultimately determines the mapping between types and criteria. A package has a validity interval, i.e. a start date and an end date. A package is active at a point in time, if that point in time is inside the validity interval. The types of an active package are the active types, and its criteria are the active criteria. Technically, more than one package can be valid at the same time. In that case, the sets of active types and criteria are the union of the sets of types and criteria for each active package. But the intention is that there is always exactly one active package. Other components may call workflow functions in order to determine what the active packages, types and criteria are, so they can render inactive and active ones in different ways.","title":"Assessment scenario"},{"location":"Functionality/Business/#assessing","text":"Applicants with write-access to a contribution can add a self-assessment to a contribution. A self assessment is a record in the assessment table, and consists of a few metadata fields. When an assessment record is created, additional detail records will be created as well. These are criteriaEntry records. For each assessment, there is a fixed set of criteriaEntry records. This set is determined by the currently active set of criteria: one criteriaEntry record will be created per active criterion. A criteriaEntry record has a field for choosing a score and a text field for entering the evidence. Scores are defined in yet another type of record.","title":"Assessing"},{"location":"Functionality/Business/#scoring","text":"The scores for a criterion are entered in with the help of score records, which are detail records of criteria. Scores have a number, typically 0 , 2 , 4 , and a short description, typically None , Partial , Full , but the number and nature of scores may vary freely between criteria. The score of an assessment as a whole is the sum of the individual scores expressed as percentage of the total amount of points that can be assigned. A temporary overall score is obtained by treating unfilled scores as having value 0 . However, some criteria may allow scores with a value -1 (non-applicable). If an assessment assigns that score to a criterion, 0 points are added, but points missed from this criterion will be subtracted from the total score, so that this criterion will not be counted in the average. Example : Suppose there are four criteria, A, B, C, D. A, B, and C have scores 0 , 2 , and 4 . D has scores -1 , 0 , 2 , 4 . Now there are two contributions U and V, with scores as follows: Criterion contrib U contrib V A 4 4 B 4 4 C 4 4 D -1 0 sum 12 12 total 12 16 score 100% 75% See how U does better than V although they have an equal number of points. But for U criterion D does not count, while for V it counts, but the score is 0. N.B. Not all criteria will allow -1 values!","title":"Scoring"},{"location":"Functionality/Business/#review-scenario","text":"After a contributor has filled out an assessment, (s)he can submit it for review. The office will select two reviewers, and they will get access to the self assessment. Upon asking for review, the assessment and the contribution will be locked temporarily. The two reviewers have distinct roles: reviewer 1 (expert) inspects the assessment closely and advises a decision; reviewer 2(final say) makes the decision. (\u2717\u2717) Both reviewers can enter comments in a comment stream, which are detail records of the assessment. The advice/decision that can be made by the reviewers is approve reject revise","title":"Review scenario"},{"location":"Functionality/Business/#consolidation","text":"In all cases, a consolidated version of the reviews will be made. This records contains the information of both of the reviews, the assessment and the contribution. Consolidated means that all links to related records have been replaced by the concrete values found in those records at that time. Consolidated records do not contain fields that point to other records, only concrete text/number/datetime values. Currently, the consolidated version is stored in the database as a tree of documents. All these documents are consolidated versions of documents that the final review document refers to, directly or indirectly. Because the final review refers to the self-assessment, and the self-assessment to both reviews, the other review is also included in the tree. The output below shows how this tree ends up in the client, on the application state. It is shown by the console of the web page, in development mode. You can see how this tree is a mini database of records and related records, hanging together with simple identifiers of the form \"ddd\" where d is a digit. It is not completely trivial to distil a nice, well-readable document out of this. What we need is a consolidation template , that grabs the relevant data from this mini-database. From that template, we can produce first HTML and then PDF. Rather than a single template, we should make templates for each of the tables involved. (\u2717\u2717) Consolidated records will be stored as PDF and viewable from within the app. What needs to be done here, is to write templates that select the desired information from the tree of consolidated documents.","title":"Consolidation"},{"location":"Functionality/Business/#approve","text":"A consolidated review-set will be stored in a collection called reviewConsolidated . Apart from the consolidated materials of the reviews, the assessment and the contribution, it contains the _id of the live contribution, and a time stamp of the moment of consolidating. The live assessment will remain immutable, but the live contribution becomes mutable again. So the consolidated review-set contains all information upon which the outcome of the assessment is based, even if the live contribution undergoes subsequent development. The reason why contributions will not be permanently immutable is this: contributions are likely to continue to evolve after assessment; their metadata (among which URLs and email addresses) may change, and the contributor may wish to keep the data for his/her contribution up to date, especially in view of data exchange between the contribution tool and the Market Place.","title":"Approve"},{"location":"Functionality/Business/#reject","text":"A consolidated version of the review will be stored. The live assessment will remain immutable, but the live contribution becomes mutable again. (\u2717\u2717) The applicant may enter an objection. In that case the back office will ask a second opinion and take appropriate action, which might lead to a change of decision, e.g. towards revise , or to a new review by other reviewers.","title":"Reject"},{"location":"Functionality/Business/#revise","text":"The live assessment and live contribution will become mutable again, and the applicant can modify both in response to comments by the reviewers. When (s)he is finished, the applicant can submit the modified version.","title":"Revise"},{"location":"Functionality/Business/#trails","text":"After an assessment and review process, the system contains a trail of all that has gone on in the following form: live contribution The contribution record is still in place, mutable, and contains only the actual situation live assessment The assessment record is still in place, but immutable. (\u2717\u2717) live comments trail (\u2717\u2717) by reviewers: comments and suggestions for modification (\u2717\u2717) by the applicant: to state an objection (\u2717) consolidated versions of assessments There are snapshots of the assessment at pivotal points in time: (\u2717\u2717) when the assessment has been offered for review (\u2717\u2717) when reviewers have made decisions (\u2717\u2717) when second opinions have been asked and given","title":"Trails"},{"location":"Functionality/Business/#management-information","text":"The app compiles management information of a statistical nature, both to the public and authenticated users. The quantity of information given is dependent on user rights. The public can see contributions, but not assessments and reviews, except the ones that are finalized with outcome \"accept\". (\u2717) In those cases, the assessment score is also visible.","title":"Management information"},{"location":"Functionality/Business/#left-overs","text":"","title":"Left-overs"},{"location":"Functionality/Business/#email-notification","text":"It might be handy to send emails to users involved in assessing and reviewing to notify them that a key event has occurred, such as the submission of an assessment, the appointment of reviewers, the decisions by reviewers.","title":"Email notification"},{"location":"Functionality/Business/#push-notification","text":"When an assessor calls up his/her assessment, and at the same time a reviewer takes a decision, this fact is not pushed to the assessor's browsing session. Only when the assessor feels like refreshing the page, (s)he will see the effects of that decision. We need some mechanism of hinting the user that important changes have been made and a refresh is needed. I know it can be done ( socket , python-socket ) but it requires a bit of research to find the best way to do it.","title":"Push notification"},{"location":"Functionality/Tables/","text":"Tables with templates \u00b6 Here are the particulars of our templates. Below you find all tables for which we do have specialized templates. Consult Templates to read how the mechanism of applying templates works. assessment \u00b6 data model main, mainEdit \u00b6 We move a number of fields from the normal record display to the action template. The idea is that we want to present the user clear workflow buttons, to perform a next step in the workflow, instead of the minute standard controls. mainAction \u00b6 A lot happens here, in terms of reading workflow attributes and triggering the display of workflow buttons and info panels. Assessment score \u00b6 In particular the current score of the assessment is presented here. The score is computed server-side by the workflow function assessmentScore . Not only the score is presented, but also its derivation. Submission \u00b6 It is presented whether the assessment currently counts as submitted for review, and if yes, also the date-time of the last submission. In this case there is also a button to withdraw the assessment from review. If the assessment does not count as submitted, a submit button is presented. This is not the whole truth, the presence of these action buttons is dependent on additional constraints, such as whether the current user has rights to submit, and whether the assessment is complete. It can also be the case that the assessment has been reviewed with outcome revise . In that case, the submit button changes into an Enter revisions button, and later to Submit for review (again) . If the contribution has received an other type since the creation of this assessment, this assessment will count as stalled , and cannot be used for review. In this case, the criteria of the assessment are not the criteria by which the contribution should be assessed. So the system stalls this assessment. It is doomed, it can never be submitted. Unless you decide to change back the type of the contribution. If that is not an option, the best thing to do is to copy the worthwhile material from this assessment into a fresh assessment. contrib \u00b6 data model criteriaEntry \u00b6 data model review \u00b6 data model reviewEntry \u00b6 data model","title":"Tables"},{"location":"Functionality/Tables/#tables-with-templates","text":"Here are the particulars of our templates. Below you find all tables for which we do have specialized templates. Consult Templates to read how the mechanism of applying templates works.","title":"Tables with templates"},{"location":"Functionality/Tables/#assessment","text":"data model","title":"assessment"},{"location":"Functionality/Tables/#main-mainedit","text":"We move a number of fields from the normal record display to the action template. The idea is that we want to present the user clear workflow buttons, to perform a next step in the workflow, instead of the minute standard controls.","title":"main, mainEdit"},{"location":"Functionality/Tables/#mainaction","text":"A lot happens here, in terms of reading workflow attributes and triggering the display of workflow buttons and info panels.","title":"mainAction"},{"location":"Functionality/Tables/#assessment-score","text":"In particular the current score of the assessment is presented here. The score is computed server-side by the workflow function assessmentScore . Not only the score is presented, but also its derivation.","title":"Assessment score"},{"location":"Functionality/Tables/#submission","text":"It is presented whether the assessment currently counts as submitted for review, and if yes, also the date-time of the last submission. In this case there is also a button to withdraw the assessment from review. If the assessment does not count as submitted, a submit button is presented. This is not the whole truth, the presence of these action buttons is dependent on additional constraints, such as whether the current user has rights to submit, and whether the assessment is complete. It can also be the case that the assessment has been reviewed with outcome revise . In that case, the submit button changes into an Enter revisions button, and later to Submit for review (again) . If the contribution has received an other type since the creation of this assessment, this assessment will count as stalled , and cannot be used for review. In this case, the criteria of the assessment are not the criteria by which the contribution should be assessed. So the system stalls this assessment. It is doomed, it can never be submitted. Unless you decide to change back the type of the contribution. If that is not an option, the best thing to do is to copy the worthwhile material from this assessment into a fresh assessment.","title":"Submission"},{"location":"Functionality/Tables/#contrib","text":"data model","title":"contrib"},{"location":"Functionality/Tables/#criteriaentry","text":"data model","title":"criteriaEntry"},{"location":"Functionality/Tables/#review","text":"data model","title":"review"},{"location":"Functionality/Tables/#reviewentry","text":"data model","title":"reviewEntry"},{"location":"Functionality/Templates/","text":"Templates \u00b6 Introduction \u00b6 For some parts of the application the generic ways of presenting records and fields is just not good enough, e.g. for the display of assessments. We need a deeper customization there, where the criteriaEntry detail records should appear in one big form. The challenge is to use as much of the generic machinery when we define custom presentations. Our solution here is by using templates . The particulars of our templates are documented in Tables , but you might need to continue reading here first about the power and organization of themt. Looking up a field value might seem a very innocent operation: you retrieve the appropriate document from the database, look up the field in question, and read out the value that you find there. Alas, there are several complicating factors: That value might be a MongoDB object identifier pointing to a related record. We do not want to display that identifier, but the corresponding record, but not the whole record. Only an informative heading. For that we have to look up additional fields in the related table, and possibly apply logic depending on what we encounter. We should not show fields that the current user is not entitled to view. We should not put in edit controls for fields that the current user is not allowed to edit. We should present values that are in some way legacy different from values that are current , where the current-ness of values is determined by certain other fields in the database (see business model . The first two concerns are built into the generic logic, in the components EditInsert ItemRead ItemEdit FieldRead FieldEdit and we do not want to reimplement this logic when we want to cater for the third concern by means of templates. Our solution is that templates are not static strings into which field values are merged dynamically. Instead, our templates are functions that take a properties object as arguments. The properties are functions that can furnish representations for fields. These functions use the general machinery to l(field) fetch labels for fields; e(field) check whether fields have empty values; v(field) fetch the raw values for fields; w(key) fetch additional workflow attributes for records; s(field) fetch the plain string values for fields, replacing identifiers into related tables by headings of related records; by entity titles; f(field) fetch values for fields (with related lookup), and wrap them in FieldRead components; fe(field) fetch values for fields, and wrap them in FieldEdit components, which are controls to let the user edit the value; fs(field) present custom controls for fields and wrap them in FieldSet components, which react to click events: upon a click, a baked in value will be saved for this field to the database; n (only for insert templates): the number of detail records in the list at a set of the active contribution types o check whether the current record is owned by the user or whether the user m(field) check whether the field is editable by the current user; is in the list of editors; me all attributes of the logged in user (empty if the user is not logged in); linkMe a direct hyperlink to a the value as part of its list; editButton a ready-made control for switching edit/read-only mode and saving the values. onInsert a ready-made handler for triggering an insert action. To be associated to the element that receives the user trigger to create a new record. Applying a template means feeding a higher order React component with a properties object of field rendering functions, which results in a concrete React component. The templates will be applied by EditInsert , ItemRead , ItemEdit , ItemAction , and ListPlain . using the functions applyTemplate , applyEditTemplate , applyInsertTemplate , and editMode . Template organization \u00b6 There are several purposes for which we invoke the template mechanism: The presentation of: headings in lists of records main records related records detail records insert buttons consolidated records the determination of: edit modes. All templates can be found in files named after the tables for which they are defined. You can find them in the tables directory. For each table there is an object of template functions, first keyed by their purpose and then, optionally, by the related/detail table they are for. Read, Edit, Action \u00b6 For main and detail records, we have several sets of templates: Head for presentation of record headings in lists, Read for presentation of records in read-only mode, Edit for presenting records as forms with editable fields, Action for presenting actions upon records. The idea is that the form can switch between Read and Edit by means of a standard control, and that the Action part is independent of that switch: it is always displayed. In the Read part, you cannot have edit controls, but in the Edit and Action parts you can have them. However, in the Action part, you do not have save and reset buttons. This part is meant for action buttons, which change a field to a predefined value and save them immediately. Insert \u00b6 For lists of detail records we have templates that format the insert button. These templates can also choose not to show the insert button, depending on conditions determined by the master record and the number of items in the detail list. Head \u00b6 When records are listed, we see a vertical list of record headings. For things that are handled by workflows, such as contributions, assessments and review, it is desirable to display some workflow information right in front of the heading. Think of an assessment score for assessments and contributions, or a review status, telling whether the assessment is being reviewed, and if it has been reviewed, what the final decision was. Main, related, detail, consolidated \u00b6 Related records are records pointed to by a field in a main record. For example, an assessment record has a field contribution , containing the identifier of the contribution record that the assessment is targeting. Here the assessment record wants to display a contribution record as read-only information. A template for this can be found in the templates file contrib This template is only invoked if a contribution record has to be displayed as part of an assessment record. If we need to display it in as part of an other type of record, we can define a separate template for that case. We use these templates for details that want to display a representation of the master inside, or for other cases where records point to other records without an explicit master detail relationship. Detail records are records that point to another record, called the master record. It is typically used when a piece of information consists of a variable number of items. Some central fields go into a master record, and the other items go into detail records that point to the master. For an example, an assessment record is accompanied by a series of criteriaEntry records. The assessment record has no pointers to the criteriaEntry records. Rather each criteriaEntry record points to an assessment record. If record A points to record B, you could say that record B is as master record and A is a detail of it. But in our application, this is not automatically so. For example, a contribution points to a year record, to indicate the year of the contribution. Yet we do not consider a contribution to be a detail of a year. If you want related records to be treated as detail records, you have to say so in the data model . These templates become active when records are displayed in the list of records below a master record. Consolidated records are records for which all related values and relevant details have been collected and represented as strings. A consolidated record is a frozen snapshot of the logical content of a record. It will not change if related records and detail records are modified. We use consolidated records for storing contribution metadata in assessment records when the assessment has finished, and other cases where we have to preserve a record of activities. Applying templates \u00b6 A template is a function that can be passed a props object containing functions that deliver field value information or workflow information: v = field => read-only string value for field f = field => <FieldRead> react component for reading field fe = field => <FieldEdit> react component for editing field fs = field => <FieldSet> customizable react component for setting field to a predefined value e = field => whether that field has an empty value m = field => whether that field is editable by the current user w = kind => workflow information, see workflow . See the library module templates Templates Details of the kinds of templates \u00b6 head \u00b6 The templates for record headings. The result should be a string, not anything that is more complex. If there is no result, do not deliver null , but emptyS (the empty string). main \u00b6 The read templates for records in tables, when presented on their own, i.e. not in relation to other, related records. They will not be passed the fe function. mainEdit \u00b6 The edit templates for records in tables, when presented on their own, i.e. not in relation to other, related records. These template functions are passed the fe function. There is an extra parameter editButton , which is a React component that holds the edit/save button for this record. mainAction \u00b6 Like mainEdit , but now the values are action templates. These template functions do get the fe function. detail \u00b6 The read templates for records in tables, when presented as detail of a master table. Per master table you can define a separate template. These templates are not passed the fe function. detailEdit \u00b6 The edit templates for records in tables, when presented as detail of a master table. Per master table you can define a separate template. These templates do get the fe function. These template functions are passed the fe function. There is an extra parameter editButton , which is a React component that holds the edit/save button for this record. detailAction \u00b6 Like detailEdit , but now the values are action templates. These template functions do get the fe function. related \u00b6 The read templates for records in tables, when an other, related table points to them. It is more like a main record pointing to a related record. Per main table you can define a separate template. These template functions are not passed the fe function, but they get an extra parameter: linkMe , a hyperlink to the main record: linkMe . consolidated \u00b6 Much like related , but here we have templates that only use consolidated values. These templates are passed a special version of the v function, that resolves all dependencies. insert \u00b6 When you want to customize the rather modest + button that inserts a new record in a table, you can write a template for it. This template does not operate on the level of individual items, so it does not get passed the usual functions. What it gets is the number of items that already exist (as details of a master record), and a handler to invoke when the instantiated template is clicked. editMode \u00b6 In some situation you want to open some records in edit mode and others in read mode. A typical situation is where you want to open incomplete records in edit mode, and others not. The template functions of this kind do not deliver templates, but a boolean, which will be used whenever a table is presented to the user as a list.","title":"Templates"},{"location":"Functionality/Templates/#templates","text":"","title":"Templates"},{"location":"Functionality/Templates/#introduction","text":"For some parts of the application the generic ways of presenting records and fields is just not good enough, e.g. for the display of assessments. We need a deeper customization there, where the criteriaEntry detail records should appear in one big form. The challenge is to use as much of the generic machinery when we define custom presentations. Our solution here is by using templates . The particulars of our templates are documented in Tables , but you might need to continue reading here first about the power and organization of themt. Looking up a field value might seem a very innocent operation: you retrieve the appropriate document from the database, look up the field in question, and read out the value that you find there. Alas, there are several complicating factors: That value might be a MongoDB object identifier pointing to a related record. We do not want to display that identifier, but the corresponding record, but not the whole record. Only an informative heading. For that we have to look up additional fields in the related table, and possibly apply logic depending on what we encounter. We should not show fields that the current user is not entitled to view. We should not put in edit controls for fields that the current user is not allowed to edit. We should present values that are in some way legacy different from values that are current , where the current-ness of values is determined by certain other fields in the database (see business model . The first two concerns are built into the generic logic, in the components EditInsert ItemRead ItemEdit FieldRead FieldEdit and we do not want to reimplement this logic when we want to cater for the third concern by means of templates. Our solution is that templates are not static strings into which field values are merged dynamically. Instead, our templates are functions that take a properties object as arguments. The properties are functions that can furnish representations for fields. These functions use the general machinery to l(field) fetch labels for fields; e(field) check whether fields have empty values; v(field) fetch the raw values for fields; w(key) fetch additional workflow attributes for records; s(field) fetch the plain string values for fields, replacing identifiers into related tables by headings of related records; by entity titles; f(field) fetch values for fields (with related lookup), and wrap them in FieldRead components; fe(field) fetch values for fields, and wrap them in FieldEdit components, which are controls to let the user edit the value; fs(field) present custom controls for fields and wrap them in FieldSet components, which react to click events: upon a click, a baked in value will be saved for this field to the database; n (only for insert templates): the number of detail records in the list at a set of the active contribution types o check whether the current record is owned by the user or whether the user m(field) check whether the field is editable by the current user; is in the list of editors; me all attributes of the logged in user (empty if the user is not logged in); linkMe a direct hyperlink to a the value as part of its list; editButton a ready-made control for switching edit/read-only mode and saving the values. onInsert a ready-made handler for triggering an insert action. To be associated to the element that receives the user trigger to create a new record. Applying a template means feeding a higher order React component with a properties object of field rendering functions, which results in a concrete React component. The templates will be applied by EditInsert , ItemRead , ItemEdit , ItemAction , and ListPlain . using the functions applyTemplate , applyEditTemplate , applyInsertTemplate , and editMode .","title":"Introduction"},{"location":"Functionality/Templates/#template-organization","text":"There are several purposes for which we invoke the template mechanism: The presentation of: headings in lists of records main records related records detail records insert buttons consolidated records the determination of: edit modes. All templates can be found in files named after the tables for which they are defined. You can find them in the tables directory. For each table there is an object of template functions, first keyed by their purpose and then, optionally, by the related/detail table they are for.","title":"Template organization"},{"location":"Functionality/Templates/#read-edit-action","text":"For main and detail records, we have several sets of templates: Head for presentation of record headings in lists, Read for presentation of records in read-only mode, Edit for presenting records as forms with editable fields, Action for presenting actions upon records. The idea is that the form can switch between Read and Edit by means of a standard control, and that the Action part is independent of that switch: it is always displayed. In the Read part, you cannot have edit controls, but in the Edit and Action parts you can have them. However, in the Action part, you do not have save and reset buttons. This part is meant for action buttons, which change a field to a predefined value and save them immediately.","title":"Read, Edit, Action"},{"location":"Functionality/Templates/#insert","text":"For lists of detail records we have templates that format the insert button. These templates can also choose not to show the insert button, depending on conditions determined by the master record and the number of items in the detail list.","title":"Insert"},{"location":"Functionality/Templates/#head","text":"When records are listed, we see a vertical list of record headings. For things that are handled by workflows, such as contributions, assessments and review, it is desirable to display some workflow information right in front of the heading. Think of an assessment score for assessments and contributions, or a review status, telling whether the assessment is being reviewed, and if it has been reviewed, what the final decision was.","title":"Head"},{"location":"Functionality/Templates/#main-related-detail-consolidated","text":"Related records are records pointed to by a field in a main record. For example, an assessment record has a field contribution , containing the identifier of the contribution record that the assessment is targeting. Here the assessment record wants to display a contribution record as read-only information. A template for this can be found in the templates file contrib This template is only invoked if a contribution record has to be displayed as part of an assessment record. If we need to display it in as part of an other type of record, we can define a separate template for that case. We use these templates for details that want to display a representation of the master inside, or for other cases where records point to other records without an explicit master detail relationship. Detail records are records that point to another record, called the master record. It is typically used when a piece of information consists of a variable number of items. Some central fields go into a master record, and the other items go into detail records that point to the master. For an example, an assessment record is accompanied by a series of criteriaEntry records. The assessment record has no pointers to the criteriaEntry records. Rather each criteriaEntry record points to an assessment record. If record A points to record B, you could say that record B is as master record and A is a detail of it. But in our application, this is not automatically so. For example, a contribution points to a year record, to indicate the year of the contribution. Yet we do not consider a contribution to be a detail of a year. If you want related records to be treated as detail records, you have to say so in the data model . These templates become active when records are displayed in the list of records below a master record. Consolidated records are records for which all related values and relevant details have been collected and represented as strings. A consolidated record is a frozen snapshot of the logical content of a record. It will not change if related records and detail records are modified. We use consolidated records for storing contribution metadata in assessment records when the assessment has finished, and other cases where we have to preserve a record of activities.","title":"Main, related, detail, consolidated"},{"location":"Functionality/Templates/#applying-templates","text":"A template is a function that can be passed a props object containing functions that deliver field value information or workflow information: v = field => read-only string value for field f = field => <FieldRead> react component for reading field fe = field => <FieldEdit> react component for editing field fs = field => <FieldSet> customizable react component for setting field to a predefined value e = field => whether that field has an empty value m = field => whether that field is editable by the current user w = kind => workflow information, see workflow . See the library module templates Templates","title":"Applying templates"},{"location":"Functionality/Templates/#details-of-the-kinds-of-templates","text":"","title":"Details of the kinds of templates"},{"location":"Functionality/Templates/#head_1","text":"The templates for record headings. The result should be a string, not anything that is more complex. If there is no result, do not deliver null , but emptyS (the empty string).","title":"head"},{"location":"Functionality/Templates/#main","text":"The read templates for records in tables, when presented on their own, i.e. not in relation to other, related records. They will not be passed the fe function.","title":"main"},{"location":"Functionality/Templates/#mainedit","text":"The edit templates for records in tables, when presented on their own, i.e. not in relation to other, related records. These template functions are passed the fe function. There is an extra parameter editButton , which is a React component that holds the edit/save button for this record.","title":"mainEdit"},{"location":"Functionality/Templates/#mainaction","text":"Like mainEdit , but now the values are action templates. These template functions do get the fe function.","title":"mainAction"},{"location":"Functionality/Templates/#detail","text":"The read templates for records in tables, when presented as detail of a master table. Per master table you can define a separate template. These templates are not passed the fe function.","title":"detail"},{"location":"Functionality/Templates/#detailedit","text":"The edit templates for records in tables, when presented as detail of a master table. Per master table you can define a separate template. These templates do get the fe function. These template functions are passed the fe function. There is an extra parameter editButton , which is a React component that holds the edit/save button for this record.","title":"detailEdit"},{"location":"Functionality/Templates/#detailaction","text":"Like detailEdit , but now the values are action templates. These template functions do get the fe function.","title":"detailAction"},{"location":"Functionality/Templates/#related","text":"The read templates for records in tables, when an other, related table points to them. It is more like a main record pointing to a related record. Per main table you can define a separate template. These template functions are not passed the fe function, but they get an extra parameter: linkMe , a hyperlink to the main record: linkMe .","title":"related"},{"location":"Functionality/Templates/#consolidated","text":"Much like related , but here we have templates that only use consolidated values. These templates are passed a special version of the v function, that resolves all dependencies.","title":"consolidated"},{"location":"Functionality/Templates/#insert_1","text":"When you want to customize the rather modest + button that inserts a new record in a table, you can write a template for it. This template does not operate on the level of individual items, so it does not get passed the usual functions. What it gets is the number of items that already exist (as details of a master record), and a handler to invoke when the instantiated template is clicked.","title":"insert"},{"location":"Functionality/Templates/#editmode","text":"In some situation you want to open some records in edit mode and others in read mode. A typical situation is where you want to open incomplete records in edit mode, and others not. The template functions of this kind do not deliver templates, but a boolean, which will be used whenever a table is presented to the user as a list.","title":"editMode"},{"location":"Functionality/Workflow/","text":"Workflow Engine \u00b6 Description \u00b6 The workflow engine of this app is a system to handle business logic. Whereas the database consists of neutral things (fields, records, lists), the workflow engine weaves additional attributes around it, that indicate additional constraints. These additional workflow attributes are computed by the server on the fly, and then stored in a separate table in the database: workflow . From then on the following happens with the workflow attributes: they are sent to client, together with the permission information for each record the client uses the workflow info to show or hide workflow related controls, and to suppress controls that lead to actions that violate the business logic the server uses the workflow info to enforce the business logic; the server updates the workflow attributes after any insert/update/delete action. No matter how good a job the client does in supporting the business logic and prohibiting actions that violate the business logic, the server always has the last word. Every access to bits and pieces in the database is first subjected to the permissions (a lower layer) and then to the additional workflow constraints. Realization \u00b6 Workflow is realized at the server and at the client. To a large extent, its rules are specified in the data model . Client \u00b6 Workflow logic is predominantly found in the templates , which may include workflow buttons and info panels, but also in workflow.js , which computes special items to present to the user, and for some of them workflow information is used. The templates themselves are applied by functions in templates.js . These functions are given workflow attributes that they pass on to the templates. Server \u00b6 The heart of the workflow code is at the server, in workflow.py . Its functions are called from db.py in many places. The principal functions exported are discussed here. readWorkflow \u00b6 Given a document in some table, this function loads the workflow attributes for that document (if any). The attributes are loaded from the workflow table. That table has records with fields table , eId and attributes , where table and eId specify exactly which the record in question is, and attributes is a dictionary of all workflow data for that record that is currently stored. If compute=True is passed, the workflow attributes will be computed. The determination of these attributes is dictated by the data model , in the individual tables , under the key workflow/read . There you find a sequence of instructions by which the system can compute workflow attributes for each record in a table. Let us look at an example: 1 2 3 4 5 6 7 8 9 10 11 12 workflow : read : - inspect : details method : hasValue linkField : contrib otherTable : assessment otherField : submitted myField : null value : true attribute : name : locked desc : being assessed Basically, this instructs the system to look at various other tables and records and fields, and if certain conditions are met the attributes locked and lockedReason are added to the workflow attributes. Line by line: 1 - inspect: details This is an instruction to look into the detail record(s) of the current record. Other possible values are: master and self , with the obvious meanings. 1 method: hasValue The name of the method by which the inspected value is taken and turned in either True or False . There is a fixed, limited supply of methods, which are hard-coded in the program, see hasValue , hasDifferent , hasIncomplete . Not all of the following parameters need to be present for all methods, and there are more possible parameters, e.g. 1 2 3 emptyFields: - score - evidence a list of fields in the other table that will be checked for emptiness. 1 linkField: contrib This is the name of the field by which detail records point to their master. 1 - otherTable: assessment This is the name of the other table (which can be the master table, the details table, or the own table, depending on the value of inspect ). 1 otherField: submitted The name of the field in the other table to look at. 1 myField: null The name of the field in the own table to look at. 1 value: true A reference value to compare the inspected value with. Summarizing: you just saw just one instruction to inspect related values and to deliver or not deliver a specific set of workflow attributes. More precisely, this is the rule that states that a contribution record becomes locked if it has an assessment that has been submitted. adjustWorkflow \u00b6 Whereas readWorkflow computes all relevant workflow for a given record in a given table, adjustWorkflow delivers a list of other records in other tables, that need new workflow attributes after a change in a given record, whether it be an insert, update or delete. The determination of these attributes is dictated by the data model , in the individual tables , under the key workflow/adjust . Typically, when a record gets workflow attributes based on master or detail records, these attributes must be updated on any change in the master or in one of the details. The system is not clever enough to generate these adjust rules itself. We have to do that. Let us look at the same example, but now at its adjust rule: 1 2 3 4 5 6 7 8 assessment : adjust : - inspect : master linkField : contrib otherTable : contrib triggerFields : - assessmentType - submitted It says that if an assessment record is changed, some other records are affected, namely its master record in the contrib table. But not all changes in the assessment trigger adjustments, only changes in one of the triggerFields , in this case obviously the field submitted . The system add the linkField silently to the triggerField , because if we, for whatever reason, reassigned this assessment to a different contribution, then that contribution has to know! The other trigger field, assessmentType is mentioned because of an other workflow rule, which we have not mentioned here as an example. enforceWorkflow \u00b6 Finally, the server has to know the consequences of the workflow attributes for behaviour. This is dictated in the generic data model , under the key workflow/prevent/ attribute where attribute is a name such as locked or incomplete . For each attribute there are optional constraints for the update and delete actions. 1 2 3 prevent : locked : delete : true means that it is forbidden to delete a record that carries the locked attribute. Likewise, 1 2 3 prevent : locked : update : true means that any update whatsoever is forbidden to such a record. However, we can relax update constraints: 1 2 3 4 prevent : locked : update : submitted : true means that any update that changes the value of the field submitted is forbidden. We can relax this even further, and here we take a real example, under attribute stalled instead of locked : 1 2 3 4 5 prevent : stalled : update : submitted : after : true This means that any update that leads to field submitted having value true is forbidden. Here we say that a stalled assessment cannot be submitted. For the sake of clarity, here is the rule that says when an assessment is stalled : 1 2 3 4 5 6 7 8 9 10 11 12 workflow : read : - inspect : master method : hasDifferent linkField : contrib otherTable : contrib otherField : typeContribution myField : assessmentType value : null workflow : stalled : true stalledReason : assessment type is different from contribution type In words: if an assessment has an assessmentType field with a different value that the contributionType field of its master contribution, then the assessment counts as stalled. manageWorkflow \u00b6 When the web server loads, it makes sure that correct workflow information is stored in the workflow table. It does so by dropping the existing workflow table and recomputing all workflow information from scratch. A sysadmin can also reset the workflow from within the app. Then the workflow table will be cleared (not dropped), and all workflow info will be recomputed. The WorkflowInfo component presents the previous resets since the web server was last started, and gives an overview of the recomputed workflow attributes. Inspecting other documents \u00b6 Both readWorkflow and adjustWorkflow have instructions to look up related documents and then apply a computing method to all those documents. The target documents can be specified with these instructions: self don't look further, look at yourself. The information from which workflow attributes are to be derived, is already present in the document itself. master look at your master document. A document can have multiple masters, so you have to specify the field in yourself that points to the master, and also what table that is. details look at your details. A document can have multiple kinds of details, so you have to specify the table that holds the details, and the field in the details that points to you. siblings look at records with the same master. You have to specify your field that points to the master, the field in your siblings that points to the master, and the table that holds your siblings. Computing attributes \u00b6 When the other documents have been found, it is time to extract information from them, in order to put it into workflow attributes. There is a limited set of functions you can call, they are all listed in worklow.py and their names start with _compute_ . Below we name them without this prefix. hasValue \u00b6 Returns {'on': True } if one of the other docs has a field with a given value. hasComplete \u00b6 Returns {'on': True} if all of the other docs have no empty field among a given list of fields. hasIncomplete \u00b6 Returns {'on': True, 'n': n } if one of the other docs has an empty field among a given list of fields. If so, n is the number of such docs. hasDifferent \u00b6 Returns {'on': True } if one of the other docs has a different value than you for a given field. getValues \u00b6 Returns 1 2 3 4 5 6 { 'items' : [ { 'field1' : value1a , 'field2' : value2a }, { 'field1' : value1b , 'field2' : value2b }, ... ] } where field1 and field2 are given fields, and value1a and value2a are values for those fields found in the other docs, and likewise for all such values value1b and value2b that can be found in all other docs. assessmentScore \u00b6 Computes the overall score of an assessment, based on its detail criteriaEntry records. The data returned is a dictionary containing: overall : the overall score as percentage of points scored with respect to total of scorable points relevantScore : the sum of the scores for all criteria that have not been scored as -1 (non-applicable) relevantMax : the total of the maximum scores for all criteria that have not been scored as -1 allMax : the total of the maximum scores for all criteria relevantN : the number of criteria that have not been scored as -1 allN : the number of criteria. aId : the id of the assessment in question. See more about the computation in the business logic . Wiring \u00b6 Let us finish with an example, to show the intricate wiring of data that is going on in the workflow system. Above we see a good deal of the workflow rules that govern contributions and their assessments and reviews, each with their detail records of criteria entries (in the self-assessment) and review entries (in the reviews). The coloured squares are particular records in the contribution, assessment, review, etc. collections. We only mention the fields that play a role in the workflow. The rounded labels indicate the workflow attributes that are computed for those records. The arrows show which fields are used for which workflow attributes. In fact, the arrows correspond exactly with the workflow/read and workflow/adjust instructions given in the data model . The reading of an arrow is like this: read workflow : whenever a record needs to be sent to the client, compute the indicated workflow labels, based on the information in the fields indicated by following the arrows in the opposite direction; adjust workflow : whenever a record is inserted, deleted, or updated, follow any arrow from any of its fields, and for every record at the opposite end, trigger a recomputation of its workflow, and send that to the client as part of the result op the modification action. In this way, whenever the user changes a record, not only the affected records are reported back, but also the records with updated workflow information. This will ultimately update the user interface in all relevant parts.","title":"Workflow"},{"location":"Functionality/Workflow/#workflow-engine","text":"","title":"Workflow Engine"},{"location":"Functionality/Workflow/#description","text":"The workflow engine of this app is a system to handle business logic. Whereas the database consists of neutral things (fields, records, lists), the workflow engine weaves additional attributes around it, that indicate additional constraints. These additional workflow attributes are computed by the server on the fly, and then stored in a separate table in the database: workflow . From then on the following happens with the workflow attributes: they are sent to client, together with the permission information for each record the client uses the workflow info to show or hide workflow related controls, and to suppress controls that lead to actions that violate the business logic the server uses the workflow info to enforce the business logic; the server updates the workflow attributes after any insert/update/delete action. No matter how good a job the client does in supporting the business logic and prohibiting actions that violate the business logic, the server always has the last word. Every access to bits and pieces in the database is first subjected to the permissions (a lower layer) and then to the additional workflow constraints.","title":"Description"},{"location":"Functionality/Workflow/#realization","text":"Workflow is realized at the server and at the client. To a large extent, its rules are specified in the data model .","title":"Realization"},{"location":"Functionality/Workflow/#client","text":"Workflow logic is predominantly found in the templates , which may include workflow buttons and info panels, but also in workflow.js , which computes special items to present to the user, and for some of them workflow information is used. The templates themselves are applied by functions in templates.js . These functions are given workflow attributes that they pass on to the templates.","title":"Client"},{"location":"Functionality/Workflow/#server","text":"The heart of the workflow code is at the server, in workflow.py . Its functions are called from db.py in many places. The principal functions exported are discussed here.","title":"Server"},{"location":"Functionality/Workflow/#readworkflow","text":"Given a document in some table, this function loads the workflow attributes for that document (if any). The attributes are loaded from the workflow table. That table has records with fields table , eId and attributes , where table and eId specify exactly which the record in question is, and attributes is a dictionary of all workflow data for that record that is currently stored. If compute=True is passed, the workflow attributes will be computed. The determination of these attributes is dictated by the data model , in the individual tables , under the key workflow/read . There you find a sequence of instructions by which the system can compute workflow attributes for each record in a table. Let us look at an example: 1 2 3 4 5 6 7 8 9 10 11 12 workflow : read : - inspect : details method : hasValue linkField : contrib otherTable : assessment otherField : submitted myField : null value : true attribute : name : locked desc : being assessed Basically, this instructs the system to look at various other tables and records and fields, and if certain conditions are met the attributes locked and lockedReason are added to the workflow attributes. Line by line: 1 - inspect: details This is an instruction to look into the detail record(s) of the current record. Other possible values are: master and self , with the obvious meanings. 1 method: hasValue The name of the method by which the inspected value is taken and turned in either True or False . There is a fixed, limited supply of methods, which are hard-coded in the program, see hasValue , hasDifferent , hasIncomplete . Not all of the following parameters need to be present for all methods, and there are more possible parameters, e.g. 1 2 3 emptyFields: - score - evidence a list of fields in the other table that will be checked for emptiness. 1 linkField: contrib This is the name of the field by which detail records point to their master. 1 - otherTable: assessment This is the name of the other table (which can be the master table, the details table, or the own table, depending on the value of inspect ). 1 otherField: submitted The name of the field in the other table to look at. 1 myField: null The name of the field in the own table to look at. 1 value: true A reference value to compare the inspected value with. Summarizing: you just saw just one instruction to inspect related values and to deliver or not deliver a specific set of workflow attributes. More precisely, this is the rule that states that a contribution record becomes locked if it has an assessment that has been submitted.","title":"readWorkflow"},{"location":"Functionality/Workflow/#adjustworkflow","text":"Whereas readWorkflow computes all relevant workflow for a given record in a given table, adjustWorkflow delivers a list of other records in other tables, that need new workflow attributes after a change in a given record, whether it be an insert, update or delete. The determination of these attributes is dictated by the data model , in the individual tables , under the key workflow/adjust . Typically, when a record gets workflow attributes based on master or detail records, these attributes must be updated on any change in the master or in one of the details. The system is not clever enough to generate these adjust rules itself. We have to do that. Let us look at the same example, but now at its adjust rule: 1 2 3 4 5 6 7 8 assessment : adjust : - inspect : master linkField : contrib otherTable : contrib triggerFields : - assessmentType - submitted It says that if an assessment record is changed, some other records are affected, namely its master record in the contrib table. But not all changes in the assessment trigger adjustments, only changes in one of the triggerFields , in this case obviously the field submitted . The system add the linkField silently to the triggerField , because if we, for whatever reason, reassigned this assessment to a different contribution, then that contribution has to know! The other trigger field, assessmentType is mentioned because of an other workflow rule, which we have not mentioned here as an example.","title":"adjustWorkflow"},{"location":"Functionality/Workflow/#enforceworkflow","text":"Finally, the server has to know the consequences of the workflow attributes for behaviour. This is dictated in the generic data model , under the key workflow/prevent/ attribute where attribute is a name such as locked or incomplete . For each attribute there are optional constraints for the update and delete actions. 1 2 3 prevent : locked : delete : true means that it is forbidden to delete a record that carries the locked attribute. Likewise, 1 2 3 prevent : locked : update : true means that any update whatsoever is forbidden to such a record. However, we can relax update constraints: 1 2 3 4 prevent : locked : update : submitted : true means that any update that changes the value of the field submitted is forbidden. We can relax this even further, and here we take a real example, under attribute stalled instead of locked : 1 2 3 4 5 prevent : stalled : update : submitted : after : true This means that any update that leads to field submitted having value true is forbidden. Here we say that a stalled assessment cannot be submitted. For the sake of clarity, here is the rule that says when an assessment is stalled : 1 2 3 4 5 6 7 8 9 10 11 12 workflow : read : - inspect : master method : hasDifferent linkField : contrib otherTable : contrib otherField : typeContribution myField : assessmentType value : null workflow : stalled : true stalledReason : assessment type is different from contribution type In words: if an assessment has an assessmentType field with a different value that the contributionType field of its master contribution, then the assessment counts as stalled.","title":"enforceWorkflow"},{"location":"Functionality/Workflow/#manageworkflow","text":"When the web server loads, it makes sure that correct workflow information is stored in the workflow table. It does so by dropping the existing workflow table and recomputing all workflow information from scratch. A sysadmin can also reset the workflow from within the app. Then the workflow table will be cleared (not dropped), and all workflow info will be recomputed. The WorkflowInfo component presents the previous resets since the web server was last started, and gives an overview of the recomputed workflow attributes.","title":"manageWorkflow"},{"location":"Functionality/Workflow/#inspecting-other-documents","text":"Both readWorkflow and adjustWorkflow have instructions to look up related documents and then apply a computing method to all those documents. The target documents can be specified with these instructions: self don't look further, look at yourself. The information from which workflow attributes are to be derived, is already present in the document itself. master look at your master document. A document can have multiple masters, so you have to specify the field in yourself that points to the master, and also what table that is. details look at your details. A document can have multiple kinds of details, so you have to specify the table that holds the details, and the field in the details that points to you. siblings look at records with the same master. You have to specify your field that points to the master, the field in your siblings that points to the master, and the table that holds your siblings.","title":"Inspecting other documents"},{"location":"Functionality/Workflow/#computing-attributes","text":"When the other documents have been found, it is time to extract information from them, in order to put it into workflow attributes. There is a limited set of functions you can call, they are all listed in worklow.py and their names start with _compute_ . Below we name them without this prefix.","title":"Computing attributes"},{"location":"Functionality/Workflow/#hasvalue","text":"Returns {'on': True } if one of the other docs has a field with a given value.","title":"hasValue"},{"location":"Functionality/Workflow/#hascomplete","text":"Returns {'on': True} if all of the other docs have no empty field among a given list of fields.","title":"hasComplete"},{"location":"Functionality/Workflow/#hasincomplete","text":"Returns {'on': True, 'n': n } if one of the other docs has an empty field among a given list of fields. If so, n is the number of such docs.","title":"hasIncomplete"},{"location":"Functionality/Workflow/#hasdifferent","text":"Returns {'on': True } if one of the other docs has a different value than you for a given field.","title":"hasDifferent"},{"location":"Functionality/Workflow/#getvalues","text":"Returns 1 2 3 4 5 6 { 'items' : [ { 'field1' : value1a , 'field2' : value2a }, { 'field1' : value1b , 'field2' : value2b }, ... ] } where field1 and field2 are given fields, and value1a and value2a are values for those fields found in the other docs, and likewise for all such values value1b and value2b that can be found in all other docs.","title":"getValues"},{"location":"Functionality/Workflow/#assessmentscore","text":"Computes the overall score of an assessment, based on its detail criteriaEntry records. The data returned is a dictionary containing: overall : the overall score as percentage of points scored with respect to total of scorable points relevantScore : the sum of the scores for all criteria that have not been scored as -1 (non-applicable) relevantMax : the total of the maximum scores for all criteria that have not been scored as -1 allMax : the total of the maximum scores for all criteria relevantN : the number of criteria that have not been scored as -1 allN : the number of criteria. aId : the id of the assessment in question. See more about the computation in the business logic .","title":"assessmentScore"},{"location":"Functionality/Workflow/#wiring","text":"Let us finish with an example, to show the intricate wiring of data that is going on in the workflow system. Above we see a good deal of the workflow rules that govern contributions and their assessments and reviews, each with their detail records of criteria entries (in the self-assessment) and review entries (in the reviews). The coloured squares are particular records in the contribution, assessment, review, etc. collections. We only mention the fields that play a role in the workflow. The rounded labels indicate the workflow attributes that are computed for those records. The arrows show which fields are used for which workflow attributes. In fact, the arrows correspond exactly with the workflow/read and workflow/adjust instructions given in the data model . The reading of an arrow is like this: read workflow : whenever a record needs to be sent to the client, compute the indicated workflow labels, based on the information in the fields indicated by following the arrows in the opposite direction; adjust workflow : whenever a record is inserted, deleted, or updated, follow any arrow from any of its fields, and for every record at the opposite end, trigger a recomputation of its workflow, and send that to the client as part of the result op the modification action. In this way, whenever the user changes a record, not only the affected records are reported back, but also the records with updated workflow information. This will ultimately update the user interface in all relevant parts.","title":"Wiring"},{"location":"Integration/API/","text":"API \u00b6 Root \u00b6 All API calls are structured like this: https://dariah-beta.dans.knaw.nl /api/db/ verb ? parameters Below there is a partial specification of the verbs and their parameters. Permissions \u00b6 Data access is controlled. You only get the data you have rights to access. If you fetch records, it depends on your access level which records and which fields are being returned. The contribution tool itself uses this API to feed itself with data. It does not use other data access methods. Source \u00b6 In those cases where this documentation fails to give the information you need you might want to look into the source code: index.py controller.py list \u00b6 list?table= table name &complete= false or true Get the records of the table with name table name . If complete=false , fetch only the titles of each record. Otherwise, fetch all fields that you are entitled to read. The result is a json object, containing sub objects for the specification of the data model of this table. The actual records are under entities , keyed by their MongoDB _id . Per entity, the fields can be found under the key values . Example 1 \u00b6 view a collection view \u00b6 view?table= table name &id= mongoId Get an individual item from the table with name table name , and identifier mongoId , having all fields you are entitled to read. Example 2 \u00b6 view an item","title":"API"},{"location":"Integration/API/#api","text":"","title":"API"},{"location":"Integration/API/#root","text":"All API calls are structured like this: https://dariah-beta.dans.knaw.nl /api/db/ verb ? parameters Below there is a partial specification of the verbs and their parameters.","title":"Root"},{"location":"Integration/API/#permissions","text":"Data access is controlled. You only get the data you have rights to access. If you fetch records, it depends on your access level which records and which fields are being returned. The contribution tool itself uses this API to feed itself with data. It does not use other data access methods.","title":"Permissions"},{"location":"Integration/API/#source","text":"In those cases where this documentation fails to give the information you need you might want to look into the source code: index.py controller.py","title":"Source"},{"location":"Integration/API/#list","text":"list?table= table name &complete= false or true Get the records of the table with name table name . If complete=false , fetch only the titles of each record. Otherwise, fetch all fields that you are entitled to read. The result is a json object, containing sub objects for the specification of the data model of this table. The actual records are under entities , keyed by their MongoDB _id . Per entity, the fields can be found under the key values .","title":"list"},{"location":"Integration/API/#example-1","text":"view a collection","title":"Example 1"},{"location":"Integration/API/#view","text":"view?table= table name &id= mongoId Get an individual item from the table with name table name , and identifier mongoId , having all fields you are entitled to read.","title":"view"},{"location":"Integration/API/#example-2","text":"view an item","title":"Example 2"},{"location":"Legacy/Content/","text":"Initial Content \u00b6 There are already 800 contributions in the system. They have been collected in a FileMaker database in the past. We convert this content and use it for an initial filling of the contribution tool. The legacy import is automated and repeatable, even into a database that has been used in production for a while. The workflow information \u00b6 All information regarding the workflow of assessing contributions, is in so-called back office tables: packages , criteria , types , etc. These have been compiled under guidance of the HaS project by Lisa de Leeuw, and I have entered them into a big back office configuration file which will be read by an import script and transported into the MongoDB database. Legacy contributions \u00b6 The legacy content for this application consists of a FileMaker database. In it there is a web of tables and value lists. The essential content is a contribution table containing 800 contributions. We have exported tables and value lists as XML. This is a manual and clumsy process. But from the XML towards the MongoDB everything flows automatically. The XML will be read, field definitions will be extracted from it, the data will be read. We do the following: adapt the table and field organization; adjust the field types and the values, especially for datetime and currency; generate value tables and cross tables; add extra information for countries, so that they can be visualized on a map; link values to existing tables; import a moderately denormalized version of the data into MongoDB. The machinery for this is programmed in the script, and the configuration details are spelled out in a config . Importing and reimporting \u00b6 The source data model is complex, the target data model is complex, and the app as a whole must support a complex workflow. It is impossible to design everything up-front, so we need to be able to retrace and our steps and redo the import. As long as the system is not in production, we can just regenerate the database whenever needed, thereby loosing all manual modifications. But there comes a time, and it has arrived now, that people want to experiment with the data. But the app is not finished yet, and maybe there are more design jumps to make. So we need an import script that can reimport the initial data without disturbing the new data. We have written mongoFromFm.py that does exactly this. From transfer to import \u00b6 We started out running the import script in the development situation, populating a MongoDB instance there, dumping its data, and bulk-importing that into the production instance. The problem with that is that the production system will have a different set of users than the development system. And contributions get tied to users, so if we move over contributions without users, their creator fields will dangle. It turns out to be much better to use the import script also in the production situation. So we ship the FileMaker input for the script to the production server, and run the import there, with slightly different settings. An additional advantage is, that we replace a coarse bulk import by a much more intelligent and sensitive approach: we add the records programmatically, and we have a chance to look before we act. Requirements \u00b6 The task for the import script boils down to these requirements: records that have been manually modified in the target system MAY NOT be overwritten; existing relationships between records MUST be preserved. See later, under Discussion how this is achieved. Usage \u00b6 1 python3 mongoFromFm.py production or 1 python3 mongoFromFm.py development In development mode, the following things happen: excel spreadsheets with the original FileMaker data and the resulting MongoDB data are generated; a bunch of test users is added; the ownership of some contributions is changed to the developer, for ease of testing. Discussion \u00b6 The main idea is that all records that come out of the conversion progress, are marked as pristine . Later, when a record is changed under the influence of the tool, this mark is removed. Preventing data loss \u00b6 All records generated by this program will have a field isPristine , set to true . The DARIAH contribution tool will remove this field from a record after it has modified it. This import tool does not delete databases, nor collections, only individual documents. Before import, an inspection is made: the ids of the existing records are retrieved. The ids will be classified: pristine , non-pristine , troublesome . Troublesome means: not pristine, and occurring in the records to be imported. The following will happen: a. Existing pristine records will be deleted. b. The import records will be filtered: the ones with troublesome ids will be left out. c. The filtered import records will be inserted. This guarantees that there is no data loss: no records that have been touched by the application are deleted nor overwritten. Maintaining existing relationships \u00b6 The mongoId creation happens deterministically, with fixed identifiers, generated on the basis of the table name and the record number ONLY. The records are generated in a deterministic order. If the import script has not changed, the results will be identical. If identical records are imported, the results will be identical. If identical records are imported repeatedly, there will be no change after the first time. If the script changes, but the number and order of records that are generated remains the same the generated ids are still the same. This does not guarantee that no relationships will break. But the only case where things might go wrong are the non-pristine records. If they refer to a value table, and the value table has been reorganized, data may become corrupt. If this happens, ad-hoc remedies are needed. The script will output a clear table with the number of non-pristine records per table. The import script should stabilize over time, in the sense that it will not change the existing organization of tables, but only add new system tables. The user table \u00b6 All production users in the system are not pristine. So they will be untouched. No initial data refers to production users. So the legacy users are disjoint from the production users. The same holds for the test users: they live only on the test system. Nothing in the production system has any link to a test user. The import script creates some group assignments for production users. These links between group and user happen per eppn, not per id. If the receiving database has different assignments in place, they will be non-pristine, and hence will not be overwritten.","title":"Content"},{"location":"Legacy/Content/#initial-content","text":"There are already 800 contributions in the system. They have been collected in a FileMaker database in the past. We convert this content and use it for an initial filling of the contribution tool. The legacy import is automated and repeatable, even into a database that has been used in production for a while.","title":"Initial Content"},{"location":"Legacy/Content/#the-workflow-information","text":"All information regarding the workflow of assessing contributions, is in so-called back office tables: packages , criteria , types , etc. These have been compiled under guidance of the HaS project by Lisa de Leeuw, and I have entered them into a big back office configuration file which will be read by an import script and transported into the MongoDB database.","title":"The workflow information"},{"location":"Legacy/Content/#legacy-contributions","text":"The legacy content for this application consists of a FileMaker database. In it there is a web of tables and value lists. The essential content is a contribution table containing 800 contributions. We have exported tables and value lists as XML. This is a manual and clumsy process. But from the XML towards the MongoDB everything flows automatically. The XML will be read, field definitions will be extracted from it, the data will be read. We do the following: adapt the table and field organization; adjust the field types and the values, especially for datetime and currency; generate value tables and cross tables; add extra information for countries, so that they can be visualized on a map; link values to existing tables; import a moderately denormalized version of the data into MongoDB. The machinery for this is programmed in the script, and the configuration details are spelled out in a config .","title":"Legacy contributions"},{"location":"Legacy/Content/#importing-and-reimporting","text":"The source data model is complex, the target data model is complex, and the app as a whole must support a complex workflow. It is impossible to design everything up-front, so we need to be able to retrace and our steps and redo the import. As long as the system is not in production, we can just regenerate the database whenever needed, thereby loosing all manual modifications. But there comes a time, and it has arrived now, that people want to experiment with the data. But the app is not finished yet, and maybe there are more design jumps to make. So we need an import script that can reimport the initial data without disturbing the new data. We have written mongoFromFm.py that does exactly this.","title":"Importing and reimporting"},{"location":"Legacy/Content/#from-transfer-to-import","text":"We started out running the import script in the development situation, populating a MongoDB instance there, dumping its data, and bulk-importing that into the production instance. The problem with that is that the production system will have a different set of users than the development system. And contributions get tied to users, so if we move over contributions without users, their creator fields will dangle. It turns out to be much better to use the import script also in the production situation. So we ship the FileMaker input for the script to the production server, and run the import there, with slightly different settings. An additional advantage is, that we replace a coarse bulk import by a much more intelligent and sensitive approach: we add the records programmatically, and we have a chance to look before we act.","title":"From transfer to import"},{"location":"Legacy/Content/#requirements","text":"The task for the import script boils down to these requirements: records that have been manually modified in the target system MAY NOT be overwritten; existing relationships between records MUST be preserved. See later, under Discussion how this is achieved.","title":"Requirements"},{"location":"Legacy/Content/#usage","text":"1 python3 mongoFromFm.py production or 1 python3 mongoFromFm.py development In development mode, the following things happen: excel spreadsheets with the original FileMaker data and the resulting MongoDB data are generated; a bunch of test users is added; the ownership of some contributions is changed to the developer, for ease of testing.","title":"Usage"},{"location":"Legacy/Content/#discussion","text":"The main idea is that all records that come out of the conversion progress, are marked as pristine . Later, when a record is changed under the influence of the tool, this mark is removed.","title":"Discussion"},{"location":"Legacy/Content/#preventing-data-loss","text":"All records generated by this program will have a field isPristine , set to true . The DARIAH contribution tool will remove this field from a record after it has modified it. This import tool does not delete databases, nor collections, only individual documents. Before import, an inspection is made: the ids of the existing records are retrieved. The ids will be classified: pristine , non-pristine , troublesome . Troublesome means: not pristine, and occurring in the records to be imported. The following will happen: a. Existing pristine records will be deleted. b. The import records will be filtered: the ones with troublesome ids will be left out. c. The filtered import records will be inserted. This guarantees that there is no data loss: no records that have been touched by the application are deleted nor overwritten.","title":"Preventing data loss"},{"location":"Legacy/Content/#maintaining-existing-relationships","text":"The mongoId creation happens deterministically, with fixed identifiers, generated on the basis of the table name and the record number ONLY. The records are generated in a deterministic order. If the import script has not changed, the results will be identical. If identical records are imported, the results will be identical. If identical records are imported repeatedly, there will be no change after the first time. If the script changes, but the number and order of records that are generated remains the same the generated ids are still the same. This does not guarantee that no relationships will break. But the only case where things might go wrong are the non-pristine records. If they refer to a value table, and the value table has been reorganized, data may become corrupt. If this happens, ad-hoc remedies are needed. The script will output a clear table with the number of non-pristine records per table. The import script should stabilize over time, in the sense that it will not change the existing organization of tables, but only add new system tables.","title":"Maintaining existing relationships"},{"location":"Legacy/Content/#the-user-table","text":"All production users in the system are not pristine. So they will be untouched. No initial data refers to production users. So the legacy users are disjoint from the production users. The same holds for the test users: they live only on the test system. Nothing in the production system has any link to a test user. The import script creates some group assignments for production users. These links between group and user happen per eppn, not per id. If the receiving database has different assignments in place, they will be non-pristine, and hence will not be overwritten.","title":"The user table"},{"location":"Maintenance/Deploy/","text":"Deployment \u00b6 Basic information \u00b6 source code GitHub repository https://github.com/Dans-labs/dariah tech doc GitHub Pages https://dans-labs.github.io/dariah/ server https://dariah-beta.dans.knaw.nl database MongoDB via pymongo (no connection information needed). Version 3.4.10 or higher. On the Mac: installing: 1 brew install MongoDB On the Mac: upgrading: 1 2 3 4 5 brew update brew upgrade MongoDB brew link --overwrite MongoDB brew services stop MongoDB brew services start MongoDB Web-app overview \u00b6 For the server application code we use Flask , a Python3 micro framework to route URLs to functions that perform requests and return responses. It contains a development web server. The list of Python dependencies to be installed is in requirements.txt . The production web server is httpd (Apache) . Flask connects to it through mod_wsgi (take care to use a version that speaks Python3). This connection is defined in the default config file See default_example.conf . /etc/httpd/config.d/ default.conf (config for this site) shib.conf (config for shibboleth authentication) ... The client code is done in React using the JSX idiom. We have added Redux to the mix and various other libraries, obtained through npm . Everything is glued together by means of modern JavaScript: ES6 = ES2015 . The build tool is Webpack . We make use of the DARIAH infrastructure for user authentication AAI (see in particular Integrating Shibboleth Authentication into your Application The app itself gives access to documentation , not only for end users, but also for developers and designers. File structure \u00b6 The absolute location is not important. Here we assume everything resides in /opt . /opt shibboleth web-apps dariah README.md short description for humans build.sh script for build/development tasks, the options are documented inside, or run it without arguments for help server controllers routes and controllers index.py entry point db.py JSON data from MongoDB file.py JSON data from file system auth.py handle the login process user.py handle the user data perm.py permission control models yaml files defining the data model (these files have been converted to python files): model.yaml (generic settings) tables table .yaml per table modeling views html templates index.tpl the html template of the single page serve.py wsgi entry-point for apache compile.py converts yaml model files into python modules config requirements.txt the list of python packages needed; to be installed with pip3 default_example.conf example config file for Apache httpd server static (static files, css, JavaScript, fonts, etc) css fixed stylesheets dist JavaScript and css built from client/src favicons images fonts docs design.pdf notes on the design of this web app about.md \"about\" text of the contribution tool tools These files are not active in the web scenarios, except for documentation. They are helpers to prepare the data for the app. update.sh script to deploy updates of the web app. Pulls code from the github repo, restarts httpd. from_filemaker.ipynb Jupyter notebook for legacy data conversion mongoFromFm.py Stand-alone definitive data conversion from FileMaker original to MongoDb dump.sh copy Filemaker legacy data to production server, as XML export load.sh run Filemaker conversion and import into MongoDB on production server compose_countries tool to tweak a map of European countries, result in /client/src/js/lib/europe.geo.js client node_modules JavaScript dependencies package.JSON npm config file webpack.config.js config file for webpack, the build tool index.html soft link to ../server/views/index.tpl, the entry html that holds the whole app src css plain CSS stylesheets js app dux connectors between React components and the Redux state. Plain ES6. Every duct handles a specific concern of the app. All contain the following sections: actions , reducer , selectors , helpers . components : React components in *.jsx files. tables : templates (in JSX) for custom formatting main.jsx client-side entry-point for the JavaScript lib _.js client-side code and data in ES6 Technology \u00b6 Server \u00b6 Installation (s) \u00b6 We assume httpd (Apache) is already installed, and MongoDB likewise. Python can be installed by means of the package manager. 1 2 3 4 5 6 yum install rh-python36 rh-python36-python-pymongo rh-python36-mod_wsgi scl enable rh-python36 bash cp /opt/rh/httpd24/root/usr/lib64/httpd/modules/mod_rh-python36-wsgi.so modules cd /etc/httpd cp /opt/rh/httpd24/root/etc/httpd/conf.modules.d/10-rh-python36-wsgi.conf conf.modules.d/ pip install flask On a development server, install Python3 . x . y from its download page . Then install additional modules by means of pip3 : 1 pip3 install pymongo flask More info about running Python3 in the web server mod_wsgi guide . The website runs with SELinux enforced, and also the updating process works. The server framework is Flask , The code for the server is basically a mapping between routes (URL patterns) and functions (request => response transformers). The app source code for the server resides in app.py and other .py files imported by it. The module app.py defines routes and associates functions to be executed for those routes. These functions take a request, and turn it into a response. This file imports a few more specialized controllers: data.py they query the MongoDB and return JSON data login.py handle all login activity The server needs a secret key, we store it in a fixed place. Here is the command to generate and store the key. 1 cd /opt/web-apps date +%s | sha256sum | base64 | head -c 32 > dariah_jwt.secret On the mac you have to say 1 date +%s | shasum -a 256 | base64 | head -c 32 &gt; dariah_jwt.secret Running \u00b6 In development, flask runs its own little web server, in production it is connected to Apache through wsgi . You can run the development server by saying, in the server directory 1 ./serve.sh which starts a small web server that listens to localhost on port 8001. Whenever you save a python source file, the server reloads itself. Client \u00b6 Installation \u00a9 \u00b6 This is only needed on machines where you want to develop the client application. If you merely want to run the app, this is not needed. Install node from its download page . Then install all JavaScript dependencies in one go by executing 1 cd /path/to/dariah/client npm install Building \u00b6 The JSX and ES6 of client components and helpers will be bundled with other JavaScript sources from node_modules . The result ends up in static/dist . JavaScript from other sources, such as leaflet , resides in static/js and will be included directly by the main html file index.html . The build tool is webpack . You can perform builds, by saying, in the client directory 1 webpack or 1 webpack-dev-server or 1 webpack -p The first one produces a development build. The second one starts op a development server, and produces an incremental development build on every saved change\\ in the source code, with hot-reloading of react modules. The third one provides a minified production build. build.sh \u00b6 We have collected all routine tasks for building and updating the app and its data into a build script . See the code for an overview of what it can do, or run 1 ./build.sh (without arguments). Cache busting \u00b6 When this app is developed, and a new version is released, we want browsers to pick it up, instead of serving the old version from cache. That is why new bundles always have different names. Webpack provide a bit of infrastructure to append hashes after the chunks that make up a bundle. The other thing is to pick those names up in the html template that embodies the Single Page App: index.tpl . You see that the links to the CSS and the Javascript are variable elements of this template. When the server starts, it may encounter two cases: there is no /static/dist directory. That means that we are in development mode running under the webpack dev-server. In this case we do not use hashed names, and the server can use fixed file names for the css and js code. there is a /static/dist directory. In there is a webpack generated minimal html file that includes the css and js bundles. The server extracts that info when it starts up and uses it to fill the template variables.","title":"Deploy"},{"location":"Maintenance/Deploy/#deployment","text":"","title":"Deployment"},{"location":"Maintenance/Deploy/#basic-information","text":"source code GitHub repository https://github.com/Dans-labs/dariah tech doc GitHub Pages https://dans-labs.github.io/dariah/ server https://dariah-beta.dans.knaw.nl database MongoDB via pymongo (no connection information needed). Version 3.4.10 or higher. On the Mac: installing: 1 brew install MongoDB On the Mac: upgrading: 1 2 3 4 5 brew update brew upgrade MongoDB brew link --overwrite MongoDB brew services stop MongoDB brew services start MongoDB","title":"Basic information"},{"location":"Maintenance/Deploy/#web-app-overview","text":"For the server application code we use Flask , a Python3 micro framework to route URLs to functions that perform requests and return responses. It contains a development web server. The list of Python dependencies to be installed is in requirements.txt . The production web server is httpd (Apache) . Flask connects to it through mod_wsgi (take care to use a version that speaks Python3). This connection is defined in the default config file See default_example.conf . /etc/httpd/config.d/ default.conf (config for this site) shib.conf (config for shibboleth authentication) ... The client code is done in React using the JSX idiom. We have added Redux to the mix and various other libraries, obtained through npm . Everything is glued together by means of modern JavaScript: ES6 = ES2015 . The build tool is Webpack . We make use of the DARIAH infrastructure for user authentication AAI (see in particular Integrating Shibboleth Authentication into your Application The app itself gives access to documentation , not only for end users, but also for developers and designers.","title":"Web-app overview"},{"location":"Maintenance/Deploy/#file-structure","text":"The absolute location is not important. Here we assume everything resides in /opt . /opt shibboleth web-apps dariah README.md short description for humans build.sh script for build/development tasks, the options are documented inside, or run it without arguments for help server controllers routes and controllers index.py entry point db.py JSON data from MongoDB file.py JSON data from file system auth.py handle the login process user.py handle the user data perm.py permission control models yaml files defining the data model (these files have been converted to python files): model.yaml (generic settings) tables table .yaml per table modeling views html templates index.tpl the html template of the single page serve.py wsgi entry-point for apache compile.py converts yaml model files into python modules config requirements.txt the list of python packages needed; to be installed with pip3 default_example.conf example config file for Apache httpd server static (static files, css, JavaScript, fonts, etc) css fixed stylesheets dist JavaScript and css built from client/src favicons images fonts docs design.pdf notes on the design of this web app about.md \"about\" text of the contribution tool tools These files are not active in the web scenarios, except for documentation. They are helpers to prepare the data for the app. update.sh script to deploy updates of the web app. Pulls code from the github repo, restarts httpd. from_filemaker.ipynb Jupyter notebook for legacy data conversion mongoFromFm.py Stand-alone definitive data conversion from FileMaker original to MongoDb dump.sh copy Filemaker legacy data to production server, as XML export load.sh run Filemaker conversion and import into MongoDB on production server compose_countries tool to tweak a map of European countries, result in /client/src/js/lib/europe.geo.js client node_modules JavaScript dependencies package.JSON npm config file webpack.config.js config file for webpack, the build tool index.html soft link to ../server/views/index.tpl, the entry html that holds the whole app src css plain CSS stylesheets js app dux connectors between React components and the Redux state. Plain ES6. Every duct handles a specific concern of the app. All contain the following sections: actions , reducer , selectors , helpers . components : React components in *.jsx files. tables : templates (in JSX) for custom formatting main.jsx client-side entry-point for the JavaScript lib _.js client-side code and data in ES6","title":"File structure"},{"location":"Maintenance/Deploy/#technology","text":"","title":"Technology"},{"location":"Maintenance/Deploy/#server","text":"","title":"Server"},{"location":"Maintenance/Deploy/#installation-s","text":"We assume httpd (Apache) is already installed, and MongoDB likewise. Python can be installed by means of the package manager. 1 2 3 4 5 6 yum install rh-python36 rh-python36-python-pymongo rh-python36-mod_wsgi scl enable rh-python36 bash cp /opt/rh/httpd24/root/usr/lib64/httpd/modules/mod_rh-python36-wsgi.so modules cd /etc/httpd cp /opt/rh/httpd24/root/etc/httpd/conf.modules.d/10-rh-python36-wsgi.conf conf.modules.d/ pip install flask On a development server, install Python3 . x . y from its download page . Then install additional modules by means of pip3 : 1 pip3 install pymongo flask More info about running Python3 in the web server mod_wsgi guide . The website runs with SELinux enforced, and also the updating process works. The server framework is Flask , The code for the server is basically a mapping between routes (URL patterns) and functions (request => response transformers). The app source code for the server resides in app.py and other .py files imported by it. The module app.py defines routes and associates functions to be executed for those routes. These functions take a request, and turn it into a response. This file imports a few more specialized controllers: data.py they query the MongoDB and return JSON data login.py handle all login activity The server needs a secret key, we store it in a fixed place. Here is the command to generate and store the key. 1 cd /opt/web-apps date +%s | sha256sum | base64 | head -c 32 > dariah_jwt.secret On the mac you have to say 1 date +%s | shasum -a 256 | base64 | head -c 32 &gt; dariah_jwt.secret","title":"Installation (s)"},{"location":"Maintenance/Deploy/#running","text":"In development, flask runs its own little web server, in production it is connected to Apache through wsgi . You can run the development server by saying, in the server directory 1 ./serve.sh which starts a small web server that listens to localhost on port 8001. Whenever you save a python source file, the server reloads itself.","title":"Running"},{"location":"Maintenance/Deploy/#client","text":"","title":"Client"},{"location":"Maintenance/Deploy/#installation-c","text":"This is only needed on machines where you want to develop the client application. If you merely want to run the app, this is not needed. Install node from its download page . Then install all JavaScript dependencies in one go by executing 1 cd /path/to/dariah/client npm install","title":"Installation (c)"},{"location":"Maintenance/Deploy/#building","text":"The JSX and ES6 of client components and helpers will be bundled with other JavaScript sources from node_modules . The result ends up in static/dist . JavaScript from other sources, such as leaflet , resides in static/js and will be included directly by the main html file index.html . The build tool is webpack . You can perform builds, by saying, in the client directory 1 webpack or 1 webpack-dev-server or 1 webpack -p The first one produces a development build. The second one starts op a development server, and produces an incremental development build on every saved change\\ in the source code, with hot-reloading of react modules. The third one provides a minified production build.","title":"Building"},{"location":"Maintenance/Deploy/#buildsh","text":"We have collected all routine tasks for building and updating the app and its data into a build script . See the code for an overview of what it can do, or run 1 ./build.sh (without arguments).","title":"build.sh"},{"location":"Maintenance/Deploy/#cache-busting","text":"When this app is developed, and a new version is released, we want browsers to pick it up, instead of serving the old version from cache. That is why new bundles always have different names. Webpack provide a bit of infrastructure to append hashes after the chunks that make up a bundle. The other thing is to pick those names up in the html template that embodies the Single Page App: index.tpl . You see that the links to the CSS and the Javascript are variable elements of this template. When the server starts, it may encounter two cases: there is no /static/dist directory. That means that we are in development mode running under the webpack dev-server. In this case we do not use hashed names, and the server can use fixed file names for the css and js code. there is a /static/dist directory. In there is a webpack generated minimal html file that includes the css and js bundles. The server extracts that info when it starts up and uses it to fill the template variables.","title":"Cache busting"},{"location":"Maintenance/Tests/","text":"Tests \u00b6 We use Mocha for testing. As we started building tests relatively late (not a good practice!) we do not have too many of them. In fact, I started writing them in order to keep some of the subtler algorithms of the app in check, such as merging new data into objects that should not mutate. fields \u00b6 Contains a test for the sortInterval function, which compares time intervals, including intervals that are open at either side, even at both sides. memo \u00b6 Our memoize function is quite sophisticated, and used many times in the app. So it should be tested thoroughly. There are extensive tests of the logic of the memoizer and there is a performance test which compares it to an older, unsophisticated version of it. merge \u00b6 Several methods for merging new data (read action data ) into an existing object (read state ) are tested. Do they create new objects even if the values have not changed? The most important test is between the two candidates lodash/merge and Immutability-Helper/update . The outcomes shows that the latter achieves a better stability: unchanged parts will not be replaced by new copies of values. genericReducer \u00b6 runActionTest \u00b6 Given an action and the description of a few state transitions, and a list of inspection instructions, with expected outcomes, this function will execute those state transitions and carry out the inspections, and check whether the expected outcomes have materialized. The inspection instructions specify a selection of the state. This part will be selected from the state before and after the transition, and then both parts will be checked for object identity. In this way you can test the effect of actions on the state in detail, and especially whether parts that you think should be unaffected, are indeed strictly equal. filtersReducer \u00b6 ... There areno tests here yet tablesReducer \u00b6 There are a fair amount of tests of the table actions. The tables slice of the state is the biggest and most complex piece of the state. There are also a fair amount of actions that operate on this slice. Together this means that there is a huge number of scenarios to be tested. After each state transition, there are two basic things to assess: the new state has the right value (the semantics is good) the unchanged parts of the new state are still the same objects as those part in the old state (the pragmatics is good). If the semantics turns out to be wrong, the app will appear to act stupidly/sloppily. This is the first order error. If the pragmatics is wrong, the app will show sluggish behaviour. For example, if you have a big list on the screen, and there are many occurrences where a new state is semantically equal, but wrapped in a fresh object, all list items will be rendered twice, or, four times, or eight times, depending on the cascades of actions that are being triggered by these spurious state changes.","title":"Tests"},{"location":"Maintenance/Tests/#tests","text":"We use Mocha for testing. As we started building tests relatively late (not a good practice!) we do not have too many of them. In fact, I started writing them in order to keep some of the subtler algorithms of the app in check, such as merging new data into objects that should not mutate.","title":"Tests"},{"location":"Maintenance/Tests/#fields","text":"Contains a test for the sortInterval function, which compares time intervals, including intervals that are open at either side, even at both sides.","title":"fields"},{"location":"Maintenance/Tests/#memo","text":"Our memoize function is quite sophisticated, and used many times in the app. So it should be tested thoroughly. There are extensive tests of the logic of the memoizer and there is a performance test which compares it to an older, unsophisticated version of it.","title":"memo"},{"location":"Maintenance/Tests/#merge","text":"Several methods for merging new data (read action data ) into an existing object (read state ) are tested. Do they create new objects even if the values have not changed? The most important test is between the two candidates lodash/merge and Immutability-Helper/update . The outcomes shows that the latter achieves a better stability: unchanged parts will not be replaced by new copies of values.","title":"merge"},{"location":"Maintenance/Tests/#genericreducer","text":"","title":"genericReducer"},{"location":"Maintenance/Tests/#runactiontest","text":"Given an action and the description of a few state transitions, and a list of inspection instructions, with expected outcomes, this function will execute those state transitions and carry out the inspections, and check whether the expected outcomes have materialized. The inspection instructions specify a selection of the state. This part will be selected from the state before and after the transition, and then both parts will be checked for object identity. In this way you can test the effect of actions on the state in detail, and especially whether parts that you think should be unaffected, are indeed strictly equal.","title":"runActionTest"},{"location":"Maintenance/Tests/#filtersreducer","text":"... There areno tests here yet","title":"filtersReducer"},{"location":"Maintenance/Tests/#tablesreducer","text":"There are a fair amount of tests of the table actions. The tables slice of the state is the biggest and most complex piece of the state. There are also a fair amount of actions that operate on this slice. Together this means that there is a huge number of scenarios to be tested. After each state transition, there are two basic things to assess: the new state has the right value (the semantics is good) the unchanged parts of the new state are still the same objects as those part in the old state (the pragmatics is good). If the semantics turns out to be wrong, the app will appear to act stupidly/sloppily. This is the first order error. If the pragmatics is wrong, the app will show sluggish behaviour. For example, if you have a big list on the screen, and there are many occurrences where a new state is semantically equal, but wrapped in a fresh object, all list items will be rendered twice, or, four times, or eight times, depending on the cascades of actions that are being triggered by these spurious state changes.","title":"tablesReducer"},{"location":"Server/Authentication/","text":"Authentication \u00b6 The login/logout actions take place at the server after visiting /login , /logout or /slogout . The server performs shibboleth authentication, with credentials coming from the DARIAH Identity provider . Currently, /logout performs a logout from this app, but not from the DARIAH Identity Provider. To do the latter, one has to go to /slogout and close the browser. User records \u00b6 When users log in, their details will be stored in the user table. This happens on every login, so the user table updates itself when the DARIAH identity provider updates attributes. These updates reach our user table only for those users that actually log in, at the moment that they do log in. Most details are provided directly by the DARIAH identity provider upon login. The system may contain records for users that have never logged in. This happens when future users of the system are assigned to field values by their email address. Whenever such a user logs in, the attributes obtained during the authentication will flow into the incomplete user record if it exists, otherwise a new user record will be made. The new user will find him/herself in all places where his/her email address had been entered. Fields \u00b6 user field in this app attribute provided by DARIAH comments eppn eppn a string by which the user is identified in the DARIAH context email mail the email address according to the DARIAH identity provider firstName givenName lastName sn name cn common name, probably just firstName lastName org o organization to which the user is affiliated membership isMemberOf a semicolon separated string of groups within the DARIAH organization to which the user belongs, e.g. lr_DARIAH-User , humanities-at-scale-contributors , dariah-eu-contributors rel affiliation the type of relation the user has with DARIAH, such as member@dariah.eu We do not use unscoped-affiliation , which is the affiliation without the @dariah.eu part. This app adds some fields to a user record: user field comments mayLogin whether the user is allowed to login. Default true , but the back office can use this field to prevent a user from logging in. When a user leaves, we advise to set mayLogin to true . It is not an option to delete a user, because (s)he can be the creator/modifier of records that are still in the system. authority the basis on which the identity of the user has been established. See the values below. group the permission level of this user. See the values below. dateLastLogin when the user has logged in most recently statusLastLogin whether the last login attempt was successful And, like almost all records in the system, some standard fields are added. You will not find these fields on the interface in most cases, but it is good to know that they will be recorded in the database. field comments creator the user that created this user record. The legacy user have HaSProject as creator, which is itself a user that cannot login. Other user records do not have a creator. So authenticated users cannot change their user records. dateCreated when the record was created modified a list of modification events, having the date of modification and the user who did it for each event. User presentation \u00b6 When a user is presented on the interface, we choose between the following representations, in order of highest preference first. name (coming from the DARIAH attribute cn (common name) firstName lastName email eppn-autority We append (org) if available. Values \u00b6 authority values \u00b6 authority comments absent the user has never been authenticated. Used for people that occur in the system, but have not yet logged in. DARIAH the user has been logged in by the DARIAH identity provider legacy the user has been imported from the FileMaker legacy data. This kind of user cannot log in. local the user has logged in on the development system. This kind of user should not be present in the production system! group values \u00b6 group comments public unidentified users (the public). No right to edit anything. Can only list/read public information. auth authenticated user. Can add items and then modify/delete them, within limits. Can see DARIAH internal information (within limits). This is the default group for logged-in users. office back office users. Can modify records created by others (within limits). Cannot do system-technical things. system system managers. Can modify system-technical records, within limits. root Complete rights. Still there are untouchable things, that would compromise the integrity of the system. Even root cannot modify those. nobody All powerful. You can also destroy the system. Detail: nobody belongs to this group. Assigning users to groups is subject to permissions, defined by the groups themselves, with a few additional rules: nobody can assign anybody to the group nobody ; a person can only assign groups that have at most his/her own power; a person can only assign groups to people that have less power than him/herself. Examples: If you are office , you cannot make yourself or anyone else system or root . If you are office , you cannot assign another member of office the group auth . You cannot demote/promote your peers, or the ones above you. You can demote yourself, but not promote yourself. You can demote people below you. You can promote people below you, but only up to your own level. A consequence is, that if there is no root in the system, nobody can be made root from within the system. When importing data into the system by means of load.sh you can specify to make a specific user root . Which user that is, is specified in config.yaml , see rootUser . Once the root user is in place, (s)he can assign system admins and back office people. Once those are in place, the daily governance of the system can take place. statusLastLogin values \u00b6 statusLastLogin comments Approved successful login attempt Rejected unsuccessful login attempt","title":"Authentication"},{"location":"Server/Authentication/#authentication","text":"The login/logout actions take place at the server after visiting /login , /logout or /slogout . The server performs shibboleth authentication, with credentials coming from the DARIAH Identity provider . Currently, /logout performs a logout from this app, but not from the DARIAH Identity Provider. To do the latter, one has to go to /slogout and close the browser.","title":"Authentication"},{"location":"Server/Authentication/#user-records","text":"When users log in, their details will be stored in the user table. This happens on every login, so the user table updates itself when the DARIAH identity provider updates attributes. These updates reach our user table only for those users that actually log in, at the moment that they do log in. Most details are provided directly by the DARIAH identity provider upon login. The system may contain records for users that have never logged in. This happens when future users of the system are assigned to field values by their email address. Whenever such a user logs in, the attributes obtained during the authentication will flow into the incomplete user record if it exists, otherwise a new user record will be made. The new user will find him/herself in all places where his/her email address had been entered.","title":"User records"},{"location":"Server/Authentication/#fields","text":"user field in this app attribute provided by DARIAH comments eppn eppn a string by which the user is identified in the DARIAH context email mail the email address according to the DARIAH identity provider firstName givenName lastName sn name cn common name, probably just firstName lastName org o organization to which the user is affiliated membership isMemberOf a semicolon separated string of groups within the DARIAH organization to which the user belongs, e.g. lr_DARIAH-User , humanities-at-scale-contributors , dariah-eu-contributors rel affiliation the type of relation the user has with DARIAH, such as member@dariah.eu We do not use unscoped-affiliation , which is the affiliation without the @dariah.eu part. This app adds some fields to a user record: user field comments mayLogin whether the user is allowed to login. Default true , but the back office can use this field to prevent a user from logging in. When a user leaves, we advise to set mayLogin to true . It is not an option to delete a user, because (s)he can be the creator/modifier of records that are still in the system. authority the basis on which the identity of the user has been established. See the values below. group the permission level of this user. See the values below. dateLastLogin when the user has logged in most recently statusLastLogin whether the last login attempt was successful And, like almost all records in the system, some standard fields are added. You will not find these fields on the interface in most cases, but it is good to know that they will be recorded in the database. field comments creator the user that created this user record. The legacy user have HaSProject as creator, which is itself a user that cannot login. Other user records do not have a creator. So authenticated users cannot change their user records. dateCreated when the record was created modified a list of modification events, having the date of modification and the user who did it for each event.","title":"Fields"},{"location":"Server/Authentication/#user-presentation","text":"When a user is presented on the interface, we choose between the following representations, in order of highest preference first. name (coming from the DARIAH attribute cn (common name) firstName lastName email eppn-autority We append (org) if available.","title":"User presentation"},{"location":"Server/Authentication/#values","text":"","title":"Values"},{"location":"Server/Authentication/#authority-values","text":"authority comments absent the user has never been authenticated. Used for people that occur in the system, but have not yet logged in. DARIAH the user has been logged in by the DARIAH identity provider legacy the user has been imported from the FileMaker legacy data. This kind of user cannot log in. local the user has logged in on the development system. This kind of user should not be present in the production system!","title":"authority values"},{"location":"Server/Authentication/#group-values","text":"group comments public unidentified users (the public). No right to edit anything. Can only list/read public information. auth authenticated user. Can add items and then modify/delete them, within limits. Can see DARIAH internal information (within limits). This is the default group for logged-in users. office back office users. Can modify records created by others (within limits). Cannot do system-technical things. system system managers. Can modify system-technical records, within limits. root Complete rights. Still there are untouchable things, that would compromise the integrity of the system. Even root cannot modify those. nobody All powerful. You can also destroy the system. Detail: nobody belongs to this group. Assigning users to groups is subject to permissions, defined by the groups themselves, with a few additional rules: nobody can assign anybody to the group nobody ; a person can only assign groups that have at most his/her own power; a person can only assign groups to people that have less power than him/herself. Examples: If you are office , you cannot make yourself or anyone else system or root . If you are office , you cannot assign another member of office the group auth . You cannot demote/promote your peers, or the ones above you. You can demote yourself, but not promote yourself. You can demote people below you. You can promote people below you, but only up to your own level. A consequence is, that if there is no root in the system, nobody can be made root from within the system. When importing data into the system by means of load.sh you can specify to make a specific user root . Which user that is, is specified in config.yaml , see rootUser . Once the root user is in place, (s)he can assign system admins and back office people. Once those are in place, the daily governance of the system can take place.","title":"group values"},{"location":"Server/Authentication/#statuslastlogin-values","text":"statusLastLogin comments Approved successful login attempt Rejected unsuccessful login attempt","title":"statusLastLogin values"},{"location":"Server/Server/","text":"Server \u00b6 Although this app is a single page application with most of the business logic coded at the client side, there are a bunch of things that are handled at the server side. All data access is handled by server side controllers that implement a data api. These controllers are informed by the data model . When the web server starts, the data model files are read, and converted to python modules with the same base name that encapsulate the information in the YAML files. These modules are then imported by all controllers, so that all data access happens in conformance with the data model and its permissions. perm \u00b6 Contains the methods to compute permissions for controllers, tables and fields. Here are the main methods. allow( table, action, msgs, controller=None, document=None, newValues=None, my=None, verbose=True) \u00b6 Given table and an action (such as read , update ), this method computes whether that action may be performed on behalf of the current web user. If a document is specified, the information in that document will be used to determine whether the document is owned by the user, and in that case the permissions tend to be more liberal. Without a document, permissions are calculated as if the user does not own any document in the table. The result has three parts: good : a boolean which tells: yes, allowed, or no: forbidden; rowFilter , which specifies, in case of a yes, to which rows the action may be applied; it has the shape of a MongoDB selection criterion, but it can also be False (no rows) or True (all rows) or None (irrelevant). fieldSet , which specifies, in case of yes, which fields in those rows may be acted upon; it is a Set . If not good, rowFilter and fieldSet will be None . If a document is passed rowFilter will be None , because it is not needed. Only if no document is given, a rowFilter will be computed. If the operation is not permitted on any row, rowFilter becomes False . The reaction to this outcome should be to not perform a database lookup at all. But this is not a permission error, because in this case the list of records for which the operation is allowed is empty. This is different from good is False and rowFilter is None . If the operation is permitted on a selection of rows, rowFilter is returned as a mongodb selection dict is returned. If the operation is permitted on all rows, rowFilter is returned as True . If no fields are permitted, fieldSet is returned as set() . This will still deliver the _id fields, because _id fields are always permitted. If all or part of the fields are permitted, the set of permitted fields is returned. db \u00b6 This is the data access module. It uses the data model to serve any data to any user in such a way that no data is sent from server to client that the current user is not entitled to see. The code in db is generic, it does not contain explicit reference to particular tables and fields. All specifics are derived form the model config file and the table specific files in tables . There are also hooks , where specific behaviour for certain tables can be specified. That behaviour is coded in the workflow module . We describe the main methods here. validate(table, itemValues, updateFields) \u00b6 Server validation of the values of a record. itemValues is a dictionary of all field values of the item, and updateFields is the set of fields to be updated. The result consists of a boolean that states whether all values are valid, a dictionary of diagnostic information if there are validation errors, a list of error messages if the validation process itself failed, and a list of new values created in related tables. getList(controller, table, rowFilter, titleOnly, withValueLists, withFilters, my) \u00b6 A true workhorse, that retrieves the contents of a table, in various circumstances. The controller is the name of the top-level method that called this function. table is the name of the table in question. rowFilter is a selection on the rows of the table. Possibly, the access levels will restrict the set of returned rows further. titleOnly tells whether only the titles or the full data of the records should be fetched. Again: access levels may constrain the set of returned fields further. withValueLists : if true and if there are fields whose values reside in value lists, these value lists will be fetched as well. withFilters : if true, the filter specifications of the table will also be returned. my : if True: only fetches rows that have been created by the current user. If my is a list of fields, these are ourFields . These fields contain user ids, and only records with the current user occurring in one of those fields, will be fetched. Where as my=True is intended to fetch records that are owned or editable by the current user, my=ourFields is intended to fetch records that are relevant to the current user in an other, configurable way. It only works if there is a section ourFields in the data model of table , which lists a number of fields. getItem(controller, table, ident) \u00b6 Fetches a single item. The controller is the name of the top-level method that called this function. table is the name of the table in question. ident is the identifier of the item in question. This function also return for each field whether the current user is entitled to update it. And also whether the current user may delete this record. Finally, the function also indicate whether the user has fetched all allowable fields. This is relevant in a scenario where the user has fetched a list of items (title only) first, and then fetches an individual item. The client application needs to know for each item how much of its field have actually been fetched. modList(controller, table, action) \u00b6 An other workhorse. This function can insert, update and delete a single item. New items are inserted as rows with blank fields. The information to update items is fetched from the request object. The client has sent this material to the server. The controller is the name of the top-level method that called this function. table is the name of the table in question. user \u00b6 Contains the logic needed to maintain the user table. When new users log in through the DARIAH infrastructure, it collects their eppn , i.e. the names by which they are identified by the authentication systems. It also retrieves to what permission groups users belong. auth \u00b6 Contains the methods to authenticate users. Here all the logic about user sessions and session cookies is written down. It builds on the Flask web framework. file \u00b6 Contains the methods to get file data from the server. There is a method to serve static files by calling the web framework Flask. And there is a method to read a file and deliver its content as JSON. utils \u00b6 Low level stuff. workflow \u00b6 Contains workflow specific behaviour, i.e. the specifics of the assessment and review process. getActiveItems(basicList) \u00b6 Calculates the active package, and from there the active types and criteria, given the current time. This is the backdrop for any assessment and review action. The parameter basicList is a function that can retrieve documents from the database, in such a way that the access restrictions are respected. It is defined in db and will be passed from there. So this module does not do its own data access, all data access is still coded in db . detailInsert(basicList, table=None, masterDocument=None) \u00b6 Method invoked by db , just before an item is inserted. This method has the opportunity to generate extra fields for that record, and to generate extra details in other tables, to be inserted. It needs to deliver a dictionary of insertValues (field=value pairs) and a dictionary of detail records, keyed by detail table name. The values are lists of field=value dictionaries. Before db will proceed to insert them, the detail records will get the id of the just inserted main record. This will be used as masterId when the details get inserted.","title":"Server"},{"location":"Server/Server/#server","text":"Although this app is a single page application with most of the business logic coded at the client side, there are a bunch of things that are handled at the server side. All data access is handled by server side controllers that implement a data api. These controllers are informed by the data model . When the web server starts, the data model files are read, and converted to python modules with the same base name that encapsulate the information in the YAML files. These modules are then imported by all controllers, so that all data access happens in conformance with the data model and its permissions.","title":"Server"},{"location":"Server/Server/#perm","text":"Contains the methods to compute permissions for controllers, tables and fields. Here are the main methods.","title":"perm"},{"location":"Server/Server/#allow-table-action-msgs-controllernone-documentnone-newvaluesnone-mynone-verbosetrue","text":"Given table and an action (such as read , update ), this method computes whether that action may be performed on behalf of the current web user. If a document is specified, the information in that document will be used to determine whether the document is owned by the user, and in that case the permissions tend to be more liberal. Without a document, permissions are calculated as if the user does not own any document in the table. The result has three parts: good : a boolean which tells: yes, allowed, or no: forbidden; rowFilter , which specifies, in case of a yes, to which rows the action may be applied; it has the shape of a MongoDB selection criterion, but it can also be False (no rows) or True (all rows) or None (irrelevant). fieldSet , which specifies, in case of yes, which fields in those rows may be acted upon; it is a Set . If not good, rowFilter and fieldSet will be None . If a document is passed rowFilter will be None , because it is not needed. Only if no document is given, a rowFilter will be computed. If the operation is not permitted on any row, rowFilter becomes False . The reaction to this outcome should be to not perform a database lookup at all. But this is not a permission error, because in this case the list of records for which the operation is allowed is empty. This is different from good is False and rowFilter is None . If the operation is permitted on a selection of rows, rowFilter is returned as a mongodb selection dict is returned. If the operation is permitted on all rows, rowFilter is returned as True . If no fields are permitted, fieldSet is returned as set() . This will still deliver the _id fields, because _id fields are always permitted. If all or part of the fields are permitted, the set of permitted fields is returned.","title":"allow( table, action, msgs, controller=None, document=None, newValues=None, my=None, verbose=True)"},{"location":"Server/Server/#db","text":"This is the data access module. It uses the data model to serve any data to any user in such a way that no data is sent from server to client that the current user is not entitled to see. The code in db is generic, it does not contain explicit reference to particular tables and fields. All specifics are derived form the model config file and the table specific files in tables . There are also hooks , where specific behaviour for certain tables can be specified. That behaviour is coded in the workflow module . We describe the main methods here.","title":"db"},{"location":"Server/Server/#validatetable-itemvalues-updatefields","text":"Server validation of the values of a record. itemValues is a dictionary of all field values of the item, and updateFields is the set of fields to be updated. The result consists of a boolean that states whether all values are valid, a dictionary of diagnostic information if there are validation errors, a list of error messages if the validation process itself failed, and a list of new values created in related tables.","title":"validate(table, itemValues, updateFields)"},{"location":"Server/Server/#getlistcontroller-table-rowfilter-titleonly-withvaluelists-withfilters-my","text":"A true workhorse, that retrieves the contents of a table, in various circumstances. The controller is the name of the top-level method that called this function. table is the name of the table in question. rowFilter is a selection on the rows of the table. Possibly, the access levels will restrict the set of returned rows further. titleOnly tells whether only the titles or the full data of the records should be fetched. Again: access levels may constrain the set of returned fields further. withValueLists : if true and if there are fields whose values reside in value lists, these value lists will be fetched as well. withFilters : if true, the filter specifications of the table will also be returned. my : if True: only fetches rows that have been created by the current user. If my is a list of fields, these are ourFields . These fields contain user ids, and only records with the current user occurring in one of those fields, will be fetched. Where as my=True is intended to fetch records that are owned or editable by the current user, my=ourFields is intended to fetch records that are relevant to the current user in an other, configurable way. It only works if there is a section ourFields in the data model of table , which lists a number of fields.","title":"getList(controller, table, rowFilter, titleOnly, withValueLists, withFilters, my)"},{"location":"Server/Server/#getitemcontroller-table-ident","text":"Fetches a single item. The controller is the name of the top-level method that called this function. table is the name of the table in question. ident is the identifier of the item in question. This function also return for each field whether the current user is entitled to update it. And also whether the current user may delete this record. Finally, the function also indicate whether the user has fetched all allowable fields. This is relevant in a scenario where the user has fetched a list of items (title only) first, and then fetches an individual item. The client application needs to know for each item how much of its field have actually been fetched.","title":"getItem(controller, table, ident)"},{"location":"Server/Server/#modlistcontroller-table-action","text":"An other workhorse. This function can insert, update and delete a single item. New items are inserted as rows with blank fields. The information to update items is fetched from the request object. The client has sent this material to the server. The controller is the name of the top-level method that called this function. table is the name of the table in question.","title":"modList(controller, table, action)"},{"location":"Server/Server/#user","text":"Contains the logic needed to maintain the user table. When new users log in through the DARIAH infrastructure, it collects their eppn , i.e. the names by which they are identified by the authentication systems. It also retrieves to what permission groups users belong.","title":"user"},{"location":"Server/Server/#auth","text":"Contains the methods to authenticate users. Here all the logic about user sessions and session cookies is written down. It builds on the Flask web framework.","title":"auth"},{"location":"Server/Server/#file","text":"Contains the methods to get file data from the server. There is a method to serve static files by calling the web framework Flask. And there is a method to read a file and deliver its content as JSON.","title":"file"},{"location":"Server/Server/#utils","text":"Low level stuff.","title":"utils"},{"location":"Server/Server/#workflow","text":"Contains workflow specific behaviour, i.e. the specifics of the assessment and review process.","title":"workflow"},{"location":"Server/Server/#getactiveitemsbasiclist","text":"Calculates the active package, and from there the active types and criteria, given the current time. This is the backdrop for any assessment and review action. The parameter basicList is a function that can retrieve documents from the database, in such a way that the access restrictions are respected. It is defined in db and will be passed from there. So this module does not do its own data access, all data access is still coded in db .","title":"getActiveItems(basicList)"},{"location":"Server/Server/#detailinsertbasiclist-tablenone-masterdocumentnone","text":"Method invoked by db , just before an item is inserted. This method has the opportunity to generate extra fields for that record, and to generate extra details in other tables, to be inserted. It needs to deliver a dictionary of insertValues (field=value pairs) and a dictionary of detail records, keyed by detail table name. The values are lists of field=value dictionaries. Before db will proceed to insert them, the detail records will get the id of the just inserted main record. This will be used as masterId when the details get inserted.","title":"detailInsert(basicList, table=None, masterDocument=None)"},{"location":"Technology/ES6/","text":"ES6 \u00b6 General \u00b6 We use ECMAScript 6, also known as ES6, also known as ES2015, also known as JavaScript for the client side of the app. The code is transpiled through Babel into a version of JavaScript that all major browsers understand. The compilation from source code to what the browser eventually gets is way more complicated. It is taken care of by the build tool of our choice: Webpack Our source code conforms to a number of style guides, which are checked by eslint . There are many options and choices, ours are here . Not all of these are relevant, because we also enforce style by means of prettier . The evolution of JavaScript to ES6 and beyond has transformed JavaScript from a \"horrible language\" into a performant language with a beautiful syntax on one of the most widely supported platforms: the browser. Instead of pushing JavaScript out of sight, we fully embrace it as our principal programming formalism at the client side. Others (see for example Meteor ) go even further and use it on the server as well, but we have not (yet) taken that step. We highlight a few, not all, concepts in ES6 that we make use of. Class notation \u00b6 In our code, we do not do that much with classes and object-oriented programming. Wherever possible, we prefer writing functions that can be used irrespective of classes. In the React/Redux world, function composition is the preferred way of building up complex functionality out of simpler functionality. Still, there are cases where object orientation definitely has advantages. The new syntax for classes is like this: 1 2 3 4 5 6 7 8 9 10 11 class Foo extends Bar { constructor () { super () } method1 ( x , y , z ) { this . prop = x } method2 = ( e , f , g ) => { this . event = e } } This is nice, terse, clean syntax. Note the difference between method1 and method2 . method1 is an ordinary method, and the this in the body points to the caller. So if you want to send method1 around as a callback, you have to manually bind the this : 1 callback = this . method1 . bind ( this ) In several react contexts, it is undesirable to do this binding, because behind the screens it creates a new object. In a react component, it is much more efficient to pass a statically defined callback around. method2 comes to the rescue. It is a class property , and the this is now lexical . So, whoever calls it, this is the this of class Foo . So you can just say: 1 callback = this . method2 Note that this syntax of class properties is in ES7, beyond ES6. Yet we can use it without issue because of Babel . Arrow Functions \u00b6 There is now a very handy notation to write functions: arrow notation. Instead of 1 2 3 function myFunc ( x , y ) { return x + y } you can write: 1 const myFunc = ( x , y ) => x + y If there is only 1 argument, it is even shorter: 1 const myFunc = x => x + 1 If you have functions that return functions, everything goes smoother now: 1 const handleEvent = id => event => dispatch ({ id , value : event . target . value }) There is more to this, notably, for arrow functions the this is lexical. Object Notations \u00b6 shorthand , destructuring , rest spread . Objects are central to JavaScript. ES6 contains new syntax, that makes working with objects very pleasant indeed. In our app we have activated linters that insist on using that syntax to the maximum amount possible. It will dramatically change the general outlook of a piece of JavaScript code. Just to have a taste, look at this bit of source code . An object contains key-value pairs like this: 1 const props = { foo : 1 , bar : { x : 2 , y : 3 } } If we want to extract the foo and y part, we could say: 1 2 const foo = props . foo const y = props . bar . y But there is a more elegant way, using destructuring : 1 const { foo : foo , bar : { y : y } } = props This does in one statement exactly the same as in the previous statement. On top of it, there is another trick: shorthand . If you have a pattern like name: name inside an object, you may also say { name } . And if you are in a scope where name is bound to a value v , you may define an object like this: 1 const props = { name } So we can write our foo bar example even more compactly: 1 const { foo , bar : { y } } = props If props has a lot of keys, and we are interested in doing something with its keys foo and bar , and want to pass the remaining keys on, we can do so using object rest spread , as follows: 1 2 3 const { foo , bar , ... rest } = props doSomething ( foo , bar ) passOn ( rest ) These things also may occurs in function definitions: 1 2 3 4 const process = ({ foo , bar , ... rest }) => { doSomething ( foo , bar ) passOn ( rest ) } If you use object destructuring and the key you destructure is not present in the object, you get undefined. But you can also specify defaults: 1 2 3 4 const process = ({ foo = 3 , bar = { x : 0 , y : 0 }, ... rest }) => { doSomething ( foo , bar ) passOn ( rest ) } Object rest spread is also handy to make a shallow copy of an object with some keys changed. Suppose we have a state object, with many keys, but we only want to update the key called filter and give it value { 35: true } , where 35 is stored in local constant id . This is how you do that: 1 const newState = { ... state , filter : { [ id ] : true } } Suppose that you do not want to replace the filter object with the one given above, but only its key 35, leaving all other keys intact. You can use object spread twice to achieve this: 1 2 3 4 5 6 7 const newState = { ... state , filter : { ... state . filter , [ id ] : 35 , } } This kind of code is often needed in reducers , functions that compute a new state from an old state in such a way that everything that is changed, is copied shallowly to a new object, and every thing that is the same, remains the same object. However, if what has changed is really deeply nested, there are better methods to achieve is, e.g. lodash merge . Promise \u00b6 Promise is an ES6 data structure to contain the result of an asynchronous function. It has as state that is either pending , failed or resolved . Once the state is failed or resolved , it will not change any more. If the state is resolved , the return value is available, and will not change any more. The typical way to use a promise is 1 2 3 4 5 6 7 8 const dataStore = {} const getData = url =&gt; fetch(url) // assuming that fetch returns a Promise, we can then say getData('/api/blob/23'). then( blob =&gt; {dataStore.url = blob}, error =&gt; console.error(error), ) Example : server.js This is virtually the only occurrence in our code where we use Promise syntax. External documentation","title":"ES6"},{"location":"Technology/ES6/#es6","text":"","title":"ES6"},{"location":"Technology/ES6/#general","text":"We use ECMAScript 6, also known as ES6, also known as ES2015, also known as JavaScript for the client side of the app. The code is transpiled through Babel into a version of JavaScript that all major browsers understand. The compilation from source code to what the browser eventually gets is way more complicated. It is taken care of by the build tool of our choice: Webpack Our source code conforms to a number of style guides, which are checked by eslint . There are many options and choices, ours are here . Not all of these are relevant, because we also enforce style by means of prettier . The evolution of JavaScript to ES6 and beyond has transformed JavaScript from a \"horrible language\" into a performant language with a beautiful syntax on one of the most widely supported platforms: the browser. Instead of pushing JavaScript out of sight, we fully embrace it as our principal programming formalism at the client side. Others (see for example Meteor ) go even further and use it on the server as well, but we have not (yet) taken that step. We highlight a few, not all, concepts in ES6 that we make use of.","title":"General"},{"location":"Technology/ES6/#class-notation","text":"In our code, we do not do that much with classes and object-oriented programming. Wherever possible, we prefer writing functions that can be used irrespective of classes. In the React/Redux world, function composition is the preferred way of building up complex functionality out of simpler functionality. Still, there are cases where object orientation definitely has advantages. The new syntax for classes is like this: 1 2 3 4 5 6 7 8 9 10 11 class Foo extends Bar { constructor () { super () } method1 ( x , y , z ) { this . prop = x } method2 = ( e , f , g ) => { this . event = e } } This is nice, terse, clean syntax. Note the difference between method1 and method2 . method1 is an ordinary method, and the this in the body points to the caller. So if you want to send method1 around as a callback, you have to manually bind the this : 1 callback = this . method1 . bind ( this ) In several react contexts, it is undesirable to do this binding, because behind the screens it creates a new object. In a react component, it is much more efficient to pass a statically defined callback around. method2 comes to the rescue. It is a class property , and the this is now lexical . So, whoever calls it, this is the this of class Foo . So you can just say: 1 callback = this . method2 Note that this syntax of class properties is in ES7, beyond ES6. Yet we can use it without issue because of Babel .","title":"Class notation"},{"location":"Technology/ES6/#arrow-functions","text":"There is now a very handy notation to write functions: arrow notation. Instead of 1 2 3 function myFunc ( x , y ) { return x + y } you can write: 1 const myFunc = ( x , y ) => x + y If there is only 1 argument, it is even shorter: 1 const myFunc = x => x + 1 If you have functions that return functions, everything goes smoother now: 1 const handleEvent = id => event => dispatch ({ id , value : event . target . value }) There is more to this, notably, for arrow functions the this is lexical.","title":"Arrow Functions"},{"location":"Technology/ES6/#object-notations","text":"shorthand , destructuring , rest spread . Objects are central to JavaScript. ES6 contains new syntax, that makes working with objects very pleasant indeed. In our app we have activated linters that insist on using that syntax to the maximum amount possible. It will dramatically change the general outlook of a piece of JavaScript code. Just to have a taste, look at this bit of source code . An object contains key-value pairs like this: 1 const props = { foo : 1 , bar : { x : 2 , y : 3 } } If we want to extract the foo and y part, we could say: 1 2 const foo = props . foo const y = props . bar . y But there is a more elegant way, using destructuring : 1 const { foo : foo , bar : { y : y } } = props This does in one statement exactly the same as in the previous statement. On top of it, there is another trick: shorthand . If you have a pattern like name: name inside an object, you may also say { name } . And if you are in a scope where name is bound to a value v , you may define an object like this: 1 const props = { name } So we can write our foo bar example even more compactly: 1 const { foo , bar : { y } } = props If props has a lot of keys, and we are interested in doing something with its keys foo and bar , and want to pass the remaining keys on, we can do so using object rest spread , as follows: 1 2 3 const { foo , bar , ... rest } = props doSomething ( foo , bar ) passOn ( rest ) These things also may occurs in function definitions: 1 2 3 4 const process = ({ foo , bar , ... rest }) => { doSomething ( foo , bar ) passOn ( rest ) } If you use object destructuring and the key you destructure is not present in the object, you get undefined. But you can also specify defaults: 1 2 3 4 const process = ({ foo = 3 , bar = { x : 0 , y : 0 }, ... rest }) => { doSomething ( foo , bar ) passOn ( rest ) } Object rest spread is also handy to make a shallow copy of an object with some keys changed. Suppose we have a state object, with many keys, but we only want to update the key called filter and give it value { 35: true } , where 35 is stored in local constant id . This is how you do that: 1 const newState = { ... state , filter : { [ id ] : true } } Suppose that you do not want to replace the filter object with the one given above, but only its key 35, leaving all other keys intact. You can use object spread twice to achieve this: 1 2 3 4 5 6 7 const newState = { ... state , filter : { ... state . filter , [ id ] : 35 , } } This kind of code is often needed in reducers , functions that compute a new state from an old state in such a way that everything that is changed, is copied shallowly to a new object, and every thing that is the same, remains the same object. However, if what has changed is really deeply nested, there are better methods to achieve is, e.g. lodash merge .","title":"Object Notations"},{"location":"Technology/ES6/#promise","text":"Promise is an ES6 data structure to contain the result of an asynchronous function. It has as state that is either pending , failed or resolved . Once the state is failed or resolved , it will not change any more. If the state is resolved , the return value is available, and will not change any more. The typical way to use a promise is 1 2 3 4 5 6 7 8 const dataStore = {} const getData = url =&gt; fetch(url) // assuming that fetch returns a Promise, we can then say getData('/api/blob/23'). then( blob =&gt; {dataStore.url = blob}, error =&gt; console.error(error), ) Example : server.js This is virtually the only occurrence in our code where we use Promise syntax. External documentation","title":"Promise"},{"location":"Technology/React/","text":"React \u00b6 React Components \u00b6 React Components represent pieces of the web page and their functionality. Components are organized hierarchically. Components can be parametrized by properties , which parents pass to children. A component acts as a template instruction to build a piece of DOM. Components can be programmed as classes or as functions. In this app we distinguish between three capability levels of components. Pure components \u00b6 If a component knows how to build the DOM, purely on the basis of its properties and a static template, it can be (and will be) coded as a pure function. Example: Stat . Simple Stateful components \u00b6 If a component needs to store the effects of the outside world (incoming server data or user interaction), it is stateful. If the component does not need life cycle methods, it can be programmed as a pure function that will be connected to the Redux state by means of a simple binding: connect . Example: Facet . Complex components \u00b6 If a component has to handle the DOM after it has been constructed, e.g. apply some hiding and showing, fill a DIV with a third party component, or get data from the state in a sophisticated way, then we need to program the component as a class with so-called life cycle methods . Example: ListContainer . React Processing Concepts \u00b6 React renders updates to components very efficiently. The render() function is a template for a element fragment , not the real DOM . So, after an update, it is not costly to recompute the fragment for that component completely, because the DOM is not touched. Reconciliation \u00b6 Once the new fragment has been constructed, a clever, React-internal process called reconciliation is carried out, which computes the minimum number of update actions that have to be applied to the previous, real DOM incarnation of the component, to change it to match the new fragment. MiniDOM \u00b6 A compact internal representation of the DOM , made from React elements . A React element is an instance of the React Element class. In jsx you can refer to a React element just by saying 1 &lt;p&gt;foo&lt;/p&gt; React elements reflect HTML elements, but you can mingle them with React components, which look nearly the same in jsx : 1 2 3 &lt;p&gt; &lt;NavLink to=\"/data\" &gt;bar&lt;/NavLink&gt; &lt;/p&gt; DOM \u00b6 DOM is an abbreviation for Document Object Model . The DOM is what the browser gets in memory once it has loaded an HTML document. One of the principal tasks of JavaScript in the browser is to manipulate this DOM. The DOM and its API are exceedingly bloated, hence DOM operations are slow, no matter how fast JavaScript currently is. This is one of the reasons that a niche for React exists, with its MiniDOM . Fragment \u00b6 A fragment is such a mixture of properly nested React elements and components. It is part of the React's toolkit to manage DOM manipulations efficiently. See Reconciliation . Property management \u00b6 PropTypes \u00b6 PropTypes are a means to do type checking for React Components is done by PropTypes . PropType checking in react only happens in development mode. React checks whether the named props that are passed to a component correspond to the props declared. In addition, it performs a basic type check on the values inside those props. I find the PropType verbose, and no match for the otherwise clean and pleasant syntax of JSX. Additionally, most of the mistakes I make, do not reveal themselves as value type mistakes. On top it this all: declaring PropTypes forces you to repeat all the names of your PropTypes, so is against the principle of do't repeat yourself . In this application, the property names are always clear in the code, either as 1 const MyComponent = ({ foo, bar )} =&gt; ... or as 1 const { props: { foo, bar} } = this Context \u00b6 Context is a React mechanism to pass data directly from ancestors to deep descendants. The React documentation considers context as a brittle part of itself, and warns against over-use. At the same time, Redux depends critically on it, so I consider it safe to use. But our code will not use it explicitly, only through Redux. Component management \u00b6 Life Cycle \u00b6 The main function of a component is to act as a template to be rendered . But if there is additional work to be done, this can be hooked up at various stages in the component's [life cycle]( https://facebook.github.io/react/docs/react-component.html#the-component-life cycle). Most stages occur during (re)rendering, and there is a stage of construction and unmounting. Constructor \u00b6 When a component is being rendered the constructor is the method to construct the corresponding React class. It will set up the state . componentDidMount \u00b6 When a component has been added to the DOM its method componentDidMount will be called just after. This is the recommended time to fetch data for this component, if needed. componentDidUpdate \u00b6 When a component has been updated due to receiving new properties, its method componentDidUpdate will be called just after. If DOM manipulations are needed to complete the rendering, this is the place to do it. NB: This will not called upon initial rendering, so if the DOM manipulation is also needed initially, it is handy to write a function for it and call it in this method and in componentDidMount() . componentWillMount \u00b6 When a component will be added to the DOM, its method componentWillMount will be called just before. This is the first thing that happens after constructor() . componentWillReceiveProps \u00b6 When a component is about to receive new props (as part of the update process), its method componentWillReceiveProps will be called just before. The new props are passed with it, so that it is possible to execute actions dependent on whether pros have changed. componentWillUnMount \u00b6 When a component will be removed from the DOM, its method componentWillUnmount will be called just before. If we want to save state, we can hook it up here. render \u00b6 The main function of a component is to act as a template to be rendered. Its method render constructs the template to be rendered. During rendering the template will be used as a set of instructions to build a real DOM somewhere on the actual web page. Controlled Component \u00b6 For elements that can receive user input (forms, inputs, etc.) there is the option to handle input in a way controlled by React, and not by the default HTML behaviour. We say that those elements are used as controlled Components . So when a user clicks a checkbox, the check is not managed by the browser, but a callback is called, a parent component executes it, state gets updated, state changes trickle down as property updates to child elements, and the checkbox in question is told to be checked (or unchecked). State \u00b6 There are two main reasons for a component to maintain [state]( https://facebook.github.io/react/docs/state-and-life cycle.html): getting external data, reacting to user events. In both cases, something happens in the outside world that must be remembered. Components remember these things in their state , which only they can update. They can compute derived data from their state and pass that as properties to their children. State updates trigger these computations automatically, and children whose properties are dependent on this state, are re-rendered automatically (and economically). Local State \u00b6 The vanilla React way is that components have their own state, which only they can modify through setState . But even in React, state is not completely local, because in many cases several components need to have access to the state. The preferred way of dealing with that is to lift state up to the nearest common ancestor of all components that need the state. Descendants that must modify ancestral state are passed a callback to do so. Local state is very intuitive and leads to nice separation of concerns, but alas. There comes a moment that components want to be informed of each other's state. Especially when components start modifying data from the server and saving it, other components that rely on the same data, want to be notified. Setting up ad-hoc communication between such components leads to an asynchronous dependency hell, which can be avoided by a central state as a single source of truth. So in this app, we have left the path of local state, and embraced central state . Central State \u00b6 A widely used approach to central state is Redux . Redux \u00b6 Redux is a popular implementation of the idea that state is centralized and all components have to subscribe to a state Provider , the store. If a component needs to update the state, it dispatches an action to the store. So-called reducers translate the action into a state update. And then the component can re-render. Using Redux requires a lot of extra code in actions and reducers, which get separated from the components for which it is used. However, there is a way to do it nicely. There is a way of writing idiomatic redux, beautifully advocated by its creator, Dan Abramov, in 30 videos , and that is by means of ducks . (we call them dux ). We divide the state into segments that are responsible for well-described tasks, such as tables of data from the server notification faceted browsing alternative presentations to the user window resizing For every such task, we make a duct and put it into the dux directory. Every duct manages a slice of the state has four sections: Actions: functions that create the actions whose dispatch will trigger a state update Reducer: a single function that translates all relevant actions into updates of its slice of the state Selectors: functions that grab data from the state in order to offer it to connected components Helpers: functions that contain additional logic, especially for selectors. See for an example filters . Merge \u00b6 When a reducer transforms a state, it must happen in such a way that unaffected parts of the state do not change, all intermediate objects between the top-level state and a changed leaf are fresh objects. The handiest way to achieve this is to use lodash merge and lodash mergeWith . Most reducers use it. The hint to use Lodash functions for this is given here . These functions take an object, and transform it on the bases of an other object, precisely as needed for our purposes. And if a little tweak is needed for certain keys of the state, mergeWith() provides a hook for that. See notes.js , the function addItem() . There, if the old state has an array of items, and we need to append some items, we create a new array, consisting of the items of the original array, with the new items concatenated after them. Select \u00b6 The opposite of merging data into the state is selecting data from the state. Our components need bits and pieces of the state in order to know what they should render. To this end, we write selector functions, that return suitable slices of the state. In some cases, selecting the data requires quite a bit of computation, especially when the data in the state is normalized and the component needs denormalized data. Or, in the case of faceted browsing, the items to show must be computed from the list of items in the table slice of the state, combined with the current filter settings from the filter slice of the state. Here we encounter a potential performance problem. Sometimes components will be re-rendered even if their piece of the state as not changed. Or, if it has changed, it is often the case that the derived data that the component needs, has not changed. In general, if we do nothing about it, the computations in selectors will be executed more often than necessary. The method to deal with this is memoization. The redux documentation suggests the reselect library here . Reselect facilitates the fabrication of selectors that remember their last output in combination with the parameters passed to it. If such a selector is called repeatedly with the same arguments, it will fetch the computed result from its cache after from the second time it is called onwards. We use this library in the dux filters and tables However, we will also encounter cases where we need more complete memoization, so that functions have a cache for their results given multiple sets of parameters. See memo . Connect \u00b6 Redux and the dux streamline very much how components deal with the centralized store. The central function is Redux connect . If a component X needs state, we can create a connected component Xc from X. Connected means: connected to the state. 1 Xc = connect(selectors, dispatchers)(X) The new component Xc has extra props: data properties provided by the selector function selectors , which is a function that reads the global state and returns information of it as a props object. callback properties, provided by the function dispatchers . This returns a props object of action creator functions. Xc can use these where a callback is needed. When such a function is called, the action will be created and dispatched, which in turn will lead to a state change. See also Architecture . Routing \u00b6 React-router is a convenient library to manage the connection between the URL and the part of your app that should be active in response to it. 1 2 3 4 5 6 &lt;Router history={browserHistory} &gt; &lt;Route path=\"/\" component={App} &gt; &lt;Route path=\"about\" component={About} /&gt; &lt;Route path=\"table\" component={ListPlain} /&gt; &lt;/Route&gt; &lt;/Router&gt; The router and its routes are basically React components . But they come loaded with some extra behaviour. Basically, when a route is rendered, it checks its path attribute with the current URL. If it matches, it renders itself. Otherwise, it does not mount, or if it was mounted, it will unmount. Several tricks are employed to make this a really useful library. See the API docs . However, precisely because of this repeated mounting and unmounting caused by routing events, the need arises for components to save their states. Especially the ones with a costly state. Here is another reason why local state becomes cumbersome. With Redux, this is not a problem, because state is severed from components.","title":"React"},{"location":"Technology/React/#react","text":"","title":"React"},{"location":"Technology/React/#react-components","text":"React Components represent pieces of the web page and their functionality. Components are organized hierarchically. Components can be parametrized by properties , which parents pass to children. A component acts as a template instruction to build a piece of DOM. Components can be programmed as classes or as functions. In this app we distinguish between three capability levels of components.","title":"React Components"},{"location":"Technology/React/#pure-components","text":"If a component knows how to build the DOM, purely on the basis of its properties and a static template, it can be (and will be) coded as a pure function. Example: Stat .","title":"Pure components"},{"location":"Technology/React/#simple-stateful-components","text":"If a component needs to store the effects of the outside world (incoming server data or user interaction), it is stateful. If the component does not need life cycle methods, it can be programmed as a pure function that will be connected to the Redux state by means of a simple binding: connect . Example: Facet .","title":"Simple Stateful components"},{"location":"Technology/React/#complex-components","text":"If a component has to handle the DOM after it has been constructed, e.g. apply some hiding and showing, fill a DIV with a third party component, or get data from the state in a sophisticated way, then we need to program the component as a class with so-called life cycle methods . Example: ListContainer .","title":"Complex components"},{"location":"Technology/React/#react-processing-concepts","text":"React renders updates to components very efficiently. The render() function is a template for a element fragment , not the real DOM . So, after an update, it is not costly to recompute the fragment for that component completely, because the DOM is not touched.","title":"React Processing Concepts"},{"location":"Technology/React/#reconciliation","text":"Once the new fragment has been constructed, a clever, React-internal process called reconciliation is carried out, which computes the minimum number of update actions that have to be applied to the previous, real DOM incarnation of the component, to change it to match the new fragment.","title":"Reconciliation"},{"location":"Technology/React/#minidom","text":"A compact internal representation of the DOM , made from React elements . A React element is an instance of the React Element class. In jsx you can refer to a React element just by saying 1 &lt;p&gt;foo&lt;/p&gt; React elements reflect HTML elements, but you can mingle them with React components, which look nearly the same in jsx : 1 2 3 &lt;p&gt; &lt;NavLink to=\"/data\" &gt;bar&lt;/NavLink&gt; &lt;/p&gt;","title":"MiniDOM"},{"location":"Technology/React/#dom","text":"DOM is an abbreviation for Document Object Model . The DOM is what the browser gets in memory once it has loaded an HTML document. One of the principal tasks of JavaScript in the browser is to manipulate this DOM. The DOM and its API are exceedingly bloated, hence DOM operations are slow, no matter how fast JavaScript currently is. This is one of the reasons that a niche for React exists, with its MiniDOM .","title":"DOM"},{"location":"Technology/React/#fragment","text":"A fragment is such a mixture of properly nested React elements and components. It is part of the React's toolkit to manage DOM manipulations efficiently. See Reconciliation .","title":"Fragment"},{"location":"Technology/React/#property-management","text":"","title":"Property management"},{"location":"Technology/React/#proptypes","text":"PropTypes are a means to do type checking for React Components is done by PropTypes . PropType checking in react only happens in development mode. React checks whether the named props that are passed to a component correspond to the props declared. In addition, it performs a basic type check on the values inside those props. I find the PropType verbose, and no match for the otherwise clean and pleasant syntax of JSX. Additionally, most of the mistakes I make, do not reveal themselves as value type mistakes. On top it this all: declaring PropTypes forces you to repeat all the names of your PropTypes, so is against the principle of do't repeat yourself . In this application, the property names are always clear in the code, either as 1 const MyComponent = ({ foo, bar )} =&gt; ... or as 1 const { props: { foo, bar} } = this","title":"PropTypes"},{"location":"Technology/React/#context","text":"Context is a React mechanism to pass data directly from ancestors to deep descendants. The React documentation considers context as a brittle part of itself, and warns against over-use. At the same time, Redux depends critically on it, so I consider it safe to use. But our code will not use it explicitly, only through Redux.","title":"Context"},{"location":"Technology/React/#component-management","text":"","title":"Component management"},{"location":"Technology/React/#life-cycle","text":"The main function of a component is to act as a template to be rendered . But if there is additional work to be done, this can be hooked up at various stages in the component's [life cycle]( https://facebook.github.io/react/docs/react-component.html#the-component-life cycle). Most stages occur during (re)rendering, and there is a stage of construction and unmounting.","title":"Life Cycle"},{"location":"Technology/React/#constructor","text":"When a component is being rendered the constructor is the method to construct the corresponding React class. It will set up the state .","title":"Constructor"},{"location":"Technology/React/#componentdidmount","text":"When a component has been added to the DOM its method componentDidMount will be called just after. This is the recommended time to fetch data for this component, if needed.","title":"componentDidMount"},{"location":"Technology/React/#componentdidupdate","text":"When a component has been updated due to receiving new properties, its method componentDidUpdate will be called just after. If DOM manipulations are needed to complete the rendering, this is the place to do it. NB: This will not called upon initial rendering, so if the DOM manipulation is also needed initially, it is handy to write a function for it and call it in this method and in componentDidMount() .","title":"componentDidUpdate"},{"location":"Technology/React/#componentwillmount","text":"When a component will be added to the DOM, its method componentWillMount will be called just before. This is the first thing that happens after constructor() .","title":"componentWillMount"},{"location":"Technology/React/#componentwillreceiveprops","text":"When a component is about to receive new props (as part of the update process), its method componentWillReceiveProps will be called just before. The new props are passed with it, so that it is possible to execute actions dependent on whether pros have changed.","title":"componentWillReceiveProps"},{"location":"Technology/React/#componentwillunmount","text":"When a component will be removed from the DOM, its method componentWillUnmount will be called just before. If we want to save state, we can hook it up here.","title":"componentWillUnMount"},{"location":"Technology/React/#render","text":"The main function of a component is to act as a template to be rendered. Its method render constructs the template to be rendered. During rendering the template will be used as a set of instructions to build a real DOM somewhere on the actual web page.","title":"render"},{"location":"Technology/React/#controlled-component","text":"For elements that can receive user input (forms, inputs, etc.) there is the option to handle input in a way controlled by React, and not by the default HTML behaviour. We say that those elements are used as controlled Components . So when a user clicks a checkbox, the check is not managed by the browser, but a callback is called, a parent component executes it, state gets updated, state changes trickle down as property updates to child elements, and the checkbox in question is told to be checked (or unchecked).","title":"Controlled Component"},{"location":"Technology/React/#state","text":"There are two main reasons for a component to maintain [state]( https://facebook.github.io/react/docs/state-and-life cycle.html): getting external data, reacting to user events. In both cases, something happens in the outside world that must be remembered. Components remember these things in their state , which only they can update. They can compute derived data from their state and pass that as properties to their children. State updates trigger these computations automatically, and children whose properties are dependent on this state, are re-rendered automatically (and economically).","title":"State"},{"location":"Technology/React/#local-state","text":"The vanilla React way is that components have their own state, which only they can modify through setState . But even in React, state is not completely local, because in many cases several components need to have access to the state. The preferred way of dealing with that is to lift state up to the nearest common ancestor of all components that need the state. Descendants that must modify ancestral state are passed a callback to do so. Local state is very intuitive and leads to nice separation of concerns, but alas. There comes a moment that components want to be informed of each other's state. Especially when components start modifying data from the server and saving it, other components that rely on the same data, want to be notified. Setting up ad-hoc communication between such components leads to an asynchronous dependency hell, which can be avoided by a central state as a single source of truth. So in this app, we have left the path of local state, and embraced central state .","title":"Local State"},{"location":"Technology/React/#central-state","text":"A widely used approach to central state is Redux .","title":"Central State"},{"location":"Technology/React/#redux","text":"Redux is a popular implementation of the idea that state is centralized and all components have to subscribe to a state Provider , the store. If a component needs to update the state, it dispatches an action to the store. So-called reducers translate the action into a state update. And then the component can re-render. Using Redux requires a lot of extra code in actions and reducers, which get separated from the components for which it is used. However, there is a way to do it nicely. There is a way of writing idiomatic redux, beautifully advocated by its creator, Dan Abramov, in 30 videos , and that is by means of ducks . (we call them dux ). We divide the state into segments that are responsible for well-described tasks, such as tables of data from the server notification faceted browsing alternative presentations to the user window resizing For every such task, we make a duct and put it into the dux directory. Every duct manages a slice of the state has four sections: Actions: functions that create the actions whose dispatch will trigger a state update Reducer: a single function that translates all relevant actions into updates of its slice of the state Selectors: functions that grab data from the state in order to offer it to connected components Helpers: functions that contain additional logic, especially for selectors. See for an example filters .","title":"Redux"},{"location":"Technology/React/#merge","text":"When a reducer transforms a state, it must happen in such a way that unaffected parts of the state do not change, all intermediate objects between the top-level state and a changed leaf are fresh objects. The handiest way to achieve this is to use lodash merge and lodash mergeWith . Most reducers use it. The hint to use Lodash functions for this is given here . These functions take an object, and transform it on the bases of an other object, precisely as needed for our purposes. And if a little tweak is needed for certain keys of the state, mergeWith() provides a hook for that. See notes.js , the function addItem() . There, if the old state has an array of items, and we need to append some items, we create a new array, consisting of the items of the original array, with the new items concatenated after them.","title":"Merge"},{"location":"Technology/React/#select","text":"The opposite of merging data into the state is selecting data from the state. Our components need bits and pieces of the state in order to know what they should render. To this end, we write selector functions, that return suitable slices of the state. In some cases, selecting the data requires quite a bit of computation, especially when the data in the state is normalized and the component needs denormalized data. Or, in the case of faceted browsing, the items to show must be computed from the list of items in the table slice of the state, combined with the current filter settings from the filter slice of the state. Here we encounter a potential performance problem. Sometimes components will be re-rendered even if their piece of the state as not changed. Or, if it has changed, it is often the case that the derived data that the component needs, has not changed. In general, if we do nothing about it, the computations in selectors will be executed more often than necessary. The method to deal with this is memoization. The redux documentation suggests the reselect library here . Reselect facilitates the fabrication of selectors that remember their last output in combination with the parameters passed to it. If such a selector is called repeatedly with the same arguments, it will fetch the computed result from its cache after from the second time it is called onwards. We use this library in the dux filters and tables However, we will also encounter cases where we need more complete memoization, so that functions have a cache for their results given multiple sets of parameters. See memo .","title":"Select"},{"location":"Technology/React/#connect","text":"Redux and the dux streamline very much how components deal with the centralized store. The central function is Redux connect . If a component X needs state, we can create a connected component Xc from X. Connected means: connected to the state. 1 Xc = connect(selectors, dispatchers)(X) The new component Xc has extra props: data properties provided by the selector function selectors , which is a function that reads the global state and returns information of it as a props object. callback properties, provided by the function dispatchers . This returns a props object of action creator functions. Xc can use these where a callback is needed. When such a function is called, the action will be created and dispatched, which in turn will lead to a state change. See also Architecture .","title":"Connect"},{"location":"Technology/React/#routing","text":"React-router is a convenient library to manage the connection between the URL and the part of your app that should be active in response to it. 1 2 3 4 5 6 &lt;Router history={browserHistory} &gt; &lt;Route path=\"/\" component={App} &gt; &lt;Route path=\"about\" component={About} /&gt; &lt;Route path=\"table\" component={ListPlain} /&gt; &lt;/Route&gt; &lt;/Router&gt; The router and its routes are basically React components . But they come loaded with some extra behaviour. Basically, when a route is rendered, it checks its path attribute with the current URL. If it matches, it renders itself. Otherwise, it does not mount, or if it was mounted, it will unmount. Several tricks are employed to make this a really useful library. See the API docs . However, precisely because of this repeated mounting and unmounting caused by routing events, the need arises for components to save their states. Especially the ones with a costly state. Here is another reason why local state becomes cumbersome. With Redux, this is not a problem, because state is severed from components.","title":"Routing"},{"location":"Technology/Tech/","text":"Technical references \u00b6 This is an alphabetical list of tech references. Sometimes we refer to a technology without making use of it in the app, we have marked those entries with an \u2717. References \u00b6 bash shell scripting cloc counting lines of code css cascading stylesheets: web design flexbox laying out boxes in flexible ways \u2717 grid laying out boxes in a grid hsl color space \u2717 sass css preprocessor geojson geographical data in json format html markup language for the web \u2717 IDE Integrated Developer's Environment \u2717 Atom IDE by GitHub \u2717 SublimeText commercial text editor vim old-hands text editor, still competes with IDEs ALE runs linters and formatters within vim \u2717 Visual Studio Code IDE by Microsoft \u2717 Webstorm commercial IDE iso8601 date and time format javascript scripting language for the web babel compiles ES6 (modern Javascript) to older Javascript (understood by browsers) es7cp static methods for classes eslint checks ES6 code against style requirements lodash handy functions for dealing with collections mocha test framework \u2717 mern mongo-express-react-node stack for web development \u2717 meteor full-stack javascript web framework node run javascript outside browsers npm package manager for javascript prettier code formatter for javascript webpack build tool for javascript leaflet geo-mapping library markdown rich text from plain text remark linter and formatter for markdown mongodb NO-SQL database, JSON/Javascript based python data-oriented scripting language flake8 code linter for Python flask micro web framework wsgi bridge between the python language and webservers yapf code formatter for Python react web framework for rendering in the browser immutability immutable data structures autovivification creating sub-objects when needed \u2717 select select boxes in React reselect selecting data from the state router routing in React tutorial redux global state management in React and other frameworks ducks source code organization for redux apps videos redux-form user entry forms, processable in redux react-redux bindings for redux in react \u2717 shebanq web interface for Hebrew text and linguistic annotations \u2717 socket push messages from server to all connected clients \u2717 python-socket python wrapper for socket.io spa single page application: webApi interacting with the loaded document in a browser yaml configuration language, as simple as markdown.","title":"Tech"},{"location":"Technology/Tech/#technical-references","text":"This is an alphabetical list of tech references. Sometimes we refer to a technology without making use of it in the app, we have marked those entries with an \u2717.","title":"Technical references"},{"location":"Technology/Tech/#references","text":"bash shell scripting cloc counting lines of code css cascading stylesheets: web design flexbox laying out boxes in flexible ways \u2717 grid laying out boxes in a grid hsl color space \u2717 sass css preprocessor geojson geographical data in json format html markup language for the web \u2717 IDE Integrated Developer's Environment \u2717 Atom IDE by GitHub \u2717 SublimeText commercial text editor vim old-hands text editor, still competes with IDEs ALE runs linters and formatters within vim \u2717 Visual Studio Code IDE by Microsoft \u2717 Webstorm commercial IDE iso8601 date and time format javascript scripting language for the web babel compiles ES6 (modern Javascript) to older Javascript (understood by browsers) es7cp static methods for classes eslint checks ES6 code against style requirements lodash handy functions for dealing with collections mocha test framework \u2717 mern mongo-express-react-node stack for web development \u2717 meteor full-stack javascript web framework node run javascript outside browsers npm package manager for javascript prettier code formatter for javascript webpack build tool for javascript leaflet geo-mapping library markdown rich text from plain text remark linter and formatter for markdown mongodb NO-SQL database, JSON/Javascript based python data-oriented scripting language flake8 code linter for Python flask micro web framework wsgi bridge between the python language and webservers yapf code formatter for Python react web framework for rendering in the browser immutability immutable data structures autovivification creating sub-objects when needed \u2717 select select boxes in React reselect selecting data from the state router routing in React tutorial redux global state management in React and other frameworks ducks source code organization for redux apps videos redux-form user entry forms, processable in redux react-redux bindings for redux in react \u2717 shebanq web interface for Hebrew text and linguistic annotations \u2717 socket push messages from server to all connected clients \u2717 python-socket python wrapper for socket.io spa single page application: webApi interacting with the loaded document in a browser yaml configuration language, as simple as markdown.","title":"References"}]}